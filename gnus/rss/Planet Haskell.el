;; -*- coding: utf-8-emacs; -*-
(setq nnrss-group-data '((423 (21012 38625 163637) "http://apfelmus.nfshost.com/blog/2013/08/21-space-invariants.html" "apfelmus: Reasoning about space leaks with space invariants" nil "Wed, 21 Aug 2013 09:25:37 +0000" "<p>Recently, the <a href=\"http://hackage.haskell.org/package/unordered-containers-0.2.3.0\">unordered-containers</a> library has included some <a href=\"http://neilmitchell.blogspot.ru/2013/08/destroying-performance-with-strictness.html\">changes that made a function much more strict</a> than is sensible in a lazy language like Haskell. The changes were <a href=\"http://www.reddit.com/r/haskell/comments/1ker84/destroying_performance_with_strictness/cboh54q\">meant to improve consistency</a> on a performance-related issue, namely whether the container should be “key-strict” or “value-strict” or some combination thereof. However, I think that the recent blooper is a sign that there is a lot of confusion around these notions. In this post, I want to clear up the issue and explain a general principle for reasoning about space usage in Haskell, namely the concept of <em>space invariants</em> as I would like to call them. One consequence of this concept will be that the word “strict” in the term “value-strict” is actually a bad idea because knowing whether a function is <em>strict</em> is not enough to reason about its <em>space</em> usage. (Hence my use of quotation marks.)</p>
<p>Another reason for writing this post is that some time ago, several people pointed out to me that my library <a href=\"http://apfelmus.nfshost.com/haskell.org/haskellwiki/Reactive-banana\">reactive-banana</a> had a couple of <a href=\"https://github.com/HeinrichApfelmus/reactive-banana/issues/52\">unpleasant space leaks</a>. I finally found the time to investigate and fix them, but I had a hard time to prove to myself that I had actually fixed the space leak for good, until space invariants gave a me an excellent way to reason about it.</p>
<p>Most importantly, <em>space invaders</em> make a great pun on space invariants.</p>
<p>Anyway, space invariants are about expressing the <a href=\"http://blog.ezyang.com/2011/05/an-insufficiently-lazy-map/\">folklore advice</a> of <a href=\"http://neilmitchell.blogspot.de/2013/02/chasing-space-leak-in-shake.html\">adding strictness annotations</a> to <a href=\"http://johantibell.com/files/haskell-performance-patterns.html#%285%29\">your data types</a> as an actual property of the data structure that can be reasoned about. The essence of space invariants is</p>
<blockquote>
<p>to ensure that whenever we evaluate a value to weak head normal form (WHNF), we automatically know a bound on its memory usage.</p>
</blockquote>
<p>The idea of attaching invariants to WHNFs has proven very successful (see <a href=\"http://www.cs.cmu.edu/~rwh/theses/okasaki.pdf\">Chris Okasaki’s book [pdf]</a>) for reasoning about the <em>time complexity</em> of lazy functional programs; this is known as the <a href=\"http://apfelmus.nfshost.com/articles/debit-method.html\">debit method</a>. Hopefully, this will help us with space usage as well.</p>
<p>In the next section, I will give a short overview aimed at more experienced Haskellers. Then we’ll have a section aimed at Haskell beginners and a section concerning the relation to strictness. Finally, I’ll present a short case study describing how I fixed a space leak in my reactive-banana library.</p>
<h2 id=\"short-overview-on-space-invariants\">Short overview on space invariants</h2>
<p>Consider a container like <code>Data.Map</code>. Here is an example container:</p>
<pre><code>container = insert \"key1\" 'a'
. delete \"key2\" . insert \"key2\" 'b' $ empty</code></pre>
<p>As written, this expression is a rather inefficient representation of the container which contains a single value <code>'a'</code> at the key <code>\"key1\"</code>. After all, the expression still contains a reference to another value <code>'b'</code>, which will take up space in memory. It is only when this expression is evaluated that the container will contain a single value. Or will it?</p>
<blockquote>
<p>spine-strict = if the container is in WHNF, then the space used by the container is the total of the space used by the values that are contained in the container (times a constant)</p>
</blockquote>
<p>Apparently, when evaluating this expression, only a <a href=\"http://blog.ezyang.com/2011/08/changes-to-intmap/\">s<em>pine-strict container</em></a> will give you the seemingly obvious guarantee that it stores references only to those values that it actually contains. You see, the value of the <code>container</code> is <em>denotationally</em> equivalent to</p>
<pre><code>container2 = fromList [(\"key1\",'a')]</code></pre>
<p>but these two expressions are represented very differently <em>operationally</em> in the computer memory. To be able to reason about the space usage, it is convenient to link the denotational side to the operational side via an <em>invariant</em>. The great thing about denotation is that it is independent of how the expression is represented. Using an invariant like spine-strictess, you can now say “Oh, I know which elements are in the container, so I can conclude how much space it takes up.”, regardless of how you constructed the container in the course of the program. For languages based on lazy evaluation, such a link is usually not available.</p>
<p>It is not necessarily a bad thing that denotation and space usage can be separate from each other, because the denotation can also be much larger than the actual expression. For instance, lists are a data structure that are <em>not</em> spine-strict and we can easily express lists of infinite (denotational) size in small space</p>
<pre><code>squares = map (^2) [1..]</code></pre>
<p>By the way, this distinction between denotation and operational behavior is also why the word “strict” in the term “spine-strict” is a bad idea. Strictness is a purely denotational concept and hence cannot give you any of the operational guarantees that we need to control space usage. (For time complexity, this is actually not a problem because up to a constant factor, lazy evaluation is always faster than eager evaluation.) The concepts are certainly related, as I will discuss below, but strictness alone doesn’t help you with space usage at all.</p>
<p>The other important space invariant for a container is the property of <a href=\"http://blog.ezyang.com/2011/08/changes-to-intmap/\"><em>value-strictness</em></a></p>
<blockquote>
<p>value-strict = if the container is in WHNF, then each value stored in the container is in WHNF</p>
</blockquote>
<p>In other words, the container will make sure that all values are stored in an evaluated form, which in turn allows us to apply other space invariants for the values and hence control the total memory usage of the container. Again, my reservations about the use of the word “strict” apply here as well.</p>
<p>As you can see, space invariants are usually of the form “if this is in WHNF, then other things are in WHNF as well”. It is generally hard to say something about expressions that are not in WHNF, their size usually doesn’t bear any relation to their denotation.</p>
<p>How do you create space invariants? Well, that is easy, by using the <code>seq</code> function. A fresh view on the definition</p>
<pre><code>x = a `seq` b</code></pre>
<p>is to not see it as a specification of evaluation order, but rather as a declaration of a relation between the evaluation of <code>x</code> and the evaluation of <code>a</code>: whenever <code>x</code> is in WHNF, so is <code>a</code>. Taking this further, another example of a space invariant is a property that I would like to call <em>deep-space</em>:</p>
<blockquote>
<p>deep-space = if the value is in WHNF, then it is already in full normal form (NF)</p>
</blockquote>
<p>In other words, a value is deep-space if it is either unevaluated or already in full normal form. This time, I have avoided the word “strictness” for good effect. :)</p>
<p>For algebraic data types, we can encode applications of the <code>seq</code> combinator directly in the constructors via “strictness annotations”. The plain data type</p>
<pre><code>data Tree a = Bin  (Tree a)  (Tree a) | Leaf  a</code></pre>
<p>has the spine-strict variant</p>
<pre><code>data Tree a = Bin !(Tree a) !(Tree a) | Leaf  a</code></pre>
<p>and the value-strict variant</p>
<pre><code>data Tree a = Bin  (Tree a)  (Tree a) | Leaf !a</code></pre>
<p>The exclamation mark before a constructor argument indicates that the corresponding value is in WHNF whenever the constructor of the algebraic data type is in WHNF.</p>
<h2 id=\"general-remarks-on-understanding-space-usage-in-haskell\">General remarks on understanding space usage in Haskell</h2>
<p>Before continuing with space invariants and their relation to strictness, I would like to make an interlude for readers that are Haskell beginners and spell out some general information about lazy evaluation and space usage that I have already assumed implicitly in the previous section. If you’re an experienced Haskeller, you can skip to the next section.</p>
<p>The main cause for why space usage in a lazy language like Haskell is hard to reason about is because it is heavily <em>context-dependent</em>. <a href=\"http://ro-che.info/articles/2012-04-08-space-usage-reasoning.html\">For example</a>, the expression <code>[1..n]</code> uses <em>O(n)</em> memory when evaluated in full, but when it appears in a different context, for instance in the expression <code>head [1..n]</code>, evaluating the whole program takes only <em>O(1)</em> memory. In contrast, the value represented by the expression <code>[1..n]</code> is independent of the context, it is <em>compositional</em>. It does not matter how you represent the list of integers from <code>1</code> to <code>n</code> in the computer, calculating its <code>head</code> will always give the same result <code>1</code>.</p>
<p>Since memory usage depends on context, it seems that in order to reason about space usage, you have to trace the evaluation of a Haskell program in detail. Edward Yang has a <a href=\"http://blog.ezyang.com/2011/05/anatomy-of-a-thunk-leak/\">beautiful visualization</a> for how to do that, but unfortunately, it is utterly impossible to trace the evaluation for anything but trivial programs in this way. We need tools that abstract the details away: we don’t want to know about the details of how GHC manipulates heap objects, and we don’t really want to know how lazy evaluation works on a more abstract level either, we just want some sort of compositionality, just like we have in the case of semantics.</p>
<p>As a first step, understanding GHC’s evaluation machinery has fortunately never been necessary. You can understand lazy evaluation entirely on the source code level, in terms of <em>graph reduction</em>. The basic idea is that lazy evaluation deals with expressions. For instance, every one of the following lines</p>
<pre><code>5
2*3 - 1
1 + (1 + (1 + (1 + 1)))</code></pre>
<p>is an expression that <em>denotes</em> the value 5, but they are still <em>different</em> expressions for the same semantic value. The <em>size</em> of an expression tells you how much <em>memory</em> is needed to store it in the computer. The last expression is very long and takes five memory cells to store, while the first expression is small and takes only one memory cell to store.</p>
<p>Executing a Haskell program is about evaluating expressions, essentially by applying the definitions of functions like <code>*</code> or <code>+</code> repeatedly. Usually, evaluation of an expression stops when it has reached <a href=\"http://stackoverflow.com/a/6889335/403805\"><em>weak head normal form</em></a> (WHNF). Of the example expressions above, only <code>5</code> is in WHNF. For tree-like data types, WHNF means that we can see the outermost constructor, but its arguments may still contain arbitrary expressions. For instance, for the type</p>
<pre><code>data Tree a = Bin (Tree a) (Tree a) | Leaf a</code></pre>
<p>the expressions</p>
<pre><code>Leaf (1+1)
Bin (insert 17 (Leaf 1)) undefined</code></pre>
<p>are in WHNF.</p>
<p>Concerning terminology, we will call an expression that is not in WHNF an <em>unevaluated expression</em>, or <em>thunk</em> for short. However, keep in mind that the latter term originally referred to a particular representation of unevaluated expressions in GHC. I would like to repeat again: no understanding of GHC internals is necessary to reason about space usage in Haskell, it can all be done on the level of expressions (graphs). The more details you have to keep track of, the less you understand your program. But it seems to me that the term “thunk” has become synonymous with “unevaluated expression” in current usage, so I will use it in this way as well.</p>
<p>An even higher level of abstraction is the notion of <em>strictness</em>. It answers the following question: a function <code>foo</code> is called <em>strict</em> if evaluating <code>foo expr</code> to WHNF will also evaluate the expression <code>expr</code> to WHNF. In other words, to evaluate the result, you have to look at the argument. The great thing about strictness is that it can be formulated in terms of denotations alone, which are independent evaluation order. In particular, the function <code>foo</code> is strict iff</p>
<pre><code>foo ⊥ = ⊥</code></pre>
<p>where <code>⊥</code> is called “bottom” and denotes a “diverging” value, for instance an expression whose evaluation does not terminate. In other words, if evaluating the argument to WHNF will throw you into an infinite loop, then evaluating the function result will also do that, because it needs to peek at the argument. (See the <a href=\"http://en.wikibooks.org/wiki/Haskell/Denotational_semantics\">Wikibook for more on ⊥</a>).</p>
<p>So much for the general setup.</p>
<h2 id=\"strictness-and-space-invariants\">Strictness and space invariants</h2>
<p>As we have seen, strictness is a denotational property that can express some relations between WHNF, but it is not powerful enough to express space invariants in general. Neither do space invariants imply strictness properties. However, I feel there is some correspondence between the two.</p>
<p>To explore the correspondence, let us focus once again on container structures. The main functionality that a container offers is the <code>lookup</code> function</p>
<pre><code>lookup :: key -> Map key value -> Maybe value</code></pre>
<p>If the container is spine-strict, then the following property seems natural for the <code>lookup</code> function:</p>
<blockquote>
<p>If looking up any one key gives ⊥, then the container was ⊥ to begin with.</p>
</blockquote>
<p>In formulas:</p>
<blockquote>
<p>∀ key. (lookup key container = ⊥ → container = ⊥)</p>
</blockquote>
<p>This formula may take a while to digest, it looks a bit like a “reverse strictness” of the <code>lookup</code> function. The idea is that if you have evaluated the container to WHNF (<code>container ≠ ⊥</code>), then you already “evaluated the possible lookups” to WHNF as well (<code>lookup key container ≠ ⊥</code>). If you imagine a tree, then this means that the branches may not contain thunks; otherwise, you could replace the thunk with ⊥ and blow up when you try to evaluate a lookup that takes this particular branch.</p>
<p>Unfortunately (and unlike I excitedly thought for some time), this property alone is not enough to imply a space invariant. In fact, it is not necessarily implied by a space invariant either. You can always have a funny implementation like</p>
<pre><code>lookup key container = container `seq` ...</code></pre>
<p>that has this strictness property, but doesn’t give any guarantees about space usage of the container itself. Likewise, it is also possible to have extra data in the container, so that a diverging <code>lookup</code> is not enough to guarantee that the whole container has to be ⊥ as well.</p>
<p>Still, I think that this denotational property is very much a close relative to a space invariant. In particular, this formulation allows us to gain some partial confidence whether container library really does provide a spine-strict data structure, for example by using <a href=\"http://kar.kent.ac.uk/30756/\">StrictCheck</a> for testing.</p>
<p>In the same spirit, a strictness property corresponding to the space invariant of value-strictness (oh, the misnomer!) would be</p>
<blockquote>
<p>If looking at a value gives ⊥, then the container was ⊥ to begin with.</p>
</blockquote>
<p>In formulas:</p>
<blockquote>
<p>∀ key. (lookup key container = Just ⊥ → container = ⊥)</p>
</blockquote>
<p>This description may take some time to understand as well. Note how we use of the lazy <code>Maybe</code> type here: in the spine-strict case, our premise is that the lookup yields a result at all, while in the case of value-strictness, the premise is that the lookup succeeds with a value (but we don’t say anything about the case where it diverges).</p>
<p>I’m sure that “reverse strictness” formulas such as the ones above have been considered in <a href=\"http://www.cs.ox.ac.uk/ralf.hinze/publications/index.html#D2\">projection-based strictness analysis</a>.</p>
<h2 id=\"case-study-reactive-banana\">Case study: reactive-banana</h2>
<p>I found all of the above considerations very helpful for fixing <a href=\"https://github.com/HeinrichApfelmus/reactive-banana/issues/52\">some space leaks</a> in my <a href=\"http://apfelmus.nfshost.com/haskell.org/haskellwiki/Reactive-banana\">reactive-banana</a> library, as it gave me a clear picture of what I can rely on and what is impossible.</p>
<p>Namely, trying to understand the details of the evaluation process is absolutely hopeless, you never really know how soon an expression is going to be evaluated to WHNF. If you have an expression <code>foo</code> that you want to be in WHNF, you can try to force its evaluation by writing <code>evaluate foo</code> instead, but that doesn’t help at all, because how do you ensure that the larger expression <code>(evaluate foo)</code> itself is evaluated? Oops. This is the same as putting a bang pattern on a function that is already strict, a common act of desperation amongst Haskell programmers when confronted with the evil space leak invaders.</p>
<p>However, what you <em>can</em> do is to <em>link</em> the evaluation of two expressions. This is precisely what a space invariant expresses and what the <code>seq</code> combinator can do: by writing <code>seq expr1 expr2</code>, you indicate that <code>expr1</code> will be in WHNF whenever <code>expr2</code> is. “If you shoot my friend, then you also have to shoot me”. No idea if a value will ever be evaluated, but when it is, then another value will be evaluated as well.</p>
<p>The situation in reactive-banana was quite hairy. Namely, I had a lazy state monad</p>
<pre><code>type Eval a = Control.Monad.State.Lazy.State (Container,Hangman) a</code></pre>
<p>and profiling indicated that the state of type <code>Container</code> was leaking like a bucket without bottom. The obvious try would be to use a strict state monad, but unfortunately, I couldn’t do that: I needed the laziness to support a tie-a-knot-around-your-neck kind of recursion with the <code>Hangman</code> type, and the values in the <code>Container</code> type got populated in a somewhat recursive fashion as well. It was simply not possible to make this state monad strict and control the evaluation of the <code>Container</code> type in a step-by-step fashion.</p>
<p>At first, I was not sure whether using a spine-strict and value-strict container would help me in this situation, but then I became happy with the idea of only being able to link evaluation instead of being able to force it. Running the state monad was part of a larger computation step, so sneaking an <code>evaluate</code> in the IO monad at the end of every step should allow the laziness I needed and yet force my container to attain a predictable size in the end. Thanks to space invariants, I can be confident that this stragety works.</p>
<p>Unfortunately, that didn’t quite help yet, though. The reason was building the new container involved reading values from the old container and many values were actually of function type, like</p>
<pre><code>value :: [A] -> [B]
value = map (fromJust $ lookup key oldContainer)</code></pre>
<p>The problem is that this expression is (almost) in WHNF already, so the <code>lookup</code> didn’t get evaluated and <code>oldContainer</code> is still lingering about. In other words, evaluating the values to WHNF was <em>not</em> sufficient to ensure a predictable memory size. Fortunately, the solution is to add new space invariant that links the WHNF of the <code>value</code> to the WHNF of the expression involving <code>lookup</code>. Problem solved!</p>
<hr />
<p>So much for space invariants. I think they offer a fresh perspective on how to reason about space usage in Haskell.</p>
<p>In particular, they explain why the <a href=\"http://neilmitchell.blogspot.ru/2013/08/destroying-performance-with-strictness.html\">changes to the unordered-containers library</a> mentioned in the introduction were a rather odd idea: the strictness of a function has, unfortunately, little to do with a guarantee on space usage.</p>
<hr /><p><a href=\"https://flattr.com/thing/29608/apfelmus-website\"><img src=\"http://api.flattr.com/button/flattr-badge-large.png\" alt=\"Flattr this\" border=\"0\" title=\"Flattr this\" /></a></p>" nil nil "35ce25084e25b50d519adc6383665d63") (422 (21012 35047 146288) "http://coldwa.st/e/blog/2013-08-21-Cabal-1-18.html" "Mikhail Glushenkov: What's new in Cabal 1.18 - sandboxes, REPL, cross-compilation and more!" nil "Wed, 21 Aug 2013 00:00:00 +0000" "<p>The 1.18 release of Cabal is almost ready. This post describes what’s new and improved in this version.</p>
<h2 id=\"user-visible-features\">User-visible features</h2>
<ul>
<li><p>Sandboxes - isolated environments for building packages, similar to (and inspired by) what the popular <code>cabal-dev</code> tool provides. See <a href=\"http://feeds.feedburner.com/blog/2013-08-20-Cabal-sandbox.html\">this article</a> for a more detailed introduction.</p></li>
<li><p><code>cabal repl</code> - New command that opens an interpreter session for the given target (executable or library). Code based on patches developed during GSoC 2011 by Sam Anklesaria.</p></li>
<li><p><code>cabal get</code> - New command that replaces <code>cabal unpack</code>. When given the <code>--source-repository</code> argument (short form: <code>-s</code>) <code>cabal get</code> checks out a working copy of a given package’s source code using the appropriate revision control system.</p></li>
<li><p><code>cabal run</code> - New command that compiles and runs the given executable. Instead of <code>cabal build && ./dist/build/prog/prog --args</code>, you can now use <code>cabal run prog -- --args</code>.</p></li>
<li><p>Better support for cross-compilation: target platform is now inferred by parsing compiler’s output (i.e., <code>ghc --info</code>). Packages are now installed to <code>$arch-$os-$compiler/$pkgid</code> instead of <code>$pkgid/$compiler</code> by default. (<a href=\"https://github.com/haskell/cabal/issues/1214\">#1214</a>)</p></li>
<li><p>It’s now possible to specify a target for the <code>build</code> and <code>repl</code> commands. For example, if your package includes executables <code>foo</code> and <code>bar</code>, you can run <code>cabal build foo</code> to build only <code>foo</code> (and its dependencies). If there’s also a library or test-suite named <code>foo</code>, <code>cabal build exe:foo</code> can be used for disambiguation.</p></li>
<li><p>New <code>cabal configure</code> and config file option: <code>extra-prog-path</code>. Allows to specify a list of directories to be searched for required programs. In newly-created config files it is initialised to <code>~/.cabal/bin</code>, which should solve the common problem when <code>cabal</code> couldn’t find programs that the user have just installed (usually <code>alex</code>/<code>happy</code>/<code>c2hs</code>) because they were in a location not on <code>$PATH</code> (<a href=\"https://github.com/haskell/cabal/pull/1415\">#1415</a>).</p></li>
<li><p>Two new config file sections: <code>program-locations</code> and <code>program-default-options</code>. This allows to specify custom paths and options for the required programs (<a href=\"https://github.com/haskell/cabal/issues/1328\">#1328</a>).</p></li>
<li><p><code>extra-doc-files</code>: new package property for installing extra files referenced from the Haddock documentation, e.g. images (the <a href=\"http://hackage.haskell.org/package/lens\"><code>lens</code> package</a> is a good example). (<a href=\"https://github.com/haskell/cabal/issues/1182\">#1182</a>).</p></li>
<li><p>Support for executables with C/C++/Obj-C main functions (<a href=\"https://github.com/haskell/cabal/issues/1080\">#1080</a>).</p></li>
<li><p><code>c-sources</code> can now depend on headers generated for Haskell FFI exports (<code>*_stub.h</code>) (<a href=\"https://github.com/haskell/cabal/issues/1080\">#1080</a>).</p></li>
<li><p>Support for test and benchmark documentation with Haddock (<a href=\"https://github.com/haskell/cabal/issues/1374\">#1374</a>).</p></li>
<li><p>Support for GNU AGPLv3 license (<a href=\"https://github.com/haskell/cabal/issues/1361\">#1361</a>).</p></li>
<li><p>The <code>jobs</code> field in the config file is now initialised with <code>$ncpus</code>.</p></li>
<li><p><code>install --dependencies-only</code> is now a synonym for <code>install   --only-dependencies</code>.</p></li>
</ul>
<h2 id=\"bug-fixes-and-minor-improvements\">Bug fixes and minor improvements</h2>
<ul>
<li><p>GHC 7.8 support (<a href=\"https://github.com/haskell/cabal/issues/1252\">#1252</a>, <a href=\"https://github.com/haskell/cabal/issues/1384\">#1384</a>).</p></li>
<li><p><code>cabal update</code> now downloads package metadata only if the server has a newer version (<a href=\"https://github.com/haskell/cabal/issues/799\">#799</a>, <a href=\"https://github.com/haskell/cabal/issues/1341\">#1341</a>).</p></li>
<li><p><code>cabal init</code> now generates less restrictive version bounds (<a href=\"https://github.com/haskell/cabal/issues/1329\">#1329</a>).</p></li>
<li><p><code>cabal init</code> now can guess common types of extra-source-files (<a href=\"https://github.com/haskell/cabal/issues/1157\">#1157</a>).</p></li>
<li><p>Absoulute paths are now passed to Haddock as proper URLs (<a href=\"https://github.com/haskell/cabal/issues/1064\">#1064</a>, <a href=\"https://github.com/haskell/cabal/issues/1406\">#1406</a>).</p></li>
<li><p><code>dist/build/autogen</code> dir is now included in the <code>-I</code> search list for c-sources (<a href=\"https://github.com/haskell/cabal/issues/1351\">#1351</a>).</p></li>
<li><p>When building libraries, <code>c-sources</code> are now built separately for profiling (<a href=\"https://github.com/haskell/cabal/issues/1286\">#1286</a>).</p></li>
<li><p>The <code>--package-db</code> flag now correctly handles relative paths (<a href=\"https://github.com/haskell/cabal/commit/234417c2a603d4d23222048e09cb2caa254ac755\">234417c2</a>).</p></li>
<li><p>Annoying missing haddock warning for the rts package is now suppressed (<a href=\"https://github.com/haskell/cabal/issues/1231\">#1231</a>).</p></li>
<li><p>Improved warning for old versions of HPC (<a href=\"https://github.com/haskell/cabal/issues/1155\">#1155</a>).</p></li>
<li><p>Miscellaneous minor and/or internal bug fixes and improvements.</p></li>
</ul>
<h2 id=\"acknowledgements\">Acknowledgements</h2>
<p>Thanks to everyone who contributed code to this release and to Johan Tibell for being the release manager.</p>" nil nil "f7971be518d26cbdcd23e2910f50bd3b") (421 (21012 35047 68867) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_2992\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_8817\"></span> time, whereas using the categorical functor takes time <span id=\"tex_1672\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_5320\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "319b2f047ef28390727c030d7cab4e0f") (420 (21012 29814 282409) "http://praisecurseandrecurse.blogspot.com/2013/08/arduino-day-2-most-minimal-scripting.html" "Paul Potts: Arduino, Day 2: the Most Minimal Scripting Language, or, Reifying Frozen Functions for Fun" "noreply@blogger.com (Paul Potts)" "Wed, 21 Aug 2013 01:40:00 +0000" "<i>Planet Haskell readers might want to skip this one.</i> <p>Recently I've been thinking about the possibilities offered by embedded interpreters. This is becoming a common design pattern in commercial software -- games written in C++ embedding Lua, for example, or Python for graphical user interfaces, or occasionally Scheme, or even the JVM. However, adapting an existing full-blown scripting language won't necessarily fly on a small system. What if you have a DSP, with nothing resembling a *nix-like operating system -- no standard C library, or almost none, no POSIX-like APIs, etc.</p> <p>Well, there are smaller languages. I've done a little research recently and come across some very small, cut-down implementations of Scheme or other Lisp dialects, or even a tiny BASIC, and languages like Forth can be very small.</p> <p>But what if we have a <i>really</i> tiny chip? What if the SRAM budget we had to implement our embedded language was, say, not 2 MiB, or even 2 KiB, but 200 bytes?</p> <p>The Arduino Uno R3 uses an <a href=\"http://en.wikipedia.org/wiki/ATmega328\">ATmega328</a> microprocessor. It's considered an 8-bit chip. Calling chips 8-bit, 16-bit, 32-bit, 64-bit, etc. can be a little confusing these days, because a lot of chips can operate on several different data sizes, but this chip has 8-bit registers, so we'll consider it to be primarily an 8-bit part. It has 32 KiB of onboard flash memory to hold your program (it is persistent across power cycles). 32 KiB can hold a moderately complex compiled program. But as for RAM -- the working memory for computation in progress and run-time state -- it has only 2 KiB, a mere 2048 bytes. That's less RAM than the first computer I owned, which was a Radio Shack TRS-80 Model 1, with 4 KiB, although I did work with some smaller computers -- for example, a KIM-1. And presumably we don't want to use all our SRAM to implement our small scripting language itself; the scripts need to have some functions to call.</p> <p>A microcontroller like this is designed to run simple programs. It's designed to be \"bomb-proof\" -- hard to fry with stray excess voltage. It has a low pin count -- miniscule, compared to the processors in my desktop and laptop machines -- and it has a number of built-in peripherals designed for digital I/O. It's a pretty cool chip -- these Arduinos have taken off among electronics hobbyists and are part of the whole \"maker\" movement because they exist in a sort of power per dollar sweet spot. If you fry the chip itself, you can replace it for a couple of dollars; if you fry the whole board, you're only out a few more.</p> <p>What they aren't, though, is very well-suited for the modern programming model that assumes a very capable operating system, dynamic linking, dynamic allocation using <b>malloc</b> or <b>new</b>, and container objects created using class libraries like the STL (don't get me wrong, the STL is impressively efficient, but it just isn't designed to work around a very tiny memory model). So the Arduino's GCC toolchain doesn't even attempt to provide, say, <b><vector></b>.</p> <p>So what would an embedded scripting language for the Uno R3 look like? Well, for one thing, the Arduino doesn't come with a file system to speak of. You can buy a \"shield\" of some time that provides a controller and a slot for a memory card, but this isn't included with the basic bard. So you can't count on a user's ability to place a script in a text file and update just that script in order to change the program's behavior, although I might do some experiments along those lines. Without something like that, you have to use the toolchain -- compiling your program and downloading it with <b>avrdude</b>. You can't count on files, but you have strings -- C-style strings, in the form of arrays of bytes. So you could implement a small BASIC or Scheme interpreter that executed a program contained in a C string. I will do some experiments along those lines too, if I can, especially if I can force the strings to live in the 32 KiB flash, which I think is possible, rather than the 2 KiB SRAM.</p> <p>But what if you want something even simpler? What if pretty much any sort of interpreter looked like it was going to be too heavyweight for your purposes, using too much SRAM -- too much space for tables, and too much stack? Is there something even simpler you can do?</p> <p>There is. You can write a \"script\" that consists of a series of objects, using some tricks I'll demonstrate. This is very definitely a work in progress; it has some rather extreme design compromises. In particular, it isn't at all friendly to the \"script\" author. If there is a typo, the compiler can't provide a very novice-friendly error message. It seems a little sadistic to inflict this sort of hair-shirt discipline on hobbyists, but let's consider it a thought experiment, exploring a a couple of implementation options.</p> <p>I'm going to build my \"scripting language\" up in reverse; instead of showing you the syntax of the \"scripting language\" first, I'll show you the constructs I'm using to implement it, we'll and arrive at the syntax last. But first I need to explain some of the less common things I'm doing with the implementation.</p> <p>Let's say I want to easily differentiate a set of overloaded functions, each of which is specialized on a single parameter type. (I won't explain why quite yet, but it will make sense later). What's the best way to do that? How about with a set of <b>typedef</b>'ed types, or enum types to distinguish them?</p> <p>C++ and C are <i>weakly typed</i>, at least in places. Although the C++ class system can enforce strong typing, when working with POD (plain old data) types and particularly the <b>typedef</b> and <b>enum</b> keywords, typing isn't strongly enforced. What do I mean by that? Well, <b>typedef</b> and <b>enum</b> allow you to write code that looks superficially like it is strongly typed:</p> <pre>typedef int special_int;<br />void handle( int a );<br />void handle( special_int a );</pre> <p>But on my compiler, if I provide the functions to match these prototypes, and call them:</p> <pre>int handle_param_1 = 0;<br />special_int handle_param_2 = 0;<br />handle( handle_param_1 );<br />handle( handle_param_2 );</pre> <p>The compiler complains that I'm redefining <b>handle</b>. The compiler won't (and can't) really make use of it to provide type safety, because it's not really a distinct type, but a <i>type alias</i> -- that is, really just a nickname, more for documentation purposes than anything else; the compiler doesn't really see the alias as a distinct type at all.</p> <p>In the case of enums, using enum can make your code more self-documenting, and it appears that I can reliably overload functions using specific enum types, which the compiler keeps distinct:</p> <pre>typedef enum { red, green, blue } color;<br />typedef enum { salty, sweet, sour } flavor;<br />void handle( color a );<br />void handle( flavor a );</pre> <p>But if there is no overloaded function with a parameter that exactly matches the enum type, C++ will happily <i>promote</i> the enum type to an <b>int</b>, or apply a <i>standard conversion</i> to turn it into a <b>float</b> -- so type-safety is potentially compromised again here. If you forget to provide an overloaded <b>handle</b> method that accepts your enum type, but there exists one that takes a single float parameter, the compiler will call that one, without a whisper of warning. Types don't get much weaker than that! (All right, yes they do, but let's not get into a sideways rant about PHP or Perl).</p> <p>The very latest versions of C++ do provide a new \"enum class\" feature that gives one more control over enumerated types and allows the more powerful class type system to kick in and keep things straight, but it isn't widely used yet, and I'm not sure the compiler I have available for Arduino supports it. So, at least for today, we'll leave it out.</p> <p>There <i>is</i> a tweak that makes this quite easy, though. In C++, a <b>struct</b> is actually a class whose members are all public by default. And it's possible to create an empty struct, with no data members. This gives me something I'll call it a <i>type tag</i> (I could call it a <b>typeType</b> in honor of the old AppleEvent manager's descriptor type, but let's not), and I'll call an <i>instance</i> of it a <i>type token</i>. They will let me reliably overload functions, since it uses C++ class types, designed for greater type safety and strictness than C's \"plain old data\" types.</p> <p>Let's briefly review structs, in case you need a review: in C, <b>struct</b>s are in their own namespace, but they can be <b>typedef</b>'ed into the common namespace:</p> <pre>struct s_tag { int m1, float m2 };</pre> <p>You can instantiate a struct in C like this:</p> <pre>struct s_tag s1;</pre> <p>But you can't say:</p> <pre>s_tag s1;</pre> <p>Unless you've used the typedef trick:</p> <pre>typedef struct s_tag s_type;<br /><br />s_type s2;</pre> <p>These are used together so frequently that the C syntax supports wrapping the type definition and <b>typedef</b> up together:</p> <pre>typedef struct s_tag { int m1; float m2 } s_type;</pre> <p>So what is the point of that <b>s_tag</b>? Well, it is mostly vestigial, but it has one important use; it is the only way you can declare a struct that is self-referential. This is imperative when declaring a tree or list of struct types, if you are going to take advantage of type-checking, instead of mashing everything through void pointers and unsafe casting to get it back to the type you need. So,</p> <pre>typdef struct s_tag { int m1; float m2; s_tag *next_p } s_type;</pre> <p>and not:</p> <pre>typedef struct s_tag { int m1; float m2; s_type *next_p } s_type;</pre> <p>because the latter would require a forward reference to an incomplete type, and there's no way to specify that. Of course, it doesn't seem that unreasonable these days to ask a compiler to keep track of incomplete things as it goes and make sense of them in a later pass, but back in the day machines were smaller and slower, and so we have that vestigial struct tag.</p> <p>And in C++, designed to maintain as much compatibility with C as possible, there are (of course) some subtle <a href=\"http://stackoverflow.com/questions/612328/difference-between-struct-and-typedef-struct-in-c/612476#612476\">complications</a> that can come into play, but that's basically how structs work.</p> <p>In case you're curious, yes, there's a similar \"enum tag\" for enums, and you can refer to enum types in the <b>enum</b> namespace. I haven't see this sort of thing much in real-world code. There's yet another namespace for <i>unions</i>, and unions are structs as well in C++ -- we'll take advantage of that later. But moving on, let's define some type tags:</p> <pre>typedef struct {} step_1_tt;<br />typedef struct {} step_2_tt;<br />typedef struct {} step_3_tt;</pre> <p>And here are some \"type tag\" instances:</p> <pre>static steps::step_1_tt step_1_tt_i;<br />static steps::step_2_tt step_2_tt_i;<br />static steps::step_3_tt step_3_tt_i;</pre> <p>The empty struct isn't standard C (although I think GCC allows it as an extension), but it is allowed in C++. In standard C there is a similar trick where you can declare a pointers to incomplete (that is, forward-declared) struct types (does that let you use self-reference in structs without using the vestigial tag? I'll have to look into that. There's a lot to know for such a seemingly simple language feature!</p> <p>Now, we need to be able to distinguish our tiny scripting language \"tokens,\" and for that we use an enumeration. (We could do this with subtypes, as well, and maybe I'll consider that for later, but for now we'll do it this way). We'll define several types that correspond to functions:</p> <pre>typedef enum<br />{<br />    step_type_1,<br />    step_type_2,<br />    step_type_3,<br /><br />} step_e;</pre> <p>Next up, we want to define the functions. This is pretty basic. We could do it with function pointers, of specific function pointer types, and I might explore that later, but for now we'll refer to a hard-coded set of actual functions. Here they are, simple placeholders that print their arguments, for testing:</p> <pre>void step_func_a( signed long );<br />void step_func_b( unsigned long );<br />void step_func_c( signed short );<br /><br />void step_func_a( signed long p1 )<br />{<br />    std::cout << \"step func a with param\" << p1 << \"\\n\";<br />}<br /><br />void step_func_b( unsigned long p1 )<br />{<br />    std::cout << \"step func b with param\" << p1 << \"\\n\";<br />}<br /><br />void step_func_c( signed short p1 )<br />{<br />    std::cout << \"step func c with param\" << p1 << \"\\n\";<br />}</pre> <p>So those are the functions we can call from our \"scripts.\" But what about the parameters? We'll use unions. This is unsafe, in the sense that the type system will not keep us safe, and we'll have to use some extra bookkeeping have to make sure we decode parameters the same way they were encoded. Because a <b>union</b> in C++ is also a class, we can provide constructors for our union type, and even overload them, to handle the different types that might be passed in:</p> <pre>union step_param_u<br />{<br />    step_param_slong    slong_param;<br />    step_param_ulong    ulong_param;<br />    step_param_sshort   sshort_param;<br />    step_param_ushort   ushort_param;<br />    step_param_schar    schar_param;<br />    step_param_uchar    uchar_param;<br />    // We could add more here, for any parameter types we need<br />    // to store and reconstitute later<br /><br />    step_param_u()                   : slong_param( 0 )   {};<br />    step_param_u( signed long   p1 ) : slong_param ( p1 ) {};<br />    step_param_u( unsigned long p1 ) : ulong_param ( p1 ) {};<br />    step_param_u( signed short  p1 ) : sshort_param( p1 ) {};<br />    step_param_u( signed char   p1 ) : schar_param( p1 )  {};<br /><br />};</pre> <p>One of those union objects will represent one parameter. Let's wrap that all up with a struct that will embody a \"frozen function call\" with up to 3 parameters. We could extend that if we need more.</p> <p>There's a sort of type-system hole in that we don't have a safe, distinguishable way to represent a null parameter -- that is, one that wasn't provided -- and so there's not quite a sensible default constructor for <b>step_param_u</b>. We could use subclasses of our \"frozen function call\" to represent function calls with no parameters, one parameter, two parameters, three parameters, etc. so that we don't have to represent the idea of an unused parameter at all, but this results in an explosion of types (and I'm not even really taking return values into account at all, at this point; our scripting language uses a completely imperative paradigm). Maybe the number of unique parameter and return value combinations is not that large in practice, but for now let's just get a simple thing working:</p> <pre>struct step_s<br />{<br />    step_e step_type;<br />    step_param_u param_1;<br />    step_param_u param_2;<br />    step_param_u param_3;<br /><br />    step_s( step_1_tt, signed long p1 ) :<br />        step_type( step_type_1 ),<br />        param_1( p1 )<br />        {};<br />    step_s( step_2_tt, signed long p1 ) :<br />        step_type( step_type_2 ),<br />        param_1( p1 )<br />        {};<br />    step_s( step_3_tt, signed short p1 ) :<br />        step_type( step_type_3 ),<br />        param_1( p1 )<br />        {};<br /><br />};</pre> <p>And now for a trick to create our so-called. We turn things that look like function calls into actual constructor calls by adding a parameter. For this quick-and-dirty prototype, I'll use some macros:</p> <pre>#define MAKE_SEQUENCE(p1) step_s const p1[]<br />#define step_call_type_1(p1) step_s(step_1_tt_i,p1)<br />#define step_call_type_2(p1) step_s(step_2_tt_i,p1)<br />#define step_call_type_3(p1) step_s(step_3_tt_i,p1)</pre> <p>Is it raw and wriggling, precious? Make sure you understand what's going on here: these macros turn function-call-like syntax into constructor calls by passing our type tokens to select a matching overloaded constructor. Of course, the compiler is looking at the preprocessed code, which can make error messages harder to understand. I sometimes have to ask the compiler to generate preprocessor output to diagnose a problem, but a beginning Arduino programmer using the IDE won't even have a way to generate the preprocessor output.</p> <p>And so here is an example of our tiny \"scriping language\" -- a sequence of steps to take, in reality function calls to make:</p> <pre>sequence(sequence_1) =<br />{<br /><br />    step_call_type_1(-50101),<br />    step_call_type_2(0xDEADBEEF),<br />    step_call_type_3(-32767)<br /><br />};</pre> <p>And that's our syntax.</p> <p>Wait, really? Yes. That's a little script. That's why I call it the \"most minimal\" scripting language.</p> <p>That actually turns into an array definition, with an implict (not explicitly declared) size, and an initialization list. Note that the ability to include constructor call expressions in an array initialization list is a newer feature of C++. Older compilers won't be able to handle the syntax at all. To support an older compiler we'd have to do some kind of post-definition assignment, which might require something like calling a variadic function with a list of macro invocations, and that could get really ugly really fast. Er, that is, even uglier than what we're already doing.</p> <p>So how do we execute that script? Well, we need another bit of macro magic to find the length of a sequence:</p> <pre>// Length of a sequence; see Imperfect C++, the book by Matt Wilson, or his blog post:<br />// http://blog.imperfectcplusplus.com/2010/06/imperfect-cinventions-dimensionof.html<br />#define SEQUENCE_LENGTH(seq) (sizeof(seq)/sizeof(0[(seq)]))</pre> <p>And now we have all we need to write a function that runs a sequence. How about this, as the simplest thing that can work:</p> <pre>static void run_sequence( step_s const p1[], int const seq_len )<br />{<br />    for ( int seq_idx = 0; seq_idx < seq_len; seq_idx++ )<br />    {<br />        p1[seq_idx].invoke();<br />    }<br /><br />}</pre> <p>Where <b>invoke</b> is a method of <b>step_s</b>:</p> <pre>void invoke() const<br />{<br />    switch( step_type )<br />    {<br />        case step_type_1:<br />            step_func_a( param_1.slong_param);<br />            break;<br />        case step_type_2:<br />            step_func_a( param_1.ulong_param);<br />            break;<br />        case step_type_3:<br />            step_func_a( param_1.sshort_param);<br />            break;<br /><br />    }<br />}</pre> <p>Well, actually, we need this, too, so a particular instance can be sized at compile time:</p> <pre>#define RUN_SEQUENCE(p1) run_sequence(p1,SEQUENCE_LENGTH(p1))</pre> <p>And then I can just execute <b>RUN_SEQUENCE(sequence_1)</b>.</p> <p>Note that invoke assumes that the entire set of functions we might want to invoke from our script is known. This could be extended in some fashion -- breaking it down into a system library and a user library, allowing the user to add macro definitions to create new usable \"statements\" to use in our scripts. This would involve a more generic way to represent steps, using function signature-specific subclasses, or a predefined set of supported function pointer types. I think that function pointers can be cast to function pointers of different types, and that might get us part of the way there, but I see an explosion happening somewhere, either in the <b>switch</b> statements in <b>invoke</b> or in subclasses. it doesn't seem easy to really capture everything we might need at compile time. A function invocation in C isn't something that supports much in the way of compile-time introspection -- there's no standard facility to look up its arity, its number of parameters, and their types; we aren't working with S-expressions here. Even gruesome hacks involving variable-length argument lists won't let us really work this out for a general case, as far as I know, and I don't think template metaprogramming can entirely remedy this, although there might be some neat tricks to minimize the code we have to write.</p> <p>Some extensions to our \"scripting language\" are clearly possible: for example, our  language could be extended to include labels, goto, counters, and even conditional branching, fairly easily -- it's just that all of those items would look like function calls and be macro invocations that boiled down to overloaded constructor calls to some single struct or class type, or different struct or class types that have a single base class so that we can treat them uniformly. Essentially, we're implementing a script without ever parsing the text of our scripting language, per se, and that's what keeps it tiny.</p> <p>The <b>run_sequence</b> function would need a little more complexity. In fact it could run multiple sequences in multiple threads -- there exist solutions for cooperative multi-tasking on Arduino. To my taste the ones I've seen so far are all still too heavyweight. I'm even tempted to implement a preemptive solution, so that a thread that is executing a delay can't delay the other threads. This may be a topic of some ongoing research, aka \"playing,\" as my time allows.</p> <p>Next time, if I can work something out, I'll consider some template-based ideas and whether they buy us anything useful. As always, I welcome your comments.</p>" nil nil "86c483493fc872e093140067d53ff9b3") (419 (21012 29814 279318) "http://coldwa.st/e/blog/2013-08-20-Cabal-sandbox.html" "Mikhail Glushenkov: An Introduction to Cabal sandboxes" nil "Tue, 20 Aug 2013 00:00:00 +0000" "<p>This post describes sandboxes, a new feature of <code>cabal</code> that will be present in the 1.18 release. Sandboxes allow to build packages in isolation by creating a private package environment for each package. If you are familiar with Python’s virtualenv or Ruby’s RVM, this is a Haskell analogue. Though 1.18 is still not out yet, you can already experiment with the new features by building <code>cabal</code> from Git. This post is mainly aimed at people new to sandboxes – if you have already used <code>cabal-dev</code>, feel free to <a href=\"http://feeds.feedburner.com/ChurningAndChurning#for-the-users-of-cabal-dev\">skip the introductory sections</a>.</p>
<h2 id=\"building-cabal-from-git\">Building Cabal from git</h2>
<p>Assuming you already have a previous version of <code>cabal</code> installed:</p>
<pre><code>$ git clone git://github.com/haskell/cabal.git /path/to/cabal
$ cd /path/to/cabal
$ cabal install Cabal/ cabal-install/</code></pre>
<p>That’s all! Now you have the latest version of the <code>cabal</code> tool installed under <code>~/.cabal/bin</code>.</p>
<p>Alternatively, if you have only GHC (but not <code>cabal</code>) installed:</p>
<pre><code>$ git clone git://github.com/haskell/cabal.git /path/to/cabal
$ cd /path/to/cabal/Cabal
$ runhaskell Setup.hs configure
$ runhaskell Setup.hs build
$ runhaskell Setup.hs install
$ cd ../cabal-install
$ sh bootstrap.sh</code></pre>
<h2 id=\"what-are-sandboxes-and-why-are-they-needed\">What are sandboxes and why are they needed?</h2>
<p>If you have used Haskell for some time, you’ve probably heard the expression “Cabal hell”. It refers to the fact that installing a new package with <code>cabal install</code> can break existing packages on your system.</p>
<p>The reason for this behaviour is <em>destructive reinstalls</em>. As of this writing, Cabal doesn’t support having <em>multiple instances</em> of the same version of a single package installed simultaneously (but note that installing <em>multiple versions</em> of the same package is completely fine). So how does this affect you, the user?</p>
<p>Imagine that you have installed the library <code>foo</code>, which depends on <code>bar-1.0</code>, which in turn depends on <code>baz</code> (any version):</p>
<figure>
<img src=\"http://feeds.feedburner.com/e/img/sandboxes-pic-0.png\" title=\"foo-1.0 -> bar-1.0 -> baz-1.0;\" />
</figure>
<p>After some time you then decide to install <code>quux</code>, which depends on <code>bar-1.0</code> and <code>baz-2.0</code>. Since you have only <code>baz-1.0</code> installed, you need to install <code>baz-2.0</code> and recompile <code>bar-1.0</code> against it:</p>
<figure>
<img src=\"http://feeds.feedburner.com/e/img/sandboxes-pic-1.png\" title=\"quux-1.0 -> bar-1.0; quux-1.0 -> baz-2.0; bar -> baz-2.0;\" />
</figure>
<p>But since Cabal allows you to have only a single instance of <code>bar-1.0</code> installed, the package <code>foo-1.0</code> is now broken since it depends on an instance of package <code>bar-1.0</code> that was removed! Cue much weeping and gnashing of teeth:</p>
<figure>
<img src=\"http://feeds.feedburner.com/e/img/sandboxes-pic-2.png\" title=\"foo-1.0 -> ???; baz-1.0;\" />
</figure>
<p>While we know what is the right way to fix this issue (see the <a href=\"http://feeds.feedburner.com/ChurningAndChurning#future-work\">“future work”</a> section below), getting there will take time, and sandboxes present a relatively low-cost interim solution. The idea is to build each package in an isolated environment (“sandbox”) with a sandbox-local package database. Because sandboxes are per-project, we can constrain them to be internally consistent and simply prohibit such conflicts as described above.</p>
<p>Besides alleviating the “Cabal hell” problem, sandboxes are also useful when your package depends on patched or unreleased libraries.</p>
<h2 id=\"usage\">Usage</h2>
<p>Using sandboxes is simple: if you already know how to use the <code>cabal</code> tool to build your packages, you only need to learn a few additional commands. To initialise a fresh sandbox in the current directory, run <code>cabal sandbox init</code>. All subsequent commands (such as <code>build</code> and <code>install</code>) from this point will use the sandbox.</p>
<pre><code>$ cd /path/to/my/haskell/library
$ cabal sandbox init                   # Initialise the sandbox
$ cabal install --only-dependencies    # Install dependencies into the sandbox
$ cabal build                          # Build your package inside the sandbox</code></pre>
<p>It can be useful to make a source package available for installation in the sandbox - for example, if your package depends on a patched or an unreleased version of a library. This can be done with the <code>cabal sandbox add-source</code> command - think of it as “local Hackage”. If an add-source dependency is later modified, it is reinstalled automatically.</p>
<pre><code>$ cabal sandbox add-source /my/patched/library # Add a new add-source dependency
$ cabal install --dependencies-only            # Install it into the sandbox
$ cabal build                                  # Build the local package
$ $EDITOR /my/patched/library/Source.hs        # Modify the add-source dependency
$ cabal build                                  # Modified dependency is automatically reinstalled</code></pre>
<p>Normally, the sandbox settings (such as optimisation level) are inherited from the main Cabal config file (<code>$HOME/cabal/config</code>). Sometimes, though, you need to change some settings specifically for a single sandbox. You can do this by creating a <code>cabal.config</code> file in the same directory with your <code>cabal.sandbox.config</code> (which was created by <code>sandbox init</code>). This file has the same syntax as the main Cabal config file.</p>
<pre><code>$ cat cabal.config
documentation: True
constraints: foo == 1.0, bar >= 2.0, baz
$ cabal build                                  # Uses settings from the cabal.config file</code></pre>
<p>When you have decided that you no longer want to build your package inside a sandbox, just delete it:</p>
<pre><code>$ cabal sandbox delete                       # Built-in command
$ rm -rf .cabal-sandbox cabal.sandbox.config # Alternative manual method</code></pre>
<h2 id=\"advanced-usage\">Advanced usage</h2>
<p>The default behaviour of the <code>add-source</code> command is to track modifications done to the added dependency and reinstall the sandbox copy of the package when needed. Sometimes this is not desirable: in these cases you can use <code>add-source --snapshot</code>, which disables the change tracking. In addition to <code>add-source</code>, there are also <code>list-sources</code> and <code>delete-source</code> commands.</p>
<p>Sometimes one wants to share a single sandbox between multiple packages. This can be easily done with the <code>--sandbox</code> option:</p>
<pre><code>$ cd /path/to/shared-sandbox
$ cabal sandbox init
$ cd /path/to/package-a
$ cabal sandbox init --sandbox /path/to/shared-sandbox
$ cd /path/to/package-b
$ cabal sandbox init --sandbox /path/to/shared-sandbox</code></pre>
<p>Using multiple different versions of GHC simultaneously is also supported, via the <code>-w</code> option:</p>
<pre><code>$ cabal sandbox init
$ cabal install --only-dependencies -w /path/to/ghc-1 # Install dependencies for both compilers
$ cabal install --only-dependencies -w /path/to/ghc-2
$ cabal configure -w /path/to/ghc-1                   # Build with the first compiler
$ cabal build
$ cabal configure -w /path/to/ghc-2                   # Build with the second compiler
$ cabal build</code></pre>
<p>It can be occasionally useful to run the <code>ghc-pkg</code> tool on the sandbox package DB directly (for example, you may need to unregister some packages). The command <code>cabal sandbox hc-pkg</code> is a convenient wrapper for <code>ghc-pkg</code> that runs it with the appropriate <code>--package-conf</code> argument:</p>
<pre><code>$ cabal -v sandbox hc-pkg list
Using a sandbox located at /path/to/.cabal-sandbox
'ghc-pkg' '--global' '--no-user-package-conf'
'--package-conf=/path/to/.cabal-sandbox/i386-linux-ghc-7.4.2-packages.conf.d'
'list'
[...]</code></pre>
<h2 id=\"for-the-users-of-cabal-dev\">For the users of cabal-dev</h2>
<p>The sandbox feature gives you basically the same functionality as <code>cabal-dev</code>, but integrated with the <code>cabal</code> tool itself. Here’s a handy cheatsheet for the users of <code>cabal-dev</code>:</p>
<table>
<tbody>
<tr class=\"odd\">
<td style=\"text-align: left;\">Action</td>
<td style=\"text-align: left;\"><code>cabal-dev</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">——————————————-</td>
<td style=\"text-align: left;\">—————————–</td>
<td style=\"text-align: left;\">—————————————</td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Initialise a sandbox</td>
<td style=\"text-align: left;\"><code>cabal-dev $ANY_COMMAND</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox init</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Delete the sandbox</td>
<td style=\"text-align: left;\"><code>rm -rf ./cabal-dev</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox delete</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Link a source directory from the sandbox</td>
<td style=\"text-align: left;\"><code>N/A</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox add-source</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Make a package available in the sandbox</td>
<td style=\"text-align: left;\"><code>cabal-dev add-source</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox add-source --snapshot</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Build the current package</td>
<td style=\"text-align: left;\"><code>cabal-dev build</code></td>
<td style=\"text-align: left;\"><code>cabal build</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Install a package into the sandbox</td>
<td style=\"text-align: left;\"><code>cabal-dev install $PKGNAME</code></td>
<td style=\"text-align: left;\"><code>cabal install $PKGNAME</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Any other standard <code>cabal</code> command</td>
<td style=\"text-align: left;\"><code>cabal-dev $COMMAND</code></td>
<td style=\"text-align: left;\"><code>cabal $COMMAND</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Install dependencies of a package</td>
<td style=\"text-align: left;\"><code>cabal-dev install-deps</code></td>
<td style=\"text-align: left;\"><code>cabal install --only-dependencies</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Run sandbox-local ghci</td>
<td style=\"text-align: left;\"><code>cabal-dev ghci</code></td>
<td style=\"text-align: left;\"><code>cabal repl</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Sandbox-restricted <code>ghc-pkg</code></td>
<td style=\"text-align: left;\"><code>cabal-dev ghc-pkg</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox hc-pkg</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Path to the sandbox directory</td>
<td style=\"text-align: left;\"><code>./cabal-dev</code></td>
<td style=\"text-align: left;\"><code>./.cabal-sandbox</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">——————————————-</td>
<td style=\"text-align: left;\">——————————</td>
<td style=\"text-align: left;\">—————————————</td>
</tr>
</tbody>
</table>
<p>One important difference is that <code>add-source</code> adds a link to a source directory instead of making a source snapshot available for install. The add-source packages are reinstalled each time the sandboxed package is built. To get <code>cabal-dev</code>’s behaviour, use <code>cabal add-source --snapshot</code>.</p>
<p>Another difference is that sandboxes are constrained to be consistent - that is, destructively reinstalling a package (like in the introduction example) is not allowed. Installing multiple versions of a package is still fine.</p>
<h2 id=\"future-work\">Future work</h2>
<p>In the future, we want to <a href=\"http://blog.johantibell.com/2012/03/cabal-of-my-dreams.html\">make hermetic builds the default</a> - that is, the build system should work as if all build artifacts were rebuilt anew each time. Ideally, this feature would be built on top of a purely functional <a href=\"http://nixos.org/nixos/\">Nix</a>-like package DB, which would allow to share build artifacts between different builds without worrying about the destructive update problem outlined in the introduction. Unfortunately, this is a large and a non-trivial project, although some work <a href=\"http://www.youtube.com/watch?v=h4QmkyN28Qs\">has already been done in this direction</a>. A possible interim solution is to run each build in its own sandbox.</p>
<p>There is also a number of relatively minor UI issues with sandboxes which were postponed until the next release (1.20). For more details on this, see the <a href=\"https://github.com/haskell/cabal/issues?labels=&milestone=21&page=1&state=open\">Cabal bug tracker</a>.</p>
<p>Last but not least, we’re really interested in your feedback on this feature, especially in how well it works on large-scale projects.</p>
<h2 id=\"acknowledgements\">Acknowledgements</h2>
<p>Thanks to Johan Tibell, Duncan Coutts and Andres Löh for code reviews and guidance, and to Google for paying me for working on this project during last summer. Thanks to Rogan Creswick for writing the original <code>cabal-dev</code> tool, which this work builds upon.</p>" nil nil "313775008e4a1cce77fa871fefd374c5") (418 (21012 29814 179297) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_7312\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_4441\"></span> time, whereas using the categorical functor takes time <span id=\"tex_3574\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_3467\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "48bdf234967eca03ef81e3e23d45f1f1") (417 (21011 39794 470193) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_2438\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_1794\"></span> time, whereas using the categorical functor takes time <span id=\"tex_5685\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_5242\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "f785ff1c2aa4f18e4e6fbfe3191649ae") (416 (21011 32994 669904) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_4836\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_5851\"></span> time, whereas using the categorical functor takes time <span id=\"tex_5142\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_3899\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "40ab0b782d20f62c2c710f0735d0ffd0") (415 (21011 25075 688938) "http://coldwa.st/e/blog/2013-08-20-Cabal-sandbox.html" "Mikhail Glushenkov: An Introduction to Cabal sandboxes" nil "Tue, 20 Aug 2013 00:00:00 +0000" "<p>This post describes sandboxes, a new feature of <code>cabal</code> that will be present in the 1.18 release. Sandboxes allow to build packages in isolation by creating a private package environment for each package. If you are familiar with Python’s virtualenv or Ruby’s RVM, this is a Haskell analogue. Though 1.18 is still not out yet, you can already experiment with the new features by building <code>cabal</code> from Git. This post is mainly aimed at people new to sandboxes – if you have already used <code>cabal-dev</code>, feel free to <a href=\"http://feeds.feedburner.com/ChurningAndChurning#for-the-users-of-cabal-dev\">skip the introductory sections</a>.</p>
<h2 id=\"building-cabal-from-git\">Building Cabal from git</h2>
<p>Assuming you already have a previous version of <code>cabal</code> installed:</p>
<pre><code>$ git clone git://github.com/haskell/cabal.git /path/to/cabal
$ cd /path/to/cabal
$ cabal install Cabal/ cabal-install/</code></pre>
<p>That’s all! Now you have the latest version of the <code>cabal</code> tool installed under <code>~/.cabal/bin</code>.</p>
<h2 id=\"what-are-sandboxes-and-why-are-they-needed\">What are sandboxes and why are they needed?</h2>
<p>If you have used Haskell for some time, you’ve probably heard the expression “Cabal hell”. It refers to the fact that installing a new package with <code>cabal install</code> can break existing packages on your system.</p>
<p>The reason for this behaviour is <em>destructive reinstalls</em>. As of this writing, Cabal doesn’t support having <em>multiple instances</em> of the same version of a single package installed simultaneously (but note that installing <em>multiple versions</em> of the same package is completely fine). So how does this affect you, the user?</p>
<p>Imagine that you have installed the library <code>foo</code>, which depends on <code>bar-1.0</code>, which in turn depends on <code>baz</code> (any version):</p>
<figure>
<img src=\"http://feeds.feedburner.com/e/img/sandboxes-pic-0.png\" title=\"foo-1.0 -> bar-1.0 -> baz-1.0;\" />
</figure>
<p>After some time you then decide to install <code>quux</code>, which depends on <code>bar-1.0</code> and <code>baz-2.0</code>. Since you have only <code>baz-1.0</code> installed, you need to install <code>baz-2.0</code> and recompile <code>bar-1.0</code> against it:</p>
<figure>
<img src=\"http://feeds.feedburner.com/e/img/sandboxes-pic-1.png\" title=\"quux-1.0 -> bar-1.0; quux-1.0 -> baz-2.0; bar -> baz-2.0;\" />
</figure>
<p>But since Cabal allows you to have only a single instance of <code>bar-1.0</code> installed, the package <code>foo-1.0</code> is now broken since it depends on an instance of package <code>bar-1.0</code> that was removed! Cue much weeping and gnashing of teeth:</p>
<figure>
<img src=\"http://feeds.feedburner.com/e/img/sandboxes-pic-2.png\" title=\"foo-1.0 -> ???; baz-1.0;\" />
</figure>
<p>While we know what is the right way to fix this issue (see the <a href=\"http://feeds.feedburner.com/ChurningAndChurning#future-work\">“future work”</a> section below), getting there will take time, and sandboxes present a relatively low-cost interim solution. The idea is to build each package in an isolated environment (“sandbox”) with a sandbox-local package database. Because sandboxes are per-project, we can constrain them to be internally consistent and simply prohibit such conflicts as described above.</p>
<p>Besides alleviating the “Cabal hell” problem, sandboxes are also useful when your package depends on patched or unreleased libraries.</p>
<h2 id=\"usage\">Usage</h2>
<p>Using sandboxes is simple: if you already know how to use the <code>cabal</code> tool to build your packages, you only need to learn a few additional commands. To initialise a fresh sandbox in the current directory, run <code>cabal sandbox init</code>. All subsequent commands (such as <code>build</code> and <code>install</code>) from this point will use the sandbox.</p>
<pre><code>$ cd /path/to/my/haskell/library
$ cabal sandbox init                   # Initialise the sandbox
$ cabal install --only-dependencies    # Install dependencies into the sandbox
$ cabal build                          # Build your package inside the sandbox</code></pre>
<p>It can be useful to make a source package available for installation in the sandbox - for example, if your package depends on a patched or an unreleased version of a library. This can be done with the <code>cabal sandbox add-source</code> command - think of it as “local Hackage”. If an add-source dependency is later modified, it is reinstalled automatically.</p>
<pre><code>$ cabal sandbox add-source /my/patched/library # Add a new add-source dependency
$ cabal install --dependencies-only            # Install it into the sandbox
$ cabal build                                  # Build the local package
$ $EDITOR /my/patched/library/Source.hs        # Modify the add-source dependency
$ cabal build                                  # Modified dependency is automatically reinstalled</code></pre>
<p>Normally, the sandbox settings (such as optimisation level) are inherited from the main Cabal config file (<code>$HOME/cabal/config</code>). Sometimes, though, you need to change some settings specifically for a single sandbox. You can do this by creating a <code>cabal.config</code> file in the same directory with your <code>cabal.sandbox.config</code> (which was created by <code>sandbox init</code>). This file has the same syntax as the main Cabal config file.</p>
<pre><code>$ cat cabal.config
documentation: True
constraints: foo == 1.0, bar >= 2.0, baz
$ cabal build                                  # Uses settings from the cabal.config file</code></pre>
<p>When you have decided that you no longer want to build your package inside a sandbox, just delete it:</p>
<pre><code>$ cabal sandbox delete                       # Built-in command
$ rm -rf .cabal-sandbox cabal.sandbox.config # Alternative manual method</code></pre>
<h2 id=\"advanced-usage\">Advanced usage</h2>
<p>The default behaviour of the <code>add-source</code> command is to track modifications done to the added dependency and reinstall the sandbox copy of the package when needed. Sometimes this is not desirable: in these cases you can use <code>add-source --snapshot</code>, which disables the change tracking. In addition to <code>add-source</code>, there are also <code>list-sources</code> and <code>delete-source</code> commands.</p>
<p>Sometimes one wants to share a single sandbox between multiple packages. This can be easily done with the <code>--sandbox</code> option:</p>
<pre><code>$ cd /path/to/shared-sandbox
$ cabal sandbox init
$ cd /path/to/package-a
$ cabal sandbox init --sandbox /path/to/shared-sandbox
$ cd /path/to/package-b
$ cabal sandbox init --sandbox /path/to/shared-sandbox</code></pre>
<p>Using multiple different versions of GHC simultaneously is also supported, via the <code>-w</code> option:</p>
<pre><code>$ cabal sandbox init
$ cabal install --only-dependencies -w /path/to/ghc-1 # Install dependencies for both compilers
$ cabal install --only-dependencies -w /path/to/ghc-2
$ cabal configure -w /path/to/ghc-1                   # Build with the first compiler
$ cabal build
$ cabal configure -w /path/to/ghc-2                   # Build with the second compiler
$ cabal build</code></pre>
<p>It can be occasionally useful to run the <code>ghc-pkg</code> tool on the sandbox package DB directly (for example, you may need to unregister some packages). The command <code>cabal sandbox hc-pkg</code> is a convenient wrapper for <code>ghc-pkg</code> that runs it with the appropriate <code>--package-conf</code> argument:</p>
<pre><code>$ cabal -v sandbox hc-pkg list
Using a sandbox located at /path/to/.cabal-sandbox
'ghc-pkg' '--global' '--no-user-package-conf'
'--package-conf=/path/to/.cabal-sandbox/i386-linux-ghc-7.4.2-packages.conf.d'
'list'
[...]</code></pre>
<h2 id=\"for-the-users-of-cabal-dev\">For the users of cabal-dev</h2>
<p>The sandbox feature gives you basically the same functionality as <code>cabal-dev</code>, but integrated with the <code>cabal</code> tool itself. Here’s a handy cheatsheet for the users of <code>cabal-dev</code>:</p>
<table>
<tbody>
<tr class=\"odd\">
<td style=\"text-align: left;\">Action</td>
<td style=\"text-align: left;\"><code>cabal-dev</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">——————————————-</td>
<td style=\"text-align: left;\">—————————–</td>
<td style=\"text-align: left;\">—————————————</td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Initialise a sandbox</td>
<td style=\"text-align: left;\"><code>cabal-dev $ANY_COMMAND</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox init</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Delete the sandbox</td>
<td style=\"text-align: left;\"><code>rm -rf ./cabal-dev</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox delete</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Link a source directory from the sandbox</td>
<td style=\"text-align: left;\"><code>N/A</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox add-source</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Make a package available in the sandbox</td>
<td style=\"text-align: left;\"><code>cabal-dev add-source</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox add-source --snapshot</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Build the current package</td>
<td style=\"text-align: left;\"><code>cabal-dev build</code></td>
<td style=\"text-align: left;\"><code>cabal build</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Install a package into the sandbox</td>
<td style=\"text-align: left;\"><code>cabal-dev install $PKGNAME</code></td>
<td style=\"text-align: left;\"><code>cabal install $PKGNAME</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Any other standard <code>cabal</code> command</td>
<td style=\"text-align: left;\"><code>cabal-dev $COMMAND</code></td>
<td style=\"text-align: left;\"><code>cabal $COMMAND</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Install dependencies of a package</td>
<td style=\"text-align: left;\"><code>cabal-dev install-deps</code></td>
<td style=\"text-align: left;\"><code>cabal install --only-dependencies</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Run sandbox-local ghci</td>
<td style=\"text-align: left;\"><code>cabal-dev ghci</code></td>
<td style=\"text-align: left;\"><code>cabal repl</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Sandbox-restricted <code>ghc-pkg</code></td>
<td style=\"text-align: left;\"><code>cabal-dev ghc-pkg</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox hc-pkg</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Path to the sandbox directory</td>
<td style=\"text-align: left;\"><code>./cabal-dev</code></td>
<td style=\"text-align: left;\"><code>./.cabal-sandbox</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">——————————————-</td>
<td style=\"text-align: left;\">——————————</td>
<td style=\"text-align: left;\">—————————————</td>
</tr>
</tbody>
</table>
<p>One important difference is that <code>add-source</code> adds a link to a source directory instead of making a source snapshot available for install. The add-source packages are reinstalled each time the sandboxed package is built. To get <code>cabal-dev</code>’s behaviour, use <code>cabal add-source --snapshot</code>.</p>
<p>Another difference is that sandboxes are constrained to be consistent - that is, destructively reinstalling a package (like in the introduction example) is not allowed. Installing multiple versions of a package is still fine.</p>
<h2 id=\"future-work\">Future work</h2>
<p>In the future, we want to <a href=\"http://blog.johantibell.com/2012/03/cabal-of-my-dreams.html\">make hermetic builds the default</a> - that is, the build system should work as if all build artifacts were rebuilt anew each time. Ideally, this feature would be built on top of a purely functional <a href=\"http://nixos.org/nixos/\">Nix</a>-like package DB, which would allow to share build artifacts between different builds without worrying about the destructive update problem outlined in the introduction. Unfortunately, this is a large and a non-trivial project, although some work <a href=\"http://www.youtube.com/watch?v=h4QmkyN28Qs\">has already been done in this direction</a>. A possible interim solution is to run each build in its own sandbox.</p>
<p>There is also a number of relatively minor UI issues with sandboxes which were postponed until the next release (1.20). For more details on this, see the <a href=\"https://github.com/haskell/cabal/issues?labels=&milestone=21&page=1&state=open\">Cabal bug tracker</a>.</p>
<p>Last but not least, we’re really interested in your feedback on this feature, especially in how well it works on large-scale projects.</p>
<h2 id=\"acknowledgements\">Acknowledgements</h2>
<p>Thanks to Johan Tibell, Duncan Coutts and Andres Löh for code reviews and guidance, and to Google for paying me for working on this project during last summer.</p>" nil nil "503484f21e4828d035b910d0422b2da0") (414 (21011 17699 838453) "http://coldwa.st/e/blog/2013-08-20-Cabal-sandbox.html" "Mikhail Glushenkov: An Introduction to Cabal sandboxes" nil "Tue, 20 Aug 2013 00:00:00 +0000" "<p>This post describes sandboxes, a new feature of <code>cabal</code> that will be present in the 1.18 release. Sandboxes allow to build packages in isolation by creating a private package environment for each package. If you are familiar with Python’s virtualenv or Ruby’s RVM, this is a Haskell analogue. Though 1.18 is still not out yet, you can already experiment with the new features by building <code>cabal</code> from Git. This post is mainly aimed at people new to sandboxes – if you have already used <code>cabal-dev</code>, feel free to <a href=\"http://feeds.feedburner.com/ChurningAndChurning#for-the-users-of-cabal-dev\">skip the introductory sections</a>.</p>
<h2 id=\"building-cabal-from-git\">Building Cabal from git</h2>
<p>The recommended method of bootstrapping the Git version of the <code>cabal</code> tool is by using <code>cabal-dev</code>. Assuming you already have a previous version of <code>cabal</code> installed:</p>
<pre><code>$ git clone git://github.com/haskell/cabal.git /path/to/cabal
$ cd /path/to/cabal
$ cabal install Cabal/ cabal-install/</code></pre>
<p>That’s all! Now you have the latest version of the <code>cabal</code> tool installed under <code>~/.cabal/bin</code>.</p>
<h2 id=\"what-are-sandboxes-and-why-are-they-needed\">What are sandboxes and why are they needed?</h2>
<p>If you have used Haskell for some time, you’ve probably heard the expression “Cabal hell”. It refers to the fact that installing a new package with <code>cabal install</code> can break existing packages on your system.</p>
<p>The reason for this behaviour is <em>destructive reinstalls</em>. As of this writing, Cabal doesn’t support having <em>multiple instances</em> of the same version of a single package installed simultaneously (but note that installing <em>multiple versions</em> of the same package is completely fine). So how does this affect you, the user?</p>
<p>Imagine that you have installed the library <code>foo</code>, which depends on <code>bar-1.0</code>, which in turn depends on <code>baz</code> (any version):</p>
<figure>
<img src=\"http://feeds.feedburner.com/e/img/sandboxes-pic-0.png\" title=\"foo-1.0 -> bar-1.0 -> baz-1.0;\" />
</figure>
<p>After some time you then decide to install <code>quux</code>, which depends on <code>bar-1.0</code> and <code>baz-2.0</code>. Since you have only <code>baz-1.0</code> installed, you need to install <code>baz-2.0</code> and recompile <code>bar-1.0</code> against it:</p>
<figure>
<img src=\"http://feeds.feedburner.com/e/img/sandboxes-pic-1.png\" title=\"quux-1.0 -> bar-1.0; quux-1.0 -> baz-2.0; bar -> baz-2.0;\" />
</figure>
<p>But since Cabal allows you to have only a single instance of <code>bar-1.0</code> installed, the package <code>foo-1.0</code> is now broken since it depends on an instance of package <code>bar-1.0</code> that was removed! Cue much weeping and gnashing of teeth:</p>
<figure>
<img src=\"http://feeds.feedburner.com/e/img/sandboxes-pic-2.png\" title=\"foo-1.0 -> ???; baz-1.0;\" />
</figure>
<p>While we know what is the right way to fix this issue (see the <a href=\"http://feeds.feedburner.com/ChurningAndChurning#future-work\">“future work”</a> section below), getting there will take time, and sandboxes present a relatively low-cost interim solution. The idea is to build each package in an isolated environment (“sandbox”) with a sandbox-local package database. Because sandboxes are per-project, we can constrain them to be internally consistent and simply prohibit such conflicts as described above.</p>
<p>Besides alleviating the “Cabal hell” problem, sandboxes are also useful when your package depends on patched or unreleased libraries.</p>
<h2 id=\"usage\">Usage</h2>
<p>Using sandboxes is simple: if you already know how to use the <code>cabal</code> tool to build your packages, you only need to learn a few additional commands. To initialise a fresh sandbox in the current directory, run <code>cabal sandbox init</code>. All subsequent commands (such as <code>build</code> and <code>install</code>) from this point will use the sandbox.</p>
<pre><code>$ cd /path/to/my/haskell/library
$ cabal sandbox init                   # Initialise the sandbox
$ cabal install --only-dependencies    # Install dependencies into the sandbox
$ cabal build                          # Build your package inside the sandbox</code></pre>
<p>It can be useful to make a source package available for installation in the sandbox - for example, if your package depends on a patched or an unreleased version of a library. This can be done with the <code>cabal sandbox add-source</code> command - think of it as “local Hackage”. If an add-source dependency is later modified, it is reinstalled automatically.</p>
<pre><code>$ cabal sandbox add-source /my/patched/library # Add a new add-source dependency
$ cabal install --dependencies-only            # Install it into the sandbox
$ cabal build                                  # Build the local package
$ $EDITOR /my/patched/library/Source.hs        # Modify the add-source dependency
$ cabal build                                  # Modified dependency is automatically reinstalled</code></pre>
<p>Normally, the sandbox settings (such as optimisation level) are inherited from the main Cabal config file (<code>$HOME/cabal/config</code>). Sometimes, though, you need to change some settings specifically for a single sandbox. You can do this by creating a <code>cabal.config</code> file in the same directory with your <code>cabal.sandbox.config</code> (which was created by <code>sandbox init</code>). This file has the same syntax as the main Cabal config file.</p>
<pre><code>$ cat cabal.config
documentation: True
constraints: foo == 1.0, bar >= 2.0, baz
$ cabal build                                  # Uses settings from the cabal.config file</code></pre>
<p>When you have decided that you no longer want to build your package inside a sandbox, just delete it:</p>
<pre><code>$ cabal sandbox delete                       # Built-in command
$ rm -rf .cabal-sandbox cabal.sandbox.config # Alternative manual method</code></pre>
<h2 id=\"advanced-usage\">Advanced usage</h2>
<p>The default behaviour of the <code>add-source</code> command is to track modifications done to the added dependency and reinstall the sandbox copy of the package when needed. Sometimes this is not desirable: in these cases you can use <code>add-source --snapshot</code>, which disables the change tracking. In addition to <code>add-source</code>, there are also <code>list-sources</code> and <code>delete-source</code> commands.</p>
<p>Sometimes one wants to share a single sandbox between multiple packages. This can be easily done with the <code>--sandbox</code> option:</p>
<pre><code>$ cd /path/to/shared-sandbox
$ cabal sandbox init
$ cd /path/to/package-a
$ cabal sandbox init --sandbox /path/to/shared-sandbox
$ cd /path/to/package-b
$ cabal sandbox init --sandbox /path/to/shared-sandbox</code></pre>
<p>Using multiple different versions of GHC simultaneously is also supported, via the <code>-w</code> option:</p>
<pre><code>$ cabal sandbox init
$ cabal install --only-dependencies -w /path/to/ghc-1 # Install dependencies for both compilers
$ cabal install --only-dependencies -w /path/to/ghc-2
$ cabal configure -w /path/to/ghc-1                   # Build with the first compiler
$ cabal build
$ cabal configure -w /path/to/ghc-2                   # Build with the second compiler
$ cabal build</code></pre>
<p>It can be occasionally useful to run the <code>ghc-pkg</code> tool on the sandbox package DB directly (for example, you may need to unregister some packages). The command <code>cabal sandbox hc-pkg</code> is a convenient wrapper for <code>ghc-pkg</code> that runs it with the appropriate <code>--package-conf</code> argument:</p>
<pre><code>$ cabal -v sandbox hc-pkg list
Using a sandbox located at /path/to/.cabal-sandbox
'ghc-pkg' '--global' '--no-user-package-conf'
'--package-conf=/path/to/.cabal-sandbox/i386-linux-ghc-7.4.2-packages.conf.d'
'list'
[...]</code></pre>
<h2 id=\"for-the-users-of-cabal-dev\">For the users of cabal-dev</h2>
<p>The sandbox feature gives you basically the same functionality as <code>cabal-dev</code>, but integrated with the <code>cabal</code> tool itself. Here’s a handy cheatsheet for the users of <code>cabal-dev</code>:</p>
<table>
<tbody>
<tr class=\"odd\">
<td style=\"text-align: left;\">Action</td>
<td style=\"text-align: left;\"><code>cabal-dev</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">——————————————-</td>
<td style=\"text-align: left;\">—————————–</td>
<td style=\"text-align: left;\">—————————————</td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Initialise a sandbox</td>
<td style=\"text-align: left;\"><code>cabal-dev $ANY_COMMAND</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox init</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Delete the sandbox</td>
<td style=\"text-align: left;\"><code>rm -rf ./cabal-dev</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox delete</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Link a source directory from the sandbox</td>
<td style=\"text-align: left;\"><code>N/A</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox add-source</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Make a package available in the sandbox</td>
<td style=\"text-align: left;\"><code>cabal-dev add-source</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox add-source --snapshot</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Build the current package</td>
<td style=\"text-align: left;\"><code>cabal-dev build</code></td>
<td style=\"text-align: left;\"><code>cabal build</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Install a package into the sandbox</td>
<td style=\"text-align: left;\"><code>cabal-dev install $PKGNAME</code></td>
<td style=\"text-align: left;\"><code>cabal install $PKGNAME</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Any other standard <code>cabal</code> command</td>
<td style=\"text-align: left;\"><code>cabal-dev $COMMAND</code></td>
<td style=\"text-align: left;\"><code>cabal $COMMAND</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Install dependencies of a package</td>
<td style=\"text-align: left;\"><code>cabal-dev install-deps</code></td>
<td style=\"text-align: left;\"><code>cabal install --only-dependencies</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Run sandbox-local ghci</td>
<td style=\"text-align: left;\"><code>cabal-dev ghci</code></td>
<td style=\"text-align: left;\"><code>cabal repl</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Sandbox-restricted <code>ghc-pkg</code></td>
<td style=\"text-align: left;\"><code>cabal-dev ghc-pkg</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox hc-pkg</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Path to the sandbox directory</td>
<td style=\"text-align: left;\"><code>./cabal-dev</code></td>
<td style=\"text-align: left;\"><code>./.cabal-sandbox</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">——————————————-</td>
<td style=\"text-align: left;\">——————————</td>
<td style=\"text-align: left;\">—————————————</td>
</tr>
</tbody>
</table>
<p>One important difference is that <code>add-source</code> adds a link to a source directory instead of making a source snapshot available for install. The add-source packages are reinstalled each time the sandboxed package is built. To get <code>cabal-dev</code>’s behaviour, use <code>cabal add-source --snapshot</code>.</p>
<p>Another difference is that sandboxes are constrained to be consistent - that is, destructively reinstalling a package (like in the introduction example) is not allowed. Installing multiple versions of a package is still fine.</p>
<h2 id=\"future-work\">Future work</h2>
<p>In the future, we want to <a href=\"http://blog.johantibell.com/2012/03/cabal-of-my-dreams.html\">make hermetic builds the default</a> - that is, the build system should work as if all build artifacts were rebuilt anew each time. Ideally, this feature would be built on top of a purely functional <a href=\"http://nixos.org/nixos/\">Nix</a>-like package DB, which would allow to share build artifacts between different builds without worrying about the destructive update problem outlined in the introduction. Unfortunately, this is a large and a non-trivial project, although some work <a href=\"http://www.youtube.com/watch?v=h4QmkyN28Qs\">has already been done in this direction</a>. A possible interim solution is to run each build in its own sandbox.</p>
<p>There is also a number of relatively minor UI issues with sandboxes which were postponed until the next release (1.20). For more details on this, see the <a href=\"https://github.com/haskell/cabal/issues?labels=&milestone=21&page=1&state=open\">Cabal bug tracker</a>.</p>
<p>Last but not least, we’re really interested in your feedback on this feature, especially in how well it works on large-scale projects.</p>
<h2 id=\"acknowledgements\">Acknowledgements</h2>
<p>Thanks to Johan Tibell, Duncan Coutts and Andres Löh for code reviews and guidance, and to Google for paying me for working on this project during last summer.</p>" nil nil "3aa15e056e466fe083683033419912ab") (413 (21011 14227 668075) "http://coldwa.st/e/blog/2013-08-20-Cabal-sandbox.html" "Mikhail Glushenkov: An Introduction to Cabal sandboxes" nil "Tue, 20 Aug 2013 00:00:00 +0000" "<p>This post describes sandboxes, a new feature of <code>cabal</code> that will be present in the 1.18 release. Sandboxes allow to build packages in isolation by creating a private package environment for each package. If you are familiar with Python’s virtualenv or Ruby’s RVM, this is a Haskell analogue. Though 1.18 is still not out yet, you can already experiment with the new features by building <code>cabal</code> from Git. This post is mainly aimed at people new to sandboxes – if you have already used <code>cabal-dev</code>, feel free to <a href=\"http://feeds.feedburner.com/ChurningAndChurning#for-the-users-of-cabal-dev\">skip the introductory sections</a>.</p>
<h2 id=\"building-cabal-from-git\">Building Cabal from git</h2>
<p>The recommended method of bootstrapping the Git version of the <code>cabal</code> tool is by using <code>cabal-dev</code>. Assuming you already have a previous version of <code>cabal</code> installed:</p>
<pre><code>$ git clone git://github.com/haskell/cabal.git /path/to/cabal
$ cd /path/to/cabal/cabal-install
$ cabal install Cabal/ cabal-install/</code></pre>
<p>That’s all! Now you have the latest version of the <code>cabal</code> tool installed under <code>~/.cabal/bin</code>.</p>
<h2 id=\"what-are-sandboxes-and-why-are-they-needed\">What are sandboxes and why are they needed?</h2>
<p>If you have used Haskell for some time, you’ve probably heard the expression “Cabal hell”. It refers to the fact that installing a new package with <code>cabal install</code> can break existing packages on your system.</p>
<p>The reason for this behaviour is <em>destructive reinstalls</em>. As of this writing, Cabal doesn’t support having <em>multiple instances</em> of the same version of a single package installed simultaneously (but note that installing <em>multiple versions</em> of the same package is completely fine). So how does this affect you, the user?</p>
<p>Imagine that you have installed the library <code>foo</code>, which depends on <code>bar-1.0</code>, which in turn depends on <code>baz</code> (any version):</p>
<figure>
<img src=\"http://feeds.feedburner.com/e/img/sandboxes-pic-0.png\" title=\"foo-1.0 -> bar-1.0 -> baz-1.0;\" />
</figure>
<p>After some time you then decide to install <code>quux</code>, which depends on <code>bar-1.0</code> and <code>baz-2.0</code>. Since you have only <code>baz-1.0</code> installed, you need to install <code>baz-2.0</code> and recompile <code>bar-1.0</code> against it:</p>
<figure>
<img src=\"http://feeds.feedburner.com/e/img/sandboxes-pic-1.png\" title=\"quux-1.0 -> bar-1.0; quux-1.0 -> baz-2.0; bar -> baz-2.0;\" />
</figure>
<p>But since Cabal allows you to have only a single instance of <code>bar-1.0</code> installed, the package <code>foo-1.0</code> is now broken since it depends on an instance of package <code>bar-1.0</code> that was removed! Cue much weeping and gnashing of teeth:</p>
<figure>
<img src=\"http://feeds.feedburner.com/e/img/sandboxes-pic-2.png\" title=\"foo-1.0 -> ???; baz-1.0;\" />
</figure>
<p>While we know what is the right way to fix this issue (see the <a href=\"http://feeds.feedburner.com/ChurningAndChurning#future-work\">“future work”</a> section below), getting there will take time, and sandboxes present a relatively low-cost interim solution. The idea is to build each package in an isolated environment (“sandbox”) with a sandbox-local package database. Because sandboxes are per-project, we can constrain them to be internally consistent and simply prohibit such conflicts as described above.</p>
<p>Besides alleviating the “Cabal hell” problem, sandboxes are also useful when your package depends on patched or unreleased libraries.</p>
<h2 id=\"usage\">Usage</h2>
<p>Using sandboxes is simple: if you already know how to use the <code>cabal</code> tool to build your packages, you only need to learn a few additional commands. To initialise a fresh sandbox in the current directory, run <code>cabal sandbox init</code>. All subsequent commands (such as <code>build</code> and <code>install</code>) from this point will use the sandbox.</p>
<pre><code>$ cd /path/to/my/haskell/library
$ cabal sandbox init                   # Initialise the sandbox
$ cabal install --only-dependencies    # Install dependencies into the sandbox
$ cabal build                          # Build your package inside the sandbox</code></pre>
<p>It can be useful to make a source package available for installation in the sandbox - for example, if your package depends on a patched or an unreleased version of a library. This can be done with the <code>cabal sandbox add-source</code> command - think of it as “local Hackage”. If an add-source dependency is later modified, it is reinstalled automatically.</p>
<pre><code>$ cabal sandbox add-source /my/patched/library # Add a new add-source dependency
$ cabal install --dependencies-only            # Install it into the sandbox
$ cabal build                                  # Build the local package
$ $EDITOR /my/patched/library/Source.hs        # Modify the add-source dependency
$ cabal build                                  # Modified dependency is automatically reinstalled</code></pre>
<p>Normally, the sandbox settings (such as optimisation level) are inherited from the main Cabal config file (<code>$HOME/cabal/config</code>). Sometimes, though, you need to change some settings specifically for a single sandbox. You can do this by creating a <code>cabal.config</code> file in the same directory with your <code>cabal.sandbox.config</code> (which was created by <code>sandbox init</code>). This file has the same syntax as the main Cabal config file.</p>
<pre><code>$ cat cabal.config
documentation: True
constraints: foo == 1.0, bar >= 2.0, baz
$ cabal build                                  # Uses settings from the cabal.config file</code></pre>
<p>When you have decided that you no longer want to build your package inside a sandbox, just delete it:</p>
<pre><code>$ cabal sandbox delete                       # Built-in command
$ rm -rf .cabal-sandbox cabal.sandbox.config # Alternative manual method</code></pre>
<h2 id=\"advanced-usage\">Advanced usage</h2>
<p>The default behaviour of the <code>add-source</code> command is to track modifications done to the added dependency and reinstall the sandbox copy of the package when needed. Sometimes this is not desirable: in these cases you can use <code>add-source --snapshot</code>, which disables the change tracking. In addition to <code>add-source</code>, there are also <code>list-sources</code> and <code>delete-source</code> commands.</p>
<p>Sometimes one wants to share a single sandbox between multiple packages. This can be easily done with the <code>--sandbox</code> option:</p>
<pre><code>$ cd /path/to/shared-sandbox
$ cabal sandbox init
$ cd /path/to/package-a
$ cabal sandbox init --sandbox /path/to/shared-sandbox
$ cd /path/to/package-b
$ cabal sandbox init --sandbox /path/to/shared-sandbox</code></pre>
<p>Using multiple different versions of GHC simultaneously is also supported, via the <code>-w</code> option:</p>
<pre><code>$ cabal sandbox init
$ cabal install --only-dependencies -w /path/to/ghc-1 # Install dependencies for both compilers
$ cabal install --only-dependencies -w /path/to/ghc-2
$ cabal configure -w /path/to/ghc-1                   # Build with the first compiler
$ cabal build
$ cabal configure -w /path/to/ghc-2                   # Build with the second compiler
$ cabal build</code></pre>
<p>It can be occasionally useful to run the <code>ghc-pkg</code> tool on the sandbox package DB directly (for example, you may need to unregister some packages). The command <code>cabal sandbox hc-pkg</code> is a convenient wrapper for <code>ghc-pkg</code> that runs it with the appropriate <code>--package-conf</code> argument:</p>
<pre><code>$ cabal -v sandbox hc-pkg list
Using a sandbox located at /path/to/.cabal-sandbox
'ghc-pkg' '--global' '--no-user-package-conf'
'--package-conf=/path/to/.cabal-sandbox/i386-linux-ghc-7.4.2-packages.conf.d'
'list'
[...]</code></pre>
<h2 id=\"for-the-users-of-cabal-dev\">For the users of cabal-dev</h2>
<p>The sandbox feature gives you basically the same functionality as <code>cabal-dev</code>, but integrated with the <code>cabal</code> tool itself. Here’s a handy cheatsheet for the users of <code>cabal-dev</code>:</p>
<table>
<tbody>
<tr class=\"odd\">
<td style=\"text-align: left;\">Action</td>
<td style=\"text-align: left;\"><code>cabal-dev</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">——————————————-</td>
<td style=\"text-align: left;\">—————————–</td>
<td style=\"text-align: left;\">—————————————</td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Initialise a sandbox</td>
<td style=\"text-align: left;\"><code>cabal-dev $ANY_COMMAND</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox init</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Delete the sandbox</td>
<td style=\"text-align: left;\"><code>rm -rf ./cabal-dev</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox delete</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Link a source directory from the sandbox</td>
<td style=\"text-align: left;\"><code>N/A</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox add-source</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Make a package available in the sandbox</td>
<td style=\"text-align: left;\"><code>cabal-dev add-source</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox add-source --snapshot</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Build the current package</td>
<td style=\"text-align: left;\"><code>cabal-dev build</code></td>
<td style=\"text-align: left;\"><code>cabal build</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Install a package into the sandbox</td>
<td style=\"text-align: left;\"><code>cabal-dev install $PKGNAME</code></td>
<td style=\"text-align: left;\"><code>cabal install $PKGNAME</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Any other standard <code>cabal</code> command</td>
<td style=\"text-align: left;\"><code>cabal-dev $COMMAND</code></td>
<td style=\"text-align: left;\"><code>cabal $COMMAND</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Install dependencies of a package</td>
<td style=\"text-align: left;\"><code>cabal-dev install-deps</code></td>
<td style=\"text-align: left;\"><code>cabal install --only-dependencies</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Run sandbox-local ghci</td>
<td style=\"text-align: left;\"><code>cabal-dev ghci</code></td>
<td style=\"text-align: left;\"><code>cabal repl</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Sandbox-restricted <code>ghc-pkg</code></td>
<td style=\"text-align: left;\"><code>cabal-dev ghc-pkg</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox hc-pkg</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Path to the sandbox directory</td>
<td style=\"text-align: left;\"><code>./cabal-dev</code></td>
<td style=\"text-align: left;\"><code>./.cabal-sandbox</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">——————————————-</td>
<td style=\"text-align: left;\">——————————</td>
<td style=\"text-align: left;\">—————————————</td>
</tr>
</tbody>
</table>
<p>One important difference is that <code>add-source</code> adds a link to a source directory instead of making a source snapshot available for install. The add-source packages are reinstalled each time the sandboxed package is built. To get <code>cabal-dev</code>’s behaviour, use <code>cabal add-source --snapshot</code>.</p>
<p>Another difference is that sandboxes are constrained to be consistent - that is, destructively reinstalling a package (like in the introduction example) is not allowed. Installing multiple versions of a package is still fine.</p>
<h2 id=\"future-work\">Future work</h2>
<p>In the future, we want to <a href=\"http://blog.johantibell.com/2012/03/cabal-of-my-dreams.html\">make hermetic builds the default</a> - that is, the build system should work as if all build artifacts were rebuilt anew each time. Ideally, this feature would be built on top of a purely functional <a href=\"http://nixos.org/nixos/\">Nix</a>-like package DB, which would allow to share build artifacts between different builds without worrying about the destructive update problem outlined in the introduction. Unfortunately, this is a large and a non-trivial project, although some work <a href=\"http://www.youtube.com/watch?v=h4QmkyN28Qs\">has already been done in this direction</a>. A possible interim solution is to run each build in its own sandbox.</p>
<p>There is also a number of relatively minor UI issues with sandboxes which were postponed until the next release (1.20). For more details on this, see the <a href=\"https://github.com/haskell/cabal/issues?labels=&milestone=21&page=1&state=open\">Cabal bug tracker</a>.</p>
<p>Last but not least, we’re really interested in your feedback on this feature, especially in how well it works on large-scale projects.</p>
<h2 id=\"acknowledgements\">Acknowledgements</h2>
<p>Thanks to Johan Tibell, Duncan Coutts and Andres Löh for code reviews and guidance, and to Google for paying me for working on this project during last summer.</p>" nil nil "38c02410bd1de548aa68e1303dbf6ff2") (412 (21011 9139 10153) "http://coldwa.st/e/blog/2013-08-20-Cabal-sandbox.html" "Mikhail Glushenkov: An Introduction to Cabal sandboxes" nil "Tue, 20 Aug 2013 00:00:00 +0000" "<p>This post describes sandboxes, a new feature of <code>cabal</code> that will be present in the 1.18 release. Sandboxes allow to build packages in isolation by creating a private package environment for each package. If you are familiar with Python’s virtualenv or Ruby’s RVM, this is a Haskell analogue. Though 1.18 is still not out yet, you can already experiment with the new features by building <code>cabal</code> from Git. This post is mainly aimed at people new to sandboxes – if you have already used <code>cabal-dev</code>, feel free to <a href=\"http://feeds.feedburner.com/ChurningAndChurning#for-the-users-of-cabal-dev\">skip the introductory sections</a>.</p>
<h2 id=\"building-cabal-from-git\">Building Cabal from git</h2>
<p>The recommended method of bootstrapping the Git version of the <code>cabal</code> tool is by using <code>cabal-dev</code>. Assuming you already have a previous version of <code>cabal</code> installed:</p>
<pre><code>$ git clone git://github.com/haskell/cabal.git /path/to/cabal
$ cd /path/to/cabal/cabal-install
$ cabal install Cabal/ cabal-install/</code></pre>
<p>That’s all! Now you have the latest version of the <code>cabal</code> tool installed under <code>~/.cabal/bin</code>.</p>
<h2 id=\"what-are-sandboxes-and-why-are-they-needed\">What are sandboxes and why are they needed?</h2>
<p>If you have used Haskell for some time, you’ve probably heard the expression “Cabal hell”. It refers to the fact that installing a new package with <code>cabal install</code> can break existing packages on your system.</p>
<p>The reason for this behaviour is <em>destructive reinstalls</em>. As of this writing, Cabal doesn’t support having <em>multiple instances</em> of the same version of a single package installed simultaneously (but note that installing <em>multiple versions</em> of the same package is completely fine). So how does this affect you, the user?</p>
<p>Imagine that you have installed the library <code>foo</code>, which depends on <code>bar-1.0</code>, which in turn depends on <code>baz</code> (any version):</p>
<figure>
<img src=\"http://feeds.feedburner.com/e/img/sandboxes-pic-0.png\" title=\"foo-1.0 -> bar-1.0 -> baz-1.0;\" />
</figure>
<p>After some time you then decide to install <code>quux</code>, which depends on <code>bar-1.0</code> and <code>baz-2.0</code>. Since you have only <code>baz-1.0</code> installed, you need to install <code>baz-2.0</code> and recompile <code>bar-1.0</code> against it:</p>
<figure>
<img src=\"http://feeds.feedburner.com/e/img/sandboxes-pic-1.png\" title=\"quux-1.0 -> bar-1.0; quux-1.0 -> baz-2.0; bar -> baz-2.0;\" />
</figure>
<p>But since Cabal allows you to have only a single instance of <code>bar-1.0</code> installed, the package <code>foo-1.0</code> is now broken since it depends on an instance of package <code>bar-1.0</code> that was removed! Cue much weeping and gnashing of teeth:</p>
<figure>
<img src=\"http://feeds.feedburner.com/e/img/sandboxes-pic-2.png\" title=\"foo-1.0 -> ???; baz-1.0;\" />
</figure>
<p>While we know what is the right way to fix this issue (see the <a href=\"http://feeds.feedburner.com/ChurningAndChurning#future-work\">“future work”</a> section below), getting there will take time, and sandboxes present a relatively low-cost interim solution. The idea is to build each package in an isolated environment (“sandbox”) with a sandbox-local package database. Because sandboxes are per-project, we can constrain them to be internally consistent and simply prohibit such conflicts as described above.</p>
<p>Besides alleviating the “Cabal hell” problem, sandboxes are also useful when your package depends on patched or unreleased libraries.</p>
<h2 id=\"usage\">Usage</h2>
<p>Using sandboxes is simple: if you already know how to use the <code>cabal</code> tool to build your packages, you only need to learn a few additional commands. To initialise a fresh sandbox in the current directory, run <code>cabal sandbox init</code>. All subsequent commands (such as <code>build</code> and <code>install</code>) from this point will use the sandbox.</p>
<pre><code>$ cd /path/to/my/haskell/library
$ cabal sandbox init                   # Initialise the sandbox
$ cabal install --only-dependencies    # Install dependencies into the sandbox
$ cabal build                          # Build your package inside the sandbox</code></pre>
<p>It can be useful to make a source package available for installation in the sandbox - for example, if your package depends on a patched or an unreleased version of a library. This can be done with the <code>cabal sandbox add-source</code> command - think of it as “local Hackage”. If an add-source dependency is later modified, it is reinstalled automatically.</p>
<pre><code>$ cabal sandbox add-source /my/patched/library # Add a new add-source dependency
$ cabal install --dependencies-only            # Install it into the sandbox
$ cabal build                                  # Build the local package
$ $EDITOR /my/patched/library/Source.hs        # Modify the add-source dependency
$ cabal build                                  # Modified dependency is automatically reinstalled</code></pre>
<p>Normally, the sandbox settings (such as optimisation level) are inherited from the main Cabal config file (<code>$HOME/cabal/config</code>). Sometimes, though, you need to change some settings specifically for a single sandbox. You can do this by creating a <code>cabal.config</code> file in the same directory with your <code>cabal.sandbox.config</code> (which was created by <code>sandbox init</code>). This file has the same syntax as the main Cabal config file.</p>
<pre><code>$ cat cabal.config
documentation: True
constraints: foo == 1.0, bar >= 2.0, baz
$ cabal build                                  # Uses settings from the cabal.config file</code></pre>
<p>When you have decided that you no longer want to build your package inside a sandbox, just delete it:</p>
<pre><code>$ cabal sandbox delete                       # Built-in command
$ rm -rf .cabal-sandbox cabal.sandbox.config # Alternative manual method</code></pre>
<h2 id=\"advanced-usage\">Advanced usage</h2>
<p>The default behaviour of the <code>add-source</code> command is to track modifications done to the added dependency and reinstall the sandbox copy of the package when needed. Sometimes this is not desirable: in these cases you can use <code>add-source --snapshot</code>, which disables the change tracking. In addition to <code>add-source</code>, there are also <code>list-sources</code> and <code>delete-source</code> commands.</p>
<p>Sometimes one wants to share a single sandbox between multiple packages. This can be easily done with the <code>--sandbox</code> option:</p>
<pre><code>$ cd /path/to/shared-sandbox
$ cabal sandbox init
$ cd /path/to/package-a
$ cabal sandbox init --sandbox /path/to/shared-sandbox
$ cd /path/to/package-b
$ cabal sandbox init --sandbox /path/to/shared-sandbox</code></pre>
<p>Using multiple different versions of GHC simultaneously is also supported, via the <code>-w</code> option:</p>
<pre><code>$ cabal sandbox init
$ cabal install --only-dependencies -w /path/to/ghc-1 # Install dependencies for both compilers
$ cabal install --only-dependencies -w /path/to/ghc-2
$ cabal configure -w /path/to/ghc-1                   # Build with the first compiler
$ cabal build
$ cabal configure -w /path/to/ghc-2                   # Build with the second compiler
$ cabal build</code></pre>
<p>It can be occasionally useful to run the <code>ghc-pkg</code> tool on the sandbox package DB directly (for example, you may need to unregister some packages). The command <code>cabal sandbox hc-pkg</code> is a convenient wrapper for <code>ghc-pkg</code> that runs it with the appropriate <code>--package-conf</code> argument:</p>
<pre><code>$ cabal -v sandbox hc-pkg list
Using a sandbox located at /path/to/.cabal-sandbox
'ghc-pkg' '--global' '--no-user-package-conf'
'--package-conf=/path/to/.cabal-sandbox/i386-linux-ghc-7.4.2-packages.conf.d'
'list'
[...]</code></pre>
<h2 id=\"for-the-users-of-cabal-dev\">For the users of cabal-dev</h2>
<p>The sandbox feature gives you basically the same functionality as <code>cabal-dev</code>, but integrated with the <code>cabal</code> tool itself. Here’s a handy cheatsheet for the users of <code>cabal-dev</code>:</p>
<table>
<tbody>
<tr class=\"odd\">
<td style=\"text-align: left;\">Action</td>
<td style=\"text-align: left;\"><code>cabal-dev</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">——————————————-</td>
<td style=\"text-align: left;\">—————————–</td>
<td style=\"text-align: left;\">—————————————</td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Initialise a sandbox</td>
<td style=\"text-align: left;\"><code>cabal-dev $ANY_COMMAND</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox init</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Delete the sandbox</td>
<td style=\"text-align: left;\"><code>rm -rf ./cabal-dev</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox delete</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Link a source directory from the sandbox</td>
<td style=\"text-align: left;\"><code>N/A</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox add-source</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Make a package available in the sandbox</td>
<td style=\"text-align: left;\"><code>cabal-dev add-source</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox add-source --snapshot</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Build the current package</td>
<td style=\"text-align: left;\"><code>cabal-dev build</code></td>
<td style=\"text-align: left;\"><code>cabal build</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Install a package into the sandbox</td>
<td style=\"text-align: left;\"><code>cabal-dev install $PKGNAME</code></td>
<td style=\"text-align: left;\"><code>cabal install $PKGNAME</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Any other standard <code>cabal</code> command</td>
<td style=\"text-align: left;\"><code>cabal-dev $COMMAND</code></td>
<td style=\"text-align: left;\"><code>cabal $COMMAND</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Install dependencies of a package</td>
<td style=\"text-align: left;\"><code>cabal-dev install-deps</code></td>
<td style=\"text-align: left;\"><code>cabal install --only-dependencies</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Run sandbox-local ghci</td>
<td style=\"text-align: left;\"><code>cabal-dev ghci</code></td>
<td style=\"text-align: left;\"><code>cabal repl</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">Sandbox-restricted <code>ghc-pkg</code></td>
<td style=\"text-align: left;\"><code>cabal-dev ghc-pkg</code></td>
<td style=\"text-align: left;\"><code>cabal sandbox hc-pkg</code></td>
</tr>
<tr class=\"odd\">
<td style=\"text-align: left;\">Path to the sandbox directory</td>
<td style=\"text-align: left;\"><code>./cabal-dev</code></td>
<td style=\"text-align: left;\"><code>./.cabal-sandbox</code></td>
</tr>
<tr class=\"even\">
<td style=\"text-align: left;\">——————————————-</td>
<td style=\"text-align: left;\">——————————</td>
<td style=\"text-align: left;\">—————————————</td>
</tr>
</tbody>
</table>
<p>One important difference is that <code>add-source</code> adds a link to a source directory instead of making a source snapshot available for install. The add-source packages are reinstalled each time the sandboxed package is built. To get <code>cabal-dev</code>’s behaviour, use <code>cabal add-source --snapshot</code>.</p>
<p>Another difference is that sandboxes are constrained to be consistent - that is, destructively reinstalling a package (like in the introduction example) is not allowed. Installing multiple versions of a package is still fine.</p>
<h2 id=\"future-work\">Future work</h2>
<p>In the future, we want to <a href=\"http://blog.johantibell.com/2012/03/cabal-of-my-dreams.html\">make hermetic builds the default</a> - that is, the build system should work as if all build artifacts were rebuilt anew each time. Ideally, this feature would be built on top of a purely functional <a href=\"http://nixos.org/nixos/\">Nix</a>-like package DB, which would allow to share build artifacts between different builds without worrying about the destructive update problem outlined in the introduction. Unfortunately, this is a large and a non-trivial project, although some work <a href=\"http://www.youtube.com/watch?v=h4QmkyN28Qs\">has already been done in this direction</a>. A possible interim solution is to run each build in its own sandbox.</p>
<p>There is also a number of relatively minor UI issues with sandboxes which were postponed until the next release (1.20). For more details on this, see the <a href=\"https://github.com/haskell/cabal/issues?labels=&milestone=21&page=1&state=open\">Cabal bug tracker</a>.</p>
<p>Last but not least, we’re really interested in your feedback on this feature, especially in how well it works on large-scale projects.</p>" nil nil "a41fcf1522f9f013200103337d7de083") (411 (21011 9139 8189) "http://wadler.blogspot.com/2013/08/partner-of-journalist-detained-for-nine.html" "Philip Wadler: Partner of journalist detained for nine hours" "noreply@blogger.com (Philip Wadler)" "Mon, 19 Aug 2013 19:38:01 +0000" "<div style=\"clear: both; text-align: center;\" class=\"separator\"></div><br /><div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://2.bp.blogspot.com/-bcY4nu0gUH4/UhJxQQspMwI/AAAAAAAAFco/DQuBHFCx-kM/s1600/greenwald-miranda-rio.jpg\"><img src=\"http://2.bp.blogspot.com/-bcY4nu0gUH4/UhJxQQspMwI/AAAAAAAAFco/DQuBHFCx-kM/s320/greenwald-miranda-rio.jpg\" height=\"192\" border=\"0\" width=\"320\" /></a></div><div style=\"clear: both; text-align: center;\" class=\"separator\"></div>David Miranda (right) was detained at Heathrow for nine hours yesterday (Sunday 18 August 2013) under Section 7 of the Prevention of Terrorist Act. He was in transit from Berlin to his home in Brazil, and in the UK only to change planes. Miranda is the partner of journalist Glen Greenwald (left), who interviewed Edward Snowden (below) and has played a key role in the ongoing revelations about the NSA and GCHQ. Miranda had his phone and laptop confiscated, and has not been told when they will be returned. The photo shows Greenwald and Miranda at the airport in Rio di Janiero, today.<br /><br />Glen Greenwald, responding to the arrest, <a href=\"http://www.theguardian.com/commentisfree/2013/aug/18/david-miranda-detained-uk-nsa\">wrote today</a>: <br /><blockquote class=\"tr_bq\"> It's bad enough to prosecute and imprison sources. It's worse still to  imprison journalists who report the truth. But to start detaining the  family members and loved ones of journalists is simply despotic. ...</blockquote><blockquote class=\"tr_bq\">If the UK and US governments believe that tactics like this are going to  deter or intimidate us in any way from continuing to report aggressively  on what these documents reveal, they are beyond deluded. If anything,  it will have only the opposite effect: to embolden us even further.  Beyond that, every time the US and UK governments show their true  character to the world - when they prevent the Bolivian President's  plane from flying safely home, when they threaten journalists with  prosecution, when they engage in behavior like what they did today - all  they do is helpfully underscore why it's so dangerous to allow them to  exercise vast, unchecked spying power in the dark. </blockquote><a href=\"http://www.theguardian.com/world/2013/aug/18/glenn-greenwald-guardian-partner-detained-heathrow\">First report, from the Guardian.</a><br /><a href=\"http://www.theguardian.com/commentisfree/2013/aug/18/david-miranda-detained-uk-nsa\">Greenwald's response. </a><br /><a href=\"http://www.theguardian.com/politics/blog/2013/aug/19/glenn-greenwald-partner-detained-live-reaction\">Live blog of ongoing reaction.</a>" nil nil "545419e541be59f58935b96fc71ab981") (410 (21011 9139 7559) "http://wadler.blogspot.com/2013/08/star-ratings-2013-edition.html" "Philip Wadler: Star ratings, 2013 edition" "noreply@blogger.com (Philip Wadler)" "Mon, 19 Aug 2013 19:03:55 +0000" "<div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://4.bp.blogspot.com/-Y7yloBjHbIY/UDSs9cbrw6I/AAAAAAAAATk/VIBAVxWM1-k/s1600/star_ratings.png\"><img src=\"http://4.bp.blogspot.com/-Y7yloBjHbIY/UDSs9cbrw6I/AAAAAAAAATk/VIBAVxWM1-k/s1600/star_ratings.png\" border=\"0\" /></a></div>August is Festival Time in Edinburgh.  But despite the wise words from XKCD above, this year I am forced to give out five stars, twice, because the shows are <i>that</i> good.<br /><br /><a href=\"https://www.edfringe.com/whats-on/comedy/pajama-men-just-the-two-of-each-of-us\">Pajama Men</a> (five stars): excruciating physical comedy. Possibly the funniest thing I've seen, ever. Favourite line: `We seem to have strangely reached a limit' (you'll understand why it's funny when you see it).<br /><br /><a href=\"https://www.edfringe.com/whats-on/dance-and-physical-theatre/that-is-all-you-need-to-know\">That is All You Need to Know</a> (four and a half stars): Physical theatre about the history of Bletchley Park, alternating between the war years and attempts to preserve the park in the nineties. They get right  the bits about Turing, but there is much more here than just  Turing.<br /><br /><a href=\"https://www.edfringe.com/whats-on/theatre/solfatara\">Solfatara</a> (four and a half stars): alternately hilarious and heartrending. In Spanish, with English surtitles that take on a life of their own ...<br /><br /><a href=\"https://www.edfringe.com/whats-on/comedy/festival-of-the-spoken-nerd-full-frontal-nerdity\">Festival of the Spoken Nerd</a> (five stars): As they explain, being a nerd is about being open to saying 'oooh' to the universe, and this show made me 'oooh' more than once, as well as laugh from start to end.  Yes, those are gliders from Conway's Game of Life on the flyer below, and they feature in one of the 'ooohs', a stunning demonstration of recursive nesting.<br /><br /><div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://2.bp.blogspot.com/-T08zm8ecFQU/UhJlx-pBXqI/AAAAAAAAFcE/w_aWsqN13t4/s1600/fotsn.jpg\"><img src=\"http://2.bp.blogspot.com/-T08zm8ecFQU/UhJlx-pBXqI/AAAAAAAAFcE/w_aWsqN13t4/s640/fotsn.jpg\" height=\"640\" border=\"0\" width=\"451\" /></a></div><br />" nil nil "81b19854152e3ab87c563b754df3fcf5") (409 (21011 9138 980578) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_4406\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_9212\"></span> time, whereas using the categorical functor takes time <span id=\"tex_4212\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_8484\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "a8b4439b8bfca824f0e2282815b93dab") (408 (21010 11596 131145) "http://wadler.blogspot.com/2013/08/bodyscapes.html" "Philip Wadler: Bodyscapes" "noreply@blogger.com (Philip Wadler)" "Mon, 19 Aug 2013 13:36:24 +0000" "<div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://4.bp.blogspot.com/-srIuqvzXRGg/UhIfHpceoII/AAAAAAAAFb0/P4qT5nafw3I/s1600/Valley-of-the-reclining-woman.jpg\"><img src=\"http://4.bp.blogspot.com/-srIuqvzXRGg/UhIfHpceoII/AAAAAAAAFb0/P4qT5nafw3I/s400/Valley-of-the-reclining-woman.jpg\" height=\"193\" border=\"0\" width=\"400\" /></a></div>Carl Warner, noted in <a href=\"http://wadler.blogspot.co.uk/2009/06/pictures-created-from-food.html\">an earlier post</a> for his <a href=\"http://www.carlwarner.com/foodscapes/\">Foodscapes</a>, is now creating <a href=\"http://www.carlwarner.com/otherscapes/\">Bodyscapes</a>." nil nil "4078a60d50d2bfa9401e36a21161f4c1") (407 (21010 7603 914983) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_2916\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_1724\"></span> time, whereas using the categorical functor takes time <span id=\"tex_8716\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_762\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "34bf3c08d60bf4c3d967f86f0c3827ba") (406 (21010 1579 339386) "http://justtesting.org/post/58689478948" "Manuel M T Chakravarty: A new home for C->Haskell" nil "Mon, 19 Aug 2013 11:16:14 +0000" "<p>The home of the C->Haskell binding generator <code>c2hs</code> is now on GitHub: <a href=\"https://github.com/haskell/c2hs\"></a><a href=\"https://github.com/haskell/c2hs\">https://github.com/haskell/c2hs</a>.</p>" nil nil "08e6aa56691591a7fa16ae2df3e59238") (405 (21010 1579 254153) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_9164\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_9527\"></span> time, whereas using the categorical functor takes time <span id=\"tex_312\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_7788\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "0b31a241ffd38179896a20eb11c0e964") (404 (21009 62661 130696) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_3734\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_1896\"></span> time, whereas using the categorical functor takes time <span id=\"tex_6639\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_2085\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "04b8a0d8ab734a84c0a3f5cf7e3cbe31") (403 (21009 59178 168559) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_1188\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_6949\"></span> time, whereas using the categorical functor takes time <span id=\"tex_323\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_3829\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "99b6d02e4a666d3caa31499eb8941643") (402 (21009 53414 242326) "http://www.yesodweb.com/blog/2013/08/exceptions-and-monad-transformers" "Yesod Web Framework: Exceptions and monad transformers" nil "Mon, 19 Aug 2013 07:00:00 +0000" "<p>John Wiegley and I are currently working- together with some members of the community- on various exception handling related code. As part of this work, we're also going to be publishing a number of tutorials on this topic. Eventually, we'll collect all of this information together into a more cohesive whole, but for now we wanted to get the content out there to the community as we produce it.</p><p>Note that this content is <a href=\"https://www.fpcomplete.com/user/snoyberg/general-haskell/exceptions/exceptions-and-monad-transformers\">available on the School of Haskell</a>; I recommend reading it there to be able to use the active code.</p><hr /><p>Love them or hate them, runtime exceptions are a reality of writing Haskell code. Consider the following fake code:</p><pre><code class=\"haskell\">myFunc = do
resource <- acquireScarceResource
useResource resource
releaseResource resource</code></pre><p>In a world without exceptions, this seems completely reasonable. However, what happens if the call to <code>useResource</code> throws a runtime exception? In such a case, <code>releaseResource</code> would never be called, and our scarce resource would never be released. In concurrent code dealing with mutexes, such a bug could lead to a deadlock.</p><p>The solution to this problem is well known: use the <hoogle results=\"1\">bracket</hoogle> function. Then our above example reduces to <code>myFunc = bracket acquireScarceResource useResource releaseResource</code>. We're now safe from any exception thrown by <code>useResource</code>, and even from asynchronous exceptions (a topic I'll try to avoid in this post).</p><p>But let's analyze the type signature of <code>bracket</code>:</p><pre><code>bracket :: IO a -> (a -> IO b) -> (a -> IO c) -> IO c</code></pre><p>How do we use such a function in monad transformer stack, where the functions we pass in won't live in the <code>IO</code> monad itself?</p><p>Note that for the rest of this tutorial, I'm going to talk about the <hoogle results=\"1\">finally</hoogle> function instead of <code>bracket</code>, which is really just a simplified version of the latter. The reasoning used will apply to not only <code>bracket</code>, but also to many other functions in <hoogle results=\"1\">Control.Exception</hoogle>. Its signature is <code>IO a -> IO b -> IO a</code>, and its purpose is to ensure that the second function is called regardless of what exceptions are thrown by the first (or any asynchronous exceptions... sorry for bringing those up again).</p><h2>The simple case: the ReaderT transformer</h2><p>Let's forget about any kind of grand solution. Instead, let's take one of the simplest monad transformers that exists, <code>ReaderT</code>, and see how we can write a <code>finally</code> that works with it. Since a <code>ReaderT</code> simply passes in some environment to all actions, this turns out to be really easy:</p><pre><code class=\"haskell active\">import Control.Monad.Reader
import Control.Exception (finally, try, ErrorCall)
finallyReaderT :: ReaderT r IO a -> ReaderT r IO b -> ReaderT r IO a
finallyReaderT a sequel = do
r <- ask
liftIO $ runReaderT a r `finally` runReaderT sequel r
main :: IO ()
main = do
res <- try $ runReaderT
(step1 `finallyReaderT` step2)
\"This is the environment\"
print (res :: Either ErrorCall ())
where
step1 = do
r <- ask
liftIO $ putStrLn $ \"In step1, r == \" ++ show r
error \"Erroring out, bye!\"
step2 = do
r <- ask
liftIO $ putStrLn $ \"In step2, r == \" ++ show r</code></pre><p>That turns out to be pretty simple. And by reusing the existing <code>finally</code> function, we can feel comfortable knowing that our implementation is correct (or at least as correct as <code>finally</code> itself).</p><h2>First complication: mutable state</h2><p>But <code>ReaderT</code> is a really simple case to support, since it's just a read-only environment. Let's up the ante a bit, and try using <code>StateT</code> instead. We'll now need to deal with threading the mutable state variable through. Before jumping into the code, let's consider abstractly how would could achieve this threading. We have two possible cases: an exception is thrown before calling the cleanup function, or an exception is not thrown. If no exception is thrown, then we can extract the state value from the result of the first function call, pass that to the cleanup function, and then return the final state value as the new mutable state.</p><p>But if an exception is thrown, there won't be a chance to extract the updated state value from the first function. In that case, we'll only have the initial state value available to pass through to the cleanup function. (The new result state is irrelevant, since the exception is going to be rethrown anyway.) As described until now, let's see what this kind of <code>finally</code> implementation may look like.</p><pre><code class=\"haskell active\">import Prelude hiding (catch)
import Control.Monad.State
import Control.Exception
finallyStateT :: StateT s IO a -> StateT s IO b -> StateT s IO a
finallyStateT a sequel = do
s1 <- get
(result, s2) <- liftIO $ runStateT a s1 `catch` \\e -> do
_ignored <- runStateT sequel s1
throwIO (e :: SomeException)
(_ignored, s3) <- liftIO $ runStateT sequel s2
put s3
return result
main :: IO ()
main = do
res <- try $ runStateT
(step1 `finallyStateT` step2)
1
print (res :: Either ErrorCall ((), Int))
where
step1 = do
s <- get
liftIO $ putStrLn $ \"In step1, s == \" ++ show s
put $ s + 1
error \"Erroring out, bye!\" -- Try commenting me out
step2 = do
s <- get
liftIO $ putStrLn $ \"In step2, s == \" ++ show s
put $ s + 1</code></pre><p>This seems to work, but there are a two problems:</p><ul><li>We were not able to reuse the standard <code>finally</code> function to implement this, since it wouldn't allow us to manually thread state. Practically, that means our implementation is susceptible to asynchronous exceptions (argh... those came up again).</li><li>The behavior is pretty inconsistent. In one case, we use the original mutable state value and ignore the updated state from the cleanup function. In the other, we use the updated state value from the first function and keep the updated mutable state.</li></ul><p>So let's instead try out a different approach. Regardless of whether an exception is thrown or not, we'll call the cleanup function using the original mutable state, and always ignore the state produced by the cleanup function.</p><pre><code class=\"haskell active\">import Control.Monad.State
import Control.Exception
finallyStateT :: StateT s IO a -> StateT s IO b -> StateT s IO a
finallyStateT a sequel = do
s1 <- get
(result, s2) <- liftIO $ runStateT a s1 `finally`
runStateT sequel s1
put s2
return result
main :: IO ()
main = do
res <- try $ runStateT
(step1 `finallyStateT` step2)
1
print (res :: Either ErrorCall ((), Int))
where
step1 = do
s <- get
liftIO $ putStrLn $ \"In step1, s == \" ++ show s
put $ s + 1
error \"Erroring out, bye!\" -- Try commenting me out
step2 = do
s <- get
liftIO $ putStrLn $ \"In step2, s == \" ++ show s
put $ s + 1</code></pre><p>This solves my two complaints from before, but unfortunately introduces a new one: the behavior is not really intuitive in the non-exception case. Nonetheless, in my opinion, this is the right way to implement things due to the consistency. We'll cover a method to get back the more intuitive semantics towards the end of this post.</p><h2>Second complication: alternative exit paths</h2><p>The previous section essentially provided two approaches to writing a transformer-based <code>finally</code>: base it off of primitives like <code>catch</code>, or reuse <code>finally</code>. It turns out that both of these approaches have quite a bit of prior art. In the first case, there are the <code>MonadCatchIO-mtl</code> and <code>MonadCatchIO-transformers</code> packages, as well as the more recent <code>exceptions</code> package. These all define a typeclass for the primitive operations of <code>catch</code>ing and masking asynchronous exceptions (we just can't escape those, can we?).</p><p>Let's extract the <code>catch</code> logic from our first <code>StateT</code> example above to demonstrate the technique:</p><pre><code class=\"haskell active\">import Prelude hiding (catch)
import Control.Monad.State
import Control.Exception
-- show
catchStateT :: Exception e
=> StateT s IO a
-> (e -> StateT s IO a)
-> StateT s IO a
catchStateT a onE = do
s1 <- get
(result, s2) <- liftIO $ runStateT a s1 `catch` \\e ->
runStateT (onE e) s1
put s2
return result
finallyStateT :: StateT s IO a -> StateT s IO b -> StateT s IO a
finallyStateT a sequel = do
result <- a `catchStateT` \\e -> do
_ignored <- sequel
liftIO $ throwIO (e :: SomeException)
_ignored <- sequel
return result
-- /show
main :: IO ()
main = do
res <- try $ runStateT
(step1 `finallyStateT` step2)
1
print (res :: Either ErrorCall ((), Int))
where
step1 = do
s <- get
liftIO $ putStrLn $ \"In step1, s == \" ++ show s
put $ s + 1
error \"Erroring out, bye!\" -- Try commenting me out
step2 = do
s <- get
liftIO $ putStrLn $ \"In step2, s == \" ++ show s
put $ s + 1</code></pre><p>That's certainly a bit prettier than what we had before (though it's still not async-exception safe). And what's really nice is that this definition of <code>finallyStateT</code> doesn't actually have anything <code>StateT</code>-specific about it. So presuming we had a <code>catch</code> function for some other transformer, we could reuse the same definition. Let's try this out for <code>ErrorT</code>.</p><pre><code class=\"haskell active\">import Prelude hiding (catch)
import Control.Monad.Error
import Control.Exception
catchErrorT :: (Exception e, Error s)
=> ErrorT s IO a
-> (e -> ErrorT s IO a)
-> ErrorT s IO a
catchErrorT a onE = do
eresult <- liftIO $ runErrorT a `catch` \\e ->
runErrorT (onE e)
either throwError return eresult
finallyErrorT :: Error s => ErrorT s IO a -> ErrorT s IO b -> ErrorT s IO a
finallyErrorT a sequel = do
result <- a `catchErrorT` \\e -> do
_ignored <- sequel
liftIO $ throwIO (e :: SomeException)
_ignored <- sequel
return result
main :: IO ()
main = do
res <- try $ runErrorT
(step1 `finallyErrorT` step2)
print (res :: Either ErrorCall (Either String ()))
where
step1 = do
liftIO $ putStrLn $ \"In step1\"
throwError \"This should be interesting\"
step2 = liftIO $ putStrLn $ \"In step2\"</code></pre><p>Go ahead and run that code snippet. Do you notice something not there to be noticed? That's right, the cleanup function is never called! Here we have a function called <code>finally</code> which, despite its name, doesn't actually call the cleanup function when it finally exits. What gives?</p><p>The issue is that, with an <code>ErrorT s IO</code> stack, there are <b>three</b> ways to exit the function: normally, with a runtime exception, or with a <code>throwError</code> result. In <code>finallyErrorT</code>, the call to <code>catchErrorT</code> accounts for the runtime exception case, and the following call to <code>sequel</code> accounts for the normal exit case. But there's no way to account for the <code>throwError</code> case without adding <code>ErrorT</code>-specific logic to <code>finally</code> (we'll do that in a moment).</p><p>You can try this example out with <code>MonadCatchIO-mtl</code> or <code>MonadCatchIO-transformers</code> and reproduce this buggy behavior. This affects both the <code>ErrorT</code> and <code>ContT</code> transformers. In the <code>exceptions</code> package, this also applies to the <code>CatchT</code> type. (John Wiegley discussed this issue with Edward, who described this as a documentation bug, since <code>CatchT</code> should not be used on top of <code>IO</code>.)</p><p>Doing this correctly is certainly possible, as you can see with the following example:</p><pre><code class=\"haskell active\">import Control.Monad.Error
import Control.Exception
-- show
finallyErrorT :: Error s => ErrorT s IO a -> ErrorT s IO b -> ErrorT s IO a
finallyErrorT a sequel = do
eresult <- liftIO $ runErrorT a `finally` runErrorT sequel
either throwError return eresult
-- /show
main :: IO ()
main = do
res <- try $ runErrorT
(step1 `finallyErrorT` step2)
print (res :: Either ErrorCall (Either String ()))
where
step1 = do
liftIO $ putStrLn $ \"In step1\"
throwError \"This should be interesting\"
step2 = liftIO $ putStrLn $ \"In step2\"</code></pre><p>But this seems to imply that we would need to write a separate implementation of <code>finally</code> for each and every transformer, which would be tedious and error-prone. There must be a better way.</p><h2>monad-control</h2><p>If you look at our various implementations so far, they all follow a similar pattern: embedding the state of the monad inside the value, running the underlying monadic action, and then rebuilding the monadic state from the result. This procedure can be done with many different transformers (basically, all common transformers except <code>ContT</code>). To capture this concept, we have the <code>MonadTransControl</code> and <code>MonadBaseControl</code> typeclasses in the <a href=\"https://www.fpcomplete.com/haddocks/monad-control\"><code>monad-control</code></a> package.</p><p><code>monad-control</code> is frankly pretty complicated, and I'm not going to delve into all of its details here. Instead, I'll point you to the <a href=\"https://www.fpcomplete.com/haddocks/lifted-base\"><code>lifted-base</code></a> package, which uses <code>monad-control</code> to create transformer-friendly versions of many common functions in <code>base</code>. As you'd expect based on this tutorial, exception handling functions are present, but also concurrency, timeouts, and mutable variables (which will become important in just a moment).</p><p><code>monad-control</code> is- as far as I know- the third attempt at a library to cover these concepts. Previous solutions were <code>monad-peel</code> and my own <a href=\"http://hackage.haskell.org/packages/archive/neither/0.1.0/doc/html/Control-Monad-Invert.html\">MonadInvertIO</a>, part of earlier versions of <code>neither</code>. While in my opinion these other two approaches are easier to understand, <code>monad-control</code> is highly optimized, and therefore gets my recommendation as the go-to library for handling monad transformer stacks.</p><h2>More intuitive mutable state</h2><p>We're left with one annoyance with the <code>monad-control</code>-based solution: we lose any mutations performed to our mutable state either before an exception is thrown, or in our cleanup functions. Is there some way to keep the elegance of <code>monad-control</code> but get back the more intuitive behavior? The answer is yes, but you may not like it.</p><p>When dealing with either <code>StateT</code> or <code>WriterT</code> transformers, the behavior which I would consider most intuitive would be that any mutations are immediately captured. Unfortunately, this can't be achieved at all using the standard <code>StateT</code> and <code>WriterT</code> implementations, since the monadic state is thrown away as soon as an exception is thrown.</p><p>In this case, my solution is to use a mutable variable- such as an <code>IORef</code>- and keep a reference to it in a <code>ReaderT</code>. As an example, this technique is used by the <hoogle results=\"1\">HandlerT</hoogle> transformer used in Yesod.</p><p>To demonstrate the concept, here's an implementation of the RWST monad transformer which uses <code>IORef</code>s for holding mutable state. For completeness, I'll include appropriate instances for <code>monad-control</code> and demonstrate usage of <code>lifted-base</code>.</p><pre><code class=\"haskell active\">{-# OPTIONS_GHC -Wall -Werror #-}
{-# LANGUAGE GeneralizedNewtypeDeriving #-}
{-# LANGUAGE FlexibleInstances #-}
{-# LANGUAGE FlexibleContexts #-}
{-# LANGUAGE MultiParamTypeClasses #-}
{-# LANGUAGE TypeFamilies #-}
{-# LANGUAGE UndecidableInstances #-}
import Control.Monad.RWS.Class
import Control.Monad.Reader
import Control.Monad.Base
import Control.Applicative (Applicative)
import Data.IORef.Lifted
import Data.Monoid (Monoid, (<>), mempty)
import Control.Exception.Lifted
import Control.Monad.Trans.Control
data Env r w s = Env
{ envReader :: !r
, envWriter :: !(IORef w)
, envState  :: !(IORef s)
}
newtype RWST r w s m a = RWST (ReaderT (Env r w s) m a)
deriving (Functor, Applicative, Monad, MonadIO, MonadTrans)
instance Monad m => MonadReader r (RWST r w s m) where
ask = RWST $ liftM envReader ask
local f (RWST g) =
RWST $ local f' g
where
f' env = env { envReader = f $ envReader env }
instance (MonadBase IO m, Monoid w) => MonadWriter w (RWST r w s m) where
tell w = RWST $ ask >>= flip modifyIORef (<> w) . envWriter
listen (RWST (ReaderT f)) = RWST $ ReaderT $ \\env -> do
iwriter <- newIORef mempty
result <- f env { envWriter = iwriter }
w <- readIORef iwriter
return (result, w)
pass (RWST (ReaderT f)) = RWST $ ReaderT $ \\env -> do
(result, g) <- f env
modifyIORef (envWriter env) g
return result
instance MonadBase IO m => MonadState s (RWST r w s m) where
get = RWST $ ask >>= readIORef . envState
put s = RWST $ ask >>= flip writeIORef s . envState
instance (MonadBase IO m, Monoid w) => MonadRWS r w s (RWST r w s m)
runRWST :: (MonadBase IO m, Monoid w) => RWST r w s m a -> r -> s -> m (a, s, w)
runRWST (RWST (ReaderT f)) r s = do
iwriter <- newIORef mempty
istate <- newIORef s
a <- f $ Env r iwriter istate
w <- readIORef iwriter
s' <- readIORef istate
return (a, s', w)
instance MonadBase b m => MonadBase b (RWST r w s m) where
liftBase = lift . liftBase
instance MonadTransControl (RWST r w s) where
newtype StT (RWST r w s) a = StRWS {unStRWS :: a}
liftWith f = RWST $ ReaderT $ \\r -> f $ \\(RWST t) -> liftM StRWS $ runReaderT t r
restoreT = RWST . ReaderT . const . liftM unStRWS
instance MonadBaseControl b m => MonadBaseControl b (RWST r w s m) where
newtype StM (RWST r w s m) a = ST { unST :: ComposeSt (RWST r w s) m a }
liftBaseWith = defaultLiftBaseWith ST
restoreM     = defaultRestoreM unST
main :: IO ()
main = do
res <- try $ runRWST
(step1 `finally` step2)
\"This is the environment\"
0
print (res :: Either ErrorCall ((), Int, [Bool]))
where
step1 = do
liftIO $ putStrLn $ \"In step1\"
modify (+ 1)
error \"User exception\"
step2 = do
s <- get
liftIO $ putStrLn $ \"In step2: \" ++ show s</code></pre>" nil nil "380bdf9a870a5a283338ea480593b7e5") (401 (21009 53414 239425) "http://lambda.jstolarek.com/2013/08/ghc-gets-new-primops/" "Jan Stolarek: GHC gets new primops" nil "Sat, 17 Aug 2013 17:42:06 +0000" "<p style=\"text-align: justify;\">I finished 7th week of my MSR internship in Cambridge, with 5 more weeks to go. I’m working on Cmm optimizations, but so far my project has been moving rather slowly and I’m not yet sure if the final results will be beneficial enough to be merged into HEAD. But I finally finished something I’ve been working on for the last couple of months – patches for new comparison PrimOps in GHC (Trac ticket <a href=\"http://ghc.haskell.org/trac/ghc/ticket/6135\">#6135</a>) have been merged on Wednesday. I created a <a href=\"http://ghc.haskell.org/trac/ghc/wiki/PrimBool\">wiki page</a> which gives detailed information about motivation behind this change, discusses some implementation details and presents preliminary benchmarking results. This post is aimed at people who want to learn more about how the previous and current implementation of comparisons work.</p>
<p style=\"text-align: justify;\">So what is a Primitive Operation – PrimOp for short – in GHC? The <a href=\"http://ghc.haskell.org/trac/ghc/wiki/Commentary/PrimOps\">developer wiki defines primops</a> as “functions that cannot be implemented in Haskell, and are provided natively by GHC”. In other words these are special functions, which are not defined in the standard libraries – because these libraries are written in Haskell and, as we just said, PrimOps cannot be expressed in Haskell – but instead are built into the compiler. Whenever GHC encounters a PrimOp invocation in the source code it magically generates machine code for that PrimOp. There’s a lot of PrimOps in GHC (their definitions are <a href=\"https://github.com/ghc/ghc/blob/master/compiler/prelude/primops.txt.pp\">here</a>) and my task was to modify the ones responsible for comparing unboxed primitive values like <code>Int#</code> or <code>Double#</code>. Up till now all these comparisons returned a <code>Bool</code> indicating whether a given equality or ordering relation holds between the two parameters. This was determined by comparing them using a machine instruction like <code>cmp</code>, which set flags in flag register of the processor. Since the result of a primop was supposed to be a <code>Bool</code> (boxed, lifted value) and not some flags, we had to use another instruction<sup><a title=\"From SETcc family.\" href=\"http://lambda.jstolarek.com/2013/08/ghc-gets-new-primops/#footnote_0_1248\" id=\"identifier_0_1248\" class=\"footnote-link footnote-identifier-link\">1</a></sup> to examine flags set by <code>cmp</code> and based on them set a value of a general purpose register to <code>0#</code> (representing <code>False</code>) or <code>1#</code> (representing <code>True</code>). This gives us an <code>Int#</code>, so still not a <code>Bool</code>, but fear not! GHC has a <code>tagToEnum#</code> primop, which takes an unboxed integer and produces a value of an enumeration<sup><a title=\"Algebraic data type with nullary constructors\" href=\"http://lambda.jstolarek.com/2013/08/ghc-gets-new-primops/#footnote_1_1248\" id=\"identifier_1_1248\" class=\"footnote-link footnote-identifier-link\">2</a></sup>. Calling <code>tagToEnum# 0#</code> means “create value represented by the first value constructor” (in case of <code>Bool</code> this is <code>False</code>), while calling <code>tagToEnum# 1#</code> means “create value represented by the second value constructor” (in case of <code>Bool</code> this is <code>True</code>)<sup><a title=\"Note that tagToEnum# has type Int# -> a, which means it is a polymorphic primop – quite an unusual thing\" href=\"http://lambda.jstolarek.com/2013/08/ghc-gets-new-primops/#footnote_2_1248\" id=\"identifier_2_1248\" class=\"footnote-link footnote-identifier-link\">3</a></sup>. So we have our <code>Bool</code> value. Now we must examine whether it is <code>True</code> or <code>False</code> and act accordingly. Since <code>Bool</code> is both boxed and lifted, its values are represented by closures. <code>Bool</code> is a bit of a special case, because closures for its value constructors are allocated statically in the data area of a compiled program and not dynamically on the heap. Normally we would have to inspect a returned closure, but GHC has two optimisations which kick in here. One of them is pointer tagging, which allows us to determine a value constructor in a closure without dereferencing the pointer. This is done using <a href=\"http://ghc.haskell.org/trac/ghc/wiki/Commentary/Rts/HaskellExecution/PointerTagging\">pointer tagging</a>. But we don’t even use pointer tagging in this case, because GHC is even smarter – it optimizes away closures generated by comparison primops and just uses an unboxed integer value generated by machine instructions doing comparison. This requires a special case in the code generator which is Not A Good Thing.</p>
<p style=\"text-align: justify;\">That’s how things were up till now. The key idea behind my change is that code generator no longer generates implicit call to <code>tagToEnum#</code>. Instead, the new primops return an <code>Int#</code> (either <code>0#</code> or <code>1#</code>) and whenever we really want a <code>Bool</code> we have to call <code>tagToEnum#</code> explicitly in the Haskell source code.</p>
<p style=\"text-align: justify;\">There is one thing that could be improved here. We still need that special case in the code generator to avoid generating <code>Bool</code> closures and inspecting results by checking pointer tags in situations where we make an explicit call to <code>tagToEnum#</code>. But Simon already has an idea how to resolve that problem. We just need to add some extra simplifier transformations that will optimize away <code>tagToEnum#</code> at the Core level, although I’m not yet sure if I’ll have enough time to implement that during my internship.</p>
<ol class=\"footnotes\"><li id=\"footnote_0_1248\" class=\"footnote\">From SETcc family.</li><li id=\"footnote_1_1248\" class=\"footnote\">Algebraic data type with nullary constructors</li><li id=\"footnote_2_1248\" class=\"footnote\">Note that <code>tagToEnum#</code> has type <code>Int# -> a</code>, which means it is a polymorphic primop – quite an unusual thing</li></ol>" nil nil "04068012c40fd43974e888d42614acd7") (400 (21009 53414 238139) "http://parenz.wordpress.com/2013/08/17/ghc-api-interpreted-compiled-and-package-modules/" "Daniil Frumin: GHC API: Interpreted, compiled and package modules" nil "Sat, 17 Aug 2013 10:13:24 +0000" "<p>The third post in the series. See also <a href=\"http://parenz.wordpress.com/2013/07/29/ghc-packagedb/\">Adding a package database to the GHC API session</a> and <a href=\"http://parenz.wordpress.com/2013/07/23/on-custom-error-handlers-for-ghc-api/\">On custom error handlers for the GHC API</a></p>
<h1 id=\"intro\">Intro</h1>
<p>It’s hard to get into writing code that uses GHC API. The API itself is and the number of various functions and options significantly outnumber the amount of tutorials around.</p>
<p>In this series of blog posts I’ll elaborate on some of the peculiar, interesting problems I’ve encountered during my experience writing code that uses GHC API and also provide various tips I find useful.</p>
<p>I have built for myself a small layer of helper functions that helped me with using GHC API for the <code>interactive-diagrams</code> project. The source can be found on <a href=\"http://github.com/co-dan/interactive-diagrams\">GitHub</a> and I plan on refactoring the code and releasing it separately.</p>
<p>Today I would like to talk about a different ways of bringing contents of Haskell modules into scope, a process that is necessary for evaluating/interpreting bits of code on-the-fly.</p>
<p>Many of the points I make in this post are actually trivial, but nevertheless I made all of the mistakes I mentioned in this, perhaps post due to my naive approach of quickly diving in and experimenting, instead of reading into the documentation and source code. Now I actually realize that this post should been the first in the series, since it probably deals with more basic (and fundamental) stuff than the previous two posts. But anyway, here it is.</p>
<h1 id=\"interpreted-modules\">Interpreted modules</h1>
<p>Imagine the following situation: we have a Haskell source file with code we want to load dynamically and evaluate. That is a basic task in the GHC API terms but nevertheless there are some caveats. We start with the most basics.</p>
<p>Let us have a file ‘test.hs’ containing the code we want to access:</p>
<pre><code><span style=\"color: blue; font-weight: bold;\">module</span> Test <span style=\"color: red;\">(</span>test<span style=\"color: red;\">)</span> <span style=\"color: blue; font-weight: bold;\">where</span>
test <span style=\"color: red;\">::</span> Int
test <span style=\"color: red;\">=</span> <span class=\"hs-num\">123</span></code></pre>
<p>The basic way to get the ‘test’ data would be to load ‘Test’ as an interpreted module:</p>
<pre><code><span style=\"color: blue; font-weight: bold;\">import</span> Control.Applicative
<span style=\"color: blue; font-weight: bold;\">import</span> DynFlags
<span style=\"color: blue; font-weight: bold;\">import</span> GHC
<span style=\"color: blue; font-weight: bold;\">import</span> GHC.Paths
<span style=\"color: blue; font-weight: bold;\">import</span> GhcMonad            <span style=\"color: red;\">(</span>liftIO<span style=\"color: red;\">)</span> <span style=\"color: green;\">-- from ghc7.7 and up you can use the usual</span>
<span style=\"color: green;\">-- liftIO from Control.Monad.IO.Class</span>
<span style=\"color: blue; font-weight: bold;\">import</span> Unsafe.Coerce
main <span style=\"color: red;\">=</span> defaultErrorHandler defaultFatalMessager defaultFlushOut $ <span style=\"color: blue; font-weight: bold;\">do</span>
runGhc <span style=\"color: red;\">(</span>Just libdir<span style=\"color: red;\">)</span> $ <span style=\"color: blue; font-weight: bold;\">do</span>
<span style=\"color: green;\">-- we have to call 'setSessionDynFlags' before doing</span>
<span style=\"color: green;\">-- everything else</span>
dflags <span style=\"color: red;\"><-</span> getSessionDynFlags
<span style=\"color: green;\">-- If we want to make GHC interpret our code on the fly, we</span>
<span style=\"color: green;\">-- ought to set those two flags, otherwise we</span>
<span style=\"color: green;\">-- wouldn't be able to use 'setContext' below</span>
setSessionDynFlags $ dflags <span style=\"color: red;\">{</span> hscTarget <span style=\"color: red;\">=</span> HscInterpreted
<span style=\"color: red;\">,</span> ghcLink   <span style=\"color: red;\">=</span> LinkInMemory
<span style=\"color: red;\">}</span>
setTargets =<< sequence <span style=\"color: red;\">[</span>guessTarget <span style=\"color: teal;\">\"test.hs\"</span> Nothing<span style=\"color: red;\">]</span>
load LoadAllTargets
<span style=\"color: green;\">-- Bringing the module into the context</span>
setContext <span style=\"color: red;\">[</span>IIModule $ mkModuleName <span style=\"color: teal;\">\"Test\"</span><span style=\"color: red;\">]</span>
<span style=\"color: green;\">-- evaluating and running an action</span>
act <span style=\"color: red;\"><-</span> unsafeCoerce <$> compileExpr <span style=\"color: teal;\">\"print test\"</span>
liftIO act</code></pre>
<p>The reason that we have to use HscInterpreted and LinkInMemory is that otherwise it would compile test.hs in the current directory and leave test.hi and test.o files, which we would not be able to load in the interpreted mode. setContext, however will try to bring the code in those files first, when looking for the module ‘Test’</p>
<pre><code>dan@aquabox
[0] % ghc --make target.hs -package ghc
[1 of 1] Compiling Main             ( target.hs, target.o )
Linking target ...
dan@aquabox
[0] % ./target
123</code></pre>
<p>Let’s try something fancier like printing a list of integers, one-by-one.</p>
<pre><code>main <span style=\"color: red;\">=</span> defaultErrorHandler defaultFatalMessager defaultFlushOut $ <span style=\"color: blue; font-weight: bold;\">do</span>
runGhc <span style=\"color: red;\">(</span>Just libdir<span style=\"color: red;\">)</span> $ <span style=\"color: blue; font-weight: bold;\">do</span>
dflags <span style=\"color: red;\"><-</span> getSessionDynFlags
setSessionDynFlags $ dflags <span style=\"color: red;\">{</span> hscTarget <span style=\"color: red;\">=</span> HscInterpreted
<span style=\"color: red;\">,</span> ghcLink   <span style=\"color: red;\">=</span> LinkInMemory
<span style=\"color: red;\">}</span>
setTargets =<< sequence <span style=\"color: red;\">[</span>guessTarget <span style=\"color: teal;\">\"test.hs\"</span> Nothing<span style=\"color: red;\">]</span>
load LoadAllTargets
<span style=\"color: green;\">-- Bringing the module into the context</span>
setContext <span style=\"color: red;\">[</span>IIModule $ mkModuleName <span style=\"color: teal;\">\"Test\"</span><span style=\"color: red;\">]</span>
<span style=\"color: green;\">-- evaluating and running an action</span>
act <span style=\"color: red;\"><-</span> unsafeCoerce <$> compileExpr <span style=\"color: teal;\">\"forM_ [1,2,test] print\"</span>
liftIO act</code></pre>
<p>But when we try to run it..</p>
<pre><code>dan@aquabox
[0] % ./target
target: panic! (the 'impossible' happened)
(GHC version 7.6.3 for x86_64-apple-darwin):
Not in scope: `forM_'
Please report this as a GHC bug:
http://www.haskell.org/ghc/reportabug</code></pre>
<p>Hm, it looks like we need to bring <code>Control.Monad</code> into the scope.</p>
<p>This brings us to the next section.</p>
<h1 id=\"package-modules\">Package modules</h1>
<p>Naively, we might want to load <code>Control.Monad</code> in a similar fashion as we did with loading <code>test.hs</code></p>
<pre><code>main <span style=\"color: red;\">=</span> defaultErrorHandler defaultFatalMessager defaultFlushOut $ <span style=\"color: blue; font-weight: bold;\">do</span>
runGhc <span style=\"color: red;\">(</span>Just libdir<span style=\"color: red;\">)</span> $ <span style=\"color: blue; font-weight: bold;\">do</span>
dflags <span style=\"color: red;\"><-</span> getSessionDynFlags
setSessionDynFlags $ dflags <span style=\"color: red;\">{</span> hscTarget <span style=\"color: red;\">=</span> HscInterpreted
<span style=\"color: red;\">,</span> ghcLink   <span style=\"color: red;\">=</span> LinkInMemory
<span style=\"color: red;\">}</span>
setTargets =<< sequence <span style=\"color: red;\">[</span> guessTarget <span style=\"color: teal;\">\"test.hs\"</span> Nothing
<span style=\"color: red;\">,</span> guessTarget <span style=\"color: teal;\">\"Control.Monad\"</span> Nothing<span style=\"color: red;\">]</span>
load LoadAllTargets
<span style=\"color: green;\">-- Bringing the module into the context</span>
setContext <span style=\"color: red;\">[</span>IIModule $ mkModuleName <span style=\"color: teal;\">\"Test\"</span><span style=\"color: red;\">]</span>
<span style=\"color: green;\">-- evaluating and running an action</span>
act <span style=\"color: red;\"><-</span> unsafeCoerce <$> compileExpr <span style=\"color: teal;\">\"forM_ [1,2,test] print\"</span>
liftIO act</code></pre>
<p>Our attempt fails:</p>
<pre><code>dan@aquabox
[0] % ./target
target: panic! (the 'impossible' happened)
(GHC version 7.6.3 for x86_64-apple-darwin):
module `Control.Monad' is a package module
Please report this as a GHC bug:
http://www.haskell.org/ghc/reportabug</code></pre>
<p>Huh, what? I thought <code>guessTarget</code> works on all kinds of modules.</p>
<p>Well, it does. But it doesn’t “load the module”, it merely sets it as the <em>target for compilation</em>, basically it (together with <code>load LoadAllTargets</code>) does what <code>ghc --make</code> does. And surely it doesn’t make much sense to <code>ghc --make Control.Monad</code> when <code>Control.Monad</code> is a module from the base package. What we need to do instead is to bring the compiled <code>Control.Monad</code> module into scope. Luckily it’s not very hard to do with the help of the <code>simpleImportDecl :: ModuleName -> ImportDecl name</code>:</p>
<pre><code>main <span style=\"color: red;\">=</span> defaultErrorHandler defaultFatalMessager defaultFlushOut $ <span style=\"color: blue; font-weight: bold;\">do</span>
runGhc <span style=\"color: red;\">(</span>Just libdir<span style=\"color: red;\">)</span> $ <span style=\"color: blue; font-weight: bold;\">do</span>
dflags <span style=\"color: red;\"><-</span> getSessionDynFlags
setSessionDynFlags $ dflags <span style=\"color: red;\">{</span> hscTarget <span style=\"color: red;\">=</span> HscInterpreted
<span style=\"color: red;\">,</span> ghcLink   <span style=\"color: red;\">=</span> LinkInMemory
<span style=\"color: red;\">}</span>
setTargets =<< sequence <span style=\"color: red;\">[</span> guessTarget <span style=\"color: teal;\">\"test.hs\"</span> Nothing <span style=\"color: red;\">]</span>
load LoadAllTargets
<span style=\"color: green;\">-- Bringing the module into the context</span>
setContext <span style=\"color: red;\">[</span> IIModule . mkModuleName $ <span style=\"color: teal;\">\"Test\"</span>
<span style=\"color: red;\">,</span> IIDecl
. simpleImportDecl
. mkModuleName $ <span style=\"color: teal;\">\"Control.Monad\"</span> <span style=\"color: red;\">]</span>
<span style=\"color: green;\">-- evaluating and running an action</span>
act <span style=\"color: red;\"><-</span> unsafeCoerce <$> compileExpr <span style=\"color: teal;\">\"forM_ [1,2,test] print\"</span>
liftIO act</code></pre>
<p>And we can run it</p>
<pre><code>dan@aquabox
[0] % ./target
1
2
123</code></pre>
<h1 id=\"compiled-modules\">Compiled modules</h1>
<p>What we have implemented so far corresponds to the <code>:load*</code> command in GHCi, which gives us the full access to the source code of the program. To illustrate this let’s modify our test file:</p>
<pre><code><span style=\"color: blue; font-weight: bold;\">module</span> Test <span style=\"color: red;\">(</span>test<span style=\"color: red;\">)</span> <span style=\"color: blue; font-weight: bold;\">where</span>
test <span style=\"color: red;\">::</span> Int
test <span style=\"color: red;\">=</span> <span class=\"hs-num\">123</span>
test2 <span style=\"color: red;\">::</span> String
test2 <span style=\"color: red;\">=</span> <span style=\"color: teal;\">\"Hi\"</span></code></pre>
<p>Now, if we try to load that file as an interpreted module and evaluate <code>test2</code> nothing will stop us from doing so.</p>
<pre><code>dan@aquabo
[0] % ./target-interp
(123,\"Hi\")</code></pre>
<p>To use the compiled module we have to bring <code>Test</code> into the context the same way we dealt with <code>Control.Monad</code></p>
<pre><code>main <span style=\"color: red;\">=</span> defaultErrorHandler defaultFatalMessager defaultFlushOut $ <span style=\"color: blue; font-weight: bold;\">do</span>
runGhc <span style=\"color: red;\">(</span>Just libdir<span style=\"color: red;\">)</span> $ <span style=\"color: blue; font-weight: bold;\">do</span>
dflags <span style=\"color: red;\"><-</span> getSessionDynFlags
setSessionDynFlags $ dflags <span style=\"color: red;\">{</span> hscTarget <span style=\"color: red;\">=</span> HscInterpreted
<span style=\"color: red;\">,</span> ghcLink   <span style=\"color: red;\">=</span> LinkInMemory
<span style=\"color: red;\">}</span>
setTargets =<< sequence <span style=\"color: red;\">[</span> guessTarget <span style=\"color: teal;\">\"Test\"</span> Nothing <span style=\"color: red;\">]</span>
load LoadAllTargets
<span style=\"color: green;\">-- Bringing the module into the context</span>
setContext <span style=\"color: red;\">[</span> IIDecl $ simpleImportDecl <span style=\"color: red;\">(</span>mkModuleName <span style=\"color: teal;\">\"Test\"</span><span style=\"color: red;\">)</span>
<span style=\"color: red;\">,</span> IIDecl $ simpleImportDecl <span style=\"color: red;\">(</span>mkModuleName <span style=\"color: teal;\">\"Prelude\"</span><span style=\"color: red;\">)</span>
<span style=\"color: red;\">]</span>
printExpr <span style=\"color: teal;\">\"test\"</span>
printExpr <span style=\"color: teal;\">\"test2\"</span>
printExpr <span style=\"color: red;\">::</span> String <span style=\"color: red;\">-></span> Ghc ()
printExpr expr <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
liftIO $ putStrLn <span style=\"color: red;\">(</span><span style=\"color: teal;\">\"-- Going to print \"</span> ++ expr<span style=\"color: red;\">)</span>
act <span style=\"color: red;\"><-</span> unsafeCoerce <$> compileExpr <span style=\"color: red;\">(</span><span style=\"color: teal;\">\"print (\"</span> ++ expr ++ <span style=\"color: teal;\">\")\"</span><span style=\"color: red;\">)</span>
liftIO act</code></pre>
<p>Output:</p>
<pre><code>dan@aquabox : ~/snippets/ghcapi
[0] % ./target
-- Going to print test
123
-- Going to print test2
target: panic! (the 'impossible' happened)
(GHC version 7.6.3 for x86_64-apple-darwin):
Not in scope: `test2'
Perhaps you meant `test' (imported from Test)
Please report this as a GHC bug:  http://www.haskell.org/ghc/reportabug</code></pre>
<p><em>Note: I had to bring the <code>Prelude</code> into context this time, like a regular module. I tried setting the <code>ideclImplicit</code> option in <a href=\"http://co-dan.github.io/ghc-docs/HsImpExp.html#t:ImportDecl\">ImportDecl</a>, but it didn’t work for some reason. Maybe it is does not what I think it supposed to do.</em></p>
<h1 id=\"outro\">Outro</h1>
<p>So, that is it, we have managed to dynamically load Haskell source code and evaluate it. I can only refer you to the <a href=\"http://co-dan.github.io/ghc-docs/\">GHC haddocs</a> for specific functions that we used in this post, most of them contain way more options that we used and they might prove to be useful to you.</p>
<br /> Tagged: <a href=\"http://parenz.wordpress.com/tag/ghc/\">ghc</a>, <a href=\"http://parenz.wordpress.com/tag/haskell-2/\">haskell</a>, <a href=\"http://parenz.wordpress.com/tag/soc/\">soc</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/parenz.wordpress.com/115/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/parenz.wordpress.com/115/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=parenz.wordpress.com&blog=26722965&post=115&subd=parenz&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "ff4bde95b3696584f32f8368947194ac") (399 (21009 53414 212668) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_6022\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_9224\"></span> time, whereas using the categorical functor takes time <span id=\"tex_3392\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_3678\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "b34c3b767d9523a7b4b6d7dc22f4ee01") (398 (21006 18672 936781) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_4113\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_7077\"></span> time, whereas using the categorical functor takes time <span id=\"tex_6583\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_6151\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "bf654c41fa666763a7726d2bb23453f8") (397 (21005 56692 244589) "http://typesandkinds.wordpress.com/2013/08/15/roles-a-new-feature-of-ghc/" "Richard Eisenberg: Roles: a new feature of GHC" nil "Thu, 15 Aug 2013 18:25:19 +0000" "<p>Last week, I pushed an implementation of <em>roles</em> to GHC HEAD. This post explains what roles are, why they exist, and why you should care. Roles will be a part of GHC 7.8.</p>
<h2 id=\"an-old-problem\">An old problem</h2>
<p><strong>Roles fix a problem in GHC’s type system that has existed for years.</strong></p>
<p>The problem is the combination of <code>GeneralizedNewtypeDeriving</code> (henceforth called GND) and type families. An example is always best:</p>
<pre><code>> <span style=\"color: green;\">{-# LANGUAGE GeneralizedNewtypeDeriving, TypeFamilies, StandaloneDeriving,
>              MultiParamTypeClasses, GADTs #-}</span>
>
> <span style=\"color: blue; font-weight: bold;\">module</span> Roles <span style=\"color: blue; font-weight: bold;\">where</span>
>
> <span style=\"color: blue; font-weight: bold;\">class</span> Incrementable a <span style=\"color: blue; font-weight: bold;\">where</span>
>   incr <span style=\"color: red;\">::</span> a <span style=\"color: red;\">-></span> a
>
> <span style=\"color: blue; font-weight: bold;\">instance</span> Incrementable Int <span style=\"color: blue; font-weight: bold;\">where</span>
>   incr x <span style=\"color: red;\">=</span> x + <span class=\"hs-num\">1</span>
>
> <span style=\"color: blue; font-weight: bold;\">newtype</span> Age <span style=\"color: red;\">=</span> MkAge Int
>   <span style=\"color: blue; font-weight: bold;\">deriving</span> Incrementable
</code></pre>
<p>The idea is that, because the declaration for <code>Age</code> says that any <code>Age</code> is really just an <code>Int</code> in disguise, we can just re-use the instance for <code>Incrementable Int</code> and make it into an instance for <code>Incrementable Age</code>. Internally, <code>Age</code> has the exact same representation as <code>Int</code>, so GHC can really just reuse the methods that were defined for <code>Int</code>.</p>
<p>So far, so good. This makes good sense, allows for less boilerplate code, and is efficient at runtime. Yet, a problem lurks if we start using some type families:</p>
<pre><code>> <span style=\"color: blue; font-weight: bold;\">type</span> family IsItAgeOrInt a
> <span style=\"color: blue; font-weight: bold;\">type</span> <span style=\"color: blue; font-weight: bold;\">instance</span> IsItAgeOrInt Int <span style=\"color: red;\">=</span> Bool
> <span style=\"color: blue; font-weight: bold;\">type</span> <span style=\"color: blue; font-weight: bold;\">instance</span> IsItAgeOrInt Age <span style=\"color: red;\">=</span> Char
>
> <span style=\"color: blue; font-weight: bold;\">class</span> BadIdea a <span style=\"color: blue; font-weight: bold;\">where</span>
>   frob <span style=\"color: red;\">::</span> a <span style=\"color: red;\">-></span> IsItAgeOrInt a
>
> <span style=\"color: blue; font-weight: bold;\">instance</span> BadIdea Int <span style=\"color: blue; font-weight: bold;\">where</span>
>   frob x <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span>x > <span class=\"hs-num\">0</span><span style=\"color: red;\">)</span>
>
> <span style=\"color: blue; font-weight: bold;\">deriving</span> <span style=\"color: blue; font-weight: bold;\">instance</span> BadIdea Age
</code></pre>
<p>Calling <code>frob</code> on an <code>Int</code> produces nothing strange:</p>
<pre><code><span style=\"color: gray;\">ghci> </span>frob 5
<span style=\"color: blue;\">True</span>
<span style=\"color: gray;\">ghci> </span>frob 0
<span style=\"color: blue;\">False</span>
<span style=\"color: gray;\">ghci> </span>frob (-3)
<span style=\"color: blue;\">False</span>
</code></pre>
<p>But, what happens if we call <code>frob</code> on an <code>Age</code>? According to <code>frob</code>’s type, calling <code>frob</code> on an <code>Age</code> should produce a <code>IsItAgeOrInt Age</code> – that is, a <code>Char</code>. But, we have reused the definition of <code>frob</code> for <code>Int</code> in the instance for <code>Age</code>! The result: general unhappiness:</p>
<pre><code><span style=\"color: gray;\">ghci> </span>frob (MkAge 5)
'\\-1152921504589753323'
<span style=\"color: gray;\">ghci> </span>frob (MkAge 0)
'\\4375976000'
<span style=\"color: gray;\">ghci> </span>frob (MkAge (-3))
'\\4375976000'
</code></pre>
<p>We’ve broken the type system.</p>
<p>This problem is fairly well-known. The GHC Trac has 3 bugs from it (<a href=\"http://ghc.haskell.org/trac/ghc/ticket/1496\">#1496</a>, <a href=\"http://ghc.haskell.org/trac/ghc/ticket/4846\">#4846</a>, and <a href=\"http://ghc.haskell.org/trac/ghc/ticket/7148\">#7148</a>), there was a <a href=\"http://www.seas.upenn.edu/~sweirich/papers/popl163af-weirich.pdf\">POPL paper</a> about it, and at least one <a href=\"http://joyoftypes.blogspot.co.uk/2012/08/generalizednewtypederiving-is.html\">blog post</a>. The bug – which rightly is a flaw of the theory, not the implementation – is one of the reasons that modules with GND enabled are not considered part of the Safe Haskell subset. (The other reason is that GND can be used to break module abstraction, a subject which is not considered further here. See ticket <a href=\"http://ghc.haskell.org/trac/ghc/ticket/5498\">#5498</a>.)</p>
<p>The solution comes from that <a href=\"http://www.seas.upenn.edu/~sweirich/papers/popl163af-weirich.pdf\">POPL paper</a>: assign so-called <em>roles</em> to type variables to constrain how those type variables are used.</p>
<h2 id=\"roles\">Roles</h2>
<p>Why precisely is it a bad idea to say <code>deriving instance BadIdea Age</code>? Because a method in that class uses a type family in its type, and type families can tell the difference between <code>Int</code> and <code>Age</code>. The GND mechanism, though, pretends that <code>Int</code> and <code>Age</code> are the same. Thus, the two bits induce GHC to experience some cognitive dissonance, and we all suffer.</p>
<p>Roles label the type variables of datatypes, classes, and vanilla type synonyms indicating whether or not these all uses of these variables respect the equality between a newtype and its representation. If all uses of a variable do respect newtype-induced equalities, we say that the variable’s role is <code>R</code> (for “representational”). If it might be possible for a use of the variable to spot the difference between <code>Age</code> and <code>Int</code>, we say that the variable’s role is <code>N</code> (for “nominal”). There is a third role, <code>P</code> for “phantom”, which I get to later.</p>
<p>In our example, the parameter to <code>Incrementable</code> would have role <code>R</code>, while <code>BadIdea</code> would get role <code>N</code>. Because of these role assignments, GHC HEAD will refuse to compile the code above. It issues this error:</p>
<pre><code>Can't make a derived instance of ‛BadIdea Age’
(even with cunning newtype deriving):
it is not type-safe to use GeneralizedNewtypeDeriving on this class;
the last parameter of ‛BadIdea’ is at role N
In the stand-alone deriving instance for ‛BadIdea Age’</code></pre>
<h2 id=\"role-inference\">Role inference</h2>
<p>How do we know what role to use for what parameter? We use role inference, of course! Role inference is actually quite straightforward. GHC will look at all uses of a type variable in a datatype, class, or vanilla type synonym definition and see if any of those uses are at role <code>N</code>. If any uses are at role <code>N</code>, then the variable itself must be at role <code>N</code>. Otherwise, (if the variable is used at all) it gets role <code>R</code>. The base cases are type families, <code>(~)</code>, and certain type applications. All arguments to type families naturally get role <code>N</code>, as do the two arguments to the type equality operator <code>(~)</code>. (This is because <code>(~)</code> will <em>not</em> say that <code>Age</code> and <code>Int</code> are equal.) Because GADTs are internally represented using <code>(~)</code>, any GADT-like parameter will also be at role <code>N</code>.</p>
<p>Above, I said that certain type applications cause a role to be forced to <code>N</code>. This is a little subtler than the other cases, and needs an example:</p>
<pre><code>> <span style=\"color: blue; font-weight: bold;\">class</span> Twiddle a b <span style=\"color: blue; font-weight: bold;\">where</span>
>   meth <span style=\"color: red;\">::</span> a Int <span style=\"color: red;\">-></span> a b
>
> <span style=\"color: blue; font-weight: bold;\">instance</span> Twiddle [] Int <span style=\"color: blue; font-weight: bold;\">where</span>
>   meth <span style=\"color: red;\">=</span> id
>
> <span style=\"color: blue; font-weight: bold;\">data</span> GADT a <span style=\"color: blue; font-weight: bold;\">where</span>
>   GInt <span style=\"color: red;\">::</span> Int <span style=\"color: red;\">-></span> GADT Int
> <span style=\"color: blue; font-weight: bold;\">deriving</span> <span style=\"color: blue; font-weight: bold;\">instance</span> Show <span style=\"color: red;\">(</span>GADT a<span style=\"color: red;\">)</span>
>
> <span style=\"color: blue; font-weight: bold;\">instance</span> Twiddle GADT Int <span style=\"color: blue; font-weight: bold;\">where</span>
>   meth <span style=\"color: red;\">=</span> id
>
> <span style=\"color: blue; font-weight: bold;\">deriving</span> <span style=\"color: blue; font-weight: bold;\">instance</span> Twiddle GADT Age
>
> weird <span style=\"color: red;\">::</span> GADT Age
> weird <span style=\"color: red;\">=</span> meth <span style=\"color: red;\">(</span>GInt <span class=\"hs-num\">5</span><span style=\"color: red;\">)</span>
</code>
<code><span style=\"color: gray;\">ghci> </span>weird
GInt 5
<span style=\"color: gray;\">ghci> </span>:t weird
weird :: GADT Age
</code></pre>
<p>What’s going on here? As usual, the GND mechanism just appropriates the definition for <code>meth</code> wholesale for the instance for <code>Age</code>. That method is just the identity function. But, in the <code>Age</code> instance for <code>Twiddle</code>, the <code>meth</code> method has type <code>GADT Int -> GADT Age</code> – clearly <em>not</em> an identity function. Yet, it still works just fine, creating the ill-typed <code>weird</code>. A little more pushing here can create <code>unsafeCoerce</code> and segfaults.</p>
<p>But we already knew that GADTs behaved strangely with respect to GND. The difference in this case is that the derived class, <code>Twiddle</code>, <em>does not mention any GADTs</em>. The solution is that, whenever a type variable is used as the argument to another type variable, such as <code>b</code> in the definition of <code>Twiddle</code>, that variable gets role <code>N</code>. The variable <code>a</code> has nothing unusual about it, so it gets role <code>R</code>.</p>
<h2 id=\"phantom-roles\">Phantom roles</h2>
<p>There is ongoing work (not mine) on implementing newtype wrappers, as described <a href=\"http://ghc.haskell.org/trac/ghc/wiki/NewtypeWrappers\">here</a>. Newtype wrappers will allow you to write code that “lifts” a newtype equality (such as the one between <code>Age</code> and <code>Int</code>) into other types (such as equating <code>[Age]</code> with <code>[Int]</code>). These lifted equalities would have no runtime cost. This is quite different than the situation today: although <code>Age</code> and <code>Int</code> can be converted for free, converting <code>[Age]</code> to <code>[Int]</code> requires iterating down the list.</p>
<p>With that application in mind, consider this type:</p>
<pre><code>> <span style=\"color: blue; font-weight: bold;\">data</span> Phantom a <span style=\"color: red;\">=</span> MkPhantom Int
</code></pre>
<p>Should we be able to convert <code>[Phantom Bool]</code> to <code>[Phantom Char]</code>? Sure we should. Labeling <code>a</code>’s role as <code>P</code> allows for this. The technical details of how <code>P</code> works internally are beyond the scope of this post (but you could see <a href=\"http://ghc.haskell.org/trac/ghc/wiki/RolesImplementation\">here</a> for starters), but we are guaranteed that any variable at role <code>P</code> is never actually used in the representation of a datatype.</p>
<h2 id=\"role-annotations\">Role annotations</h2>
<p>Sometimes, an implementation of an idea doesn’t quite match the abstraction. For example, the definition of <code>Ptr</code>, GHC’s type for pointers that might be used with foreign functions, is this:</p>
<pre><code><span style=\"color: blue; font-weight: bold;\">data</span> Ptr a <span style=\"color: red;\">=</span> Ptr Addr#</code></pre>
<p>If left to its own devices, GHC would infer role <code>P</code> for the type parameter <code>a</code>, because <code>a</code> is not used in the definition of <code>Ptr</code>. Yet, that goes against what we have in mind – we don’t really want to convert <code>Ptr Int</code>s to <code>Ptr (Bool -> Bool)</code>s willy-nilly. So, we use a <em>role annotation</em> (enabled with <code>-XRoleAnnotations</code>) which allows the programmer to override GHC’s inference, thus:</p>
<pre><code><span style=\"color: blue; font-weight: bold;\">data</span> Ptr a<span style=\"color: red;\">@</span>R <span style=\"color: red;\">=</span> Ptr Addr#</code></pre>
<p>This role annotation (the <code>@R</code>) forces <code>a</code>’s role to be <code>R</code>, as desired. Note that you can’t force an unsafe role, such as requiring <code>BadIdea</code>’s parameter to be at role <code>R</code>. Role annotations only allow for stricter roling.</p>
<h2 id=\"how-does-all-this-affect-you\">How does all this affect you?</h2>
<p>Hopefully, roles won’t affect your code too much. But, it is possible that some code that has previously worked now will not. Although code breakage is rightly seen as a terrible thing, it’s actually intentional here: much of the broken code probably has a type error lurking somewhere. In my experience, there are two problems that may arise:</p>
<ul>
<li>Uses of GND that worked previously and you know are safe now fail. First off, are you <em>sure</em> that it’s safe? Sometimes, the answer is a resounding “yes!”, but GHC still won’t let you use GND. You will have to write an instance yourself, or provide other wrappers. In the design of this feature, we have considered adding a way to use GND unsafely, but we’re not sure what the demand will be. Do you need to use GND unsafely? Let me know.</li>
<li>In <code>.hs-boot</code> files (see the <a href=\"http://www.haskell.org/ghc/docs/latest/html/users_guide/separate-compilation.html\">relevant section</a> of GHC’s user manual), all declarations must match exactly with the declarations in the corresponding <code>.hs</code> file. This includes roles. However, it is acceptable to leave out definitions in a <code>.hs-boot</code> file. By default, roles are guessed to be <code>R</code> in <code>.hs-boot</code> files. If you have an <code>.hs-boot</code> file that declares a datatype or class whose definition is omitted and whose parameters are not at role <code>R</code>, you will have to add a role annotation. I’m hoping this doesn’t come up too often.</li>
</ul>
<p>Separately from breakage, writers of libraries may also want to think about whether a role annotation would be helpful in their declarations. The best reason I can think of to do this is to prevent users from using GND on a class. For example, a <code>Set</code> uses a type’s <code>Ord</code> instance to order the data internally. But, the definition of <code>Set</code> does not use type families or other features forcing an <code>N</code> role. So, <code>Set</code>’s parameter will be at role <code>R</code>. Yet, if GND is used to lift a class mentioning <code>Set</code> from, say, <code>Int</code> to <code>Age</code>, the <code>Ord</code> instances for <code>Int</code> and <code>Age</code> might be different, and bad behavior will result. Note that this “bad behavior” would not be a type error, just incorrect runtime behavior. (If it were a type error, roles would hopefully stop this from happening!) The upshot of this is that <code>Set</code>’s parameter should be labeled with role <code>N</code>.</p>
<h2 id=\"further-reading\">Further reading</h2>
<p>To learn more about roles in GHC, you can check out the up-to-date wiki pages on the subject, <a href=\"http://ghc.haskell.org/trac/ghc/wiki/Roles\">for users</a> and <a href=\"http://ghc.haskell.org/trac/ghc/wiki/RolesImplementation\">for implementers</a>.</p>
<p>If you run into problems, do let me know!</p>
<br />  <a href=\"http://feeds.wordpress.com/1.0/gocomments/typesandkinds.wordpress.com/153/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/typesandkinds.wordpress.com/153/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=typesandkinds.wordpress.com&blog=43305225&post=153&subd=typesandkinds&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "93a10b4b4da41ca94783429171e7a138") (396 (21005 1051 21960) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_7973\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_7413\"></span> time, whereas using the categorical functor takes time <span id=\"tex_7334\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_2785\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "16e5c99a0268c6812159fb6da97704e7") (395 (21004 37477 80270) "http://lpuppet.banquise.net/blog/2013/08/15/version-0-dot-9-0-is-out-for-testing/" "language-puppet: Version 0.9.0 is out for testing" nil "Thu, 15 Aug 2013 07:34:00 +0000" "<p>Finally the huge rewrite is almost done !</p>
<h2>It is beta</h2>
<p>It is now only accessible though GitHub, in the <a href=\"https://github.com/bartavelle/language-puppet/tree/beta\">beta</a> branch. It uses another highly experimental
module : <a href=\"http://hackage.haskell.org/package/filecache\">filecache</a>. This module should provide a quick and easy method for caching the result of an IO
computation on a file. It uses hinotify for cache expiration, and is completely untested !</p>
<p>The behaviour of the interpreter is radically different from the previous version in many ways. It should hopefully be a better approximation of the “real” Puppet implementation.
This is one of the major goals of this rewrite, especially concerning resource dependencies that were totally off the mark in the previous version.</p>
<p>On the other hand, most of the documentation has disappeared.</p>
<h2>Performance improvements</h2>
<p>The second goal is to increase performances. In order to do so, several radical changes have been performed :</p>
<ul>
<li>The Ruby interpreter now lives in its own system thread, which is pretty useful as this package now only works with the threaded runtime !</li>
<li>The “unresolved” types that lived between parsing and final interpretation have been ditched.</li>
<li>All important types are now strict, and the strict-base-types module is well used.</li>
</ul>
<p>I do not have hard numbers right now, but now that everything is strict using more cores actually speeds things up. This is still not perfect and will require tuning, but this is
much better than the previous state of affairs. The parser seems a bit slower (between 10% and 30%), but the interpreter is much faster. This means that single testing is a bit
slower (about 5% slower), but future embedding in a long lived process will give a huge performance increase.</p>
<h2>Nicer codebase</h2>
<p>First of all, the lens package is now used everywhere. This might look like obfuscation for those not used to it, but I believe it is incredibly nice, especially when working with
a complex state.</p>
<p>The parser has been completely rewritten, using the <a href=\"http://hackage.haskell.org/package/parsers\">parsers</a> abstraction, with a little hack to use Parsec underneath with my own
“lexeme” function. I would have liked to use <a href=\"http://hackage.haskell.org/package/trifecta\">trifecta</a> for its nicer error messages, but I could not find how to do the same trick
with it.</p>
<p>Speaking of which, now almost all text is <a href=\"http://hackage.haskell.org/package/ansi-wl-pprint\">pretty printed</a> in color. This is noticeably slower when rendering a large catalog,
but so much nicer to the eyes it is well worth it.</p>
<p>The “puppetresources” and “facter” modules are now merged, and will be marked as deprecated when this version stabilizes.</p>
<p>There is still a lot of work to do with it, but the testing API should be much easier to use. I am considering writing a DSL to it so that it wouldn’t require a development
environment to test stuff.</p>
<p>Finally, there used to be a lot of tuples in the type signatures that are now replaced by proper types, making function signatures much more expressive.</p>
<figure class=\"code\"><figcaption><span>before.hs </span></figcaption>
<div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
</pre></td><td class=\"code\"><pre><code class=\"hs\"><span class=\"line\"><span class=\"nf\">_unresolvedRels</span> <span class=\"ow\">::</span> <span class=\"o\">!</span><span class=\"p\">[([(</span><span class=\"kt\">LinkType</span><span class=\"p\">,</span> <span class=\"kt\">GeneralValue</span><span class=\"p\">,</span> <span class=\"kt\">GeneralValue</span><span class=\"p\">)],</span> <span class=\"p\">(</span><span class=\"kt\">T</span><span class=\"o\">.</span><span class=\"kt\">Text</span><span class=\"p\">,</span> <span class=\"kt\">GeneralString</span><span class=\"p\">),</span> <span class=\"kt\">RelUpdateType</span><span class=\"p\">,</span> <span class=\"kt\">SourcePos</span><span class=\"p\">,</span> <span class=\"p\">[[</span><span class=\"kt\">ScopeName</span><span class=\"p\">]])],</span>
</span></code></pre></td></tr></tbody></table></div></figure>
<figure class=\"code\"><figcaption><span>after.hs </span></figcaption>
<div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
<span class=\"line-number\">2</span>
<span class=\"line-number\">3</span>
<span class=\"line-number\">4</span>
<span class=\"line-number\">5</span>
<span class=\"line-number\">6</span>
</pre></td><td class=\"code\"><pre><code class=\"hs\"><span class=\"line\"><span class=\"nf\">_extraRelations</span>     <span class=\"ow\">::</span> <span class=\"o\">!</span><span class=\"p\">[</span><span class=\"kt\">LinkInformation</span><span class=\"p\">]</span>
</span><span class=\"line\"><span class=\"kr\">data</span> <span class=\"kt\">LinkInformation</span> <span class=\"ow\">=</span> <span class=\"kt\">LinkInformation</span> <span class=\"p\">{</span> <span class=\"n\">_linksrc</span>  <span class=\"ow\">::</span> <span class=\"o\">!</span><span class=\"kt\">RIdentifier</span>
</span><span class=\"line\">                                       <span class=\"p\">,</span> <span class=\"n\">_linkdst</span>  <span class=\"ow\">::</span> <span class=\"o\">!</span><span class=\"kt\">RIdentifier</span>
</span><span class=\"line\">                                       <span class=\"p\">,</span> <span class=\"n\">_linkType</span> <span class=\"ow\">::</span> <span class=\"o\">!</span><span class=\"kt\">LinkType</span>
</span><span class=\"line\">                                       <span class=\"p\">,</span> <span class=\"n\">_linkPos</span>  <span class=\"ow\">::</span> <span class=\"o\">!</span><span class=\"kt\">PPosition</span>
</span><span class=\"line\">                                       <span class=\"p\">}</span>
</span></code></pre></td></tr></tbody></table></div></figure>" nil nil "553f6e5de34f41caaa3a9269516d9a49") (394 (21004 37476 985700) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_5081\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_8101\"></span> time, whereas using the categorical functor takes time <span id=\"tex_8506\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_3126\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "19722666dfcdc3dd23b38e8618746b94") (393 (21004 31843 224179) "http://justtesting.org/post/58297256486" "Manuel M T Chakravarty: Embedded Languages for High-Performance Computing in Haskell" nil "Thu, 15 Aug 2013 02:51:43 +0000" "<p>At the Facebook Faculty Summit, I talked about <a href=\"https://speakerdeck.com/mchakravarty/embedded-languages-for-high-performance-computing-in-haskell\">Embedded Languages for High-Performance Computing in Haskell</a>. Using Accelerate as an example, this talk discusses the use of embedded languages with template-based code generation for targeting parallel architectures.</p>" nil nil "ae2a71b197cc00d24a282fd6fa089881") (392 (21004 31843 223759) "http://fuuzetsu.co.uk/blog/posts/2013-08-14-adding-markup-to-haddock-part-2.html" "Mateusz Kowalczyk: Adding bold to Haddock (part 2)" nil "Thu, 15 Aug 2013 02:06:08 +0000" "<div class=\"info\">
Posted on August 15, 2013

by Fūzetsu

</div>
<p>A while ago, <a href=\"http://fuuzetsu.co.uk/posts/2013-08-05-adding-markup-to-Haddock.html\">I wrote</a> about adding support for <strong>bold</strong> to Haddock. Last time, I added tests and made the initial implementation. Now I’m going to briefly go over which files one needs to change for the back-ends.</p>
<p>There are three back-ends: LaTeX, Hoogle and XHtml. XHtml is the one people see the most, I imagine. There are no tests for either Hoogle nor LaTeX and I suspect they might have seen a fair amount of breakage already. I haven’t heard direct complaints though so I’ll look into verifying these later.</p>
<p>First in <code>Utils.hs</code> we add a new default field called <code>markupBold</code> to the <code>idMarkup</code> identity record and immediately after we add a new pattern covering <code>DocBold</code> to the <code>markup</code> function. This is used throughout the back-ends as a uniform interface. We also need to add a pattern for <code>DocBold</code> in the <code>renameDoc</code> function <code>Rename.hs</code>. From what I gather from the very scarce comments, this module renames things such as identifiers into a more human-friendly form: there’s no need to render something as <code>Foo.Bar.Baz</code> if we’re in <code>Foo.Bar</code>. Unfortunately, it’s 500 LOC of juggling of GHC’s types so I can’t be certain. Also add the new pattern to the <code>rename</code> function in <code>LexParseRn.hs</code> which runs the actual look-up.</p>
<p>Updating the interfaces is quite simple in this case. In each of</p>
<pre><code> src/Haddock/Backends/Hoogle.hs
src/Haddock/Backends/LaTeX.hs
src/Haddock/Backends/Xhtml/DocMarkup.hs</code></pre>
<p>find the function where other markup is translated and add your change. For example for LateX, it was a 3 line change:</p>
<pre class=\"sourceCode diff\"><code class=\"sourceCode diff\">   markupEmphasis             = \\p v -> emph (p v),
<span class=\"ot\">+  markupBold                 = \\p v -> bold (p v),</span>
markupMonospaced           = \\p _ -> tt (p Mono),
<span class=\"st\">-- snip…</span>
<span class=\"ot\">+bold :: LaTeX -> LaTeX</span>
<span class=\"ot\">+bold ltx = text \"\\\\textbf\" <> braces ltx</span></code></pre>
<p>It’s easy to look around and see how things are done and mimic the behaviour. Last but not least, there’s a <code>InterfaceFile.hs</code> which unsurprisingly deals with Haddock’s interface file. This file can be used later by Haddock to link against packages it has already generated documentation for. Look at the <code>Binary</code> instance for <code>Doc id</code> and change it accordingly. <strong>If you change the instance, make sure to bump the <code>binaryInterfaceVersion</code></strong>. Also update the <code>binaryInterfaceVersionCompatibility</code>. This will ensure that we get a nice error message if we try to link between incompatible versions rather than weird behaviour. This file is only relevant if you add/remove markup or structurally change existing one. Simple parser changes to existing markup do not affect this file.</p>
<p>I am not bumping this until everything is finalised and ready for release but I have to be careful to not let any test docs I generate with it get out of the sandbox.</p>
<p>We’re done, both test-suites pass. Here’s a list of changes I had to make all together. The majority is just the tests, with very few actual code changes (and some of it is just clobbering whitespace &c).</p>
<pre><code>12 files changed, 170 insertions(+), 12 deletions(-)
html-test/ref/Bold.html                 | 102
html-test/src/Bold.hs                   |   9
src/Haddock/Backends/Hoogle.hs          |   7
src/Haddock/Backends/LaTeX.hs           |   3
src/Haddock/Backends/Xhtml/DocMarkup.hs |   1
src/Haddock/Interface/LexParseRn.hs     |   1
src/Haddock/Interface/Rename.hs         |   7
src/Haddock/InterfaceFile.hs            |   6
src/Haddock/Parser.hs                   |  13
src/Haddock/Types.hs                    |   3
src/Haddock/Utils.hs                    |  11
test/Haddock/ParseSpec.hs               |  19</code></pre>
<p>It’s time for some images. What use is all this if it doesn’t look pretty in the end? Here’s the result of the efforts. Generating docs for the following code</p>
<pre class=\"sourceCode haskell\"><code class=\"sourceCode haskell\"><span class=\"co\">-- | Module : File</span>
<span class=\"kw\">module</span> <span class=\"dt\">File</span> <span class=\"kw\">where</span>
<span class=\"co\">-- | /SomeType/</span>
<span class=\"kw\">data</span> <span class=\"dt\">SomeType</span>
<span class=\"co\">-- | __Othertype__</span>
<span class=\"kw\">data</span> <span class=\"dt\">OtherType</span>
<span class=\"co\">-- | Here's some __bold__</span>
<span class=\"ot\">foo ::</span> <span class=\"dt\">SomeType</span> <span class=\"ot\">-></span> <span class=\"dt\">SomeType</span>
foo <span class=\"fu\">=</span> <span class=\"fu\">undefined</span>
<span class=\"co\">-- | __Multi-word bold__</span>
<span class=\"ot\">bar ::</span> <span class=\"dt\">OtherType</span> <span class=\"ot\">-></span> <span class=\"dt\">OtherType</span>
bar <span class=\"fu\">=</span> <span class=\"fu\">undefined</span>
<span class=\"co\">-- | __No multi-line</span>
<span class=\"co\">-- bold, no sir__</span>
<span class=\"ot\">baz ::</span> [a] <span class=\"ot\">-></span> [a]
baz <span class=\"fu\">=</span> <span class=\"fu\">undefined</span>
<span class=\"co\">-- | __Can't escape \\\\__ the underscores__</span>
<span class=\"ot\">qux ::</span> <span class=\"dt\">SomeType</span> <span class=\"ot\">-></span> <span class=\"dt\">OtherType</span>
qux <span class=\"fu\">=</span> <span class=\"fu\">undefined</span>
<span class=\"co\">-- | __Can't even have a single unescaped _ in the string__</span>
<span class=\"ot\">quux ::</span> t
quux <span class=\"fu\">=</span> <span class=\"fu\">undefined</span>
<span class=\"co\">-- | __No other /markup/ inside either__</span>
<span class=\"ot\">corge ::</span> <span class=\"dt\">OtherType</span> <span class=\"ot\">-></span> <span class=\"dt\">SomeType</span>
corge <span class=\"fu\">=</span> <span class=\"fu\">undefined</span></code></pre>
<p>yields us</p>
<div class=\"figure\">
<img src=\"http://fuuzetsu.co.uk/images/poor_bold.png\" alt=\"naive bold implementation\" /><p class=\"caption\">naive bold implementation</p>
</div>
<p>Something that I wanted to do for a while and that was further motivated by a <a href=\"http://trac.haskell.org/haddock/ticket/252\">recent Trac ticket</a> was to allow markup inside of emphasis (and now bold). There’s also a <a href=\"http://trac.haskell.org/haddock/ticket/126\">much less recent ticket</a> about multi-line emphasis (and now bold). Here’s an exclusive preview of both of these features. In fact, even I’m actually rendering the documentation for the first time to inspect with my eyes as I rely on tests otherwise:</p>
<div class=\"figure\">
<img src=\"http://fuuzetsu.co.uk/images/inside_markup.png\" alt=\"markup inside markup\" /><p class=\"caption\">markup inside markup</p>
</div>
<p>Also, something I’m less enthusiastic about, multi-line markup:</p>
<div class=\"figure\">
<img src=\"http://fuuzetsu.co.uk/images/multi_markup.png\" alt=\"multi-line bold\" /><p class=\"caption\">multi-line bold</p>
</div>
<p>See the first ticket I linked to for reasoning. I’m writing <a href=\"http://hackage.haskell.org/package/doccheck\">a tool</a> on a side to help to determine the effects of various changes on existing documentation but it is not usable it. It’s difficult to reliably extract Haddock comments from thousands of files without actually building the projects. I’m thinking of using <a href=\"http://hackage.haskell.org/package/haskell-src-exts\">haskell-src-exts</a> to help and make this task easier but there’s <a href=\"http://comments.gmane.org/gmane.comp.lang.haskell.cafe/106768\">a problem</a> with this approach as well. Currently I compensate for the lack of such tool with tests.</p>
<p>I might write a post in the future on the progress of this and if and how the problems were solved (or weren’t solved!). A warning system enabled with a flag might be nice in Haddock itself but this is not currently planned.</p>
<p>As a side note, I had problem with my e-mail address from 4th to 14th of August, so if you tried to <a href=\"http://fuuzetsu.co.uk/contact.html\">contact me</a> and didn’t get a reply, please try again.</p>" nil nil "2abc792ef621b6e49ef8e5fbb292b1d4") (391 (21004 31843 222394) "http://justtesting.org/post/58283812372" "Manuel M T Chakravarty: Do Extraterrestrials Use Functional Programming?" nil "Thu, 15 Aug 2013 00:01:58 +0000" "<p>The slides of my keynote from YOW! Lambda Jam 2013 in May in Brisbane consider a key question: <a href=\"https://speakerdeck.com/mchakravarty/do-extraterrestrials-use-functional-programming\">Do Extraterrestrials Use Functional Programming?</a> The talk discusses fundamental aspects of programming as well as means to leverage an understanding of these fundamental aspects to improve our programming practice.</p>" nil nil "2d5f83eab3fc48f7da1022996fefba8b") (390 (21004 31843 221969) "http://neilmitchell.blogspot.com/2013/08/destroying-performance-with-strictness.html" "Neil Mitchell: Destroying Performance with Strictness" "noreply@blogger.com (Neil Mitchell)" "Wed, 14 Aug 2013 21:52:00 +0000" "<i>Summary: New versions of unordered-containers cause a massive performance regression in uniplate (10x slower is typical), which I have fixed in uniplate-1.6.11.</i><br /><br />I've just uploaded <a href=\"http://neilmitchell.blogspot.de/hackage.haskell.org/package/uniplate\">uniplate-1.6.11</a>, which fixes a severe performance regression introduced by <a href=\"http://hackage.haskell.org/package/unordered-containers\">unordered-containers-0.2.3.0</a> and above. As an example, the time to run <a href=\"http://hackage.haskell.org/package/hlint\">HLint</a> on the HLint source code (<a href=\"http://neilmitchell.blogspot.co.uk/2010/01/optimising-hlint.html\">my standard benchmark</a>) jumped from 1.7 seconds to 18.6 seconds, more than ten times slower. I strongly recommend anyone using Uniplate/HLint to upgrade.<br /><br />The problem is caused by the <tt>lookupDefault</tt> function from the <tt>Data.HashMap.Strict</tt> module:<br /><br /><pre>lookupDefault :: (Eq k, Hashable k) => v -> k -> HashMap k v -> v<br />lookupDefault def k mp = ...<br /></pre><br />This function looks up <tt>k</tt> in <tt>mp</tt>, but if <tt>k</tt> is not found, returns <tt>def</tt>. There has <a href=\"http://www.haskell.org/pipermail/libraries/2012-December/018855.html\">been discussion</a> over whether <tt>def</tt> should be evaluated even if <tt>k</tt> is present in <tt>mp</tt>, and since unordered-containers-0.2.3.0 <tt>lookupDefault</tt> always evaluates <tt>def</tt>. There are many legitimate discussions on semantics in the Haskell community, but I do not consider this discussion to be one of them - <tt>lookupDefault</tt> should not pointlessly evaluate <tt>def</tt>. As John Hughes elegantly argues in <a href=\"http://www.cs.kent.ac.uk/people/staff/dat/miranda/whyfp90.pdf\">\"Why Functional Programming Matters\"</a>, laziness lets you write functions that composable properly. I have spent several days debugging two problems caused by the excessive strictness in <tt>lookupDefault</tt>:<br /><br /><b>Problem 1: Error Defaults</b><br /><br />uniplate-1.6.9 contained the following code:<br /><br /><pre>lookupDefault (error \"Uniplate internal error: Report to Neil Mitchell, couldn't grab in follower\") x mp<br /></pre><br />Uniplate uses a very complex and highly tuned algorithm to determine which values can be recursively contained by a type. The algorithm relies on subtle invariants, in particular that <tt>x</tt> must be a member of <tt>mp</tt> at this particular point. If that fails for certain data types, I want users to submit a bug report, rather than wonder if they called Uniplate incorrectly. The simplest way to achieve that goal is using a default value of <tt>error</tt> that is only evaluated if <tt>x</tt> is not present in <tt>mp</tt>. Unfortunately, by making <tt>lookupDefault</tt> strict, this error message was always triggered. People have argued that passing <tt>error</tt> as the default is only to work around the absence of stack traces in GHC - an argument disproven by the example above. The error message provides information that would not be provided by a stack trace - the error is not merely an error, but an error that is my fault. I fixed this bug in uniplate-1.6.10 by switching to:<br /><br /><pre>fromMaybe (error \"Uniplate internal error: Report to Neil Mitchell, couldn't grab in follower\") $ lookup x mp<br /></pre><br /><b>Problem 2: Expensive Defaults</b><br /><br />uniplate-1.6.10 contained the following code:<br /><br /><pre>lookupDefault (hit ! x) x mp<br /></pre><br />In this example I look up <tt>x</tt> in <tt>mp</tt>, but if that fails, look up <tt>x</tt> in <tt>hit</tt>. By forcing the default to be evaluated this code always performs the lookup in <tt>hit</tt>, resulting in a slowdown of more than 10 times in HLint, and more than 20 times in Uniplate microbenchmarks. I fixed this bug in February by changing all instances of <tt>lookupDefault</tt> to use <tt>fromMaybe</tt> after finding out <tt>lookupDefault</tt> was incorrect, but was unaware of the significant performance impact until earlier today.<br /><br /><b>Counterarguments</b><br /><br />There are various arguments for making <tt>lookupDefault</tt> strict in the default argument:<br /><br /><ul><li>\"You are using Data.HashMap.Strict\" - the Strict module for a data structure should provide a data structure containing strict values, not a module of functions which are unnecessarily strict - values which are never stored in the data structure should never be evaluated. As another example consider the <tt>Control.Monad.State.Strict</tt> module, which provides a strict state monad. In that module, the state is strict, but functions like <tt>return</tt> are not needlessly strict.</li><li>\"We don't support using undefined values\" - I expect all Haskell libraries to work with undefined values where sensible, not be corrupted in the presence of exceptions and be multithread safe. These are some of the attributes that are essential to allow libraries to be used predictably and reused in situations the authors did not consider.</li><li>\"Strictness is faster\" - a strict <tt>lookupDefault</tt> may occasionally shave nanoseconds off a program, but can make a program arbitrarily slower, and in the case of HLint makes a commonly used program 10 times slower.</li><li>\"It is what people expect\" - I didn't expect <tt>lookupDefault</tt> to be strict, despite being one of a handful of Haskell programmers to program in a strict variant of Haskell all day long.</li></ul>" nil nil "17c453c29b1a05d0665cc2156c1ec8bc") (389 (21003 35962 3082) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_6028\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_5964\"></span> time, whereas using the categorical functor takes time <span id=\"tex_1685\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_8001\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "0d584cd98df0e51b7747492eac347256") (388 (21003 31621 892034) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_337\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_8673\"></span> time, whereas using the categorical functor takes time <span id=\"tex_6896\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_9596\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "2c5413680834f0981dac97dae2c16ee6") (387 (21003 27177 761478) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_8726\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_5746\"></span> time, whereas using the categorical functor takes time <span id=\"tex_7084\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_1575\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "03a3ceb311270c06b653bb08778dfa50") (386 (21003 24763 820768) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_3422\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_8130\"></span> time, whereas using the categorical functor takes time <span id=\"tex_9365\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_4769\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "736b6c3b71abbc40b6ff37fc75f2bb2e") (385 (21003 22168 672260) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_1025\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_8972\"></span> time, whereas using the categorical functor takes time <span id=\"tex_7146\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_9369\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "b4c51289c70afe12734a9f7ad2b7f603") (384 (21003 14951 899713) "http://praisecurseandrecurse.blogspot.com/2013/08/arduino-day-1.html" "Paul Potts: Arduino, Day 1" "noreply@blogger.com (Paul Potts)" "Wed, 14 Aug 2013 05:16:00 +0000" "<p><i>Warning for Planet Haskell readers: imperative content! (Or, I tried to get GHC working in 2048 bytes of RAM but didn't get very far...)</i></p> <p>A friend of mine sent me a <a href=\"https://www.sparkfun.com/products/11575\">RedBoard</a> and asked me to collaborate with him on a development idea. So I'm playing with an Arduino-compatible device for the first time. I've been aware of the Arduino devices, and the maker... erm, what, \"movement?\" But just never got one. There were various reasons -- one was that after writing embedded code all day, what I've wanted to do with my time off is not necessarily write more embedded code. Another was that they are very small. But I'm always interested in learning something new, or maybe something quite old -- maybe a board designed specifically for hobbyists might help me revive some of my childhood interest in electronics.</p> <p>So, I downloaded the Arduino IDE and checked that out a bit. There are some things about the way it's presented that drive me a little batty. The language is C++, but Arduino calls it the \"Arduino Programming Language\" -- it even has its own language reference page. Down at the bottom the fine print says \"The Arduino language is based on C/C++.\" Ummm. What?</p> <p>That really makes me mad. First, it seems to give the Arduino team credit for creating something that they really haven't. That team deserves plenty of credit -- not least for building a very useful library -- but they did not, repeat, did not, invent a programming language.</p> <p>Second, it fails to give credit (and blame) for the language to the large number of people who actually designed and implemented C, C++, and the GCC cross-compiler running behind the scenes, with its reduced standard libraries and all. Of course, it's not that the Arduino team was really trying to hide the fact that there's an open-source compiler inside, but calling it the \"Arduino Programming Langage\" obfuscates this reality, at the very least.</p> <p>And third, it obfuscates what programmers are actually learning -- specifically, the distinction between a <i>language</i> and a <i>library</i>.</p> <p>That might keep things simpler for beginners but this is supposed to be a teaching tool, isn't it? I don't think it's a good idea to obfuscate the difference between the core language (for example, bitwise and arithmetic operators), macros (like <b>min</b>), and functions in the standard Arduino libraries. The Arduino documentation muddles this distinction. But it's important -- for one thing, errors in using each of these will result in profoundly different kinds of diagnostic messages or other failure modes. It also obfuscates something important for experts. That something is \"which C++ is this?\"</p> <p>C++ has many variations now. Can I use enum classes or other C++11 features? I don't know, and because of the facade that Arduino is a distinct language, it is harder to find out. They even have the gall to list <b>true</b> and <b>false</b> as constants. Sure, they are constants, but that doesn't mean C and C++ have an actual, useful Boolean type. In fact, they can't, for reasons of backwards compatibility. And if there's one thing C and C++ programmers know, and beginners need to learn quickly, it's that logical truth in C and C++ is messy and requires vigilance. I would hate to have to explain to a beginner why testing a masked bit that is not equal to one against <b>true</b> does not give the expected result.</p> <p>Anyway, all that aside, this is C++ where the IDE does a few hidden things for you when you compile your code. It inserts a standard header, <b>Arduino.h</b>. It links you to a standard <b>main()</b>. I guess that's all helpful. But finally, it generates prototypes for your functions. That implies a parsing stage, via a separate tool that is not a C++ compiler. If that very thought doesn't cause your brow to furrow, you don't know much about C++.</p> <p>But let's talk about plugging in the Redboard. On my Mac Pro running Mountain Lion, the board was not recognized as a serial device at all. There's some kind of workaround for this but I just switched over to Ubuntu 12.04 on a ThinkPad laptop. The IDE works flawlessly. I tried to follow some directions to see where the code was actually built by engaging a verbose mode for compilation and uploading, but I couldn't get that working. So I decided that the IDE was obfuscating more than helping, and ditched it.</p> <p>This was fairly easy, with the caveat that there are a bunch of outdated tools out there, and outdated blog posts explaining how to do it. I went down some dead ends and rabbit holes, but the procedure is really not hard. Ultimately, I used <b>sudo apt-get install</b> to install <b>arduino-core</b> and <b>arduino-mk</b>.</p> <p>There is now a common <b>Arduino.mk</b> makefile in my <b>/usr/share/arduino</b> directory and I can make project folders with makefiles that refer to it. To make this work I had to add a new export to my <b>.bashrc</b> file, <b>export ARDUINO_DIR=/usr/share/arduino</b> (your mileage may vary depending on how your Linux version works, but that's where I define additional environment variables).</p> <p>The Makefile in my project directory has the following in it:</p> <pre>BOARD_TAG    = uno<br />ARDUINO_PORT = /dev/serial/by-id/usb-*<br />include /usr/share/arduino/Arduino.mk</pre> <p>And that's it. Nothing else. Everything else is inherited from the common Arduino.mk. I can throw <b>.cpp</b> and <b>.h</b> files in there and <b>make</b> builds them and <b>make upload</b> uploads them using the amusingly named utility <b>avrdude</b> (the name stands for AVR Downloader/UploaDEr... er, Dude, that's OK, you can just call it AVRDUDE because you're into AVR chips and you wrote it, that's good enough...</p> <p>If you have trouble with the upload (wait, is this an \"upload\" or a \"download?\" I always thought of \"down\" as being \"downstream\" from the bigger computer/data store/ocean to the smaller computer/pond -- like from the Internet to your computer -- but I guess you can call it whatever you want) you might take a look at your devices. A little experimentation (listing the contents of <b>/dev</b> before and after unpluging the board) reveals that the RedBoard is showing up on my system as a device under <b>/dev/serial</b> -- in my case, <b>/dev/serial/by-id/usb-FTDI_FT232R_USB_UART_A601EGHT-if00-port0</b> and <b>/dev/serial/by-path/pci-0000:00:1d.0-usb-0:2:1.0-port0</b> (your values will no doubt vary). That's why my <b>Makefile</b> reads <b>ARDUINO_PORT = /dev/serial/by-id/usb-*</b> -- so it will catch anything that shows up in there with the <b>usb-</b> prefix. Of course, if your device is showing up elsewhere, or you have more than one device, you might need to tweak this to properly identify your board.</p> <p>When you look at the basic blink demo program in the Arduino IDE, you see this, the contents of an <b>.ino</b> file (except that I have removed the comments):</p> <pre>int led = 13;<br /><br />void setup() {                <br />    pinMode(led, OUTPUT);     <br />}<br /><br />void loop() {<br />    digitalWrite(led, HIGH);<br />    delay(1000);<br />    digitalWrite(led, LOW);<br />    delay(1000);<br />}</pre> <p>The Makefile knows how to build an <b>.ino</b> file and inserts the necessary header, implementation of <b>main</b>, and generates any necessary prototypes. Here's what the file looks like to the compiler (and if you want to build this code with <b>make</b> as a <b>.cpp</b> file, it needs to look more like this):</p> <pre>#include <Arduino.h><br /><br />int led = 13;<br /><br />void setup() {<br />    pinMode(led, OUTPUT);<br />}<br /><br />void loop() {<br />    digitalWrite(led, HIGH);<br />    delay(1000);<br />    digitalWrite(led, LOW);<br />    delay(1000);<br />}<br /><br />int main(void)<br />{<br />    init();<br /><br />#if defined(USBCON)<br />    USBDevice.attach();<br />#endif<br /><br />    setup();<br /><br />    for (;;) {<br />        loop();<br />        if (serialEventRun) serialEventRun();<br />    }<br /><br />return 0;<br /><br />}</pre> <p>And there it is -- C++, <b>make</b>, and no IDE. Relaxen and watchen <a href=\"http://en.wikipedia.org/wiki/Blinkenlights\">Das blinkenlights</a>!</p>" nil nil "e40c437b69cb1b1a3f1aa432064f5157") (383 (21003 14951 897869) "http://brandon.si/code/a-typefamilies-primer/" "Brandon Simmons: A TypeFamilies Primer" nil "Mon, 12 Aug 2013 18:16:00 +0000" "<p><code>TypeFamilies</code> is a GHC extension that lets you create formerly-impossible
abstractions in a very straightforward way. It took me several tries before
they clicked for me though, so this is the introduction to <code>TypeFamilies</code> that
I wish I had read first (although I just found <a href=\"http://byorgey.wordpress.com/2010/07/06/typed-type-level-programming-in-haskell-part-ii-type-families/\">Brent Yorgey's</a>, which would have done the trick).</p>
<p>I'm treating the subject very narrowly for most of this post, and try to round
things out a little at the very end.</p>
<h2>Primal Ignorance</h2>
<p>If this isn't the first thing you've read about <code>TypeFamilies</code>, it might be
helpful to forget a few things. The question \"what precisely is a type family?\"
isn't going to be very helpful; in general, the terminology for the
constellation of constructions that <code>TypeFamilies</code> gives you is a huge mess,
with multiple partially-overlapping terms in the wild, none of which are
helpful for developing an intuition about what all of this is about.</p>
<p>I also found various analogies I'd read to be useless, so forget those too.</p>
<h2>Type synonyms as type-level functions</h2>
<p>Consider the familiar <a href=\"http://www.haskell.org/haskellwiki/Type_synonym\">type synonym</a>:</p>
<pre><code>type PairOf a = (a,a)
</code></pre>
<p>Normally this is presented as syntactic sugar, with little to do with the type
system.</p>
<p>A more interesting way of thinking about <code>PairOf</code> is as a <em>function</em> (as
suggested by the <code>=</code>), where evaluation involves substituting occurrences of
the left hand side (LHS) with the right, in the usual way. These functions are
evaluated <em>in your type signatures</em> at compile time.</p>
<p>The analogous regular term-level function would of course be:</p>
<pre><code>pairOf a = (a,a)
</code></pre>
<p>Simple enough. Now let's think about a simple <em>term-level</em> function, and see
what an analogous <em>type-level</em> type synonym/function might look like:</p>
<pre><code>last (a: [])     = a
last (a: (b:bs)) = last (b:bs)
</code></pre>
<p>For our type-level <code>Last</code> we need something like lists at the type-level, so
we'll use the common nested tuple representation of <code>(,)</code> as cons and <code>()</code> as
the empty list, e.g.:</p>
<pre><code>x :: (Int,(Int,(Int,())))  -- like [1,2,3]
</code></pre>
<p>Hopefully I didn't just lose you. Remember for now we just care about using
this list-like tuple thing in our <em>type signatures</em>.</p>
<p>If you were to charge ahead and try to define <code>Last</code> using type synonyms
treated as full blown functions, you might come up with:</p>
<pre><code>-- this isn't okay:
type Last (a, ())     = a
type Last (a, (b,bs)) = Last (b,bs)
</code></pre>
<p>Unfortunately the compiler will laugh at you. Type synonyms can only have
abstract variable arguments on the LHS where above we have tried to
deconstruct them using pattern matching, and to define a different RHS for both
cases. Further we've made the definition recursive. None of that is okay.</p>
<p>In fact the humble type synonym is only a very simple sort of function (a
<a href=\"http://blog.sigfpe.com/2008/05/you-could-have-defined-natural.html\">natural transformation</a>
or something close) which is very easy to evaluate, but also very limited.</p>
<h2>Finally, Enter TypeFamilies</h2>
<p>The <code>TypeFamilies</code> extension lets us define <code>Last</code> successfully almost exactly
as we did above.</p>
<pre><code>{-# LANGUAGE TypeFamilies #-}
-- we have to \"declare\" `Last` separately, and the \"family\"
-- here distinguishes the syntax from a normal type synonym:
type family   Last l
-- ...and then can define our \"cases\":
type instance Last (a,())     = a
type instance Last (a,(b,bs)) = Last (b,bs)
</code></pre>
<p>At this point when the type-checker sees <code>Last (a,(b,bs))</code> in a type signature
it will replace it with <code>Last (b,bs)</code>, and continue until all of these \"type
functions\" are evaluated. I may be fudging things a bit but that's the
general idea.</p>
<p>Since these are a more general sort of type function, they can even be used to
replace traditional type synonyms:</p>
<pre><code>type family   PairOf a
type instance PairOf a = (a,a)
</code></pre>
<h3>But what is that good for?</h3>
<p>It would be neat to be able to work with \"lists\" that look like e.g.
<code>(1,('a',(\"hello\",())))</code>; they are heterogeneous, operations like <code>head</code> would
be type-safe, etc. So imagine we want to define a <code>last</code> on types of this
list-like tuple sort of data.</p>
<p>What would the type of <code>last</code> look like? We know it has to be polymorphic,
since its arguments might look like <code>()</code> or <code>(1,(2,()))</code>, different types of
course. So we'll need a type-class (and a couple other standard extensions):</p>
<pre><code>{-# LANGUAGE FlexibleInstances, FlexibleContexts #-}
class LastOfTupleList l where
last' :: l -> Last l      -- < we use our `Last` type function
</code></pre>
<p>Our instances are trivial:</p>
<pre><code>instance LastOfTupleList (a,()) where
last' (a,()) = a  -- < the type-checker can see that, indeed, `a`
--   is equal to `Last (a,())`
instance (LastOfTupleList (b, bs))=> LastOfTupleList (a,(b,bs)) where
last' (a,(b,bs)) = last' (b,bs)
</code></pre>
<p>Letting us do:</p>
<pre><code>>>> last' (1,(2,()))
2
>>> last' (1,('a',(\"hello\",())))
\"hello\"
</code></pre>
<p>Notice how our instances of <code>Last</code> and <code>last</code> have almost the same structure;
this is very common.</p>
<h2>Functions... but open!</h2>
<p>If you're a programmer type you were probably irritated by my initial clumsy
definition of <code>last</code>; why not:</p>
<pre><code>last (a:[]) = a
last (a:as) = last as -- `as` matches whatever can fall through the pattern
-- above; in this case only non-empty lists
</code></pre>
<p>Well, I was being sneaky because the type-level analogue isn't allowed!</p>
<pre><code>type instance Last (a,()) = a
type instance Last (a,as) = Last as -- BAD!
</code></pre>
<p>This is because unlike functions, type families are <em>open</em> meaning, like
typeclasses, a new instance can be added at any moment. Therefore there's
no way to define a \"default\" instance to use after all other matches fail,
you simply get illegal overlapping synonym instances such as the one above;
the order in which we defined the two doesn't matter.</p>
<p>For some use cases this is what we need, for others (such as our <code>last'</code>) we'd
really prefer that type synonym families be <em>closed</em> so that we can pattern
match in the usual way.
<a href=\"http://ghc.haskell.org/trac/ghc/wiki/NewAxioms\">This feature</a> is apparently
coming soon.</p>
<hr />
<h2>Other details</h2>
<p>That should give you an intuition. At this point you might want to stop and
read through the following documentation, or continue reading below before
coming back to these links for a more refined understanding and additional
details:</p>
<ul>
<li><a href=\"http://www.haskell.org/haskellwiki/GHC/Type_families\">Type-families at haskellwiki</a></li>
<li><a href=\"http://www.haskell.org/ghc/docs/7.4.1/html/users_guide/type-families.html\">GHC docs</a></li>
</ul>
<h3>Associated type synonyms</h3>
<p>Since we so often define define a type class in terms of one or more type
families, we're given a simplified syntax for combining them in one place.</p>
<pre><code>class LastOfTupleList l  where
type Last l        -- an *associated* type family
last' :: l -> Last l
instance LastOfTupleList (a,()) where
type Last (a,()) = a
last' (a,()) = a
</code></pre>
<p>When people say \"associated types\" they mean type functions that are associated
with a typeclass using the syntax above.</p>
<h3>Injectivity</h3>
<p>Type synonym family instances are said to be <em>not injective</em>, meaning two
different type functions can map to the same type on the RHS, e.g.</p>
<pre><code>type instance F Int  = Bool
type instance F Char = Bool
</code></pre>
<p>It's easy to forget this when building new abstractions, and assume that the
typechecker will infer from the RHS (e.g. <code>Bool</code> above) the argument passed in
to the type function (<code>Int</code> or <code>Char</code>).</p>
<h3>Data families</h3>
<p>I've completely focused on the <em>type synonym</em> flavor of <code>TypeFamilies</code> above,
but there is also a <code>data/newtype</code> flavor in which, for each instance
definition the RHS is a <em>brand new</em> type declaration, rather than mapping to an
existing type</p>
<pre><code>-- from http://www.haskell.org/ghc/docs/7.4.1/html/users_guide/type-families.html
data family T a
data    instance T Int  = T1 Int | T2 Bool -- new constructors T1 and T2 defined here
newtype instance T Char = TC Bool
</code></pre>
<p>Because each instance maps to a unique type, data families <em>are</em> injective
allowing the type checker to infer the LHS of the equation knowing the right.</p>
<h3>More other things</h3>
<ul>
<li><code>TypeFamilies</code> provides the syntax <code>a ~ b</code> to indicate <a href=\"http://www.haskell.org/ghc/docs/7.4.1/html/users_guide/equality-constraints.html\">type equality constraints</a>; this is especially useful with type synonym functions, but can be useful <a href=\"http://okmij.org/ftp/Haskell/ConEQ.hs\">on its own</a> as well.</li>
<li><a href=\"http://www.haskell.org/haskellwiki/Kind\">kind</a> signatures are required for type functions on types taking arguments, e.g. <code>Maybe</code></li>
</ul>" nil nil "c30bcca2c76accdf7c3120dc6ff8d484") (382 (21003 14951 801693) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_67\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_4872\"></span> time, whereas using the categorical functor takes time <span id=\"tex_8294\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_6026\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "d64dc108513afc0b4587b787b9cf33cd") (381 (21002 21225 253460) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_7777\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_1246\"></span> time, whereas using the categorical functor takes time <span id=\"tex_3834\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_545\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "15deb71d9bb912cb59f3a1f26ac8a18b") (380 (21002 18591 290196) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_2370\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_745\"></span> time, whereas using the categorical functor takes time <span id=\"tex_3462\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_9522\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "b405dab80c828efce439b07fd3fc5197") (379 (21002 11520 514776) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_3413\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_5783\"></span> time, whereas using the categorical functor takes time <span id=\"tex_2301\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_9376\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "b8368c4279dfcdee8fcc538bac1b073d") (378 (21002 2894 409583) "http://wadler.blogspot.com/2013/08/all-party-parliamentary-cycling-group.html" "Philip Wadler: All Party Parliamentary Cycling Group" "noreply@blogger.com (Philip Wadler)" "Tue, 13 Aug 2013 09:20:52 +0000" "<div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://3.bp.blogspot.com/-36TTQfLeMbU/Ugn2aqU22FI/AAAAAAAAFXc/mO_rW1nNJ7k/s1600/Screenshot.png\"><img src=\"http://3.bp.blogspot.com/-36TTQfLeMbU/Ugn2aqU22FI/AAAAAAAAFXc/mO_rW1nNJ7k/s320/Screenshot.png\" height=\"320\" border=\"0\" width=\"227\" /></a></div>Last April, the <a href=\"http://allpartycycling.org/\">All Party Parliamentary Group on Cycling</a> released a <a href=\"http://allpartycycling.files.wordpress.com/2013/04/get-britain-cycling1.pdf\">report</a>, and a <a href=\"http://epetitions.direct.gov.uk/petitions/49196\">petition</a> called for a parliamentary debate. The debate is upcoming on <a href=\"http://road.cc/content/news/87688-get-britain-cycling-report-secures-parliamentary-debate-september\">2 September</a>.<br /><blockquote class=\"tr_bq\">Some cities are performing well. Having put cycling closer to the heart of transport for decades, Oxford and Cambridge boast continental levels of journeys made by bike (17% and 30%).<br /><br />In 2009, the six cycling demonstration towns, including Exeter and Darlington, recorded an increase in cycling of almost a third. This boost was delivered at an average cost of just £3m per town.<br /><br />We should not be daunted by how far we still have to go to reach the levels of other European cities. Cycle commuting in New York doubled in four years thanks to investment in high-profile cycling improvements, and further expansion is planned. Seville recently managed a ten-fold increase in cycle use in just three years - from 6000 to 60,000 cycle journeys per day between 2007 and 2010.</blockquote> Recommendations include:<br /><ul><li>\"Create a cycling budget of at least £10 per person per year, increasing to £20.\"</li><li>\"Revise existing design guidance, to include more secure cycle parking, continental best practice for cycle-friendly planning and design, and an audit process to help planners, engineers and architects to think bike in all their work.\"</li><li>\"Strengthen the enforcement of road traffic law, including speed<br />limits, and ensuring that driving offences - especially those resulting<br />in death or injury - are treated sufficiently seriously by police,<br />prosecutors and judges.\"</li><li>\"The government should set national targets to increase cycle use<br />from less than 2% of journeys in 2011, to 10% of all journeys in 2025,<br />and 25% by 2050.\"</li></ul>" nil nil "f96f51f4412e2ff2a62986b67e72b334") (377 (21002 2894 390424) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_882\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_2456\"></span> time, whereas using the categorical functor takes time <span id=\"tex_6526\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_2476\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "b88f874910aefaf9740341eb42cface4") (376 (21001 59624 736342) "http://feedproxy.google.com/~r/ezyang/~3/wwoDan9gmYc/" "Edward Z. Yang: Blame Trees" nil "Mon, 12 Aug 2013 18:55:28 +0000" "<div class=\"document\">
<p>I just presented <em>Blame Trees</em> at the <a href=\"http://www.wads.org/\" class=\"reference external\">13th Algorithms and Data Structures Symposium</a>. Blame trees are a functional data structure which support an efficient merge operation by incorporating information about the “blame” (think <tt class=\"docutils literal\">git blame</tt>) of any given part of the structure. It’s a theory paper, so the constant factors are not so good, but the asymptotics are much better than traditional merge algorithms used by modern VCSes.</p>
<p>This was joint work with <a href=\"http://web.mit.edu/dwilson/www/\" class=\"reference external\">David A. Wilson</a>, <a href=\"http://pavpanchekha.com/\" class=\"reference external\">Pavel Panchekha</a> and <a href=\"http://erikdemaine.org/\" class=\"reference external\">Erik D. Demaine</a>. You can view the <a href=\"http://ezyang.com/papers/demaine13-blametrees.pdf\" class=\"reference external\">paper</a> or check out the <a href=\"http://ezyang.com/slides/ezyang13-blametrees-slides.pdf\" class=\"reference external\">slides.</a>  I also have a slightly older version of the talk recorded on <a href=\"http://youtu.be/f8e-QE6Gus8\" class=\"reference external\">YouTube (20 minutes)</a> which I had used to help get feedback from my out-of-town collaborators before actually giving the talk.  Thanks also to David Mazières for giving useful comments on the presentation in person.</p>
</div>
<img src=\"http://feeds.feedburner.com/~r/ezyang/~4/wwoDan9gmYc\" height=\"1\" width=\"1\" />" nil nil "586842a43804f0e250418bcf6d7a70bf") (375 (21001 59624 717631) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_9588\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_2516\"></span> time, whereas using the categorical functor takes time <span id=\"tex_1902\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_6483\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "1f57ea041a477cf7b0b4d3de0f0dd882") (374 (21000 62171 745800) "http://www.joachim-breitner.de/blog/archives/607-A-song-about-Isabelle-the-theorem-prover.html" "Joachim Breitner: A song about Isabelle (the theorem prover)" "mail@joachim-breitner.de (nomeata)" "Mon, 12 Aug 2013 12:17:38 +0000" "<p>For the final dinner of the <a href=\"https://asimod.in.tum.de/\">Marktoberdorf Summer School 2013</a> I created the song “<a href=\"http://www.joachim-breitner.de/content/parodie/This_is_a_Theorem\">This is a theorem</a>” about working with the <a href=\"https://isabelle.in.tum.de/\">theorem prover Isabelle</a>, to the lyrics of Boomtown Rat’s “I don’t like mondays”. Nice-to-print <a href=\"https://lists.cam.ac.uk/pipermail/cl-isabelle-users/2013-August/pdf8evY7kNOmn.pdf\">PDF version</a> available as well. Enjoy, and if you like it, have a look at <a href=\"http://www.joachim-breitner.de/content#parodie\">other song texts</a> that I wrote.<br /></p>" nil nil "3f12adc8e5b32b1436f3f396d31c3e38") (373 (21000 62171 726839) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_5727\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_1757\"></span> time, whereas using the categorical functor takes time <span id=\"tex_3238\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_64\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "bec2962a4f4fe53a80388a525043ae69") (372 (21000 48118 638075) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_3375\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_8436\"></span> time, whereas using the categorical functor takes time <span id=\"tex_6973\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_4632\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "db99f471ce12708340aa82e24412b99f") (371 (21000 46861 100974) "http://parenz.wordpress.com/2013/08/12/ann-restricted-workers-0-1-0/" "Daniil Frumin: ANN: restricted-workers-0.1.0" nil "Mon, 12 Aug 2013 07:42:09 +0000" "<p>Introducing: restricted-workers library, version 0.1.0.</p>
<p>This library provides an abstract interface for running various kinds of workers under resource restrictions. It is being developed as part of the interactive-diagrams project and you can read more about the origins of the library in my GSoC report: <a href=\"http://parenz.wordpress.com/2013/07/15/interactive-diagrams-gsoc-progress-report/\">http://parenz.wordpress.com/2013/07/15/interactive-diagrams-gsoc-progress-report/</a></p>
<p>The library provides a convenient way of running worker processes, saving data obtained by the workers at start-up, a simple pool abstraction and a configurable security and resource limitations.</p>
<p>Right now there are several kinds of security restrictions that could be applied to the worker process:</p>
<ul>
<li>RLimits</li>
<li>chroot jail</li>
<li>custom process euid</li>
<li>cgroups</li>
<li>process niceness</li>
<li>SELinux security context</li>
</ul>
<p>You can read more about the library on the wiki: <a href=\"https://github.com/co-dan/interactive-diagrams/wiki/Restricted-Workers\">https://github.com/co-dan/interactive-diagrams/wiki/Restricted-Workers</a></p>
<p>The library has been uploaded to hackage and you can install it using cabal-install.</p>
<br /> Tagged: <a href=\"http://parenz.wordpress.com/tag/haskell-2/\">haskell</a>, <a href=\"http://parenz.wordpress.com/tag/interactive-diagrams/\">interactive-diagrams</a>, <a href=\"http://parenz.wordpress.com/tag/soc/\">soc</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/parenz.wordpress.com/112/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/parenz.wordpress.com/112/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=parenz.wordpress.com&blog=26722965&post=112&subd=parenz&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "a80df8416ce7a307e91965cb9e7a6241") (370 (21000 46861 19081) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_1125\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_7349\"></span> time, whereas using the categorical functor takes time <span id=\"tex_7632\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_2077\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "e91b052bb46ac0104a68cdc8e27aca2d") (369 (21000 35661 486165) "http://feedproxy.google.com/~r/holdenkarau/iYtm/~3/jUDZgUnhMt0/the-icfp-2013-contest-is-over.html" "Holden Karau: The ICFP 2013 contest is over :)" "noreply@blogger.com (Holden Karau)" "Mon, 12 Aug 2013 00:07:42 +0000" "For the past few years I've been participating in the ICFP contests as a way of keeping in touch with some friends from university. This years was run by MSR <a href=\"http://research.microsoft.com/en-us/events/icfpcontest2013/\">http://research.microsoft.com/en-us/events/icfpcontest2013/</a> . The vague \"plan\" for next year is to try and be more awesome next year during the lightning round as we only seem to actually write much in the way of the code during the first day. Our code is up at <a href=\"https://github.com/abarbu/icfp2013\">https://github.com/abarbu/icfp2013</a> (not that you actually want to read it, but if you are crazy :)).<div class=\"feedflare\">
<a href=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?a=jUDZgUnhMt0:zRadnIbwzSg:yIl2AUoC8zA\"><img src=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?d=yIl2AUoC8zA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?a=jUDZgUnhMt0:zRadnIbwzSg:63t7Ie-LG7Y\"><img src=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?d=63t7Ie-LG7Y\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?a=jUDZgUnhMt0:zRadnIbwzSg:V_sGLiPBpWU\"><img src=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?i=jUDZgUnhMt0:zRadnIbwzSg:V_sGLiPBpWU\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?a=jUDZgUnhMt0:zRadnIbwzSg:7Q72WNTAKBA\"><img src=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?d=7Q72WNTAKBA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?a=jUDZgUnhMt0:zRadnIbwzSg:qj6IDK7rITs\"><img src=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?d=qj6IDK7rITs\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?a=jUDZgUnhMt0:zRadnIbwzSg:gIN9vFwOqvQ\"><img src=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?i=jUDZgUnhMt0:zRadnIbwzSg:gIN9vFwOqvQ\" border=\"0\" /></a>
</div><img src=\"http://feeds.feedburner.com/~r/holdenkarau/iYtm/~4/jUDZgUnhMt0\" height=\"1\" width=\"1\" />" nil nil "4d3c4e0c7d25f3df00fac115f383df0b") (368 (21000 35661 485694) "http://byorgey.wordpress.com/2013/08/10/come-visit-the-farm/" "Brent Yorgey: Come visit the FARM!" nil "Sun, 11 Aug 2013 01:56:45 +0000" "<p><a href=\"https://regmaster3.com/2013conf/ICFP13/register.php\">Registration is now open</a> for the first (!) <a href=\"http://www.cis.upenn.edu/~byorgey/farm13/\">ACM SIGPLAN Workshop on Functional Art, Music, Modeling and Design (FARM)</a>, to be held in Boston on September 28 (the day after ICFP).  I’m really excited—it’s shaping up to be a really awesome event.   Check out the list of accepted papers and demos:</p>
<ul>
<li>Samuel Aaron and Alan F. Blackwell. <em>From Sonic Pi to Overtone: Creative Musical Experiences with Domain-Speciﬁc and Functional Languages</em></li>
<li>Henrik Bäärnhielm, Mikael Vejdemo-Johansson and Daniel Sundström. <em>Using Haskell as DSL for controlling immersive media experiences</em> (Demo)</li>
<li>Guillaume Baudart, Louis Mandel and Marc Pouzet. <em>Programming Mixed Music in ReactiveML</em></li>
<li>Jean Bresson, Raphael Foulon and Marco Stroppa. <em>Reduction as a Transition Controller for Sound Synthesis Events</em></li>
<li>Kelsey D’Souza. <em>PySTEMM – A STEM Learning Tool for Exploring and Building Executable Concept Models</em> (Demo)</li>
<li>Andy Gill and Brent A. Yorgey. <em>Functional active animation</em> (Demo)</li>
<li>Jason Hemann and Eric Holk. <em>Visualizing the Turing Tarpit</em></li>
<li>Paul Hudak. <em>Euterpea: From Signals to Symphonies</em> (Demo)</li>
<li>David Janin, Florent Berthaut, Myriam Desainte-Catherine, Yann Orlarey and Sylvain Salvati. <em>The T-Calculus : towards a structured programing of (musical) time and space</em></li>
<li>David Janin and Florent Berthaut. <em>LiveTuiles for tiled composition of audio patterns</em> (Demo)</li>
<li>Thomas Jordan. <em>Spontaneous Musical Explorations of Visible Symmetric Structures</em> (Demo)</li>
<li>Hendrik Vincent Koops, José Pedro Magalhães and W. Bas de Haas. <em>A Functional Approach To Automatic Melody Harmonisation</em></li>
<li>José Pedro Magalhães, Bas De Haas, Gijs Bekenkamp, Dion ten Heggeler and Tijmen Ruizendaal. <em>Chordify: Chord Transcription for the Masses</em> (Demo)</li>
<li>Donya Quick and Paul Hudak. <em>Grammar-Based Automated Music Composition in Haskell</em></li>
<li>Chung‐chieh Shan and Dylan Thurston. <em>Braiding in circles</em> (Demo)</li>
</ul>
<p>Note the early registration deadline is August 22, so don’t delay!  In case you’re not already convinced, here’s a short description of the workshop and what it’s trying to accomplish:</p>
<p>The functional programming community is largely interested in writing beautiful programs. This workshop is intended to gather researchers and practitioners interested in writing <em>beautiful programs that generate beautiful artifacts</em>. Such artifacts may include visual art, music, 3D sculptures, animations, GUIs, video games, physical models, architectural models, choreographies for dance, poetry, and even physical objects such as VLSI layouts, GPU configurations, or mechanical engineering designs.</p>
<p>The goal of FARM is to gather together researchers, practitioners, and educators in this interdisciplinary field, as well as anyone else with even a casual interest in the area. We wish to share ideas, look for common ground, and encourage more activity. We also hope to legitimize work in the field and facilitate potential collaboration among the participants.</p>
<br />  <a href=\"http://feeds.wordpress.com/1.0/gocomments/byorgey.wordpress.com/1094/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/byorgey.wordpress.com/1094/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=byorgey.wordpress.com&blog=1152889&post=1094&subd=byorgey&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "300e01f4dfa2fe91f8484c680565e579") (367 (21000 35661 484947) "http://wadler.blogspot.com/2013/08/lavabit-e-mail-service-used-by-edward.html" "Philip Wadler: Lavabit, e-mail service used by Edward Snowden, shuts in mysterious circumstances" "noreply@blogger.com (Philip Wadler)" "Sat, 10 Aug 2013 15:55:16 +0000" "<div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://1.bp.blogspot.com/-MK-UsNY8B9c/UgZdm7fVnUI/AAAAAAAAFXE/MNUUqvWP064/s1600/snowden.jpg\"><img src=\"http://1.bp.blogspot.com/-MK-UsNY8B9c/UgZdm7fVnUI/AAAAAAAAFXE/MNUUqvWP064/s400/snowden.jpg\" height=\"225\" border=\"0\" width=\"400\" /></a></div><br />Invitations to attend a press conference at Moscow's Sheremetyevo Airport came from edsnowden@lavabit.com. Now, the secure e-mail service has shut down in mysterious circumstances. The message on their <a href=\"http://lavabit.com/\">web site</a> makes chilling reading:<br /><div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://3.bp.blogspot.com/-HSjp9yRJuO4/UgZdbrth2OI/AAAAAAAAFW8/gg8I7UxDi3Q/s1600/lavabit.jpg\"><img src=\"http://3.bp.blogspot.com/-HSjp9yRJuO4/UgZdbrth2OI/AAAAAAAAFW8/gg8I7UxDi3Q/s1600/lavabit.jpg\" border=\"0\" /></a></div><a href=\"http://boingboing.net/2013/08/08/lavabit-email-service-snowden.html\">The story breaks on Boing Boing</a><br /><a href=\"http://boingboing.net/2013/08/09/lavabit-competitor-silent-circ.html\">Silent Circle, a similar service, closes a day later</a><br /><a href=\"http://www.theguardian.com/technology/2013/aug/08/lavabit-email-shut-down-edward-snowden\">Lavabit founder tells Forbes `If you knew what I knew, you'd stop using e-mail'</a><br /><a href=\"http://www.theguardian.com/technology/2013/aug/08/lavabit-email-shut-down-edward-snowden\">Coverage in the Guardian</a> (and <a href=\"http://www.theguardian.com/technology/shortcuts/2013/aug/09/lavabit-defunct-secure-email\">a light-hearted summary</a>)" nil nil "4ae4e80a24c395626c16d3038416e168") (366 (21000 35661 484535) "http://joyful.com/blog/2013-08-09-fungen-0-4.html" "Simon Michael: FunGEn 0.4!" nil "Fri, 09 Aug 2013 10:04:00 +0000" "<div style=\"font-style: italic;\">August 10, 2013</div>
<h2>FunGEn 0.4!</h2>
<p>
</p><p>I finally cleaned up the <a href=\"http://joyful.com/fungen\">FunGEn website</a> and <a href=\"http://www.haskell.org/pipermail/haskell-cafe/2013-August/108260.html\">released FunGEn 0.4</a>. Hurrah! Here’s the announcement.</p>
<hr />
<p>I’m pleased to announce the hackage release of FunGEn 0.4!</p>
<p>FunGEn (Functional Game Engine) is a BSD-licensed, cross-platform, OpenGL/GLUT-based, imperative game engine/framework. With very few dependencies and two example games, it’s one of the easiest ways to get started with game development in Haskell.</p>
<p>FunGEn was probably the first Haskell game framework, created by Andre Furtado in 2002 (!). Here’s his original feature list:</p>
<ul>
<li>Initialization, updating, removing, rendering and grouping routines for game objects;</li>
<li>Definition of a game background (or map), including texture-based maps and tile maps;</li>
<li>Reading and intepretation of the player’s keyboard input;</li>
<li>Collision detection;</li>
<li>Time-based functions and pre-defined game actions;</li>
<li>Loading and displaying of 24-bit bitmap files;</li>
<li>Some debugging and game performance evaluation facilities;</li>
<li>Sound support (actually for windows platforms only… :-[ )</li>
</ul>
<p>What’s new in 0.4.x:</p>
<ul>
<li>a new hakyll-based website, incorporating the old site content</li>
<li>new haddock documentation</li>
<li>tested with GHC 7.6</li>
<li>fixed buggy input when holding down keys on windows</li>
<li>input handlers now receive mouse position and modifier state (inspired by Pradeep Kumar; see fungentest.hs for examples)</li>
<li>added q as quit key in examples</li>
</ul>
<p>Home: <a href=\"http://joyful.com/fungen\">http://joyful.com/fungen</a><br />Hackage: <a href=\"http://hackage.haskell.org/package/FunGEn\">http://hackage.haskell.org/package/FunGEn</a><br />Code: <a href=\"http://hub.darcs.net/simon/fungen\">http://hub.darcs.net/simon/fungen</a><br /></p>
<p>Install from hackage:</p>
<pre><code>$ cabal update
$ cabal install FunGEn</code></pre>
<p>Install source and run examples:</p>
<pre><code>$ darcs get http://hub.darcs.net/simon/fungen
$ cd fungen
$ cabal install
$ (cd examples/pong; ghc pong; ./pong)
$ (cd examples/worms; ghc worms; ./worms)</code></pre>
<p>Contribute patches:</p>
<ul>
<li>log in to hub.darcs.net and fork <a href=\"http://hub.darcs.net/simon/fungen\">http://hub.darcs.net/simon/fungen</a></li>
<li>push changes to your branch</li>
<li>give me a “pull request” on #haskell-game</li>
</ul>
<p>I have maintained FunGEn very sporadically. If you’d like to take it and run with it, or co-maintain, let’s chat! I’m sm on the #haskell-game IRC channel.</p>
<p>
<br />
<em><a href=\"http://joyful.com/tags/fungen.html\">fungen</a>, <a href=\"http://joyful.com/tags/games.html\">games</a>, <a href=\"http://joyful.com/tags/haskell.html\">haskell</a></em></p>" nil nil "511ebc54461c014adbf045954c544468") (365 (21000 35661 483976) "http://joyful.com/blog/2013-08-09-darcs-hub-hledger-fungen-updates.html" "Simon Michael: darcs hub, hledger, game dev" nil "Fri, 09 Aug 2013 10:01:00 +0000" "<div style=\"font-style: italic;\">August 10, 2013</div>
<h2>darcs hub, hledger, game dev</h2>
<p>
</p><p>Hello blog. Since <a href=\"http://joyful.com/2013-07-23-darcs-hub-repo-stats-hledger-balance-sheet.html\">last time</a> I’ve been doing plenty of stuff, but not telling you about it. Let’s do a bullet list and move on..</p>
<p><strong>darcsden/darcs hub</strong></p>
<ul>
<li>fixed some <a href=\"http://hub.darcs.net/simon/darcsden/issues/closed\">bugs</a></li>
<li><a href=\"http://hub.darcs.net/simon/darcsden/patch/20130727151541-3c3f9\">committed</a> the hub.darcs.net front page, for easy hacking</li>
<li>added repo counts to the <a href=\"http://hub.darcs.net\">front page</a></li>
<li><a href=\"http://bsrkaditya.blogspot.com/search/label/darcs\">GSOC</a> testing/support</li>
</ul>
<p><strong>hledger</strong></p>
<ul>
<li>expanded the docs for conditional blocks (if statement) in <a href=\"http://hledger.org/MANUAL.html#csv-files\">CSV rules</a></li>
<li>added an <code>include</code> directive to allow sharing of common CSV rules</li>
</ul>
<p><strong>FunGEn & game dev</strong></p>
<p>A sudden burst of activity here.</p>
<ul>
<li>schmoozed in #haskell-game, got caught up on haskell game development, updated the <a href=\"http://www.haskell.org/haskellwiki/Games\">Games</a> wiki page a bit</li>
<li>updated and published my template for SDL projects on OSX: <a href=\"http://hub.darcs.net/simon/hssdl-osx-template\">hssdl-osx-template</a></li>
<li>continued some FunGEn updates I’ve been sitting for a year and did a release - see <a href=\"http://joyful.com/2013-08-09-fungen-0-4.html\">next post</a>.</li>
</ul>
<p>
<br />
<em><a href=\"http://joyful.com/tags/darcs.html\">darcs</a>, <a href=\"http://joyful.com/tags/hledger.html\">hledger</a>, <a href=\"http://joyful.com/tags/fungen.html\">fungen</a>, <a href=\"http://joyful.com/tags/games.html\">games</a>, <a href=\"http://joyful.com/tags/haskell.html\">haskell</a></em></p>" nil nil "bdace5a80e3ec673cdd01fd80056d521") (364 (21000 35661 479133) "http://idontgetoutmuch.wordpress.com/2013/08/06/planetary-simulation-with-excursions-in-symplectic-manifolds-6/" "Dominic Steinitz: Planetary Simulation with Excursions in Symplectic Manifolds" nil "Tue, 06 Aug 2013 13:22:45 +0000" "<p>This article attempts to show that Haskell [@Hudak:2007:HHL:1238844.1238856] performs reasonably well on numerical problems.</p>
<p>When I started to do this, it seemed straightforward enough: pick a problem which admitted a numerical solution, find an algorithm and code it up. I chose the problem of orbital dynamics as I had always been fascinated by the precession of the perihelion of Mercury (which is mainly caused by the pull of the other planets in the Solar System) and because this admits of at least two different methods of numerical solution both of which I hope will show the power of Haskell in this area. This led to the selection of a suitable algorithm and I read that one should prefer a symplectic method such as the Leapfrog which conserves the energy of a system (a highly desirable requirement when modelling orbital dynamics). My conscience would not let me write about such a method without being able to explain it. This led into the Hamiltonian formulation of classical mechanics, symplectic manifolds and symplectic (numerical) methods.</p>
<p>The reader interested in the Haskell implementations and performance comparisons (currently <em>not</em> with other programming languages) can read the <a href=\"http://idontgetoutmuch.wordpress.com/feed/#Introduction\">introduction</a> and skip to the section on <a href=\"http://idontgetoutmuch.wordpress.com/feed/#Performance\">performance</a>. I apologise in advance to experts in classical mechanics, symplectic geometery and numerical analysis and can only hope I have not traduced their subjects too much.</p>
<p>Note that we do not make it as far the perihelion of Mercury in this article but we do simulate the planets in the outer solar system.</p>
<h2 id=\"introduction\">Introduction</h2>
<p>Forget about Newton and suppose you are told that the way to do mechanics is to write down the total energy of the system in which you are interested and then apply Hamilton’s equations.</p>
<p>Consider a mass of <img src=\"http://s0.wp.com/latex.php?latex=m&bg=ffffff&fg=333333&s=0\" alt=\"m\" class=\"latex\" title=\"m\" /> attached to a light rod of length <img src=\"http://s0.wp.com/latex.php?latex=l&bg=ffffff&fg=333333&s=0\" alt=\"l\" class=\"latex\" title=\"l\" /> which is attached to a point from which it can swing freely in a plane. Then the kinetic energy is:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B1%7D%7B2%7Dmv%5E2+%3D+%5Cfrac%7B1%7D%7B2%7Dml%5E2%5Cdot%7B%5Ctheta%7D%5E2++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\frac{1}{2}mv^2 = \\frac{1}{2}ml^2\\dot{\\theta}^2  \" class=\"latex\" title=\"\\displaystyle  \\frac{1}{2}mv^2 = \\frac{1}{2}ml^2\\dot{\\theta}^2  \" /></div>
<p>and the potential energy (taking this to be 0 at <img src=\"http://s0.wp.com/latex.php?latex=%5Ctheta+%3D+0&bg=ffffff&fg=333333&s=0\" alt=\"\\theta = 0\" class=\"latex\" title=\"\\theta = 0\" />) is:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++mgl%281+-+%5Ccos%5Ctheta%29++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  mgl(1 - \\cos\\theta)  \" class=\"latex\" title=\"\\displaystyle  mgl(1 - \\cos\\theta)  \" /></div>
<p>Thus the Hamiltonian is:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathbb%7BH%7D+%3D+%5Cfrac%7B1%7D%7B2%7Dml%5E2%5Cdot%7B%5Ctheta%7D%5E2+%2B+mgl%281+-+%5Ccos%5Ctheta%29++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\mathbb{H} = \\frac{1}{2}ml^2\\dot{\\theta}^2 + mgl(1 - \\cos\\theta)  \" class=\"latex\" title=\"\\displaystyle  \\mathbb{H} = \\frac{1}{2}ml^2\\dot{\\theta}^2 + mgl(1 - \\cos\\theta)  \" /></div>
<p>Using the Langrangian <img src=\"http://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BL%7D%7D+%3D+T+-+V&bg=ffffff&fg=333333&s=0\" alt=\"{\\mathbb{L}} = T - V\" class=\"latex\" title=\"{\\mathbb{L}} = T - V\" /> where <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" /> and <img src=\"http://s0.wp.com/latex.php?latex=V&bg=ffffff&fg=333333&s=0\" alt=\"V\" class=\"latex\" title=\"V\" /> are the kinetic and potential energies respectively, let us set the generalized momentum</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++p+%3D+%5Cfrac%7B%5Cpartial%5Cmathbb%7BL%7D%7D%7B%5Cpartial%5Cdot%7B%5Ctheta%7D%7D+%3D+ml%5E2%5Cdot%7B%5Ctheta%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  p = \\frac{\\partial\\mathbb{L}}{\\partial\\dot{\\theta}} = ml^2\\dot{\\theta}  \" class=\"latex\" title=\"\\displaystyle  p = \\frac{\\partial\\mathbb{L}}{\\partial\\dot{\\theta}} = ml^2\\dot{\\theta}  \" /></div>
<p>Then we can re-write the Hamiltonian as:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathbb%7BH%7D+%3D+%5Cfrac%7Bp%5E2%7D%7B2ml%5E2%7D+%2B+mgl%281+-+%5Ccos%5Ctheta%29++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\mathbb{H} = \\frac{p^2}{2ml^2} + mgl(1 - \\cos\\theta)  \" class=\"latex\" title=\"\\displaystyle  \\mathbb{H} = \\frac{p^2}{2ml^2} + mgl(1 - \\cos\\theta)  \" /></div>
<p>Applying Hamilton’s equations we obtain</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++%5Cdot%7B%5Ctheta%7D+%26%3D+%5Cfrac%7B%5Cpartial%5Cmathbb%7BH%7D%7D%7B%5Cpartial+p%7D+%3D+%5Cfrac%7Bp%7D%7Bml%5E2%7D+%5C%5C++%5Cdot%7Bp%7D+%26%3D+-%5Cfrac%7B%5Cpartial%5Cmathbb%7BH%7D%7D%7B%5Cpartial+%5Ctheta%7D+%3D+-mgl%5Csin%5Ctheta++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  \\dot{\\theta} &= \\frac{\\partial\\mathbb{H}}{\\partial p} = \\frac{p}{ml^2} \\\\  \\dot{p} &= -\\frac{\\partial\\mathbb{H}}{\\partial \\theta} = -mgl\\sin\\theta  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  \\dot{\\theta} &= \\frac{\\partial\\mathbb{H}}{\\partial p} = \\frac{p}{ml^2} \\\\  \\dot{p} &= -\\frac{\\partial\\mathbb{H}}{\\partial \\theta} = -mgl\\sin\\theta  \\end{aligned}  \" /></div>
<p>Differentiating the first equation with respect to time we then obtain the familiar equation describing the motion of a simple pendulum.</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cddot%7B%5Ctheta%7D+%3D+%5Cfrac%7B%5Cdot%7Bp%7D%7D%7Bml%5E2%7D+%3D+%5Cfrac%7B-mgl%5Csin%5Ctheta%7D%7Bml%5E2%7D+%3D+-%5Cfrac%7Bg%7D%7Bl%7D%5Csin%5Ctheta++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\ddot{\\theta} = \\frac{\\dot{p}}{ml^2} = \\frac{-mgl\\sin\\theta}{ml^2} = -\\frac{g}{l}\\sin\\theta  \" class=\"latex\" title=\"\\displaystyle  \\ddot{\\theta} = \\frac{\\dot{p}}{ml^2} = \\frac{-mgl\\sin\\theta}{ml^2} = -\\frac{g}{l}\\sin\\theta  \" /></div>
<p>Now we would like to calculate the pendulum’s position and velocity at a given time. The obvious starting place is to use the explicit Euler method.</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++%5Ctheta_%7Bn%2B1%7D+%26%3D+%5Ctheta_n+%2B+h%5Cfrac%7Bp_n%7D%7Bml%5E2%7D+%5C%5C++p_%7Bn%2B1%7D+%26%3D+p_n+-+hmgl%5Csin%5Ctheta_n++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  \\theta_{n+1} &= \\theta_n + h\\frac{p_n}{ml^2} \\\\  p_{n+1} &= p_n - hmgl\\sin\\theta_n  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  \\theta_{n+1} &= \\theta_n + h\\frac{p_n}{ml^2} \\\\  p_{n+1} &= p_n - hmgl\\sin\\theta_n  \\end{aligned}  \" /></div>
<h3 id=\"haskell-for-explicit-euler\">Haskell for Explicit Euler</h3>
<p>First we need some pragmas, exports (required to create the diagrams) and imports.</p>
<pre><code>> <span style=\"color: green;\">{-# OPTIONS_GHC -Wall                     #-}</span>
> <span style=\"color: green;\">{-# OPTIONS_GHC -fno-warn-name-shadowing  #-}</span>
> <span style=\"color: green;\">{-# OPTIONS_GHC -fno-warn-type-defaults   #-}</span>
</code>
<code>> <span style=\"color: green;\">{-# LANGUAGE NoMonomorphismRestriction    #-}</span>
> <span style=\"color: green;\">{-# LANGUAGE FlexibleContexts             #-}</span>
> <span style=\"color: green;\">{-# LANGUAGE ScopedTypeVariables          #-}</span>
> <span style=\"color: green;\">{-# LANGUAGE GeneralizedNewtypeDeriving   #-}</span>
> <span style=\"color: green;\">{-# LANGUAGE TypeOperators                #-}</span>
</code>
<code>> <span style=\"color: blue; font-weight: bold;\">module</span> Symplectic <span style=\"color: red;\">(</span>
>     pendulumEE
>   <span style=\"color: red;\">,</span> pendulumSE
>   <span style=\"color: red;\">,</span> jupiterEarth
>   <span style=\"color: red;\">,</span> outerPlanets
>   <span style=\"color: red;\">,</span> main
>   <span style=\"color: red;\">)</span> <span style=\"color: blue; font-weight: bold;\">where</span>
</code>
<code>> <span style=\"color: blue; font-weight: bold;\">import</span>           Data.Array.Repa hiding <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>++<span style=\"color: red;\">)</span><span style=\"color: red;\">,</span> zipWith<span style=\"color: red;\">)</span>
> <span style=\"color: blue; font-weight: bold;\">import</span> <span style=\"color: blue; font-weight: bold;\">qualified</span> Data.Array.Repa <span style=\"color: blue; font-weight: bold;\">as</span> Repa
</code>
<code>> <span style=\"color: blue; font-weight: bold;\">import</span>           Control.Monad
> <span style=\"color: blue; font-weight: bold;\">import</span>           Control.Monad.Identity
> <span style=\"color: blue; font-weight: bold;\">import</span>           System.Environment
> <span style=\"color: blue; font-weight: bold;\">import</span>           System.Console.GetOpt
</code>
<code>> <span style=\"color: blue; font-weight: bold;\">import</span>           Foreign.Storable
</code>
<code>> <span style=\"color: blue; font-weight: bold;\">import</span> <span style=\"color: blue; font-weight: bold;\">qualified</span> Data.Yarr <span style=\"color: blue; font-weight: bold;\">as</span> Y
> <span style=\"color: blue; font-weight: bold;\">import</span>           Data.Yarr <span style=\"color: red;\">(</span>loadS<span style=\"color: red;\">,</span> dzip2<span style=\"color: red;\">,</span> dzip3<span style=\"color: red;\">,</span> F<span style=\"color: red;\">,</span> L<span style=\"color: red;\">)</span>
> <span style=\"color: blue; font-weight: bold;\">import</span>           Data.Yarr.Repr.Delayed <span style=\"color: red;\">(</span>UArray<span style=\"color: red;\">)</span>
> <span style=\"color: blue; font-weight: bold;\">import</span> <span style=\"color: blue; font-weight: bold;\">qualified</span> Data.Yarr.Shape <span style=\"color: blue; font-weight: bold;\">as</span> S
> <span style=\"color: blue; font-weight: bold;\">import</span> <span style=\"color: blue; font-weight: bold;\">qualified</span> Data.Yarr.Utils.FixedVector <span style=\"color: blue; font-weight: bold;\">as</span> V
> <span style=\"color: blue; font-weight: bold;\">import</span>           Data.Yarr.Utils.FixedVector <span style=\"color: red;\">(</span>VecList<span style=\"color: red;\">,</span> N3<span style=\"color: red;\">)</span>
> <span style=\"color: blue; font-weight: bold;\">import</span> <span style=\"color: blue; font-weight: bold;\">qualified</span> Data.Yarr.IO.List <span style=\"color: blue; font-weight: bold;\">as</span> YIO
> <span style=\"color: blue; font-weight: bold;\">import</span> <span style=\"color: blue; font-weight: bold;\">qualified</span> Data.Yarr.Walk <span style=\"color: blue; font-weight: bold;\">as</span> W
>
> <span style=\"color: blue; font-weight: bold;\">import</span> <span style=\"color: blue; font-weight: bold;\">qualified</span> Initial <span style=\"color: blue; font-weight: bold;\">as</span> I
</code></pre>
<p>Some type synomyms although it is doubtful how useful these are since the generalized co-ordinates and momenta that one uses with Hamiltonian methods can have different units depending on how the physical problem is formulated.</p>
<pre><code>> <span style=\"color: blue; font-weight: bold;\">type</span> Distance <span style=\"color: red;\">=</span> Double
> <span style=\"color: blue; font-weight: bold;\">type</span> Mass     <span style=\"color: red;\">=</span> Double
> <span style=\"color: blue; font-weight: bold;\">type</span> Speed    <span style=\"color: red;\">=</span> Double
</code></pre>
<p>The functions to update the position and momentum.</p>
<pre><code>> stepMomentumEE <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double
> stepMomentumEE m l p q <span style=\"color: red;\">=</span> p <span style=\"color: green;\">-</span>  h * m * g * l * sin q
</code>
<code>> stepPositionEE <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double
> stepPositionEE m l p q <span style=\"color: red;\">=</span> q + h * p / <span style=\"color: red;\">(</span>m * l^<span class=\"hs-num\">2</span><span style=\"color: red;\">)</span>
</code></pre>
<p>The explicit Euler method itself. Notice that both update functions use the previous position and momentum.</p>
<pre><code>> stepOnceEE <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> <span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> Double<span style=\"color: red;\">)</span>
> stepOnceEE m l p q <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span>newP<span style=\"color: red;\">,</span> newQ<span style=\"color: red;\">)</span>
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     newP <span style=\"color: red;\">=</span> stepMomentumEE m l p q
>     newQ <span style=\"color: red;\">=</span> stepPositionEE m l p q
</code></pre>
<p>The physical data for our problem and also the step length for the numerical method.</p>
<pre><code>> h<span style=\"color: red;\">,</span> m<span style=\"color: red;\">,</span> l<span style=\"color: red;\">,</span> g <span style=\"color: red;\">::</span> Double
> h <span style=\"color: red;\">=</span> <span class=\"hs-num\">0.01</span> <span style=\"color: green;\">-- Seconds</span>
> l <span style=\"color: red;\">=</span> <span class=\"hs-num\">1.0</span>  <span style=\"color: green;\">-- Metres</span>
> m <span style=\"color: red;\">=</span> <span class=\"hs-num\">1.0</span>  <span style=\"color: green;\">-- Kilograms</span>
> g <span style=\"color: red;\">=</span> <span class=\"hs-num\">9.81</span> <span style=\"color: green;\">-- Metres * Seconds^-2</span>
</code></pre>
<p>Let’s start our pendulum at the bottom with an angular velocity that ensures we don’t go over the top.</p>
<pre><code>> initTheta<span style=\"color: red;\">,</span> initThetaDot<span style=\"color: red;\">,</span> initP <span style=\"color: red;\">::</span> Double
> initTheta    <span style=\"color: red;\">=</span> <span class=\"hs-num\">0.0</span>
> initThetaDot <span style=\"color: red;\">=</span> <span class=\"hs-num\">1.7</span>
> initP        <span style=\"color: red;\">=</span> m * l^<span class=\"hs-num\">2</span> * initThetaDot
</code>
<code>> runEE <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> <span style=\"color: red;\">[</span><span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> Double<span style=\"color: red;\">)</span><span style=\"color: red;\">]</span>
> runEE initP initTheta <span style=\"color: red;\">=</span> iterate <span style=\"color: red;\">(</span>uncurry <span style=\"color: red;\">(</span>stepOnceEE m l<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span>
>                                 <span style=\"color: red;\">(</span>initP<span style=\"color: red;\">,</span> initTheta<span style=\"color: red;\">)</span>
</code>
<code>> pendulumEE <span style=\"color: red;\">::</span> <span style=\"color: red;\">[</span><span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> Double<span style=\"color: red;\">)</span><span style=\"color: red;\">]</span>
> pendulumEE <span style=\"color: red;\">=</span> runEE initP initTheta
</code></pre>
<p>The diagram below plots the position of the pendulum (the angle it makes with the vertical) against momentum, both axes normalised so that the maximum position and momentum are 1.0. We would expect that the trajectory would form a closed path that is traversed indefinitely as the pendulum swings back and forth. Instead we see that trajectory gradually spirals outward showing that energy is not conserved but steadily increases over time, an undesirable state of affairs.</p>
<div style=\"text-align: center;\">
<p><img src=\"http://idontgetoutmuch.files.wordpress.com/2013/08/af8a52f9970786658632beffec59bde3.png?w=450\" alt=\"\" /></p>
</div>
<h3 id=\"haskell-for-symplectic-euler\">Haskell for Symplectic Euler</h3>
<p>Instead let us apply the the symplectic Euler method:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++p_%7Bn%2B1%7D+%3D+p_n+-+hmgl%5Csin%5Ctheta_n+%5C%5C++%5Ctheta_%7Bn%2B1%7D+%3D+%5Ctheta_n+%2B+%5Cfrac%7Bhp_%7Bn%2B1%7D%7D%7B2ml%5E2%7D++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  p_{n+1} = p_n - hmgl\\sin\\theta_n \\\\  \\theta_{n+1} = \\theta_n + \\frac{hp_{n+1}}{2ml^2}  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  p_{n+1} = p_n - hmgl\\sin\\theta_n \\\\  \\theta_{n+1} = \\theta_n + \\frac{hp_{n+1}}{2ml^2}  \\end{aligned}  \" /></div>
<p>The functions to update the position and momentum.</p>
<pre><code>> stepMomentum <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double
> stepMomentum m l p q <span style=\"color: red;\">=</span> p <span style=\"color: green;\">-</span>  h * m * g * l * sin q
</code>
<code>> stepPosition <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double
> stepPosition m l p q <span style=\"color: red;\">=</span> q + h * p / <span style=\"color: red;\">(</span>m * l^<span class=\"hs-num\">2</span><span style=\"color: red;\">)</span>
</code></pre>
<p>The symplectic Euler method itself. Notice that only the update function for momentum uses both the previous position and momentum; the update function for position uses the previous position but the new momentum.</p>
<pre><code>> stepOnce <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> <span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> Double<span style=\"color: red;\">)</span>
> stepOnce m l p q <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span>newP<span style=\"color: red;\">,</span> newQ<span style=\"color: red;\">)</span>
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     newP <span style=\"color: red;\">=</span> stepMomentum m l p q
>     newQ <span style=\"color: red;\">=</span> stepPosition m l newP q
</code>
<code>> runSE <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> <span style=\"color: red;\">[</span><span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> Double<span style=\"color: red;\">)</span><span style=\"color: red;\">]</span>
> runSE initP initTheta <span style=\"color: red;\">=</span> iterate <span style=\"color: red;\">(</span>uncurry <span style=\"color: red;\">(</span>stepOnce m l<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span>
>                                 <span style=\"color: red;\">(</span>initP<span style=\"color: red;\">,</span> initTheta<span style=\"color: red;\">)</span>
</code>
<code>> pendulumSE <span style=\"color: red;\">::</span> <span style=\"color: red;\">[</span><span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> Double<span style=\"color: red;\">)</span><span style=\"color: red;\">]</span>
> pendulumSE <span style=\"color: red;\">=</span> runSE initP initTheta
</code></pre>
<p>The diagram below plots the position of the pendulum (the angle it makes with the vertical) against momentum, both axes normalised so that the maximum position and momentum are 1.0. We would expect that the trajectory would form a closed path that is traversed indefinitely as the pendulum swings back and forth. And indeed this is the case.</p>
<div style=\"text-align: center;\">
<p><img src=\"http://idontgetoutmuch.files.wordpress.com/2013/08/ed9f4120277fbdbe30ad1b8f5570b4d7.png?w=450\" alt=\"\" /></p>
</div>
<p>So in this case the energy is conserved so this looks like a good candidate for simulating orbital dynamics. But why does this work? It really looks very similar to the explicit Euler method.</p>
<h2 id=\"theory\">Theory</h2>
<p>Warning: some handwaving as a full and formal exposition of the theory would take much more space than can be contained in this blog article.</p>
<p>We can think of the evolution of the pendulum as taking place on a 2-dimensional manifold <a href=\"http://en.wikipedia.org/wiki/Manifold\" title=\"Wikipedia definition\">manifold</a> <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathbb%7BS%7D%5E1+%5Ctimes+%5Cmathbb%7BR%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathbb{S}^1 \\times \\mathbb{R}\" class=\"latex\" title=\"\\mathbb{S}^1 \\times \\mathbb{R}\" /> where <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathbb%7BS%7D%5E1&bg=ffffff&fg=333333&s=0\" alt=\"\\mathbb{S}^1\" class=\"latex\" title=\"\\mathbb{S}^1\" /> is the 1-dimensional sphere (a circle) since the pendulum’s space co-ordinate can only take on values <img src=\"http://s0.wp.com/latex.php?latex=0+%5Cle+q+%3C+2%5Cpi&bg=ffffff&fg=333333&s=0\" alt=\"0 \\le q < 2\\pi\" class=\"latex\" title=\"0 \\le q < 2\\pi\" />.</p>
<p>We can define a (<a href=\"https://en.wikipedia.org/wiki/Symplectic_manifold\" title=\"Wikipedia definition\">symplectic</a>) <a href=\"https://en.wikipedia.org/wiki/Differential_form\" title=\"Wikipedia definition\">2-form</a> on this manifold:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Comega+%3D+dq+%5Cwedge+dp++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\omega = dq \\wedge dp  \" class=\"latex\" title=\"\\displaystyle  \\omega = dq \\wedge dp  \" /></div>
<p>Using this we can now produce a vector field from the Hamiltonian: <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathbb%7BH%7D+%3A+%5Cmathbb%7BS%7D%5E1+%5Ctimes+%5Cmathbb%7BR%7D+%5Clongrightarrow+%5Cmathbb%7BR%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathbb{H} : \\mathbb{S}^1 \\times \\mathbb{R} \\longrightarrow \\mathbb{R}\" class=\"latex\" title=\"\\mathbb{H} : \\mathbb{S}^1 \\times \\mathbb{R} \\longrightarrow \\mathbb{R}\" /></p>
<p>In order to this and without proof let us record the following fact.</p>
<p><strong>Theorem</strong></p>
<p>Let <img src=\"http://s0.wp.com/latex.php?latex=%28M%2C+%5Comega%29&bg=ffffff&fg=333333&s=0\" alt=\"(M, \\omega)\" class=\"latex\" title=\"(M, \\omega)\" /> be a symplectic manifold. Then there exists a bundle isomorphism <img src=\"http://s0.wp.com/latex.php?latex=%5Ctilde%7B%5Comega%7D+%3A+TM+%5Clongrightarrow+T%5E%2AM&bg=ffffff&fg=333333&s=0\" alt=\"\\tilde{\\omega} : TM \\longrightarrow T^*M\" class=\"latex\" title=\"\\tilde{\\omega} : TM \\longrightarrow T^*M\" /> defined by <img src=\"http://s0.wp.com/latex.php?latex=%5Ctilde%7B%5Comega%7D%28X_p%29%28Y_p%29+%3D+%5Comega_p%28X_p%2C+Y_p%29&bg=ffffff&fg=333333&s=0\" alt=\"\\tilde{\\omega}(X_p)(Y_p) = \\omega_p(X_p, Y_p)\" class=\"latex\" title=\"\\tilde{\\omega}(X_p)(Y_p) = \\omega_p(X_p, Y_p)\" />.</p>
<p><img src=\"http://s0.wp.com/latex.php?latex=%5Cblacksquare&bg=ffffff&fg=333333&s=0\" alt=\"\\blacksquare\" class=\"latex\" title=\"\\blacksquare\" /></p>
<p>This is analagous to the isomorphism one can derive in a (semi) Riemannian manifold with the metric in some sense playing the role of the 2-form (see [@o1983semi] for example).</p>
<p>We assume the Hamiltonian to be a smooth function. We can form the 1-form <img src=\"http://s0.wp.com/latex.php?latex=dH&bg=ffffff&fg=333333&s=0\" alt=\"dH\" class=\"latex\" title=\"dH\" /> and we can define the Hamiltonian vector field <img src=\"http://s0.wp.com/latex.php?latex=X_H+%3D+%5Ctilde%7B%5Comega%7D%5E%7B-1%7D%28dH%29&bg=ffffff&fg=333333&s=0\" alt=\"X_H = \\tilde{\\omega}^{-1}(dH)\" class=\"latex\" title=\"X_H = \\tilde{\\omega}^{-1}(dH)\" />.</p>
<p>We have</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++d%5Cmathbb%7BH%7D+%3D+%5Cfrac%7B%5Cpartial%7B%5Cmathbb%7BH%7D%7D%7D%7B%5Cpartial+q%7Ddq+%2B++%5Cfrac%7B%5Cpartial%7B%5Cmathbb%7BH%7D%7D%7D%7B%5Cpartial+p%7Ddp++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  d\\mathbb{H} = \\frac{\\partial{\\mathbb{H}}}{\\partial q}dq +  \\frac{\\partial{\\mathbb{H}}}{\\partial p}dp  \" class=\"latex\" title=\"\\displaystyle  d\\mathbb{H} = \\frac{\\partial{\\mathbb{H}}}{\\partial q}dq +  \\frac{\\partial{\\mathbb{H}}}{\\partial p}dp  \" /></div>
<p>Thus the corresponding vector field is given by</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X_%5Cmathbb%7BH%7D+%3D+%5Cfrac%7B%5Cpartial%7B%5Cmathbb%7BH%7D%7D%7D%7B%5Cpartial+q%7D%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+q%7D+-++%5Cfrac%7B%5Cpartial%7B%5Cmathbb%7BH%7D%7D%7D%7B%5Cpartial+p%7D%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+p%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  X_\\mathbb{H} = \\frac{\\partial{\\mathbb{H}}}{\\partial q}\\frac{\\partial}{\\partial q} -  \\frac{\\partial{\\mathbb{H}}}{\\partial p}\\frac{\\partial}{\\partial p}  \" class=\"latex\" title=\"\\displaystyle  X_\\mathbb{H} = \\frac{\\partial{\\mathbb{H}}}{\\partial q}\\frac{\\partial}{\\partial q} -  \\frac{\\partial{\\mathbb{H}}}{\\partial p}\\frac{\\partial}{\\partial p}  \" /></div>
<p>The flow of this vector field is the solution to</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++%5Cdot%7Bq%7D+%26%3D+%5Cfrac%7B%5Cpartial+%5Cmathbb%7BH%7D%7D%7B%5Cpartial+p%7D+%5C%5C++%5Cdot%7Bp%7D+%26%3D+-%5Cfrac%7B%5Cpartial+%5Cmathbb%7BH%7D%7D%7B%5Cpartial+q%7D+%5C%5C++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  \\dot{q} &= \\frac{\\partial \\mathbb{H}}{\\partial p} \\\\  \\dot{p} &= -\\frac{\\partial \\mathbb{H}}{\\partial q} \\\\  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  \\dot{q} &= \\frac{\\partial \\mathbb{H}}{\\partial p} \\\\  \\dot{p} &= -\\frac{\\partial \\mathbb{H}}{\\partial q} \\\\  \\end{aligned}  \" /></div>
<p>In other words by using the symplectic 2-form and the Hamiltonian we have regained Hamilton’s equations.</p>
<p><strong>Theorem</strong></p>
<p><em><img src=\"http://s0.wp.com/latex.php?latex=%5Cmathbb%7BH%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathbb{H}\" class=\"latex\" title=\"\\mathbb{H}\" /> is constant on flows of <img src=\"http://s0.wp.com/latex.php?latex=X_%5Cmathbb%7BH%7D&bg=ffffff&fg=333333&s=0\" alt=\"X_\\mathbb{H}\" class=\"latex\" title=\"X_\\mathbb{H}\" />.</em></p>
<p><em>Proof</em></p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X_%7B%5Cmathbb%7BH%7D%7D%7B%5Cmathbb%7BH%7D%7D+%3D+%5Comega%28X_%7B%5Cmathbb%7BH%7D%7D%2C+X_%7B%5Cmathbb%7BH%7D%7D%29+%3D+0++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  X_{\\mathbb{H}}{\\mathbb{H}} = \\omega(X_{\\mathbb{H}}, X_{\\mathbb{H}}) = 0  \" class=\"latex\" title=\"\\displaystyle  X_{\\mathbb{H}}{\\mathbb{H}} = \\omega(X_{\\mathbb{H}}, X_{\\mathbb{H}}) = 0  \" /></div>
<p>since <img src=\"http://s0.wp.com/latex.php?latex=%5Comega&bg=ffffff&fg=333333&s=0\" alt=\"\\omega\" class=\"latex\" title=\"\\omega\" /> is alternating.</p>
<p><img src=\"http://s0.wp.com/latex.php?latex=%5Cblacksquare&bg=ffffff&fg=333333&s=0\" alt=\"\\blacksquare\" class=\"latex\" title=\"\\blacksquare\" /></p>
<p>When the Hamiltonian function represents the energy of the system being studied then this says that energy remains constant on flows. That is, as the system evolves according to the flow <img src=\"http://s0.wp.com/latex.php?latex=%5Cphi_t&bg=ffffff&fg=333333&s=0\" alt=\"\\phi_t\" class=\"latex\" title=\"\\phi_t\" /> given by the vector field <img src=\"http://s0.wp.com/latex.php?latex=X_%7B%5Cmathbb%7BH%7D%7D&bg=ffffff&fg=333333&s=0\" alt=\"X_{\\mathbb{H}}\" class=\"latex\" title=\"X_{\\mathbb{H}}\" /> then <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathbb%7BH%7D%28q_t%2C+p_t%29+%3D+%5Cmathbb%7BH%7D%28%5Cphi_t%28q_0%2C+p_0%29%29+%3D+%5Cmathbb%7BH%7D%28q_0%2C+p_0%29&bg=ffffff&fg=333333&s=0\" alt=\"\\mathbb{H}(q_t, p_t) = \\mathbb{H}(\\phi_t(q_0, p_0)) = \\mathbb{H}(q_0, p_0)\" class=\"latex\" title=\"\\mathbb{H}(q_t, p_t) = \\mathbb{H}(\\phi_t(q_0, p_0)) = \\mathbb{H}(q_0, p_0)\" />.</p>
<p>Thus it makes sense to look for numeric methods which maintain this invariant, that is methods which preserve the symplectic 2-form.</p>
<p><strong>Definition</strong></p>
<p>A diffeomorphsim between two symplectic manifolds <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+%28M%2C+%5Cmu%29+%5Clongrightarrow+%28M%2C+%5Cnu%29&bg=ffffff&fg=333333&s=0\" alt=\"f : (M, \\mu) \\longrightarrow (M, \\nu)\" class=\"latex\" title=\"f : (M, \\mu) \\longrightarrow (M, \\nu)\" /> is a symplectomorphism if</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%5E%2A%5Cnu+%3D+%5Cmu++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  f^*\\nu = \\mu  \" class=\"latex\" title=\"\\displaystyle  f^*\\nu = \\mu  \" /></div>
<p><img src=\"http://s0.wp.com/latex.php?latex=%5Cblacksquare&bg=ffffff&fg=333333&s=0\" alt=\"\\blacksquare\" class=\"latex\" title=\"\\blacksquare\" /></p>
<p>In co-ordinates, we have</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++f%5E%2A%28dq+%5Cwedge+dp%29+%26%3D+%28%5Cfrac%7B%5Cpartial+f_q%7D%7B%5Cpartial+q%7D+dq+%2B+%5Cfrac%7B%5Cpartial+f_q%7D%7B%5Cpartial+p%7D+dp%29++%5Cwedge++%28%5Cfrac%7B%5Cpartial+f_p%7D%7B%5Cpartial+q%7D+dq+%2B+%5Cfrac%7B%5Cpartial+f_p%7D%7B%5Cpartial+p%7D+dp%29+%5C%5C++%26%3D+%28%5Cfrac%7B%5Cpartial+f_q%7D%7B%5Cpartial+q%7D%5Cfrac%7B%5Cpartial+f_p%7D%7B%5Cpartial+p%7D+-++%5Cfrac%7B%5Cpartial+f_p%7D%7B%5Cpartial+q%7D%5Cfrac%7B%5Cpartial+f_q%7D%7B%5Cpartial+p%7D%29dq+%5Cwedge+dp+%5C%5C++%26%3D+dq+%5Cwedge+dp++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  f^*(dq \\wedge dp) &= (\\frac{\\partial f_q}{\\partial q} dq + \\frac{\\partial f_q}{\\partial p} dp)  \\wedge  (\\frac{\\partial f_p}{\\partial q} dq + \\frac{\\partial f_p}{\\partial p} dp) \\\\  &= (\\frac{\\partial f_q}{\\partial q}\\frac{\\partial f_p}{\\partial p} -  \\frac{\\partial f_p}{\\partial q}\\frac{\\partial f_q}{\\partial p})dq \\wedge dp \\\\  &= dq \\wedge dp  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  f^*(dq \\wedge dp) &= (\\frac{\\partial f_q}{\\partial q} dq + \\frac{\\partial f_q}{\\partial p} dp)  \\wedge  (\\frac{\\partial f_p}{\\partial q} dq + \\frac{\\partial f_p}{\\partial p} dp) \\\\  &= (\\frac{\\partial f_q}{\\partial q}\\frac{\\partial f_p}{\\partial p} -  \\frac{\\partial f_p}{\\partial q}\\frac{\\partial f_q}{\\partial p})dq \\wedge dp \\\\  &= dq \\wedge dp  \\end{aligned}  \" /></div>
<p>Or in matrix form</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Cbegin%7Bbmatrix%7D++%5Cfrac%7B%5Cpartial+f_q%7D%7B%5Cpartial+q%7D+%26+%5Cfrac%7B%5Cpartial+f_q%7D%7B%5Cpartial+p%7D+%5C%5C++%5Cfrac%7B%5Cpartial+f_p%7D%7B%5Cpartial+q%7D+%26+%5Cfrac%7B%5Cpartial+f_p%7D%7B%5Cpartial+p%7D++%5Cend%7Bbmatrix%7D%7D%5E%5Ctop++%5C%2C++%5Cbegin%7Bbmatrix%7D++0+%26+1+%5C%5C++-1+%26+0++%5Cend%7Bbmatrix%7D++%5C%2C++%5Cbegin%7Bbmatrix%7D++%5Cfrac%7B%5Cpartial+f_q%7D%7B%5Cpartial+q%7D+%26+%5Cfrac%7B%5Cpartial+f_q%7D%7B%5Cpartial+p%7D+%5C%5C++%5Cfrac%7B%5Cpartial+f_p%7D%7B%5Cpartial+q%7D+%26+%5Cfrac%7B%5Cpartial+f_p%7D%7B%5Cpartial+p%7D++%5Cend%7Bbmatrix%7D++%3D++%5Cbegin%7Bbmatrix%7D++0+%26+1+%5C%5C++-1+%26+0++%5Cend%7Bbmatrix%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  {\\begin{bmatrix}  \\frac{\\partial f_q}{\\partial q} & \\frac{\\partial f_q}{\\partial p} \\\\  \\frac{\\partial f_p}{\\partial q} & \\frac{\\partial f_p}{\\partial p}  \\end{bmatrix}}^\\top  \\,  \\begin{bmatrix}  0 & 1 \\\\  -1 & 0  \\end{bmatrix}  \\,  \\begin{bmatrix}  \\frac{\\partial f_q}{\\partial q} & \\frac{\\partial f_q}{\\partial p} \\\\  \\frac{\\partial f_p}{\\partial q} & \\frac{\\partial f_p}{\\partial p}  \\end{bmatrix}  =  \\begin{bmatrix}  0 & 1 \\\\  -1 & 0  \\end{bmatrix}  \" class=\"latex\" title=\"\\displaystyle  {\\begin{bmatrix}  \\frac{\\partial f_q}{\\partial q} & \\frac{\\partial f_q}{\\partial p} \\\\  \\frac{\\partial f_p}{\\partial q} & \\frac{\\partial f_p}{\\partial p}  \\end{bmatrix}}^\\top  \\,  \\begin{bmatrix}  0 & 1 \\\\  -1 & 0  \\end{bmatrix}  \\,  \\begin{bmatrix}  \\frac{\\partial f_q}{\\partial q} & \\frac{\\partial f_q}{\\partial p} \\\\  \\frac{\\partial f_p}{\\partial q} & \\frac{\\partial f_p}{\\partial p}  \\end{bmatrix}  =  \\begin{bmatrix}  0 & 1 \\\\  -1 & 0  \\end{bmatrix}  \" /></div>
<p>We now check that the symplectic Euler method satisfies this.</p>
<h3 id=\"symplectic-euler\">Symplectic Euler</h3>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++p_%7Bn%2B1%7D+%26%3D+p_n+-+h%5Cnabla_q+H%28p_%7Bn%2B1%7D%2C+q_n%29+%5C%5C++q_%7Bn%2B1%7D+%26%3D+q_n+%2B+h%5Cnabla_p+H%28p_%7Bn%2B1%7D%2C+q_n%29++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  p_{n+1} &= p_n - h\\nabla_q H(p_{n+1}, q_n) \\\\  q_{n+1} &= q_n + h\\nabla_p H(p_{n+1}, q_n)  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  p_{n+1} &= p_n - h\\nabla_q H(p_{n+1}, q_n) \\\\  q_{n+1} &= q_n + h\\nabla_p H(p_{n+1}, q_n)  \\end{aligned}  \" /></div>
<p>We check that this really is symplectic. First suppose we have two functions:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++x+%26%3D+u+-+f%28x%2Cv%29+%5C%5C++y+%26%3D+v+%2B+g%28x%2Cv%29+%5C%5C++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  x &= u - f(x,v) \\\\  y &= v + g(x,v) \\\\  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  x &= u - f(x,v) \\\\  y &= v + g(x,v) \\\\  \\end{aligned}  \" /></div>
<p>Then we can find partial derivatives:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++dx+%26%3D+du+-+%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+x%7Ddx+-+%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+v%7Ddv+%5C%5C++dy+%26%3D+dv+%2B+%5Cfrac%7B%5Cpartial+g%7D%7B%5Cpartial+x%7Ddx+%2B+%5Cfrac%7B%5Cpartial+g%7D%7B%5Cpartial+v%7D+dv+%5C%5C++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  dx &= du - \\frac{\\partial f}{\\partial x}dx - \\frac{\\partial f}{\\partial v}dv \\\\  dy &= dv + \\frac{\\partial g}{\\partial x}dx + \\frac{\\partial g}{\\partial v} dv \\\\  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  dx &= du - \\frac{\\partial f}{\\partial x}dx - \\frac{\\partial f}{\\partial v}dv \\\\  dy &= dv + \\frac{\\partial g}{\\partial x}dx + \\frac{\\partial g}{\\partial v} dv \\\\  \\end{aligned}  \" /></div>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++%5Cfrac%7B%5Cpartial+x%7D%7B%5Cpartial+u%7D+%26%3D+1+-+%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+x%7D%5Cfrac%7B%5Cpartial+x%7D%7B%5Cpartial+u%7D+%5C%5C++%5Cfrac%7B%5Cpartial+x%7D%7B%5Cpartial+v%7D+%26%3D+-%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+x%7D%5Cfrac%7B%5Cpartial+x%7D%7B%5Cpartial+v%7D+-%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+v%7D+%5C%5C++%5Cfrac%7B%5Cpartial+y%7D%7B%5Cpartial+u%7D+%26%3D+%5Cfrac%7B%5Cpartial+g%7D%7B%5Cpartial+x%7D%5Cfrac%7B%5Cpartial+x%7D%7B%5Cpartial+u%7D+%5C%5C++%5Cfrac%7B%5Cpartial+y%7D%7B%5Cpartial+v%7D+%26%3D+1+%2B+%5Cfrac%7B%5Cpartial+g%7D%7B%5Cpartial+x%7D%5Cfrac%7B%5Cpartial+x%7D%7B%5Cpartial+v%7D+%2B+%5Cfrac%7B%5Cpartial+g%7D%7B%5Cpartial+v%7D++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  \\frac{\\partial x}{\\partial u} &= 1 - \\frac{\\partial f}{\\partial x}\\frac{\\partial x}{\\partial u} \\\\  \\frac{\\partial x}{\\partial v} &= -\\frac{\\partial f}{\\partial x}\\frac{\\partial x}{\\partial v} -\\frac{\\partial f}{\\partial v} \\\\  \\frac{\\partial y}{\\partial u} &= \\frac{\\partial g}{\\partial x}\\frac{\\partial x}{\\partial u} \\\\  \\frac{\\partial y}{\\partial v} &= 1 + \\frac{\\partial g}{\\partial x}\\frac{\\partial x}{\\partial v} + \\frac{\\partial g}{\\partial v}  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  \\frac{\\partial x}{\\partial u} &= 1 - \\frac{\\partial f}{\\partial x}\\frac{\\partial x}{\\partial u} \\\\  \\frac{\\partial x}{\\partial v} &= -\\frac{\\partial f}{\\partial x}\\frac{\\partial x}{\\partial v} -\\frac{\\partial f}{\\partial v} \\\\  \\frac{\\partial y}{\\partial u} &= \\frac{\\partial g}{\\partial x}\\frac{\\partial x}{\\partial u} \\\\  \\frac{\\partial y}{\\partial v} &= 1 + \\frac{\\partial g}{\\partial x}\\frac{\\partial x}{\\partial v} + \\frac{\\partial g}{\\partial v}  \\end{aligned}  \" /></div>
<p>Re-arranging:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++%5Cfrac%7B%5Cpartial+x%7D%7B%5Cpartial+u%7D%281+%2B+%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+x%7D%29+%26%3D+1+%5C%5C++%5Cfrac%7B%5Cpartial+x%7D%7B%5Cpartial+v%7D%281+%2B+%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+x%7D%29+%26%3D+-%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+v%7D+%5C%5C++%5Cfrac%7B%5Cpartial+y%7D%7B%5Cpartial+u%7D+-%5Cfrac%7B%5Cpartial+g%7D%7B%5Cpartial+x%7D%5Cfrac%7B%5Cpartial+x%7D%7B%5Cpartial+u%7D+%26%3D+0+%5C%5C++%5Cfrac%7B%5Cpartial+y%7D%7B%5Cpartial+v%7D+-+%5Cfrac%7B%5Cpartial+g%7D%7B%5Cpartial+x%7D%5Cfrac%7B%5Cpartial+x%7D%7B%5Cpartial+v%7D+%26%3D+1+%2B+%5Cfrac%7B%5Cpartial+g%7D%7B%5Cpartial+v%7D++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  \\frac{\\partial x}{\\partial u}(1 + \\frac{\\partial f}{\\partial x}) &= 1 \\\\  \\frac{\\partial x}{\\partial v}(1 + \\frac{\\partial f}{\\partial x}) &= -\\frac{\\partial f}{\\partial v} \\\\  \\frac{\\partial y}{\\partial u} -\\frac{\\partial g}{\\partial x}\\frac{\\partial x}{\\partial u} &= 0 \\\\  \\frac{\\partial y}{\\partial v} - \\frac{\\partial g}{\\partial x}\\frac{\\partial x}{\\partial v} &= 1 + \\frac{\\partial g}{\\partial v}  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  \\frac{\\partial x}{\\partial u}(1 + \\frac{\\partial f}{\\partial x}) &= 1 \\\\  \\frac{\\partial x}{\\partial v}(1 + \\frac{\\partial f}{\\partial x}) &= -\\frac{\\partial f}{\\partial v} \\\\  \\frac{\\partial y}{\\partial u} -\\frac{\\partial g}{\\partial x}\\frac{\\partial x}{\\partial u} &= 0 \\\\  \\frac{\\partial y}{\\partial v} - \\frac{\\partial g}{\\partial x}\\frac{\\partial x}{\\partial v} &= 1 + \\frac{\\partial g}{\\partial v}  \\end{aligned}  \" /></div>
<p>Pulling everything together in matrix form:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Bbmatrix%7D++1+%2B+%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+x%7D+%26+0+%5C%5C++-%5Cfrac%7B%5Cpartial+g%7D%7B%5Cpartial+x%7D+%26+1++%5Cend%7Bbmatrix%7D++%5C%2C++%5Cbegin%7Bbmatrix%7D++%5Cfrac%7B%5Cpartial+x%7D%7B%5Cpartial+u%7D+%26+%5Cfrac%7B%5Cpartial+x%7D%7B%5Cpartial+v%7D+%5C%5C++%5Cfrac%7B%5Cpartial+y%7D%7B%5Cpartial+u%7D+%26+%5Cfrac%7B%5Cpartial+y%7D%7B%5Cpartial+v%7D++%5Cend%7Bbmatrix%7D++%3D++%5Cbegin%7Bbmatrix%7D++1+%26+-%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+v%7D+%5C%5C++0+%26+1+%2B+%5Cfrac%7B%5Cpartial+g%7D%7B%5Cpartial+v%7D++%5Cend%7Bbmatrix%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{bmatrix}  1 + \\frac{\\partial f}{\\partial x} & 0 \\\\  -\\frac{\\partial g}{\\partial x} & 1  \\end{bmatrix}  \\,  \\begin{bmatrix}  \\frac{\\partial x}{\\partial u} & \\frac{\\partial x}{\\partial v} \\\\  \\frac{\\partial y}{\\partial u} & \\frac{\\partial y}{\\partial v}  \\end{bmatrix}  =  \\begin{bmatrix}  1 & -\\frac{\\partial f}{\\partial v} \\\\  0 & 1 + \\frac{\\partial g}{\\partial v}  \\end{bmatrix}  \" class=\"latex\" title=\"\\displaystyle  \\begin{bmatrix}  1 + \\frac{\\partial f}{\\partial x} & 0 \\\\  -\\frac{\\partial g}{\\partial x} & 1  \\end{bmatrix}  \\,  \\begin{bmatrix}  \\frac{\\partial x}{\\partial u} & \\frac{\\partial x}{\\partial v} \\\\  \\frac{\\partial y}{\\partial u} & \\frac{\\partial y}{\\partial v}  \\end{bmatrix}  =  \\begin{bmatrix}  1 & -\\frac{\\partial f}{\\partial v} \\\\  0 & 1 + \\frac{\\partial g}{\\partial v}  \\end{bmatrix}  \" /></div>
<p>Now substitute in the functions for the Euler symplectic method and we obtain</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Bbmatrix%7D++1+%2B+hH_%7Bqp%7D+%26+0+%5C%5C++-hG_%7Bpp%7D+%26+1++%5Cend%7Bbmatrix%7D++%5C%2C++%5Cfrac%7B%5Cpartial+%5Cbig%28p_%7Bn%2B1%7D%2Cq_%7Bn%2B1%7D%5Cbig%29%7D%7B%5Cpartial+%5Cbig%28p_%7Bn%7D%2Cq_%7Bn%7D%5Cbig%29%7D++%3D++%5Cbegin%7Bbmatrix%7D++1+%26+-hH_%7Bqq%7D+%5C%5C++0+%26+1+%2B+hH_%7Bqp%7D++%5Cend%7Bbmatrix%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{bmatrix}  1 + hH_{qp} & 0 \\\\  -hG_{pp} & 1  \\end{bmatrix}  \\,  \\frac{\\partial \\big(p_{n+1},q_{n+1}\\big)}{\\partial \\big(p_{n},q_{n}\\big)}  =  \\begin{bmatrix}  1 & -hH_{qq} \\\\  0 & 1 + hH_{qp}  \\end{bmatrix}  \" class=\"latex\" title=\"\\displaystyle  \\begin{bmatrix}  1 + hH_{qp} & 0 \\\\  -hG_{pp} & 1  \\end{bmatrix}  \\,  \\frac{\\partial \\big(p_{n+1},q_{n+1}\\big)}{\\partial \\big(p_{n},q_{n}\\big)}  =  \\begin{bmatrix}  1 & -hH_{qq} \\\\  0 & 1 + hH_{qp}  \\end{bmatrix}  \" /></div>
<p>The reader can then check by a straightforward but tedious calculation that</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B%5Cpartial+%5Cbig%28p_%7Bn%2B1%7D%2Cq_%7Bn%2B1%7D%5Cbig%29%7D%7B%5Cpartial+%5Cbig%28p_%7Bn%7D%2Cq_%7Bn%7D%5Cbig%29%7D%5E%5Ctop+J+%5Cfrac%7B%5Cpartial+%5Cbig%28p_%7Bn%2B1%7D%2Cq_%7Bn%2B1%7D%5Cbig%29%7D%7B%5Cpartial+%5Cbig%28p_%7Bn%7D%2Cq_%7Bn%7D%5Cbig%29%7D+%3D+J++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\frac{\\partial \\big(p_{n+1},q_{n+1}\\big)}{\\partial \\big(p_{n},q_{n}\\big)}^\\top J \\frac{\\partial \\big(p_{n+1},q_{n+1}\\big)}{\\partial \\big(p_{n},q_{n}\\big)} = J  \" class=\"latex\" title=\"\\displaystyle  \\frac{\\partial \\big(p_{n+1},q_{n+1}\\big)}{\\partial \\big(p_{n},q_{n}\\big)}^\\top J \\frac{\\partial \\big(p_{n+1},q_{n+1}\\big)}{\\partial \\big(p_{n},q_{n}\\big)} = J  \" /></div>
<p>where</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++J++%3D++%5Cbegin%7Bbmatrix%7D++0+%26+1+%5C%5C++-1+%26+0++%5Cend%7Bbmatrix%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  J  =  \\begin{bmatrix}  0 & 1 \\\\  -1 & 0  \\end{bmatrix}  \" class=\"latex\" title=\"\\displaystyle  J  =  \\begin{bmatrix}  0 & 1 \\\\  -1 & 0  \\end{bmatrix}  \" /></div>
<p>Thus the symplectic Euler method really is symplectic.</p>
<p>On the other hand for the explicit Euler for this particular example we have</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B%5Cpartial+%5Cbig%28p_%7Bn%2B1%7D%2Cq_%7Bn%2B1%7D%5Cbig%29%7D%7B%5Cpartial+%5Cbig%28p_%7Bn%7D%2Cq_%7Bn%7D%5Cbig%29%7D++%3D++%5Cbegin%7Bbmatrix%7D++1+%26+h+%2F+ml%5E2+%5C%5C++-hmglcos%5Ctheta_n+%26+1++%5Cend%7Bbmatrix%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\frac{\\partial \\big(p_{n+1},q_{n+1}\\big)}{\\partial \\big(p_{n},q_{n}\\big)}  =  \\begin{bmatrix}  1 & h / ml^2 \\\\  -hmglcos\\theta_n & 1  \\end{bmatrix}  \" class=\"latex\" title=\"\\displaystyle  \\frac{\\partial \\big(p_{n+1},q_{n+1}\\big)}{\\partial \\big(p_{n},q_{n}\\big)}  =  \\begin{bmatrix}  1 & h / ml^2 \\\\  -hmglcos\\theta_n & 1  \\end{bmatrix}  \" /></div>
<p>And a simple calculation shows that</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B%5Cpartial+%5Cbig%28p_%7Bn%2B1%7D%2Cq_%7Bn%2B1%7D%5Cbig%29%7D%7B%5Cpartial+%5Cbig%28p_%7Bn%7D%2Cq_%7Bn%7D%5Cbig%29%7D%5E%5Ctop+J+%5Cfrac%7B%5Cpartial+%5Cbig%28p_%7Bn%2B1%7D%2Cq_%7Bn%2B1%7D%5Cbig%29%7D%7B%5Cpartial+%5Cbig%28p_%7Bn%7D%2Cq_%7Bn%7D%5Cbig%29%7D++%3D++%5Cbegin%7Bbmatrix%7D++0+%26+1+%2B+h%5E2%5Ccos%5Ctheta%5C%5C++-1+-+h%5E2%5Ccos%5Ctheta+%26+0++%5Cend%7Bbmatrix%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\frac{\\partial \\big(p_{n+1},q_{n+1}\\big)}{\\partial \\big(p_{n},q_{n}\\big)}^\\top J \\frac{\\partial \\big(p_{n+1},q_{n+1}\\big)}{\\partial \\big(p_{n},q_{n}\\big)}  =  \\begin{bmatrix}  0 & 1 + h^2\\cos\\theta\\\\  -1 - h^2\\cos\\theta & 0  \\end{bmatrix}  \" class=\"latex\" title=\"\\displaystyle  \\frac{\\partial \\big(p_{n+1},q_{n+1}\\big)}{\\partial \\big(p_{n},q_{n}\\big)}^\\top J \\frac{\\partial \\big(p_{n+1},q_{n+1}\\big)}{\\partial \\big(p_{n},q_{n}\\big)}  =  \\begin{bmatrix}  0 & 1 + h^2\\cos\\theta\\\\  -1 - h^2\\cos\\theta & 0  \\end{bmatrix}  \" /></div>
<p>Thus the explicit Euler method is not symplectic i.e., does not preserve areas. Thus the path traversed is not an integral curve of the Hamiltonian vector field. We can see this in the diagram: the path spirals outwards. More details and examples can be found in [@IAUS:152:407Y; @Cross:2005:SIOC].</p>
<h2 id=\"planetary-motion\">Planetary Motion</h2>
<p>Normally we would express the gravitational constant in SI units but to be consistent with [@hairer2010geometric] we use units in which distances are expressed in astronomical units, masses are measured relative to the sun and time is measured in earth days.</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Cmathbb+H%7D+%3D+%5Cfrac%7B1%7D%7B2%7D%5Csum_%7Bi%3D0%7D%5En+%5Cfrac%7Bp_i%5E%5Ctop+p_i%7D%7Bm_i%7D+-+%5Cfrac%7BG%7D%7B2%7D%5Csum_%7Bi%3D0%7D%5En%5Csum_%7Bj+%5Cneq+i%7D+%5Cfrac%7Bm_i+m_j%7D%7B%5C%7Cq_i+-+q_j%5C%7C%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  {\\mathbb H} = \\frac{1}{2}\\sum_{i=0}^n \\frac{p_i^\\top p_i}{m_i} - \\frac{G}{2}\\sum_{i=0}^n\\sum_{j \\neq i} \\frac{m_i m_j}{\\|q_i - q_j\\|}  \" class=\"latex\" title=\"\\displaystyle  {\\mathbb H} = \\frac{1}{2}\\sum_{i=0}^n \\frac{p_i^\\top p_i}{m_i} - \\frac{G}{2}\\sum_{i=0}^n\\sum_{j \\neq i} \\frac{m_i m_j}{\\|q_i - q_j\\|}  \" /></div>
<p>Applying Hamilton’s equations we obtain</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++%5Cdot%7Bq_k%5Ea%7D+%26%3D+%5Cfrac%7B%5Cpartial%5Cmathbb%7BH%7D%7D%7B%5Cpartial+p_k%5Ea%7D+%3D+%5Cfrac%7Bp_k%5Ea%7D%7Bm_k%7D+%5C%5C++%5Cdot%7Bp_k%5Ea%7D+%26%3D+-%5Cfrac%7B%5Cpartial%5Cmathbb%7BH%7D%7D%7B%5Cpartial+q_k%5Ea%7D+%3D+G%5Csum_%7Bj+%5Cneq+k%7Dm_k+m_i+%5Cfrac%7Bq_k%5Ea+-+q_j%5Ea%7D%7B%5C%7Cq_k+-+q_j%5C%7C%5E3%7D++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  \\dot{q_k^a} &= \\frac{\\partial\\mathbb{H}}{\\partial p_k^a} = \\frac{p_k^a}{m_k} \\\\  \\dot{p_k^a} &= -\\frac{\\partial\\mathbb{H}}{\\partial q_k^a} = G\\sum_{j \\neq k}m_k m_i \\frac{q_k^a - q_j^a}{\\|q_k - q_j\\|^3}  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  \\dot{q_k^a} &= \\frac{\\partial\\mathbb{H}}{\\partial p_k^a} = \\frac{p_k^a}{m_k} \\\\  \\dot{p_k^a} &= -\\frac{\\partial\\mathbb{H}}{\\partial q_k^a} = G\\sum_{j \\neq k}m_k m_i \\frac{q_k^a - q_j^a}{\\|q_k - q_j\\|^3}  \\end{aligned}  \" /></div>
<p>In this case it easy to see that these are the same as Newton’s laws of motion.</p>
<p>Applying the Euler symplectic method we obtain:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++q_k%5E%7Bn%2B1%7D+%26%3D+q_k%5En+%2B+h+%5Cfrac%7Bp_k%5En%7D%7Bm_k%7D+%5C%5C++p_k%5E%7Bn%2B1%7D+%26%3D+p_k%5En+%2B+h+G%5Csum_%7Bj+%5Cneq+k%7Dm_k+m_i+%5Cfrac%7Bq_k%5E%7Bn%2B1%7D+-+q_j%5E%7Bn%2B1%7D%7D%7B%5C%7Cq_k%5E%7Bn%2B1%7D+-+q_j%5E%7Bn%2B1%7D%5C%7C%5E3%7D++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  q_k^{n+1} &= q_k^n + h \\frac{p_k^n}{m_k} \\\\  p_k^{n+1} &= p_k^n + h G\\sum_{j \\neq k}m_k m_i \\frac{q_k^{n+1} - q_j^{n+1}}{\\|q_k^{n+1} - q_j^{n+1}\\|^3}  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  q_k^{n+1} &= q_k^n + h \\frac{p_k^n}{m_k} \\\\  p_k^{n+1} &= p_k^n + h G\\sum_{j \\neq k}m_k m_i \\frac{q_k^{n+1} - q_j^{n+1}}{\\|q_k^{n+1} - q_j^{n+1}\\|^3}  \\end{aligned}  \" /></div>
<h3 id=\"repa-implementation\">Repa Implementation</h3>
<p>We use <a href=\"http://hackage.haskell.org/package/repa\" title=\"Hackage\">repa</a> represent our positions and momenta as 2-dimensional arrays, each planet is given a 3-dimensional position vector and a 3-dimensional momentum vector.</p>
<pre><code>> <span style=\"color: blue; font-weight: bold;\">newtype</span> PositionP a <span style=\"color: red;\">=</span> QP <span style=\"color: red;\">{</span> positionP <span style=\"color: red;\">::</span> Array a DIM2 Double <span style=\"color: red;\">}</span>
> <span style=\"color: blue; font-weight: bold;\">newtype</span> MomentaP  a <span style=\"color: red;\">=</span> PP <span style=\"color: red;\">{</span> momentaP <span style=\"color: red;\">::</span> Array a DIM2 Double <span style=\"color: red;\">}</span>
> <span style=\"color: blue; font-weight: bold;\">newtype</span> MassP     a <span style=\"color: red;\">=</span> MP <span style=\"color: red;\">{</span> massP <span style=\"color: red;\">::</span> Array a DIM1 Double <span style=\"color: red;\">}</span>
</code>
<code>> stepPositionP <span style=\"color: red;\">::</span> <span style=\"color: blue; font-weight: bold;\">forall</span> a b c m .
>                  <span style=\"color: red;\">(</span> Monad m
>                  <span style=\"color: red;\">,</span> Source a Double
>                  <span style=\"color: red;\">,</span> Source b Double
>                  <span style=\"color: red;\">,</span> Source c Double
>                  <span style=\"color: red;\">)</span> <span style=\"color: red;\">=></span>
>                  Double <span style=\"color: red;\">-></span>
>                  PositionP a <span style=\"color: red;\">-></span>
>                  MassP b <span style=\"color: red;\">-></span>
>                  MomentaP c <span style=\"color: red;\">-></span>
>                  m <span style=\"color: red;\">(</span>PositionP U<span style=\"color: red;\">)</span>
> stepPositionP h qs ms ps <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   <span style=\"color: blue; font-weight: bold;\">do</span> newQs <span style=\"color: red;\"><-</span> computeP $ <span style=\"color: red;\">(</span>positionP qs<span style=\"color: red;\">)</span> +^ <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>momentaP ps<span style=\"color: red;\">)</span> *^ h3 /^ ms2<span style=\"color: red;\">)</span>
>      return $ QP newQs
>     <span style=\"color: blue; font-weight: bold;\">where</span>
>       <span style=\"color: red;\">(</span>Z :. i :. j<span style=\"color: red;\">)</span> <span style=\"color: red;\">=</span> extent $ momentaP ps
>
>       h3  <span style=\"color: red;\">=</span> extend <span style=\"color: red;\">(</span>Any :. i :. j<span style=\"color: red;\">)</span> $ fromListUnboxed Z <span style=\"color: red;\">[</span>h<span style=\"color: red;\">]</span>
>       ms2 <span style=\"color: red;\">=</span> extend <span style=\"color: red;\">(</span>Any :. j<span style=\"color: red;\">)</span> $ massP ms
</code></pre>
<p>Each planet produces forces on every other planet so we work with 3-dimsenional arrays and explicitly set the force of a planet on itself to zero. Once the forces on each planet have been calculated, we sum them to produce a resultant force which we then use to step the momentum forward.</p>
<pre><code>> stepMomentumP <span style=\"color: red;\">::</span> <span style=\"color: blue; font-weight: bold;\">forall</span> a b c m .
>                  <span style=\"color: red;\">(</span> Monad m
>                  <span style=\"color: red;\">,</span> Source a Double
>                  <span style=\"color: red;\">,</span> Source b Double
>                  <span style=\"color: red;\">,</span> Source c Double
>                  <span style=\"color: red;\">)</span> <span style=\"color: red;\">=></span>
>                  Double <span style=\"color: red;\">-></span>
>                  Double <span style=\"color: red;\">-></span>
>                  PositionP a <span style=\"color: red;\">-></span>
>                  MassP b <span style=\"color: red;\">-></span>
>                  MomentaP c <span style=\"color: red;\">-></span>
>                  m <span style=\"color: red;\">(</span>MomentaP U<span style=\"color: red;\">)</span>
> stepMomentumP gConst h qs ms ps <span style=\"color: red;\">=</span>
>   <span style=\"color: blue; font-weight: bold;\">do</span> fs <span style=\"color: red;\"><-</span> sumP $ transpose $ zeroDiags fss
>      newPs <span style=\"color: red;\"><-</span> computeP $ <span style=\"color: red;\">(</span>momentaP ps<span style=\"color: red;\">)</span> +^ <span style=\"color: red;\">(</span>fs *^ dt2<span style=\"color: red;\">)</span>
>      return $ PP newPs
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     is <span style=\"color: red;\">=</span> repDim2to3Outer $ prodPairsMasses $ massP ms
>     qDiffs <span style=\"color: red;\">=</span> pointDiffs $ positionP qs
>     preDs <span style=\"color: red;\">=</span> Repa.map <span style=\"color: red;\">(</span>^<span class=\"hs-num\">3</span><span style=\"color: red;\">)</span> $
>             Repa.map sqrt $
>             sumS $
>             Repa.map <span style=\"color: red;\">(</span>^<span class=\"hs-num\">2</span><span style=\"color: red;\">)</span> $
>             qDiffs
>     ds    <span style=\"color: red;\">=</span> repDim2to3Outer preDs
>     preFs <span style=\"color: red;\">=</span> Repa.map <span style=\"color: red;\">(</span>* <span style=\"color: red;\">(</span>negate gConst<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> $
>             qDiffs /^ ds
>     fss <span style=\"color: red;\">=</span> is *^ preFs
>     Z :.i :. <span class=\"hs-sel\">_j</span> :. k <span style=\"color: red;\">=</span> extent fss
>     dt2              <span style=\"color: red;\">=</span> extend <span style=\"color: red;\">(</span>Any :. i :. k<span style=\"color: red;\">)</span> $ fromListUnboxed Z <span style=\"color: red;\">[</span>h<span style=\"color: red;\">]</span>
>
>     repDim2to3Outer a <span style=\"color: red;\">=</span> extend <span style=\"color: red;\">(</span>Any :. I.spaceDim<span style=\"color: red;\">)</span> a
>
>     zeroDiags x <span style=\"color: red;\">=</span> traverse x id f
>       <span style=\"color: blue; font-weight: bold;\">where</span>
>         f <span style=\"color: blue; font-weight: bold;\">_</span> <span style=\"color: red;\">(</span>Z :. i :. j :. k<span style=\"color: red;\">)</span> <span style=\"color: red;\">|</span> i == j    <span style=\"color: red;\">=</span> <span class=\"hs-num\">0.0</span>
>                                <span style=\"color: red;\">|</span> otherwise <span style=\"color: red;\">=</span> x!<span style=\"color: red;\">(</span>Z :. i :. j :. k<span style=\"color: red;\">)</span>
</code>
<code>> stepOnceP <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span> Monad m
>              <span style=\"color: red;\">,</span> Source a Double
>              <span style=\"color: red;\">,</span> Source b Double
>              <span style=\"color: red;\">,</span> Source c Double
>              <span style=\"color: red;\">)</span> <span style=\"color: red;\">=></span>
>              Double <span style=\"color: red;\">-></span>
>              Double <span style=\"color: red;\">-></span>
>              MassP b <span style=\"color: red;\">-></span>
>              PositionP a <span style=\"color: red;\">-></span>
>              MomentaP c <span style=\"color: red;\">-></span>
>              m <span style=\"color: red;\">(</span>PositionP U<span style=\"color: red;\">,</span> MomentaP U<span style=\"color: red;\">)</span>
> stepOnceP gConst h ms qs ps <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   newPs <span style=\"color: red;\"><-</span> stepMomentumP gConst h qs ms ps
>   newQs <span style=\"color: red;\"><-</span> stepPositionP h qs ms newPs
>   return <span style=\"color: red;\">(</span>newQs<span style=\"color: red;\">,</span> newPs<span style=\"color: red;\">)</span>
</code>
<code>> kineticEnergyP <span style=\"color: red;\">::</span> MassP U <span style=\"color: red;\">-></span> MomentaP U <span style=\"color: red;\">-></span> IO <span style=\"color: red;\">(</span>Array D DIM0 Double<span style=\"color: red;\">)</span>
> kineticEnergyP ms ps <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   preKes <span style=\"color: red;\"><-</span> sumP $ <span style=\"color: red;\">(</span>momentaP ps<span style=\"color: red;\">)</span> *^ <span style=\"color: red;\">(</span>momentaP ps<span style=\"color: red;\">)</span>
>   ke     <span style=\"color: red;\"><-</span> sumP $ preKes /^ <span style=\"color: red;\">(</span>massP ms<span style=\"color: red;\">)</span>
>   return $ Repa.map <span style=\"color: red;\">(</span>* <span class=\"hs-num\">0.5</span><span style=\"color: red;\">)</span> ke
>
> potentialEnergyP <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span>
>                     MassP U <span style=\"color: red;\">-></span>
>                     PositionP U <span style=\"color: red;\">-></span>
>                     IO <span style=\"color: red;\">(</span>Array U DIM1 Double<span style=\"color: red;\">)</span>
> potentialEnergyP gConst ms qs <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   ds2 <span style=\"color: red;\"><-</span> sumP $ Repa.map <span style=\"color: red;\">(</span>^<span class=\"hs-num\">2</span><span style=\"color: red;\">)</span> $ pointDiffs $ positionP qs
>   <span style=\"color: blue; font-weight: bold;\">let</span> ds   <span style=\"color: red;\">=</span> Repa.map sqrt ds2
>       is   <span style=\"color: red;\">=</span> prodPairsMasses $ massP ms
>       pess <span style=\"color: red;\">=</span> zeroDiags $ Repa.map <span style=\"color: red;\">(</span>* <span style=\"color: red;\">(</span><span class=\"hs-num\">0.5</span> * negate gConst<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> $ is /^ ds
>   pes <span style=\"color: red;\"><-</span> sumP pess
>   return pes
>
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>
>     zeroDiags x <span style=\"color: red;\">=</span> traverse x id f
>       <span style=\"color: blue; font-weight: bold;\">where</span>
>         f <span style=\"color: blue; font-weight: bold;\">_</span> <span style=\"color: red;\">(</span>Z :. i :. j<span style=\"color: red;\">)</span> <span style=\"color: red;\">|</span> i == j    <span style=\"color: red;\">=</span> <span class=\"hs-num\">0.0</span>
>                           <span style=\"color: red;\">|</span> otherwise <span style=\"color: red;\">=</span> x!<span style=\"color: red;\">(</span>Z :. i :. j<span style=\"color: red;\">)</span>
</code>
<code>> hamiltonianP <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span>
>                 MassP U <span style=\"color: red;\">-></span>
>                 PositionP U <span style=\"color: red;\">-></span>
>                 MomentaP U <span style=\"color: red;\">-></span>
>                 IO Double
> hamiltonianP gConst ms qs ps <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   ke <span style=\"color: red;\"><-</span> kineticEnergyP ms ps
>   pes <span style=\"color: red;\"><-</span> potentialEnergyP gConst ms qs
>   pe  <span style=\"color: red;\"><-</span> sumP pes
>   te <span style=\"color: red;\">::</span> Array U DIM0 Double <span style=\"color: red;\"><-</span> computeP $ ke +^ pe
>   return $ head $ toList te
</code>
<code>> prodPairsMasses <span style=\"color: red;\">::</span> Source a Double <span style=\"color: red;\">=></span>
>                    Array a DIM1 Double <span style=\"color: red;\">-></span>
>                    Array D DIM2 Double
> prodPairsMasses ms <span style=\"color: red;\">=</span> ns *^ <span style=\"color: red;\">(</span>transpose ns<span style=\"color: red;\">)</span>
>
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     <span style=\"color: red;\">(</span>Z :. i<span style=\"color: red;\">)</span> <span style=\"color: red;\">=</span> extent ms
>     ns <span style=\"color: red;\">=</span> extend <span style=\"color: red;\">(</span>Any :. i :. All<span style=\"color: red;\">)</span> ms
</code>
<code>>
> pointDiffs <span style=\"color: red;\">::</span> Source a Double <span style=\"color: red;\">=></span>
>               Array a DIM2 Double <span style=\"color: red;\">-></span>
>               Array D DIM3 Double
> pointDiffs qs <span style=\"color: red;\">=</span> qss -^ <span style=\"color: red;\">(</span>transposeOuter qss<span style=\"color: red;\">)</span>
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>
>     qss <span style=\"color: red;\">=</span> replicateRows qs
>
>     transposeOuter qs <span style=\"color: red;\">=</span> backpermute <span style=\"color: red;\">(</span>f e<span style=\"color: red;\">)</span> f qs
>       <span style=\"color: blue; font-weight: bold;\">where</span>
>         e <span style=\"color: red;\">=</span> extent qs
>         f <span style=\"color: red;\">(</span>Z :. i :. i' :. j<span style=\"color: red;\">)</span> <span style=\"color: red;\">=</span> Z :. i' :. i :. j
>
>     replicateRows <span style=\"color: red;\">::</span> Source a Double <span style=\"color: red;\">=></span>
>                      Array a DIM2 Double <span style=\"color: red;\">-></span>
>                      Array D DIM3 Double
>     replicateRows a <span style=\"color: red;\">=</span> extend <span style=\"color: red;\">(</span>Any :. i :. All<span style=\"color: red;\">)</span> a
>       <span style=\"color: blue; font-weight: bold;\">where</span> <span style=\"color: red;\">(</span>Z :. i :. <span class=\"hs-sel\">_j</span><span style=\"color: red;\">)</span> <span style=\"color: red;\">=</span> extent a
</code></pre>
<p>Using the single step udate, we can step as many times as we wish.</p>
<pre><code>> stepN <span style=\"color: red;\">::</span> <span style=\"color: blue; font-weight: bold;\">forall</span> m . Monad m <span style=\"color: red;\">=></span>
>          Int <span style=\"color: red;\">-></span>
>          Double <span style=\"color: red;\">-></span>
>          Double <span style=\"color: red;\">-></span>
>          MassP U <span style=\"color: red;\">-></span>
>          PositionP U <span style=\"color: red;\">-></span>
>          MomentaP U <span style=\"color: red;\">-></span>
>          m <span style=\"color: red;\">(</span>PositionP U<span style=\"color: red;\">,</span> MomentaP U<span style=\"color: red;\">)</span>
> stepN n gConst dt masses <span style=\"color: red;\">=</span> curry updaterMulti
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     updaterMulti <span style=\"color: red;\">=</span> foldr <span style=\"color: red;\">(</span>>=><span style=\"color: red;\">)</span> return updaters
>     updaters <span style=\"color: red;\">=</span> replicate n <span style=\"color: red;\">(</span>uncurry <span style=\"color: red;\">(</span>stepOnceP gConst dt masses<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span>
</code></pre>
<p>Sometimes we need all the intermediate steps e.g. for plotting.</p>
<pre><code>> stepNs <span style=\"color: red;\">::</span> Monad m <span style=\"color: red;\">=></span>
>           Int <span style=\"color: red;\">-></span>
>           Double <span style=\"color: red;\">-></span>
>           Double <span style=\"color: red;\">-></span>
>           MassP U <span style=\"color: red;\">-></span>
>           PositionP U <span style=\"color: red;\">-></span>
>           MomentaP U <span style=\"color: red;\">-></span>
>           m <span style=\"color: red;\">[</span><span style=\"color: red;\">(</span>PositionP U<span style=\"color: red;\">,</span> MomentaP U<span style=\"color: red;\">)</span><span style=\"color: red;\">]</span>
> stepNs n gConst dt ms rs vs <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   rsVs <span style=\"color: red;\"><-</span> stepAux n rs vs
>   return $ <span style=\"color: red;\">(</span>rs<span style=\"color: red;\">,</span> vs<span style=\"color: red;\">)</span> : rsVs
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     stepAux <span class=\"hs-num\">0</span>  <span style=\"color: blue; font-weight: bold;\">_</span>  <span style=\"color: blue; font-weight: bold;\">_</span> <span style=\"color: red;\">=</span> return []
>     stepAux n rs vs <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>       <span style=\"color: red;\">(</span>newRs<span style=\"color: red;\">,</span> newVs<span style=\"color: red;\">)</span> <span style=\"color: red;\"><-</span> stepOnceP gConst dt ms rs vs
>       rsVs <span style=\"color: red;\"><-</span> stepAux <span style=\"color: red;\">(</span>n<span style=\"color: green;\">-</span><span class=\"hs-num\">1</span><span style=\"color: red;\">)</span> newRs newVs
>       return $ <span style=\"color: red;\">(</span>newRs<span style=\"color: red;\">,</span> newVs<span style=\"color: red;\">)</span> : rsVs
</code></pre>
<h3 id=\"yarr-implementation\">Yarr Implementation</h3>
<p>We use <a href=\"http://hackage.haskell.org/package/yarr\" title=\"Hackage\">yarr</a> represent our positions and momenta as 1-dimensional arrays, each planet is given a 3-dimensional position vector and a 3-dimensional momentum vector.</p>
<pre><code>> vZero <span style=\"color: red;\">::</span> VecList N3 Double
> vZero <span style=\"color: red;\">=</span> V.replicate <span class=\"hs-num\">0</span>
</code>
<code>> <span style=\"color: blue; font-weight: bold;\">type</span> ArrayY <span style=\"color: red;\">=</span> UArray F L S.Dim1
</code>
<code>> <span style=\"color: blue; font-weight: bold;\">newtype</span> PositionY  <span style=\"color: red;\">=</span> QY <span style=\"color: red;\">{</span> positionY <span style=\"color: red;\">::</span> VecList N3 Double <span style=\"color: red;\">}</span>
>   <span style=\"color: blue; font-weight: bold;\">deriving</span> <span style=\"color: red;\">(</span>Show<span style=\"color: red;\">,</span> Storable<span style=\"color: red;\">)</span>
> <span style=\"color: blue; font-weight: bold;\">newtype</span> MomentumY <span style=\"color: red;\">=</span> PY <span style=\"color: red;\">{</span> momentumY <span style=\"color: red;\">::</span> VecList N3 Double <span style=\"color: red;\">}</span>
>   <span style=\"color: blue; font-weight: bold;\">deriving</span> <span style=\"color: red;\">(</span>Show<span style=\"color: red;\">,</span> Storable<span style=\"color: red;\">)</span>
> <span style=\"color: blue; font-weight: bold;\">type</span> MomentaY     <span style=\"color: red;\">=</span> ArrayY MomentumY
> <span style=\"color: blue; font-weight: bold;\">type</span> PositionsY   <span style=\"color: red;\">=</span> ArrayY PositionY
> <span style=\"color: blue; font-weight: bold;\">type</span> MassesY      <span style=\"color: red;\">=</span> ArrayY Mass
> <span style=\"color: blue; font-weight: bold;\">type</span> ForceY       <span style=\"color: red;\">=</span> VecList N3 Double
> <span style=\"color: blue; font-weight: bold;\">type</span> ForcesY      <span style=\"color: red;\">=</span> ArrayY ForceY
</code>
<code>> stepPositionY <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span> PositionsY <span style=\"color: red;\">-></span> MassesY <span style=\"color: red;\">-></span> MomentaY <span style=\"color: red;\">-></span> IO ()
> stepPositionY h qs ms ps <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   loadS S.fill <span style=\"color: red;\">(</span>dzip3 upd qs ms ps<span style=\"color: red;\">)</span> qs
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     upd <span style=\"color: red;\">::</span> PositionY <span style=\"color: red;\">-></span> Mass <span style=\"color: red;\">-></span> MomentumY <span style=\"color: red;\">-></span> PositionY
>     upd q m p <span style=\"color: red;\">=</span> QY $ V.zipWith <span style=\"color: red;\">(</span>+<span style=\"color: red;\">)</span>
>                 <span style=\"color: red;\">(</span>positionY q<span style=\"color: red;\">)</span>
>                 <span style=\"color: red;\">(</span>V.map <span style=\"color: red;\">(</span>* <span style=\"color: red;\">(</span>h / m<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>momentumY p<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span>
</code></pre>
<p>Note the requirement to fill the forces array with zeros before using it.</p>
<pre><code>> stepMomentumY <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span>
>                  Double <span style=\"color: red;\">-></span>
>                  PositionsY <span style=\"color: red;\">-></span>
>                  MassesY <span style=\"color: red;\">-></span>
>                  MomentaY <span style=\"color: red;\">-></span>
>                  IO ()
> stepMomentumY gConst h qs ms ps <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   <span style=\"color: blue; font-weight: bold;\">let</span> nBodies <span style=\"color: red;\">=</span> Y.extent ms
>   fs <span style=\"color: red;\">::</span> ForcesY <span style=\"color: red;\"><-</span> Y.new nBodies
>   S.fill <span style=\"color: red;\">(</span><span style=\"color: red;\">\\</span><span style=\"color: blue; font-weight: bold;\">_</span> <span style=\"color: red;\">-></span> return vZero<span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>Y.write fs<span style=\"color: red;\">)</span> <span class=\"hs-num\">0</span> nBodies
>   <span style=\"color: blue; font-weight: bold;\">let</span> forceBetween i pos1 mass1 j
>         <span style=\"color: red;\">|</span> i == j <span style=\"color: red;\">=</span> return vZero
>         <span style=\"color: red;\">|</span> otherwise <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>           pos2 <span style=\"color: red;\"><-</span> qs `Y.index` j
>           mass2 <span style=\"color: red;\"><-</span> ms `Y.index` j
>           <span style=\"color: blue; font-weight: bold;\">let</span> deltas <span style=\"color: red;\">=</span> V.zipWith <span style=\"color: red;\">(</span><span style=\"color: green;\">-</span><span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>positionY pos1<span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>positionY pos2<span style=\"color: red;\">)</span>
>               dist2  <span style=\"color: red;\">=</span> V.sum $ V.map <span style=\"color: red;\">(</span>^ <span class=\"hs-num\">2</span><span style=\"color: red;\">)</span> deltas
>               a <span style=\"color: red;\">=</span> <span class=\"hs-num\">1.0</span> / dist2
>               b <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span>negate gConst<span style=\"color: red;\">)</span> * mass1 * mass2 * a * <span style=\"color: red;\">(</span>sqrt a<span style=\"color: red;\">)</span>
>           return $ V.map <span style=\"color: red;\">(</span>* b<span style=\"color: red;\">)</span> deltas
>       forceAdd <span style=\"color: red;\">::</span> Int <span style=\"color: red;\">-></span> Int <span style=\"color: red;\">-></span> ForceY <span style=\"color: red;\">-></span> IO ()
>       forceAdd i <span style=\"color: blue; font-weight: bold;\">_</span> f <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>         f0 <span style=\"color: red;\"><-</span> fs `Y.index` i
>         Y.write fs i <span style=\"color: red;\">(</span>V.zipWith <span style=\"color: red;\">(</span>+<span style=\"color: red;\">)</span> f0 f<span style=\"color: red;\">)</span>
>       force i pos <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>         mass <span style=\"color: red;\"><-</span> ms `Y.index` i
>         S.fill <span style=\"color: red;\">(</span>forceBetween i pos mass<span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>forceAdd i<span style=\"color: red;\">)</span> <span class=\"hs-num\">0</span> nBodies
>       upd momentum force <span style=\"color: red;\">=</span>
>         PY $ V.zipWith <span style=\"color: red;\">(</span>+<span style=\"color: red;\">)</span>
>         <span style=\"color: red;\">(</span>momentumY momentum<span style=\"color: red;\">)</span>
>         <span style=\"color: red;\">(</span>V.map <span style=\"color: red;\">(</span><span style=\"color: red;\">\\</span>f <span style=\"color: red;\">-></span> f * h<span style=\"color: red;\">)</span> force<span style=\"color: red;\">)</span>
>   S.fill <span style=\"color: red;\">(</span>Y.index qs<span style=\"color: red;\">)</span> force <span class=\"hs-num\">0</span> nBodies
>   loadS S.fill <span style=\"color: red;\">(</span>dzip2 upd ps fs<span style=\"color: red;\">)</span> ps
</code>
<code>> stepOnceY <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span>
>              Double <span style=\"color: red;\">-></span>
>              MassesY <span style=\"color: red;\">-></span>
>              PositionsY <span style=\"color: red;\">-></span>
>              MomentaY <span style=\"color: red;\">-></span>
>              IO ()
> stepOnceY gConst h ms qs ps <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   stepMomentumY gConst h qs ms ps
>   stepPositionY h qs ms ps
</code>
<code>> potentialEnergyY <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span>
>                     MassesY <span style=\"color: red;\">-></span>
>                     PositionsY <span style=\"color: red;\">-></span>
>                     IO <span style=\"color: red;\">(</span>ArrayY Double<span style=\"color: red;\">)</span>
> potentialEnergyY gConst ms qs <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   <span style=\"color: blue; font-weight: bold;\">let</span> nBodies <span style=\"color: red;\">=</span> Y.extent ms
>   pes <span style=\"color: red;\">::</span> ArrayY Double <span style=\"color: red;\"><-</span> Y.new nBodies
>   S.fill <span style=\"color: red;\">(</span><span style=\"color: red;\">\\</span><span style=\"color: blue; font-weight: bold;\">_</span> <span style=\"color: red;\">-></span> return <span class=\"hs-num\">0.0</span><span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>Y.write pes<span style=\"color: red;\">)</span> <span class=\"hs-num\">0</span> nBodies
>   <span style=\"color: blue; font-weight: bold;\">let</span> peOnePairParticles <span style=\"color: red;\">::</span> Int <span style=\"color: red;\">-></span>
>                             Int <span style=\"color: red;\">-></span>
>                             IO Double
>       peOnePairParticles i j
>         <span style=\"color: red;\">|</span> i == j <span style=\"color: red;\">=</span> return <span class=\"hs-num\">0.0</span>
>         <span style=\"color: red;\">|</span> otherwise <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>           q1 <span style=\"color: red;\"><-</span> qs `Y.index` i
>           m1 <span style=\"color: red;\"><-</span> ms `Y.index` i
>           q2 <span style=\"color: red;\"><-</span> qs `Y.index` j
>           m2 <span style=\"color: red;\"><-</span> ms `Y.index` j
>           <span style=\"color: blue; font-weight: bold;\">let</span> qDiffs <span style=\"color: red;\">=</span> V.zipWith <span style=\"color: red;\">(</span><span style=\"color: green;\">-</span><span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>positionY q1<span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>positionY q2<span style=\"color: red;\">)</span>
>               dist2  <span style=\"color: red;\">=</span> V.sum $ V.map <span style=\"color: red;\">(</span>^<span class=\"hs-num\">2</span><span style=\"color: red;\">)</span> qDiffs
>               a      <span style=\"color: red;\">=</span> <span class=\"hs-num\">1.0</span> / dist2
>               b      <span style=\"color: red;\">=</span> <span class=\"hs-num\">0.5</span> * <span style=\"color: red;\">(</span>negate gConst<span style=\"color: red;\">)</span> * m1 * m2 * <span style=\"color: red;\">(</span>sqrt a<span style=\"color: red;\">)</span>
>           return b
>       peAdd i <span style=\"color: blue; font-weight: bold;\">_</span> pe <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>         peDelta <span style=\"color: red;\"><-</span> pes `Y.index` i
>         Y.write pes i <span style=\"color: red;\">(</span>pe + peDelta<span style=\"color: red;\">)</span>
>       peFn i <span style=\"color: blue; font-weight: bold;\">_</span> <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>         S.fill <span style=\"color: red;\">(</span>peOnePairParticles i<span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>peAdd i<span style=\"color: red;\">)</span> <span class=\"hs-num\">0</span> nBodies
>   S.fill <span style=\"color: red;\">(</span>Y.index qs<span style=\"color: red;\">)</span> peFn <span class=\"hs-num\">0</span> nBodies
>   return pes
</code>
<code>> kineticEnergyY <span style=\"color: red;\">::</span> MassesY <span style=\"color: red;\">-></span> MomentaY<span style=\"color: red;\">-></span> IO Double
> kineticEnergyY ms ps <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   <span style=\"color: blue; font-weight: bold;\">let</span> nakedPs <span style=\"color: red;\">=</span> Y.delay $ Y.dmap momentumY ps
>   <span style=\"color: blue; font-weight: bold;\">let</span> preKes <span style=\"color: red;\">=</span> Y.dmap V.sum $ dzip2 <span style=\"color: red;\">(</span>V.zipWith <span style=\"color: red;\">(</span>*<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> nakedPs nakedPs
>       kes     <span style=\"color: red;\">=</span> dzip2 <span style=\"color: red;\">(</span>/<span style=\"color: red;\">)</span> preKes <span style=\"color: red;\">(</span>Y.delay ms<span style=\"color: red;\">)</span>
>   ke <span style=\"color: red;\"><-</span> W.walk <span style=\"color: red;\">(</span>W.reduceL S.foldl <span style=\"color: red;\">(</span>+<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>return <span class=\"hs-num\">0</span><span style=\"color: red;\">)</span> kes
>   return $ <span class=\"hs-num\">0.5</span> * ke
</code>
<code>> hamiltonianY <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span> MassesY <span style=\"color: red;\">-></span> PositionsY <span style=\"color: red;\">-></span> MomentaY<span style=\"color: red;\">-></span> IO Double
> hamiltonianY gConst ms qs ps <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   ke  <span style=\"color: red;\"><-</span> kineticEnergyY ms ps
>   pes <span style=\"color: red;\"><-</span> potentialEnergyY gConst ms qs
>   pe  <span style=\"color: red;\"><-</span> W.walk <span style=\"color: red;\">(</span>W.reduceL S.foldl <span style=\"color: red;\">(</span>+<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>return <span class=\"hs-num\">0</span><span style=\"color: red;\">)</span> pes
>   return $ pe + ke
</code></pre>
<h2 id=\"the-outer-solar-system\">The Outer Solar System</h2>
<p>We convert the starting positions and momenta for the planets into repa and yarr friendly representations.</p>
<pre><code>> mosssP <span style=\"color: red;\">::</span> MassP U
> mosssP <span style=\"color: red;\">=</span> MP $ fromListUnboxed <span style=\"color: red;\">(</span>Z :. n<span style=\"color: red;\">)</span> I.massesOuter
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     n <span style=\"color: red;\">=</span> length I.massesOuter
>
> mosssY <span style=\"color: red;\">::</span> IO MassesY
> mosssY <span style=\"color: red;\">=</span> YIO.fromList n I.massesOuter
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     n <span style=\"color: red;\">=</span> length I.massesOuter
>
> qosss <span style=\"color: red;\">::</span> PositionP U
> qosss <span style=\"color: red;\">=</span> QP $ fromListUnboxed <span style=\"color: red;\">(</span>Z :. n :. I.spaceDim<span style=\"color: red;\">)</span> xs
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     xs <span style=\"color: red;\">=</span> concat I.initQsOuter
>     n  <span style=\"color: red;\">=</span> length xs `div` I.spaceDim
>
> qosssY <span style=\"color: red;\">::</span> IO PositionsY
> qosssY <span style=\"color: red;\">=</span> YIO.fromList nBodies $ Prelude.map f <span style=\"color: red;\">[</span><span class=\"hs-num\">0</span> <span style=\"color: red;\">..</span> nBodies <span style=\"color: green;\">-</span> <span class=\"hs-num\">1</span><span style=\"color: red;\">]</span>
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     nBodies <span style=\"color: red;\">=</span> length I.initQsOuter
>     f <span style=\"color: red;\">::</span> Int <span style=\"color: red;\">-></span> PositionY
>     f i <span style=\"color: red;\">=</span> QY $
>           V.vl_3 <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>I.initQsOuter!!i<span style=\"color: red;\">)</span>!!<span class=\"hs-num\">0</span><span style=\"color: red;\">)</span>
>                  <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>I.initQsOuter!!i<span style=\"color: red;\">)</span>!!<span class=\"hs-num\">1</span><span style=\"color: red;\">)</span>
>                  <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>I.initQsOuter!!i<span style=\"color: red;\">)</span>!!<span class=\"hs-num\">2</span><span style=\"color: red;\">)</span>
>
> posss <span style=\"color: red;\">::</span> MomentaP U
> posss <span style=\"color: red;\">=</span> PP $ fromListUnboxed <span style=\"color: red;\">(</span>Z :. n :. I.spaceDim<span style=\"color: red;\">)</span> xs
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     xs <span style=\"color: red;\">=</span> concat I.initPsOuter
>     n  <span style=\"color: red;\">=</span> length xs `div` I.spaceDim
>
> posssY <span style=\"color: red;\">::</span> IO MomentaY
> posssY <span style=\"color: red;\">=</span> YIO.fromList nBodies $ Prelude.map f <span style=\"color: red;\">[</span><span class=\"hs-num\">0</span> <span style=\"color: red;\">..</span> nBodies <span style=\"color: green;\">-</span> <span class=\"hs-num\">1</span><span style=\"color: red;\">]</span>
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     nBodies <span style=\"color: red;\">=</span> length I.initPsOuter
>     f <span style=\"color: red;\">::</span> Int <span style=\"color: red;\">-></span> MomentumY
>     f i <span style=\"color: red;\">=</span> PY $
>           V.vl_3 <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>I.initPsOuter!!i<span style=\"color: red;\">)</span>!!<span class=\"hs-num\">0</span><span style=\"color: red;\">)</span>
>                  <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>I.initPsOuter!!i<span style=\"color: red;\">)</span>!!<span class=\"hs-num\">1</span><span style=\"color: red;\">)</span>
>                  <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>I.initPsOuter!!i<span style=\"color: red;\">)</span>!!<span class=\"hs-num\">2</span><span style=\"color: red;\">)</span>
</code></pre>
<p>Rather arbitrarily we run the outer planets for 2000 steps with a step length of 100 days.</p>
<pre><code>> outerPlanets <span style=\"color: red;\">::</span> <span style=\"color: red;\">[</span><span style=\"color: red;\">[</span><span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> Double<span style=\"color: red;\">)</span><span style=\"color: red;\">]</span><span style=\"color: red;\">]</span>
> outerPlanets <span style=\"color: red;\">=</span> runIdentity $ <span style=\"color: blue; font-weight: bold;\">do</span>
>   rsVs <span style=\"color: red;\"><-</span> stepNs <span class=\"hs-num\">2000</span> I.gConstAu <span class=\"hs-num\">100</span> mosssP qosss posss
>   <span style=\"color: blue; font-weight: bold;\">let</span> qs <span style=\"color: red;\">=</span> Prelude.map fst rsVs
>       xxs <span style=\"color: red;\">=</span> Prelude.map
>             <span style=\"color: red;\">(</span><span style=\"color: red;\">\\</span>i <span style=\"color: red;\">-></span> Prelude.map <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>!<span style=\"color: red;\">(</span>Z :. <span style=\"color: red;\">(</span>i <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span> :. <span style=\"color: red;\">(</span><span class=\"hs-num\">0</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> .
>                                 positionP<span style=\"color: red;\">)</span> qs<span style=\"color: red;\">)</span>
>             <span style=\"color: red;\">[</span><span class=\"hs-num\">5</span><span style=\"color: red;\">,</span><span class=\"hs-num\">0</span><span style=\"color: red;\">,</span><span class=\"hs-num\">1</span><span style=\"color: red;\">,</span><span class=\"hs-num\">2</span><span style=\"color: red;\">,</span><span class=\"hs-num\">3</span><span style=\"color: red;\">,</span><span class=\"hs-num\">4</span><span style=\"color: red;\">]</span>
>       xys <span style=\"color: red;\">=</span> Prelude.map
>             <span style=\"color: red;\">(</span><span style=\"color: red;\">\\</span>i <span style=\"color: red;\">-></span> Prelude.map <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>!<span style=\"color: red;\">(</span>Z :. <span style=\"color: red;\">(</span>i <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span> :. <span style=\"color: red;\">(</span><span class=\"hs-num\">1</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> .
>                                 positionP<span style=\"color: red;\">)</span> qs<span style=\"color: red;\">)</span>
>             <span style=\"color: red;\">[</span><span class=\"hs-num\">5</span><span style=\"color: red;\">,</span><span class=\"hs-num\">0</span><span style=\"color: red;\">,</span><span class=\"hs-num\">1</span><span style=\"color: red;\">,</span><span class=\"hs-num\">2</span><span style=\"color: red;\">,</span><span class=\"hs-num\">3</span><span style=\"color: red;\">,</span><span class=\"hs-num\">4</span><span style=\"color: red;\">]</span>
>   return $ zipWith zip xxs xys
</code></pre>
<p>Plotting the results, we can see that we have a simulation which, as we expect, conserves energy.</p>
<div style=\"text-align: center;\">
<p><img src=\"http://idontgetoutmuch.files.wordpress.com/2013/08/49ddf2abcabc480eec452f2ec6cbd211.png?w=450\" alt=\"\" /></p>
</div>
<h2 id=\"performance\">Performance</h2>
<p>Let’s see how repa and yarr perform against each other.</p>
<pre><code>> <span style=\"color: blue; font-weight: bold;\">data</span> YarrOrRepa <span style=\"color: red;\">=</span> Repa <span style=\"color: red;\">|</span> Yarr
>   <span style=\"color: blue; font-weight: bold;\">deriving</span> Show
>
> <span style=\"color: blue; font-weight: bold;\">data</span> Options <span style=\"color: red;\">=</span> Options  <span style=\"color: red;\">{</span> optYarr <span style=\"color: red;\">::</span> YarrOrRepa
>                         <span style=\"color: red;\">}</span>
>
> startOptions <span style=\"color: red;\">::</span> Options
> startOptions <span style=\"color: red;\">=</span> Options  <span style=\"color: red;\">{</span> optYarr <span style=\"color: red;\">=</span> Repa
>                         <span style=\"color: red;\">}</span>
>
> options <span style=\"color: red;\">::</span> <span style=\"color: red;\">[</span>OptDescr <span style=\"color: red;\">(</span>Options <span style=\"color: red;\">-></span> IO Options<span style=\"color: red;\">)</span><span style=\"color: red;\">]</span>
> options <span style=\"color: red;\">=</span> <span style=\"color: red;\">[</span>
>   Option <span style=\"color: red;\">[</span><span style=\"color: teal;\">'Y'</span><span style=\"color: red;\">]</span> <span style=\"color: red;\">[</span><span style=\"color: teal;\">\"yarr\"</span><span style=\"color: red;\">]</span> <span style=\"color: red;\">(</span>NoArg <span style=\"color: red;\">(</span><span style=\"color: red;\">\\</span>opt <span style=\"color: red;\">-></span> return opt <span style=\"color: red;\">{</span> optYarr <span style=\"color: red;\">=</span> Yarr <span style=\"color: red;\">}</span><span style=\"color: red;\">)</span><span style=\"color: red;\">)</span>
>          <span style=\"color: teal;\">\"Use yarr\"</span>
>   <span style=\"color: red;\">]</span>
</code>
<code>> main <span style=\"color: red;\">::</span> IO ()
> main <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   args <span style=\"color: red;\"><-</span> getArgs
>   <span style=\"color: blue; font-weight: bold;\">let</span> <span style=\"color: red;\">(</span>actions<span style=\"color: red;\">,</span> <span class=\"hs-sel\">_nonOpts</span><span style=\"color: red;\">,</span> <span class=\"hs-sel\">_msgs</span><span style=\"color: red;\">)</span> <span style=\"color: red;\">=</span> getOpt RequireOrder options args
>   opts <span style=\"color: red;\"><-</span> foldl <span style=\"color: red;\">(</span>>>=<span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>return startOptions<span style=\"color: red;\">)</span> actions
>   <span style=\"color: blue; font-weight: bold;\">case</span> optYarr opts <span style=\"color: blue; font-weight: bold;\">of</span>
>     Repa <span style=\"color: red;\">-></span> <span style=\"color: blue; font-weight: bold;\">do</span>
>       hPre <span style=\"color: red;\"><-</span> hamiltonianP I.gConstAu mosssP qosss posss
>       putStrLn $ show hPre
>       <span style=\"color: red;\">(</span>qsPost<span style=\"color: red;\">,</span> psPost<span style=\"color: red;\">)</span> <span style=\"color: red;\"><-</span> stepN I.nStepsOuter I.gConstAu I.stepOuter
>                           mosssP qosss posss
>       hPost <span style=\"color: red;\"><-</span> hamiltonianP I.gConstAu mosssP qsPost psPost
>       putStrLn $ show hPost
>     Yarr <span style=\"color: red;\">-></span> <span style=\"color: blue; font-weight: bold;\">do</span>
>       ms <span style=\"color: red;\">::</span> MassesY <span style=\"color: red;\"><-</span> mosssY
>       ps <span style=\"color: red;\"><-</span> posssY
>       qs <span style=\"color: red;\"><-</span> qosssY
>       hPre <span style=\"color: red;\"><-</span> hamiltonianY I.gConstAu ms qs ps
>       putStrLn $ show hPre
>       S.fill <span style=\"color: red;\">(</span><span style=\"color: red;\">\\</span><span style=\"color: blue; font-weight: bold;\">_</span> <span style=\"color: red;\">-></span> return ()<span style=\"color: red;\">)</span>
>              <span style=\"color: red;\">(</span><span style=\"color: red;\">\\</span><span style=\"color: blue; font-weight: bold;\">_</span> <span style=\"color: blue; font-weight: bold;\">_</span> <span style=\"color: red;\">-></span> stepOnceY I.gConstAu I.stepOuter ms qs ps<span style=\"color: red;\">)</span>
>              <span style=\"color: red;\">(</span><span class=\"hs-num\">0</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span> I.nStepsOuter
>       hPost <span style=\"color: red;\"><-</span> hamiltonianY I.gConstAu ms qs ps
>       putStrLn $ show hPost
</code></pre>
<p>With 200,000 steps we get the following for repa.</p>
<pre><code>$ time ./Symplectic
-3.215453183208164e-8
-3.139737384661333e-8
real	0m18.400s
user	0m18.245s
sys	0m0.154s</code></pre>
<p>And a significant speed up with yarr.</p>
<pre><code>$ time ./Symplectic -Y
-3.215453183208164e-8
-3.13973738466838e-8
real	0m0.553s
user	0m0.539s
sys	0m0.013s</code></pre>
<p>With 2,000,000 steps (about 548,000 years) we get the following with yarr.</p>
<pre><code>$ time ./Symplectic -Y
-3.215453183208164e-8
-3.2144315777817145e-8
real	0m5.477s
user	0m5.369s
sys	0m0.107s</code></pre>
<p>It would be interesting to compare this against a C implementation.</p>
<h2 id=\"appendices\">Appendices</h2>
<h3 id=\"appendix-a-jupiter-earth-and-sun\">Appendix A: Jupiter, Earth and Sun</h3>
<p>We need some initial conditions to start our simulation. Instead of taking real data, let’s make up something which is realistic but within our control.</p>
<p>Following [@Fitz:Newtonian:Dynamics] we can write Kepler’s laws as</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++r+%26%3D+%5Cfrac%7Ba%281+-+e%5E2%29%7D%7B1+-+e%5Ccos%5Ctheta%7D+%5C%5C++r%5E2%5Cdot%7B%5Ctheta%7D+%26%3D+%5Csqrt%7B%281+-+e%5E2%29%7Dna%5E2+%5C%5C++GM_%7B%5Crm+Sun%7D+%26%3D+n%5E2a%5E3++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  r &= \\frac{a(1 - e^2)}{1 - e\\cos\\theta} \\\\  r^2\\dot{\\theta} &= \\sqrt{(1 - e^2)}na^2 \\\\  GM_{\\rm Sun} &= n^2a^3  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  r &= \\frac{a(1 - e^2)}{1 - e\\cos\\theta} \\\\  r^2\\dot{\\theta} &= \\sqrt{(1 - e^2)}na^2 \\\\  GM_{\\rm Sun} &= n^2a^3  \\end{aligned}  \" /></div>
<p>where <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" /> is the period of the orbit, <img src=\"http://s0.wp.com/latex.php?latex=n+%3D+2%5Cpi+%2F+T&bg=ffffff&fg=333333&s=0\" alt=\"n = 2\\pi / T\" class=\"latex\" title=\"n = 2\\pi / T\" /> is the mean angular orbital velocity, <img src=\"http://s0.wp.com/latex.php?latex=a&bg=ffffff&fg=333333&s=0\" alt=\"a\" class=\"latex\" title=\"a\" /> is the major radius of the elliptical orbit (Kepler’s first law: “The orbit of every planet is an ellipse with the Sun at one of the two foci”), <img src=\"http://s0.wp.com/latex.php?latex=G&bg=ffffff&fg=333333&s=0\" alt=\"G\" class=\"latex\" title=\"G\" /> is the gravitational constant and <img src=\"http://s0.wp.com/latex.php?latex=M_%7B%5Crm+Sun%7D&bg=ffffff&fg=333333&s=0\" alt=\"M_{\\rm Sun}\" class=\"latex\" title=\"M_{\\rm Sun}\" /> is the mass of the sun and <img src=\"http://s0.wp.com/latex.php?latex=e&bg=ffffff&fg=333333&s=0\" alt=\"e\" class=\"latex\" title=\"e\" /> is the eccentricity of a planet’s orbit.</p>
<p>We can calculate the mean angular orbital velocity of Jupiter:</p>
<pre><code>> nJupiter <span style=\"color: red;\">::</span> Double
> nJupiter <span style=\"color: red;\">=</span> sqrt $ I.gConst * I.sunMass / I.jupiterMajRad^<span class=\"hs-num\">3</span>
</code></pre>
<p>Let us calculate the initial conditions assuming that Jupiter starts at its perihelion. The angular velocity at that point is entirely in the negative <img src=\"http://s0.wp.com/latex.php?latex=y&bg=ffffff&fg=333333&s=0\" alt=\"y\" class=\"latex\" title=\"y\" /> direction.</p>
<p>With the Leapfrog Method we need the velocity to be half a time step before the perihelion.</p>
<p>If we take <img src=\"http://s0.wp.com/latex.php?latex=%280.0%2C+-v_p%2C+0.0%29&bg=ffffff&fg=333333&s=0\" alt=\"(0.0, -v_p, 0.0)\" class=\"latex\" title=\"(0.0, -v_p, 0.0)\" /> to be the velocity of Jupiter at the perihelion then if <img src=\"http://s0.wp.com/latex.php?latex=%5Cdelta%5Ctheta&bg=ffffff&fg=333333&s=0\" alt=\"\\delta\\theta\" class=\"latex\" title=\"\\delta\\theta\" /> is the angle with respect to the negative y-axis at half a time step before Jupiter reaches the perihelion then the velocity of Jupiter at this point is given by simple trigonometry:<br />
<span class=\"math\">( − <em>v</em><sub><em>p</em></sub>sin(<em>δ</em><em>θ</em>),  − <em>v</em><sub><em>p</em></sub>cos(<em>δ</em><em>θ</em>), 0. 0) ≈ ( − <em>v</em><sub><em>p</em></sub><em>δ</em><em>θ</em>,  − <em>v</em><sub><em>p</em></sub>(1 − <em>δ</em><em>θ</em><sup>2</sup> / 2), 0. 0)</span></p>
<p>In Haskell, we get the following initial conditions:</p>
<pre><code>> jupiterThetaDotP <span style=\"color: red;\">::</span> Double
> jupiterThetaDotP <span style=\"color: red;\">=</span>
>   nJupiter *
>   I.jupiterMajRad^<span class=\"hs-num\">2</span> *
>   sqrt <span style=\"color: red;\">(</span><span class=\"hs-num\">1</span> <span style=\"color: green;\">-</span> I.jupiterEccentrity^<span class=\"hs-num\">2</span><span style=\"color: red;\">)</span> / I.jupiterPerihelion^<span class=\"hs-num\">2</span>
>
> jupiterDeltaThetaP <span style=\"color: red;\">::</span> Double
> jupiterDeltaThetaP <span style=\"color: red;\">=</span> jupiterThetaDotP * I.stepTwoPlanets / <span class=\"hs-num\">2</span>
>
> jupiterVPeri <span style=\"color: red;\">::</span> Speed
> jupiterVPeri <span style=\"color: red;\">=</span> jupiterThetaDotP * I.jupiterPerihelion
>
> jupiterInitX <span style=\"color: red;\">::</span> Speed
> jupiterInitX <span style=\"color: red;\">=</span> negate $ jupiterVPeri * jupiterDeltaThetaP
>
> jupiterInitY <span style=\"color: red;\">::</span> Speed
> jupiterInitY <span style=\"color: red;\">=</span> negate $ jupiterVPeri * <span style=\"color: red;\">(</span><span class=\"hs-num\">1</span> <span style=\"color: green;\">-</span> jupiterDeltaThetaP^<span class=\"hs-num\">2</span> / <span class=\"hs-num\">2</span><span style=\"color: red;\">)</span>
>
> jupiterV <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span>Speed<span style=\"color: red;\">,</span> Speed<span style=\"color: red;\">,</span> Speed<span style=\"color: red;\">)</span>
> jupiterV <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span>jupiterInitX<span style=\"color: red;\">,</span> jupiterInitY<span style=\"color: red;\">,</span> <span class=\"hs-num\">0.0</span><span style=\"color: red;\">)</span>
>
> jupiterR <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span>Distance<span style=\"color: red;\">,</span> Distance<span style=\"color: red;\">,</span> Distance<span style=\"color: red;\">)</span>
> jupiterR <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span>negate I.jupiterPerihelion<span style=\"color: red;\">,</span> <span class=\"hs-num\">0.0</span><span style=\"color: red;\">,</span> <span class=\"hs-num\">0.0</span><span style=\"color: red;\">)</span>
</code></pre>
<p>We can do the same for Earth but we assume the earth is at its perihelion on the opposite side of the Sun to Jupiter.</p>
<pre><code>> nEarth <span style=\"color: red;\">::</span> Double
> nEarth <span style=\"color: red;\">=</span> sqrt $ I.gConst * I.sunMass / I.earthMajRad^<span class=\"hs-num\">3</span>
>
> earthThetaDotP <span style=\"color: red;\">::</span> Double
> earthThetaDotP <span style=\"color: red;\">=</span> nEarth *
>                  I.earthMajRad^<span class=\"hs-num\">2</span> *
>                  sqrt <span style=\"color: red;\">(</span><span class=\"hs-num\">1</span> <span style=\"color: green;\">-</span> I.earthEccentrity^<span class=\"hs-num\">2</span><span style=\"color: red;\">)</span> / I.earthPerihelion^<span class=\"hs-num\">2</span>
>
> earthDeltaThetaP <span style=\"color: red;\">::</span> Double
> earthDeltaThetaP <span style=\"color: red;\">=</span> earthThetaDotP * I.stepTwoPlanets / <span class=\"hs-num\">2</span>
>
> earthVPeri <span style=\"color: red;\">::</span> Speed
> earthVPeri <span style=\"color: red;\">=</span> earthThetaDotP * I.earthPerihelion
>
> earthInitX <span style=\"color: red;\">::</span> Speed
> earthInitX <span style=\"color: red;\">=</span> earthVPeri * earthDeltaThetaP
>
> earthInitY <span style=\"color: red;\">::</span> Speed
> earthInitY <span style=\"color: red;\">=</span> earthVPeri * <span style=\"color: red;\">(</span><span class=\"hs-num\">1</span> <span style=\"color: green;\">-</span> earthDeltaThetaP^<span class=\"hs-num\">2</span> / <span class=\"hs-num\">2</span><span style=\"color: red;\">)</span>
>
> earthV <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span>Speed<span style=\"color: red;\">,</span> Speed<span style=\"color: red;\">,</span> Speed<span style=\"color: red;\">)</span>
> earthV <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span>earthInitX<span style=\"color: red;\">,</span> earthInitY<span style=\"color: red;\">,</span> <span class=\"hs-num\">0.0</span><span style=\"color: red;\">)</span>
>
> earthR <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span>Distance<span style=\"color: red;\">,</span> Distance<span style=\"color: red;\">,</span> Distance<span style=\"color: red;\">)</span>
> earthR <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span>I.earthPerihelion<span style=\"color: red;\">,</span> <span class=\"hs-num\">0.0</span><span style=\"color: red;\">,</span> <span class=\"hs-num\">0.0</span><span style=\"color: red;\">)</span>
</code></pre>
<p>For completeness we give the Sun’s starting conditions.</p>
<pre><code>> sunV <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span>Speed<span style=\"color: red;\">,</span> Speed<span style=\"color: red;\">,</span> Speed<span style=\"color: red;\">)</span>
> sunV <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span><span class=\"hs-num\">0.0</span><span style=\"color: red;\">,</span> <span class=\"hs-num\">0.0</span><span style=\"color: red;\">,</span> <span class=\"hs-num\">0.0</span><span style=\"color: red;\">)</span>
>
> sunR <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span>Distance<span style=\"color: red;\">,</span> Distance<span style=\"color: red;\">,</span> Distance<span style=\"color: red;\">)</span>
> sunR <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span><span class=\"hs-num\">0.0</span><span style=\"color: red;\">,</span> <span class=\"hs-num\">0.0</span><span style=\"color: red;\">,</span> <span class=\"hs-num\">0.0</span><span style=\"color: red;\">)</span>
</code>
<code>> initVs <span style=\"color: red;\">::</span> Array U DIM2 Speed
> initVs <span style=\"color: red;\">=</span> fromListUnboxed <span style=\"color: red;\">(</span>Z :. nBodies :. I.spaceDim<span style=\"color: red;\">)</span> $ concat xs
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     nBodies <span style=\"color: red;\">=</span> length xs
>     xs <span style=\"color: red;\">=</span> <span style=\"color: red;\">[</span> <span style=\"color: red;\">[</span>earthX<span style=\"color: red;\">,</span>   earthY<span style=\"color: red;\">,</span>   earthZ<span style=\"color: red;\">]</span>
>          <span style=\"color: red;\">,</span> <span style=\"color: red;\">[</span>jupiterX<span style=\"color: red;\">,</span> jupiterY<span style=\"color: red;\">,</span> jupiterZ<span style=\"color: red;\">]</span>
>          <span style=\"color: red;\">,</span> <span style=\"color: red;\">[</span>sunX<span style=\"color: red;\">,</span>     sunY<span style=\"color: red;\">,</span>     sunZ<span style=\"color: red;\">]</span>
>          <span style=\"color: red;\">]</span>
>     <span style=\"color: red;\">(</span>earthX<span style=\"color: red;\">,</span>   earthY<span style=\"color: red;\">,</span>   earthZ<span style=\"color: red;\">)</span>   <span style=\"color: red;\">=</span> earthV
>     <span style=\"color: red;\">(</span>jupiterX<span style=\"color: red;\">,</span> jupiterY<span style=\"color: red;\">,</span> jupiterZ<span style=\"color: red;\">)</span> <span style=\"color: red;\">=</span> jupiterV
>     <span style=\"color: red;\">(</span>sunX<span style=\"color: red;\">,</span>     sunY<span style=\"color: red;\">,</span>     sunZ<span style=\"color: red;\">)</span>     <span style=\"color: red;\">=</span> sunV
</code>
<code>> initPs <span style=\"color: red;\">::</span> MomentaP U
> initPs <span style=\"color: red;\">=</span> PP $ runIdentity $ computeP $ ms2 *^ initVs
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     <span style=\"color: red;\">(</span>Z :. <span class=\"hs-sel\">_i</span> :. j<span style=\"color: red;\">)</span> <span style=\"color: red;\">=</span> extent initVs
>     ms2 <span style=\"color: red;\">=</span> extend <span style=\"color: red;\">(</span>Any :. j<span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>massP masses<span style=\"color: red;\">)</span>
</code>
<code>> initQs <span style=\"color: red;\">::</span> PositionP U
> initQs <span style=\"color: red;\">=</span> QP $ fromListUnboxed <span style=\"color: red;\">(</span>Z :. nBodies :. I.spaceDim<span style=\"color: red;\">)</span> $ concat xs
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     nBodies <span style=\"color: red;\">=</span> length xs
>     xs <span style=\"color: red;\">=</span> <span style=\"color: red;\">[</span> <span style=\"color: red;\">[</span>earthX<span style=\"color: red;\">,</span>   earthY<span style=\"color: red;\">,</span>   earthZ<span style=\"color: red;\">]</span>
>          <span style=\"color: red;\">,</span> <span style=\"color: red;\">[</span>jupiterX<span style=\"color: red;\">,</span> jupiterY<span style=\"color: red;\">,</span> jupiterZ<span style=\"color: red;\">]</span>
>          <span style=\"color: red;\">,</span> <span style=\"color: red;\">[</span>sunX<span style=\"color: red;\">,</span>     sunY<span style=\"color: red;\">,</span>     sunZ<span style=\"color: red;\">]</span>
>          <span style=\"color: red;\">]</span>
>     <span style=\"color: red;\">(</span>earthX<span style=\"color: red;\">,</span>   earthY<span style=\"color: red;\">,</span>   earthZ<span style=\"color: red;\">)</span>   <span style=\"color: red;\">=</span> earthR
>     <span style=\"color: red;\">(</span>jupiterX<span style=\"color: red;\">,</span> jupiterY<span style=\"color: red;\">,</span> jupiterZ<span style=\"color: red;\">)</span> <span style=\"color: red;\">=</span> jupiterR
>     <span style=\"color: red;\">(</span>sunX<span style=\"color: red;\">,</span>     sunY<span style=\"color: red;\">,</span>     sunZ<span style=\"color: red;\">)</span>     <span style=\"color: red;\">=</span> sunR
</code>
<code>> masses <span style=\"color: red;\">::</span> MassP U
> masses <span style=\"color: red;\">=</span> MP $ fromListUnboxed <span style=\"color: red;\">(</span>Z :. nBodies<span style=\"color: red;\">)</span> I.massesTwoPlanets
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     nBodies <span style=\"color: red;\">=</span> length I.massesTwoPlanets
</code>
<code>> jupiterEarth <span style=\"color: red;\">::</span> <span style=\"color: red;\">[</span><span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> Double<span style=\"color: red;\">)</span><span style=\"color: red;\">,</span>
>                   <span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> Double<span style=\"color: red;\">)</span><span style=\"color: red;\">,</span>
>                   <span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> Double<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span><span style=\"color: red;\">]</span>
> jupiterEarth <span style=\"color: red;\">=</span> runIdentity $ <span style=\"color: blue; font-weight: bold;\">do</span>
>   rsVs <span style=\"color: red;\"><-</span> stepNs I.nStepsTwoPlanets I.gConst I.stepTwoPlanets
>                  masses initQs initPs
>   <span style=\"color: blue; font-weight: bold;\">let</span> qs <span style=\"color: red;\">=</span> Prelude.map fst rsVs
>       exs <span style=\"color: red;\">=</span> Prelude.map <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>!<span style=\"color: red;\">(</span>Z :. <span style=\"color: red;\">(</span><span class=\"hs-num\">0</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span> :. <span style=\"color: red;\">(</span><span class=\"hs-num\">0</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> .
>                          positionP<span style=\"color: red;\">)</span> qs
>       eys <span style=\"color: red;\">=</span> Prelude.map <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>!<span style=\"color: red;\">(</span>Z :. <span style=\"color: red;\">(</span><span class=\"hs-num\">0</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span> :. <span style=\"color: red;\">(</span><span class=\"hs-num\">1</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> .
>                          positionP<span style=\"color: red;\">)</span> qs
>       jxs <span style=\"color: red;\">=</span> Prelude.map <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>!<span style=\"color: red;\">(</span>Z :. <span style=\"color: red;\">(</span><span class=\"hs-num\">1</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span> :. <span style=\"color: red;\">(</span><span class=\"hs-num\">0</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> .
>                          positionP<span style=\"color: red;\">)</span> qs
>       jys <span style=\"color: red;\">=</span> Prelude.map <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>!<span style=\"color: red;\">(</span>Z :. <span style=\"color: red;\">(</span><span class=\"hs-num\">1</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span> :. <span style=\"color: red;\">(</span><span class=\"hs-num\">1</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> .
>                          positionP<span style=\"color: red;\">)</span> qs
>       sxs <span style=\"color: red;\">=</span> Prelude.map <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>!<span style=\"color: red;\">(</span>Z :. <span style=\"color: red;\">(</span><span class=\"hs-num\">2</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span> :. <span style=\"color: red;\">(</span><span class=\"hs-num\">0</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> .
>                          positionP<span style=\"color: red;\">)</span> qs
>       sys <span style=\"color: red;\">=</span> Prelude.map <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>!<span style=\"color: red;\">(</span>Z :. <span style=\"color: red;\">(</span><span class=\"hs-num\">2</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span> :. <span style=\"color: red;\">(</span><span class=\"hs-num\">1</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> .
>                          positionP<span style=\"color: red;\">)</span> qs
>   return $ zip3 <span style=\"color: red;\">(</span>zip exs eys<span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>zip jxs jys<span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>zip sxs sys<span style=\"color: red;\">)</span>
</code></pre>
<p>Plotting the results we can see a reasonable picture for Jupiter’s and Earth’s orbits.</p>
<div style=\"text-align: center;\">
<p><img src=\"http://idontgetoutmuch.files.wordpress.com/2013/08/bff53ea397264e7102dcbfea33be1e22.png?w=450\" alt=\"\" /></p>
</div>
<h3 id=\"appendix-b-the-canonical-symplectic-form-for-the-cotangent-bundle\">Appendix B: The Canonical Symplectic Form for the Cotangent Bundle</h3>
<p>There are plenty of symplectic manifolds besides <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5E%7B2n%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathbb{R}^{2n}\" class=\"latex\" title=\"\\mathbb{R}^{2n}\" />. The cotangent bundle has a canonical symplectic 2-form and hence is a symplectic manifold.</p>
<p><em>Proof</em></p>
<p>Let <img src=\"http://s0.wp.com/latex.php?latex=%5Cpi+%3A+T%5E%2A+M+%5Clongrightarrow+M&bg=ffffff&fg=333333&s=0\" alt=\"\\pi : T^* M \\longrightarrow M\" class=\"latex\" title=\"\\pi : T^* M \\longrightarrow M\" /> be the projection function from the cotangent bundle to the base manifold, that is, <img src=\"http://s0.wp.com/latex.php?latex=%5Cpi%28x%2C%5Cxi%29+%3D+x&bg=ffffff&fg=333333&s=0\" alt=\"\\pi(x,\\xi) = x\" class=\"latex\" title=\"\\pi(x,\\xi) = x\" />. Then <img src=\"http://s0.wp.com/latex.php?latex=%5Cpi_%2A+%3A+T%28T%5E%2AM%29+%5Clongrightarrow+TM&bg=ffffff&fg=333333&s=0\" alt=\"\\pi_* : T(T^*M) \\longrightarrow TM\" class=\"latex\" title=\"\\pi_* : T(T^*M) \\longrightarrow TM\" /> and we can define a 1-form (the canonical or tautological 1-form) on <img src=\"http://s0.wp.com/latex.php?latex=v+%5Cin+T_%7B%28x%2C%5Cxi%29%7D%28T%5E%2A+M%29&bg=ffffff&fg=333333&s=0\" alt=\"v \\in T_{(x,\\xi)}(T^* M)\" class=\"latex\" title=\"v \\in T_{(x,\\xi)}(T^* M)\" /> as</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctheta_%7B%28x%2C%5Cxi%29%7D+%28v%29+%3D+%5Cxi%28%5Cpi_%2A+v%29++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\theta_{(x,\\xi)} (v) = \\xi(\\pi_* v)  \" class=\"latex\" title=\"\\displaystyle  \\theta_{(x,\\xi)} (v) = \\xi(\\pi_* v)  \" /></div>
<p>By definition:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpi_%2A+%5Cbigg%28%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+x_i%7D%5Cbigg%29%28f%29+%3D+%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+x_i%7D%28f+%5Ccirc+%5Cpi%29+%3D+%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+x_i%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\pi_* \\bigg(\\frac{\\partial}{\\partial x_i}\\bigg)(f) = \\frac{\\partial}{\\partial x_i}(f \\circ \\pi) = \\frac{\\partial f}{\\partial x_i}  \" class=\"latex\" title=\"\\displaystyle  \\pi_* \\bigg(\\frac{\\partial}{\\partial x_i}\\bigg)(f) = \\frac{\\partial}{\\partial x_i}(f \\circ \\pi) = \\frac{\\partial f}{\\partial x_i}  \" /></div>
<p>and</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpi_%2A+%5Cbigg%28%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+%5Cxi_i%7D%5Cbigg%29%28f%29+%3D+%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+%5Cxi_i%7D%28f+%5Ccirc+%5Cpi%29+%3D+0++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\pi_* \\bigg(\\frac{\\partial}{\\partial \\xi_i}\\bigg)(f) = \\frac{\\partial}{\\partial \\xi_i}(f \\circ \\pi) = 0  \" class=\"latex\" title=\"\\displaystyle  \\pi_* \\bigg(\\frac{\\partial}{\\partial \\xi_i}\\bigg)(f) = \\frac{\\partial}{\\partial \\xi_i}(f \\circ \\pi) = 0  \" /></div>
<p>If we then write <img src=\"http://s0.wp.com/latex.php?latex=v+%5Cin+T_%7B%28x%2C%5Cxi%29%7D%28T%5E%2AM%29&bg=ffffff&fg=333333&s=0\" alt=\"v \\in T_{(x,\\xi)}(T^*M)\" class=\"latex\" title=\"v \\in T_{(x,\\xi)}(T^*M)\" /> in co-ordinate form:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++v+%3D+a%5Ei%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+x_i%7D+%2B+%5Calpha%5Ei%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+%5Cxi_i%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  v = a^i\\frac{\\partial}{\\partial x_i} + \\alpha^i\\frac{\\partial}{\\partial \\xi_i}  \" class=\"latex\" title=\"\\displaystyle  v = a^i\\frac{\\partial}{\\partial x_i} + \\alpha^i\\frac{\\partial}{\\partial \\xi_i}  \" /></div>
<p>we have</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpi_%2Av+%3D+a%5Ei%5Cpi_%2A%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+x_i%7D+%2B+%5Calpha%5Ei%5Cpi_%2A%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+%5Cxi_i%7D+%3D+a%5Ei%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+x_i%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\pi_*v = a^i\\pi_*\\frac{\\partial}{\\partial x_i} + \\alpha^i\\pi_*\\frac{\\partial}{\\partial \\xi_i} = a^i\\frac{\\partial}{\\partial x_i}  \" class=\"latex\" title=\"\\displaystyle  \\pi_*v = a^i\\pi_*\\frac{\\partial}{\\partial x_i} + \\alpha^i\\pi_*\\frac{\\partial}{\\partial \\xi_i} = a^i\\frac{\\partial}{\\partial x_i}  \" /></div>
<p>Taking <img src=\"http://s0.wp.com/latex.php?latex=%5Cxi+%3D+%5Cxi_i+dx%5Ei&bg=ffffff&fg=333333&s=0\" alt=\"\\xi = \\xi_i dx^i\" class=\"latex\" title=\"\\xi = \\xi_i dx^i\" /> we have that</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cxi%28%5Cpi_%2Av%29+%3D+%5Cxi_i+a%5Ei++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\xi(\\pi_*v) = \\xi_i a^i  \" class=\"latex\" title=\"\\displaystyle  \\xi(\\pi_*v) = \\xi_i a^i  \" /></div>
<p>Thus we have:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctheta_%7B%28x%2C%5Cxi%29%7D+%3D+%5Cxi_i+dx%5Ei++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\theta_{(x,\\xi)} = \\xi_i dx^i  \" class=\"latex\" title=\"\\displaystyle  \\theta_{(x,\\xi)} = \\xi_i dx^i  \" /></div>
<p>We then have a closed 2-form</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Comega+%3D+d%5Ctheta++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\omega = d\\theta  \" class=\"latex\" title=\"\\displaystyle  \\omega = d\\theta  \" /></div>
<p>In co-ordinate terms:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Comega+%3D+d%5Ctheta+%3D+d+%28%5Cxi_i+dx%5Ei%29+%3D+d%5Cxi%5Ei+%5Cwedge+dx%5Ei++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\omega = d\\theta = d (\\xi_i dx^i) = d\\xi^i \\wedge dx^i  \" class=\"latex\" title=\"\\displaystyle  \\omega = d\\theta = d (\\xi_i dx^i) = d\\xi^i \\wedge dx^i  \" /></div>
<h3 id=\"bibliography\">Bibliography</h3>
<p>Cross, Matthew I. 2006. <em>Symplectic integrators and optimal control</em>. UK.</p>
<p>Fitzpatrick, Richard. 1996. “Newtonian Dynamics.” <a href=\"http://farside.ph.utexas.edu/teaching/336k/lectures\" title=\"http://farside.ph.utexas.edu/teaching/336k/lectures\">http://farside.ph.utexas.edu/teaching/336k/lectures</a>.</p>
<p>Hairer, E., C. Lubich, and G. Wanner. 2010. <em>Geometric Numerical Integration: Structure-Preserving Algorithms for Ordinary Differential Equations</em>. <em>Springer Series in Computational Mathematics</em>. Springer. <a href=\"http://books.google.co.uk/books?id=ssrFQQAACAAJ\" title=\"http://books.google.co.uk/books?id=ssrFQQAACAAJ\">http://books.google.co.uk/books?id=ssrFQQAACAAJ</a>.</p>
<p>Hudak, Paul, John Hughes, Simon Peyton Jones, and Philip Wadler. 2007. “A history of Haskell: being lazy with class.” In <em>Proceedings of the third ACM SIGPLAN conference on History of programming languages</em>, 12–1. New York, NY, USA: ACM. <a href=\"http://doi.acm.org/10.1145/1238844.1238856\" title=\"http://doi.acm.org/10.1145/1238844.1238856\">http://doi.acm.org/10.1145/1238844.1238856</a>.</p>
<p>O’Neill, B. 1983. <em>Semi-Riemannian Geometry With Applications to Relativity, 103</em>. <em>Pure and Applied Mathematics</em>. Elsevier Science. <a href=\"http://books.google.co.uk/books?id=CGk1eRSjFIIC\" title=\"http://books.google.co.uk/books?id=CGk1eRSjFIIC\">http://books.google.co.uk/books?id=CGk1eRSjFIIC</a>.</p>
<p>Yoshida, H. 1992. “Symplectic Integrators for Hamiltonian Systems: Basic Theory.” In <em>Chaos, Resonance, and Collective Dynamical Phenomena in the Solar System</em>, ed. S. Ferraz-Mello, 152:407.</p>
<br />  <a href=\"http://feeds.wordpress.com/1.0/gocomments/idontgetoutmuch.wordpress.com/509/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/idontgetoutmuch.wordpress.com/509/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=idontgetoutmuch.wordpress.com&blog=2944309&post=509&subd=idontgetoutmuch&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "3f27e9c80003551df006c2bb916cbf45") (363 (21000 35661 396126) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_7163\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_9958\"></span> time, whereas using the categorical functor takes time <span id=\"tex_5807\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_2439\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "e910b557791c21bf81622ba54d51df74") (362 (20996 43058 384086) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_6887\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_4835\"></span> time, whereas using the categorical functor takes time <span id=\"tex_8376\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_6247\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "9b236ce0304a3733a594d1381cec536b") (361 (20995 35250 763894) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_971\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_1233\"></span> time, whereas using the categorical functor takes time <span id=\"tex_8620\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_1707\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "7494c0d39e286f1bdfba8ded68148d69") (360 (20995 23176 305084) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_8530\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_8033\"></span> time, whereas using the categorical functor takes time <span id=\"tex_120\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_3462\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "3f334c4b874728feee393760b621e060") (359 (20995 20657 879863) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_7174\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_173\"></span> time, whereas using the categorical functor takes time <span id=\"tex_4738\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_7356\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "eb23482e4cedb28e9d1ccac5b2923067") (358 (20994 35011 918199) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_8861\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_9837\"></span> time, whereas using the categorical functor takes time <span id=\"tex_6503\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_4629\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "93f1678583722c6c11362e066cc19480") (357 (20994 23747 697090) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_3276\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_4295\"></span> time, whereas using the categorical functor takes time <span id=\"tex_7356\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_8458\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "d6526cedd66736ea4efb58fbd5ea989b") (356 (20994 18452 252111) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_4393\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_5804\"></span> time, whereas using the categorical functor takes time <span id=\"tex_9991\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_1547\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "f978e9bb3c34ff1baec78f516dc124f6") (355 (20994 12612 624432) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_7972\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_7188\"></span> time, whereas using the categorical functor takes time <span id=\"tex_4706\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_6494\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "4f91b5869e33e2a0d5151e7af793e99b") (354 (20994 11135 67952) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_8409\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_5461\"></span> time, whereas using the categorical functor takes time <span id=\"tex_7586\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_235\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "427a5586291cecd13d4b417822d051bb") (353 (20994 4128 102382) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_3019\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_2970\"></span> time, whereas using the categorical functor takes time <span id=\"tex_5866\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_3785\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "59b3e47c64ac6b379a8b9601748fafbe") (352 (20993 65524 925874) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_8112\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_9665\"></span> time, whereas using the categorical functor takes time <span id=\"tex_3384\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_6774\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "921904819d370fc532d3accab55cbebf") (351 (20993 9392 581348) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_1396\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_3071\"></span> time, whereas using the categorical functor takes time <span id=\"tex_6505\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_5027\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "63959ad7bbbcdd66b19b6dcfff1f325f") (350 (20993 4255 795919) "http://idontgetoutmuch.wordpress.com/2013/08/06/planetary-simulation-with-excursions-in-symplectic-manifolds-6/" "Dominic Steinitz: Planetary Simulation with Excursions in Symplectic Manifolds" nil "Tue, 06 Aug 2013 13:22:45 +0000" "<p>This article attempts to show that Haskell [@Hudak:2007:HHL:1238844.1238856] performs reasonably well on numerical problems.</p>
<p>When I started to do this, it seemed straightforward enough: pick a problem which admitted a numerical solution, find an algorithm and code it up. I chose the problem of orbital dynamics as I had always been fascinated by the precession of the perihelion of Mercury (which is mainly caused by the pull of the other planets in the Solar System) and because this admits of at least two different methods of numerical solution both of which I hope will show the power of Haskell in this area. This led to the selection of a suitable algorithm and I read that one should prefer a symplectic method such as the Leapfrog which conserves the energy of a system (a highly desirable requirement when modelling orbital dynamics). My conscience would not let me write about such a method without being able to explain it. This led into the Hamiltonian formulation of classical mechanics, symplectic manifolds and symplectic (numerical) methods.</p>
<p>The reader interested in the Haskell implementations and performance comparisons (currently <em>not</em> with other programming languages) can read the <a href=\"http://idontgetoutmuch.wordpress.com/feed/#Introduction\">introduction</a> and skip to the section on <a href=\"http://idontgetoutmuch.wordpress.com/feed/#Performance\">performance</a>. I apologise in advance to experts in classical mechanics, symplectic geometery and numerical analysis and can only hope I have not traduced their subjects too much.</p>
<p>Note that we do not make it as far the perihelion of Mercury in this article but we do simulate the planets in the outer solar system.</p>
<h2 id=\"introduction\">Introduction</h2>
<p>Forget about Newton and suppose you are told that the way to do mechanics is to write down the total energy of the system in which you are interested and then apply Hamilton’s equations.</p>
<p>Consider a mass of <img src=\"http://s0.wp.com/latex.php?latex=m&bg=ffffff&fg=333333&s=0\" alt=\"m\" class=\"latex\" title=\"m\" /> attached to a light rod of length <img src=\"http://s0.wp.com/latex.php?latex=l&bg=ffffff&fg=333333&s=0\" alt=\"l\" class=\"latex\" title=\"l\" /> which is attached to a point from which it can swing freely in a plane. Then the kinetic energy is:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B1%7D%7B2%7Dmv%5E2+%3D+%5Cfrac%7B1%7D%7B2%7Dml%5E2%5Cdot%7B%5Ctheta%7D%5E2++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\frac{1}{2}mv^2 = \\frac{1}{2}ml^2\\dot{\\theta}^2  \" class=\"latex\" title=\"\\displaystyle  \\frac{1}{2}mv^2 = \\frac{1}{2}ml^2\\dot{\\theta}^2  \" /></div>
<p>and the potential energy (taking this to be 0 at <img src=\"http://s0.wp.com/latex.php?latex=%5Ctheta+%3D+0&bg=ffffff&fg=333333&s=0\" alt=\"\\theta = 0\" class=\"latex\" title=\"\\theta = 0\" />) is:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++mgl%281+-+%5Ccos%5Ctheta%29++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  mgl(1 - \\cos\\theta)  \" class=\"latex\" title=\"\\displaystyle  mgl(1 - \\cos\\theta)  \" /></div>
<p>Thus the Hamiltonian is:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathbb%7BH%7D+%3D+%5Cfrac%7B1%7D%7B2%7Dml%5E2%5Cdot%7B%5Ctheta%7D%5E2+%2B+mgl%281+-+%5Ccos%5Ctheta%29++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\mathbb{H} = \\frac{1}{2}ml^2\\dot{\\theta}^2 + mgl(1 - \\cos\\theta)  \" class=\"latex\" title=\"\\displaystyle  \\mathbb{H} = \\frac{1}{2}ml^2\\dot{\\theta}^2 + mgl(1 - \\cos\\theta)  \" /></div>
<p>Using the Langrangian <img src=\"http://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BL%7D%7D+%3D+T+-+V&bg=ffffff&fg=333333&s=0\" alt=\"{\\mathbb{L}} = T - V\" class=\"latex\" title=\"{\\mathbb{L}} = T - V\" /> where <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" /> and <img src=\"http://s0.wp.com/latex.php?latex=V&bg=ffffff&fg=333333&s=0\" alt=\"V\" class=\"latex\" title=\"V\" /> are the kinetic and potential energies respectively, let us set the generalized momentum</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++p+%3D+%5Cfrac%7B%5Cpartial%5Cmathbb%7BL%7D%7D%7B%5Cpartial%5Cdot%7B%5Ctheta%7D%7D+%3D+ml%5E2%5Cdot%7B%5Ctheta%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  p = \\frac{\\partial\\mathbb{L}}{\\partial\\dot{\\theta}} = ml^2\\dot{\\theta}  \" class=\"latex\" title=\"\\displaystyle  p = \\frac{\\partial\\mathbb{L}}{\\partial\\dot{\\theta}} = ml^2\\dot{\\theta}  \" /></div>
<p>Then we can re-write the Hamiltonian as:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathbb%7BH%7D+%3D+%5Cfrac%7Bp%5E2%7D%7B2ml%5E2%7D+%2B+mgl%281+-+%5Ccos%5Ctheta%29++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\mathbb{H} = \\frac{p^2}{2ml^2} + mgl(1 - \\cos\\theta)  \" class=\"latex\" title=\"\\displaystyle  \\mathbb{H} = \\frac{p^2}{2ml^2} + mgl(1 - \\cos\\theta)  \" /></div>
<p>Applying Hamilton’s equations we obtain</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++%5Cdot%7B%5Ctheta%7D+%26%3D+%5Cfrac%7B%5Cpartial%5Cmathbb%7BH%7D%7D%7B%5Cpartial+p%7D+%3D+%5Cfrac%7Bp%7D%7Bml%5E2%7D+%5C%5C++%5Cdot%7Bp%7D+%26%3D+-%5Cfrac%7B%5Cpartial%5Cmathbb%7BH%7D%7D%7B%5Cpartial+%5Ctheta%7D+%3D+-mgl%5Csin%5Ctheta++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  \\dot{\\theta} &= \\frac{\\partial\\mathbb{H}}{\\partial p} = \\frac{p}{ml^2} \\\\  \\dot{p} &= -\\frac{\\partial\\mathbb{H}}{\\partial \\theta} = -mgl\\sin\\theta  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  \\dot{\\theta} &= \\frac{\\partial\\mathbb{H}}{\\partial p} = \\frac{p}{ml^2} \\\\  \\dot{p} &= -\\frac{\\partial\\mathbb{H}}{\\partial \\theta} = -mgl\\sin\\theta  \\end{aligned}  \" /></div>
<p>Differentiating the first equation with respect to time we then obtain the familiar equation describing the motion of a simple pendulum.</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cddot%7B%5Ctheta%7D+%3D+%5Cfrac%7B%5Cdot%7Bp%7D%7D%7Bml%5E2%7D+%3D+%5Cfrac%7B-mgl%5Csin%5Ctheta%7D%7Bml%5E2%7D+%3D+-%5Cfrac%7Bg%7D%7Bl%7D%5Csin%5Ctheta++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\ddot{\\theta} = \\frac{\\dot{p}}{ml^2} = \\frac{-mgl\\sin\\theta}{ml^2} = -\\frac{g}{l}\\sin\\theta  \" class=\"latex\" title=\"\\displaystyle  \\ddot{\\theta} = \\frac{\\dot{p}}{ml^2} = \\frac{-mgl\\sin\\theta}{ml^2} = -\\frac{g}{l}\\sin\\theta  \" /></div>
<p>Now we would like to calculate the pendulum’s position and velocity at a given time. The obvious starting place is to use the explicit Euler method.</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++%5Ctheta_%7Bn%2B1%7D+%26%3D+h%5Cfrac%7Bp_n%7D%7Bml%5E2%7D+%5C%5C++p_%7Bn%2B1%7D+%26%3D+-hmgl%5Csin%5Ctheta_n++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  \\theta_{n+1} &= h\\frac{p_n}{ml^2} \\\\  p_{n+1} &= -hmgl\\sin\\theta_n  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  \\theta_{n+1} &= h\\frac{p_n}{ml^2} \\\\  p_{n+1} &= -hmgl\\sin\\theta_n  \\end{aligned}  \" /></div>
<h3 id=\"haskell-for-explicit-euler\">Haskell for Explicit Euler</h3>
<p>First we need some pragmas, exports (required to create the diagrams) and imports.</p>
<pre><code>> <span style=\"color: green;\">{-# OPTIONS_GHC -Wall                     #-}</span>
> <span style=\"color: green;\">{-# OPTIONS_GHC -fno-warn-name-shadowing  #-}</span>
> <span style=\"color: green;\">{-# OPTIONS_GHC -fno-warn-type-defaults   #-}</span>
</code>
<code>> <span style=\"color: green;\">{-# LANGUAGE NoMonomorphismRestriction    #-}</span>
> <span style=\"color: green;\">{-# LANGUAGE FlexibleContexts             #-}</span>
> <span style=\"color: green;\">{-# LANGUAGE ScopedTypeVariables          #-}</span>
> <span style=\"color: green;\">{-# LANGUAGE GeneralizedNewtypeDeriving   #-}</span>
> <span style=\"color: green;\">{-# LANGUAGE TypeOperators                #-}</span>
</code>
<code>> <span style=\"color: blue; font-weight: bold;\">module</span> Symplectic <span style=\"color: red;\">(</span>
>     pendulumEE
>   <span style=\"color: red;\">,</span> pendulumSE
>   <span style=\"color: red;\">,</span> jupiterEarth
>   <span style=\"color: red;\">,</span> outerPlanets
>   <span style=\"color: red;\">,</span> main
>   <span style=\"color: red;\">)</span> <span style=\"color: blue; font-weight: bold;\">where</span>
</code>
<code>> <span style=\"color: blue; font-weight: bold;\">import</span>           Data.Array.Repa hiding <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>++<span style=\"color: red;\">)</span><span style=\"color: red;\">,</span> zipWith<span style=\"color: red;\">)</span>
> <span style=\"color: blue; font-weight: bold;\">import</span> <span style=\"color: blue; font-weight: bold;\">qualified</span> Data.Array.Repa <span style=\"color: blue; font-weight: bold;\">as</span> Repa
</code>
<code>> <span style=\"color: blue; font-weight: bold;\">import</span>           Control.Monad
> <span style=\"color: blue; font-weight: bold;\">import</span>           Control.Monad.Identity
> <span style=\"color: blue; font-weight: bold;\">import</span>           System.Environment
> <span style=\"color: blue; font-weight: bold;\">import</span>           System.Console.GetOpt
</code>
<code>> <span style=\"color: blue; font-weight: bold;\">import</span>           Foreign.Storable
</code>
<code>> <span style=\"color: blue; font-weight: bold;\">import</span> <span style=\"color: blue; font-weight: bold;\">qualified</span> Data.Yarr <span style=\"color: blue; font-weight: bold;\">as</span> Y
> <span style=\"color: blue; font-weight: bold;\">import</span>           Data.Yarr <span style=\"color: red;\">(</span>loadS<span style=\"color: red;\">,</span> dzip2<span style=\"color: red;\">,</span> dzip3<span style=\"color: red;\">,</span> F<span style=\"color: red;\">,</span> L<span style=\"color: red;\">)</span>
> <span style=\"color: blue; font-weight: bold;\">import</span>           Data.Yarr.Repr.Delayed <span style=\"color: red;\">(</span>UArray<span style=\"color: red;\">)</span>
> <span style=\"color: blue; font-weight: bold;\">import</span> <span style=\"color: blue; font-weight: bold;\">qualified</span> Data.Yarr.Shape <span style=\"color: blue; font-weight: bold;\">as</span> S
> <span style=\"color: blue; font-weight: bold;\">import</span> <span style=\"color: blue; font-weight: bold;\">qualified</span> Data.Yarr.Utils.FixedVector <span style=\"color: blue; font-weight: bold;\">as</span> V
> <span style=\"color: blue; font-weight: bold;\">import</span>           Data.Yarr.Utils.FixedVector <span style=\"color: red;\">(</span>VecList<span style=\"color: red;\">,</span> N3<span style=\"color: red;\">)</span>
> <span style=\"color: blue; font-weight: bold;\">import</span> <span style=\"color: blue; font-weight: bold;\">qualified</span> Data.Yarr.IO.List <span style=\"color: blue; font-weight: bold;\">as</span> YIO
> <span style=\"color: blue; font-weight: bold;\">import</span> <span style=\"color: blue; font-weight: bold;\">qualified</span> Data.Yarr.Walk <span style=\"color: blue; font-weight: bold;\">as</span> W
>
> <span style=\"color: blue; font-weight: bold;\">import</span> <span style=\"color: blue; font-weight: bold;\">qualified</span> Initial <span style=\"color: blue; font-weight: bold;\">as</span> I
</code></pre>
<p>Some type synomyms although it is doubtful how useful these are since the generalized co-ordinates and momenta that one uses with Hamiltonian methods can have different units depending on how the physical problem is formulated.</p>
<pre><code>> <span style=\"color: blue; font-weight: bold;\">type</span> Distance <span style=\"color: red;\">=</span> Double
> <span style=\"color: blue; font-weight: bold;\">type</span> Mass     <span style=\"color: red;\">=</span> Double
> <span style=\"color: blue; font-weight: bold;\">type</span> Speed    <span style=\"color: red;\">=</span> Double
</code></pre>
<p>The functions to update the position and momentum.</p>
<pre><code>> stepMomentumEE <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double
> stepMomentumEE m l p q <span style=\"color: red;\">=</span> p <span style=\"color: green;\">-</span>  h * m * g * l * sin q
</code>
<code>> stepPositionEE <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double
> stepPositionEE m l p q <span style=\"color: red;\">=</span> q + h * p / <span style=\"color: red;\">(</span>m * l^<span class=\"hs-num\">2</span><span style=\"color: red;\">)</span>
</code></pre>
<p>The explicit Euler method itself. Notice that both update functions use the previous position and momentum.</p>
<pre><code>> stepOnceEE <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> <span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> Double<span style=\"color: red;\">)</span>
> stepOnceEE m l p q <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span>newP<span style=\"color: red;\">,</span> newQ<span style=\"color: red;\">)</span>
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     newP <span style=\"color: red;\">=</span> stepMomentumEE m l p q
>     newQ <span style=\"color: red;\">=</span> stepPositionEE m l p q
</code></pre>
<p>The physical data for our problem and also the step length for the numerical method.</p>
<pre><code>> h<span style=\"color: red;\">,</span> m<span style=\"color: red;\">,</span> l<span style=\"color: red;\">,</span> g <span style=\"color: red;\">::</span> Double
> h <span style=\"color: red;\">=</span> <span class=\"hs-num\">0.01</span> <span style=\"color: green;\">-- Seconds</span>
> l <span style=\"color: red;\">=</span> <span class=\"hs-num\">1.0</span>  <span style=\"color: green;\">-- Metres</span>
> m <span style=\"color: red;\">=</span> <span class=\"hs-num\">1.0</span>  <span style=\"color: green;\">-- Kilograms</span>
> g <span style=\"color: red;\">=</span> <span class=\"hs-num\">9.81</span> <span style=\"color: green;\">-- Metres * Seconds^-2</span>
</code></pre>
<p>Let’s start our pendulum at the bottom with an angular velocity that ensures we don’t go over the top.</p>
<pre><code>> initTheta<span style=\"color: red;\">,</span> initThetaDot<span style=\"color: red;\">,</span> initP <span style=\"color: red;\">::</span> Double
> initTheta    <span style=\"color: red;\">=</span> <span class=\"hs-num\">0.0</span>
> initThetaDot <span style=\"color: red;\">=</span> <span class=\"hs-num\">1.7</span>
> initP        <span style=\"color: red;\">=</span> m * l^<span class=\"hs-num\">2</span> * initThetaDot
</code>
<code>> runEE <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> <span style=\"color: red;\">[</span><span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> Double<span style=\"color: red;\">)</span><span style=\"color: red;\">]</span>
> runEE initP initTheta <span style=\"color: red;\">=</span> iterate <span style=\"color: red;\">(</span>uncurry <span style=\"color: red;\">(</span>stepOnceEE m l<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span>
>                                 <span style=\"color: red;\">(</span>initP<span style=\"color: red;\">,</span> initTheta<span style=\"color: red;\">)</span>
</code>
<code>> pendulumEE <span style=\"color: red;\">::</span> <span style=\"color: red;\">[</span><span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> Double<span style=\"color: red;\">)</span><span style=\"color: red;\">]</span>
> pendulumEE <span style=\"color: red;\">=</span> runEE initP initTheta
</code></pre>
<p>The diagram below plots the position of the pendulum (the angle it makes with the vertical) against momentum, both axes normalised so that the maximum position and momentum are 1.0. We would expect that the trajectory would form a closed path that is traversed indefinitely as the pendulum swings back and forth. Instead we see that trajectory gradually spirals outward showing that energy is not conserved but steadily increases over time, an undesirable state of affairs.</p>
<div style=\"text-align: center;\">
<p><img src=\"http://idontgetoutmuch.files.wordpress.com/2013/08/af8a52f9970786658632beffec59bde3.png?w=450\" alt=\"\" /></p>
</div>
<h3 id=\"haskell-for-symplectic-euler\">Haskell for Symplectic Euler</h3>
<p>Instead let us apply the the symplectic Euler method:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++p_%7Bn%2B1%7D+%3D+p_n+-+hmgl%5Csin%5Ctheta_n+%5C%5C++%5Ctheta_%7Bn%2B1%7D+%3D+%5Ctheta_n+%2B+%5Cfrac%7Bhp_%7Bn%2B1%7D%7D%7B2ml%5E2%7D++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  p_{n+1} = p_n - hmgl\\sin\\theta_n \\\\  \\theta_{n+1} = \\theta_n + \\frac{hp_{n+1}}{2ml^2}  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  p_{n+1} = p_n - hmgl\\sin\\theta_n \\\\  \\theta_{n+1} = \\theta_n + \\frac{hp_{n+1}}{2ml^2}  \\end{aligned}  \" /></div>
<p>The functions to update the position and momentum.</p>
<pre><code>> stepMomentum <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double
> stepMomentum m l p q <span style=\"color: red;\">=</span> p <span style=\"color: green;\">-</span>  h * m * g * l * sin q
</code>
<code>> stepPosition <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double
> stepPosition m l p q <span style=\"color: red;\">=</span> q + h * p / <span style=\"color: red;\">(</span>m * l^<span class=\"hs-num\">2</span><span style=\"color: red;\">)</span>
</code></pre>
<p>The symplectic Euler method itself. Notice that only the update function for momentum uses both the previous position and momentum; the update function for position uses the previous position but the new momentum.</p>
<pre><code>> stepOnce <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> <span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> Double<span style=\"color: red;\">)</span>
> stepOnce m l p q <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span>newP<span style=\"color: red;\">,</span> newQ<span style=\"color: red;\">)</span>
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     newP <span style=\"color: red;\">=</span> stepMomentum m l p q
>     newQ <span style=\"color: red;\">=</span> stepPosition m l newP q
</code>
<code>> runSE <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> <span style=\"color: red;\">[</span><span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> Double<span style=\"color: red;\">)</span><span style=\"color: red;\">]</span>
> runSE initP initTheta <span style=\"color: red;\">=</span> iterate <span style=\"color: red;\">(</span>uncurry <span style=\"color: red;\">(</span>stepOnce m l<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span>
>                                 <span style=\"color: red;\">(</span>initP<span style=\"color: red;\">,</span> initTheta<span style=\"color: red;\">)</span>
</code>
<code>> pendulumSE <span style=\"color: red;\">::</span> <span style=\"color: red;\">[</span><span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> Double<span style=\"color: red;\">)</span><span style=\"color: red;\">]</span>
> pendulumSE <span style=\"color: red;\">=</span> runSE initP initTheta
</code></pre>
<p>The diagram below plots the position of the pendulum (the angle it makes with the vertical) against momentum, both axes normalised so that the maximum position and momentum are 1.0. We would expect that the trajectory would form a closed path that is traversed indefinitely as the pendulum swings back and forth. And indeed this is the case.</p>
<div style=\"text-align: center;\">
<p><img src=\"http://idontgetoutmuch.files.wordpress.com/2013/08/ed9f4120277fbdbe30ad1b8f5570b4d7.png?w=450\" alt=\"\" /></p>
</div>
<p>So in this case the energy is conserved so this looks like a good candidate for simulating orbital dynamics. But why does this work? It really looks very similar to the explicit Euler method.</p>
<h2 id=\"theory\">Theory</h2>
<p>Warning: some handwaving as a full and formal exposition of the theory would take much more space than can be contained in this blog article.</p>
<p>We can think of the evolution of the pendulum as taking place on a 2-dimensional manifold <a href=\"http://en.wikipedia.org/wiki/Manifold\" title=\"Wikipedia definition\">manifold</a> <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathbb%7BS%7D%5E1+%5Ctimes+%5Cmathbb%7BR%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathbb{S}^1 \\times \\mathbb{R}\" class=\"latex\" title=\"\\mathbb{S}^1 \\times \\mathbb{R}\" /> where <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathbb%7BS%7D%5E1&bg=ffffff&fg=333333&s=0\" alt=\"\\mathbb{S}^1\" class=\"latex\" title=\"\\mathbb{S}^1\" /> is the 1-dimensional sphere (a circle) since the pendulum’s space co-ordinate can only take on values <img src=\"http://s0.wp.com/latex.php?latex=0+%5Cle+q+%3C+2%5Cpi&bg=ffffff&fg=333333&s=0\" alt=\"0 \\le q < 2\\pi\" class=\"latex\" title=\"0 \\le q < 2\\pi\" />.</p>
<p>We can define a (<a href=\"https://en.wikipedia.org/wiki/Symplectic_manifold\" title=\"Wikipedia definition\">symplectic</a>) <a href=\"https://en.wikipedia.org/wiki/Differential_form\" title=\"Wikipedia definition\">2-form</a> on this manifold:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Comega+%3D+dq+%5Cwedge+dp++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\omega = dq \\wedge dp  \" class=\"latex\" title=\"\\displaystyle  \\omega = dq \\wedge dp  \" /></div>
<p>Using this we can now produce a vector field from the Hamiltonian: <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathbb%7BH%7D+%3A+%5Cmathbb%7BS%7D%5E1+%5Ctimes+%5Cmathbb%7BR%7D+%5Clongrightarrow+%5Cmathbb%7BR%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathbb{H} : \\mathbb{S}^1 \\times \\mathbb{R} \\longrightarrow \\mathbb{R}\" class=\"latex\" title=\"\\mathbb{H} : \\mathbb{S}^1 \\times \\mathbb{R} \\longrightarrow \\mathbb{R}\" /></p>
<p>In order to this and without proof let us record the following fact.</p>
<p><strong>Theorem</strong></p>
<p>Let <img src=\"http://s0.wp.com/latex.php?latex=%28M%2C+%5Comega%29&bg=ffffff&fg=333333&s=0\" alt=\"(M, \\omega)\" class=\"latex\" title=\"(M, \\omega)\" /> be a symplectic manifold. Then there exists a bundle isomorphism <img src=\"http://s0.wp.com/latex.php?latex=%5Ctilde%7B%5Comega%7D+%3A+TM+%5Clongrightarrow+T%5E%2AM&bg=ffffff&fg=333333&s=0\" alt=\"\\tilde{\\omega} : TM \\longrightarrow T^*M\" class=\"latex\" title=\"\\tilde{\\omega} : TM \\longrightarrow T^*M\" /> defined by <img src=\"http://s0.wp.com/latex.php?latex=%5Ctilde%7B%5Comega%7D%28X_p%29%28Y_p%29+%3D+%5Comega_p%28X_p%2C+Y_p%29&bg=ffffff&fg=333333&s=0\" alt=\"\\tilde{\\omega}(X_p)(Y_p) = \\omega_p(X_p, Y_p)\" class=\"latex\" title=\"\\tilde{\\omega}(X_p)(Y_p) = \\omega_p(X_p, Y_p)\" />.</p>
<p><img src=\"http://s0.wp.com/latex.php?latex=%5Cblacksquare&bg=ffffff&fg=333333&s=0\" alt=\"\\blacksquare\" class=\"latex\" title=\"\\blacksquare\" /></p>
<p>This is analagous to the isomorphism one can derive in a (semi) Riemannian manifold with the metric in some sense playing the role of the 2-form (see [@o1983semi] for example).</p>
<p>We assume the Hamiltonian to be a smooth function. We can form the 1-form <img src=\"http://s0.wp.com/latex.php?latex=dH&bg=ffffff&fg=333333&s=0\" alt=\"dH\" class=\"latex\" title=\"dH\" /> and we can define the Hamiltonian vector field <img src=\"http://s0.wp.com/latex.php?latex=X_H+%3D+%5Ctilde%7B%5Comega%7D%5E%7B-1%7D%28dH%29&bg=ffffff&fg=333333&s=0\" alt=\"X_H = \\tilde{\\omega}^{-1}(dH)\" class=\"latex\" title=\"X_H = \\tilde{\\omega}^{-1}(dH)\" />.</p>
<p>We have</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++d%5Cmathbb%7BH%7D+%3D+%5Cfrac%7B%5Cpartial%7B%5Cmathbb%7BH%7D%7D%7D%7B%5Cpartial+q%7Ddq+%2B++%5Cfrac%7B%5Cpartial%7B%5Cmathbb%7BH%7D%7D%7D%7B%5Cpartial+p%7Ddp++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  d\\mathbb{H} = \\frac{\\partial{\\mathbb{H}}}{\\partial q}dq +  \\frac{\\partial{\\mathbb{H}}}{\\partial p}dp  \" class=\"latex\" title=\"\\displaystyle  d\\mathbb{H} = \\frac{\\partial{\\mathbb{H}}}{\\partial q}dq +  \\frac{\\partial{\\mathbb{H}}}{\\partial p}dp  \" /></div>
<p>Thus the corresponding vector field is given by</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X_%5Cmathbb%7BH%7D+%3D+%5Cfrac%7B%5Cpartial%7B%5Cmathbb%7BH%7D%7D%7D%7B%5Cpartial+q%7D%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+q%7D+-++%5Cfrac%7B%5Cpartial%7B%5Cmathbb%7BH%7D%7D%7D%7B%5Cpartial+p%7D%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+p%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  X_\\mathbb{H} = \\frac{\\partial{\\mathbb{H}}}{\\partial q}\\frac{\\partial}{\\partial q} -  \\frac{\\partial{\\mathbb{H}}}{\\partial p}\\frac{\\partial}{\\partial p}  \" class=\"latex\" title=\"\\displaystyle  X_\\mathbb{H} = \\frac{\\partial{\\mathbb{H}}}{\\partial q}\\frac{\\partial}{\\partial q} -  \\frac{\\partial{\\mathbb{H}}}{\\partial p}\\frac{\\partial}{\\partial p}  \" /></div>
<p>The flow of this vector field is the solution to</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++%5Cdot%7Bq%7D+%26%3D+%5Cfrac%7B%5Cpartial+%5Cmathbb%7BH%7D%7D%7B%5Cpartial+p%7D+%5C%5C++%5Cdot%7Bp%7D+%26%3D+-%5Cfrac%7B%5Cpartial+%5Cmathbb%7BH%7D%7D%7B%5Cpartial+q%7D+%5C%5C++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  \\dot{q} &= \\frac{\\partial \\mathbb{H}}{\\partial p} \\\\  \\dot{p} &= -\\frac{\\partial \\mathbb{H}}{\\partial q} \\\\  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  \\dot{q} &= \\frac{\\partial \\mathbb{H}}{\\partial p} \\\\  \\dot{p} &= -\\frac{\\partial \\mathbb{H}}{\\partial q} \\\\  \\end{aligned}  \" /></div>
<p>In other words by using the symplectic 2-form and the Hamiltonian we have regained Hamilton’s equations.</p>
<p><strong>Theorem</strong></p>
<p><em><img src=\"http://s0.wp.com/latex.php?latex=%5Cmathbb%7BH%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathbb{H}\" class=\"latex\" title=\"\\mathbb{H}\" /> is constant on flows of <img src=\"http://s0.wp.com/latex.php?latex=X_%5Cmathbb%7BH%7D&bg=ffffff&fg=333333&s=0\" alt=\"X_\\mathbb{H}\" class=\"latex\" title=\"X_\\mathbb{H}\" />.</em></p>
<p><em>Proof</em></p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X_%7B%5Cmathbb%7BH%7D%7D%7B%5Cmathbb%7BH%7D%7D+%3D+%5Comega%28X_%7B%5Cmathbb%7BH%7D%7D%2C+X_%7B%5Cmathbb%7BH%7D%7D%29+%3D+0++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  X_{\\mathbb{H}}{\\mathbb{H}} = \\omega(X_{\\mathbb{H}}, X_{\\mathbb{H}}) = 0  \" class=\"latex\" title=\"\\displaystyle  X_{\\mathbb{H}}{\\mathbb{H}} = \\omega(X_{\\mathbb{H}}, X_{\\mathbb{H}}) = 0  \" /></div>
<p>since <img src=\"http://s0.wp.com/latex.php?latex=%5Comega&bg=ffffff&fg=333333&s=0\" alt=\"\\omega\" class=\"latex\" title=\"\\omega\" /> is alternating.</p>
<p><img src=\"http://s0.wp.com/latex.php?latex=%5Cblacksquare&bg=ffffff&fg=333333&s=0\" alt=\"\\blacksquare\" class=\"latex\" title=\"\\blacksquare\" /></p>
<p>When the Hamiltonian function represents the energy of the system being studied then this says that energy remains constant on flows. That is, as the system evolves according to the flow <img src=\"http://s0.wp.com/latex.php?latex=%5Cphi_t&bg=ffffff&fg=333333&s=0\" alt=\"\\phi_t\" class=\"latex\" title=\"\\phi_t\" /> given by the vector field <img src=\"http://s0.wp.com/latex.php?latex=X_%7B%5Cmathbb%7BH%7D%7D&bg=ffffff&fg=333333&s=0\" alt=\"X_{\\mathbb{H}}\" class=\"latex\" title=\"X_{\\mathbb{H}}\" /> then <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathbb%7BH%7D%28q_t%2C+p_t%29+%3D+%5Cmathbb%7BH%7D%28%5Cphi_t%28q_0%2C+p_0%29%29+%3D+%5Cmathbb%7BH%7D%28q_0%2C+p_0%29&bg=ffffff&fg=333333&s=0\" alt=\"\\mathbb{H}(q_t, p_t) = \\mathbb{H}(\\phi_t(q_0, p_0)) = \\mathbb{H}(q_0, p_0)\" class=\"latex\" title=\"\\mathbb{H}(q_t, p_t) = \\mathbb{H}(\\phi_t(q_0, p_0)) = \\mathbb{H}(q_0, p_0)\" />.</p>
<p>Thus it makes sense to look for numeric methods which maintain this invariant, that is methods which preserve the symplectic 2-form.</p>
<p><strong>Definition</strong></p>
<p>A diffeomorphsim between two symplectic manifolds <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+%28M%2C+%5Cmu%29+%5Clongrightarrow+%28M%2C+%5Cnu%29&bg=ffffff&fg=333333&s=0\" alt=\"f : (M, \\mu) \\longrightarrow (M, \\nu)\" class=\"latex\" title=\"f : (M, \\mu) \\longrightarrow (M, \\nu)\" /> is a symplectomorphism if</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%5E%2A%5Cnu+%3D+%5Cmu++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  f^*\\nu = \\mu  \" class=\"latex\" title=\"\\displaystyle  f^*\\nu = \\mu  \" /></div>
<p><img src=\"http://s0.wp.com/latex.php?latex=%5Cblacksquare&bg=ffffff&fg=333333&s=0\" alt=\"\\blacksquare\" class=\"latex\" title=\"\\blacksquare\" /></p>
<p>In co-ordinates, we have</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++f%5E%2A%28dq+%5Cwedge+dp%29+%26%3D+%28%5Cfrac%7B%5Cpartial+f_q%7D%7B%5Cpartial+q%7D+dq+%2B+%5Cfrac%7B%5Cpartial+f_q%7D%7B%5Cpartial+p%7D+dp%29++%5Cwedge++%28%5Cfrac%7B%5Cpartial+f_p%7D%7B%5Cpartial+q%7D+dq+%2B+%5Cfrac%7B%5Cpartial+f_p%7D%7B%5Cpartial+p%7D+dp%29+%5C%5C++%26%3D+%28%5Cfrac%7B%5Cpartial+f_q%7D%7B%5Cpartial+q%7D%5Cfrac%7B%5Cpartial+f_p%7D%7B%5Cpartial+p%7D+-++%5Cfrac%7B%5Cpartial+f_p%7D%7B%5Cpartial+q%7D%5Cfrac%7B%5Cpartial+f_q%7D%7B%5Cpartial+p%7D%29dq+%5Cwedge+dp+%5C%5C++%26%3D+dq+%5Cwedge+dp++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  f^*(dq \\wedge dp) &= (\\frac{\\partial f_q}{\\partial q} dq + \\frac{\\partial f_q}{\\partial p} dp)  \\wedge  (\\frac{\\partial f_p}{\\partial q} dq + \\frac{\\partial f_p}{\\partial p} dp) \\\\  &= (\\frac{\\partial f_q}{\\partial q}\\frac{\\partial f_p}{\\partial p} -  \\frac{\\partial f_p}{\\partial q}\\frac{\\partial f_q}{\\partial p})dq \\wedge dp \\\\  &= dq \\wedge dp  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  f^*(dq \\wedge dp) &= (\\frac{\\partial f_q}{\\partial q} dq + \\frac{\\partial f_q}{\\partial p} dp)  \\wedge  (\\frac{\\partial f_p}{\\partial q} dq + \\frac{\\partial f_p}{\\partial p} dp) \\\\  &= (\\frac{\\partial f_q}{\\partial q}\\frac{\\partial f_p}{\\partial p} -  \\frac{\\partial f_p}{\\partial q}\\frac{\\partial f_q}{\\partial p})dq \\wedge dp \\\\  &= dq \\wedge dp  \\end{aligned}  \" /></div>
<p>Or in matrix form</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Cbegin%7Bbmatrix%7D++%5Cfrac%7B%5Cpartial+f_q%7D%7B%5Cpartial+q%7D+%26+%5Cfrac%7B%5Cpartial+f_q%7D%7B%5Cpartial+p%7D+%5C%5C++%5Cfrac%7B%5Cpartial+f_p%7D%7B%5Cpartial+q%7D+%26+%5Cfrac%7B%5Cpartial+f_p%7D%7B%5Cpartial+p%7D++%5Cend%7Bbmatrix%7D%7D%5E%5Ctop++%5C%2C++%5Cbegin%7Bbmatrix%7D++0+%26+1+%5C%5C++-1+%26+0++%5Cend%7Bbmatrix%7D++%5C%2C++%5Cbegin%7Bbmatrix%7D++%5Cfrac%7B%5Cpartial+f_q%7D%7B%5Cpartial+q%7D+%26+%5Cfrac%7B%5Cpartial+f_q%7D%7B%5Cpartial+p%7D+%5C%5C++%5Cfrac%7B%5Cpartial+f_p%7D%7B%5Cpartial+q%7D+%26+%5Cfrac%7B%5Cpartial+f_p%7D%7B%5Cpartial+p%7D++%5Cend%7Bbmatrix%7D++%3D++%5Cbegin%7Bbmatrix%7D++0+%26+1+%5C%5C++-1+%26+0++%5Cend%7Bbmatrix%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  {\\begin{bmatrix}  \\frac{\\partial f_q}{\\partial q} & \\frac{\\partial f_q}{\\partial p} \\\\  \\frac{\\partial f_p}{\\partial q} & \\frac{\\partial f_p}{\\partial p}  \\end{bmatrix}}^\\top  \\,  \\begin{bmatrix}  0 & 1 \\\\  -1 & 0  \\end{bmatrix}  \\,  \\begin{bmatrix}  \\frac{\\partial f_q}{\\partial q} & \\frac{\\partial f_q}{\\partial p} \\\\  \\frac{\\partial f_p}{\\partial q} & \\frac{\\partial f_p}{\\partial p}  \\end{bmatrix}  =  \\begin{bmatrix}  0 & 1 \\\\  -1 & 0  \\end{bmatrix}  \" class=\"latex\" title=\"\\displaystyle  {\\begin{bmatrix}  \\frac{\\partial f_q}{\\partial q} & \\frac{\\partial f_q}{\\partial p} \\\\  \\frac{\\partial f_p}{\\partial q} & \\frac{\\partial f_p}{\\partial p}  \\end{bmatrix}}^\\top  \\,  \\begin{bmatrix}  0 & 1 \\\\  -1 & 0  \\end{bmatrix}  \\,  \\begin{bmatrix}  \\frac{\\partial f_q}{\\partial q} & \\frac{\\partial f_q}{\\partial p} \\\\  \\frac{\\partial f_p}{\\partial q} & \\frac{\\partial f_p}{\\partial p}  \\end{bmatrix}  =  \\begin{bmatrix}  0 & 1 \\\\  -1 & 0  \\end{bmatrix}  \" /></div>
<p>We now check that the symplectic Euler method satisfies this.</p>
<h3 id=\"symplectic-euler\">Symplectic Euler</h3>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++p_%7Bn%2B1%7D+%26%3D+p_n+-+h%5Cnabla_q+H%28p_%7Bn%2B1%7D%2C+q_n%29+%5C%5C++q_%7Bn%2B1%7D+%26%3D+q_n+%2B+h%5Cnabla_p+H%28p_%7Bn%2B1%7D%2C+q_n%29++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  p_{n+1} &= p_n - h\\nabla_q H(p_{n+1}, q_n) \\\\  q_{n+1} &= q_n + h\\nabla_p H(p_{n+1}, q_n)  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  p_{n+1} &= p_n - h\\nabla_q H(p_{n+1}, q_n) \\\\  q_{n+1} &= q_n + h\\nabla_p H(p_{n+1}, q_n)  \\end{aligned}  \" /></div>
<p>We check that this really is symplectic. First suppose we have two functions:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++x+%26%3D+u+-+f%28x%2Cv%29+%5C%5C++y+%26%3D+v+%2B+g%28x%2Cv%29+%5C%5C++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  x &= u - f(x,v) \\\\  y &= v + g(x,v) \\\\  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  x &= u - f(x,v) \\\\  y &= v + g(x,v) \\\\  \\end{aligned}  \" /></div>
<p>Then we can find partial derivatives:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++dx+%26%3D+du+-+%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+x%7Ddx+-+%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+v%7Ddv+%5C%5C++dy+%26%3D+dv+%2B+%5Cfrac%7B%5Cpartial+g%7D%7B%5Cpartial+x%7Ddx+%2B+%5Cfrac%7B%5Cpartial+g%7D%7B%5Cpartial+v%7D+dv+%5C%5C++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  dx &= du - \\frac{\\partial f}{\\partial x}dx - \\frac{\\partial f}{\\partial v}dv \\\\  dy &= dv + \\frac{\\partial g}{\\partial x}dx + \\frac{\\partial g}{\\partial v} dv \\\\  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  dx &= du - \\frac{\\partial f}{\\partial x}dx - \\frac{\\partial f}{\\partial v}dv \\\\  dy &= dv + \\frac{\\partial g}{\\partial x}dx + \\frac{\\partial g}{\\partial v} dv \\\\  \\end{aligned}  \" /></div>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++%5Cfrac%7B%5Cpartial+x%7D%7B%5Cpartial+u%7D+%26%3D+1+-+%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+x%7D%5Cfrac%7B%5Cpartial+x%7D%7B%5Cpartial+u%7D+%5C%5C++%5Cfrac%7B%5Cpartial+x%7D%7B%5Cpartial+v%7D+%26%3D+-%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+x%7D%5Cfrac%7B%5Cpartial+x%7D%7B%5Cpartial+v%7D+-%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+v%7D+%5C%5C++%5Cfrac%7B%5Cpartial+y%7D%7B%5Cpartial+u%7D+%26%3D+%5Cfrac%7B%5Cpartial+g%7D%7B%5Cpartial+x%7D%5Cfrac%7B%5Cpartial+x%7D%7B%5Cpartial+u%7D+%5C%5C++%5Cfrac%7B%5Cpartial+y%7D%7B%5Cpartial+v%7D+%26%3D+1+%2B+%5Cfrac%7B%5Cpartial+g%7D%7B%5Cpartial+x%7D%5Cfrac%7B%5Cpartial+x%7D%7B%5Cpartial+v%7D+%2B+%5Cfrac%7B%5Cpartial+g%7D%7B%5Cpartial+v%7D++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  \\frac{\\partial x}{\\partial u} &= 1 - \\frac{\\partial f}{\\partial x}\\frac{\\partial x}{\\partial u} \\\\  \\frac{\\partial x}{\\partial v} &= -\\frac{\\partial f}{\\partial x}\\frac{\\partial x}{\\partial v} -\\frac{\\partial f}{\\partial v} \\\\  \\frac{\\partial y}{\\partial u} &= \\frac{\\partial g}{\\partial x}\\frac{\\partial x}{\\partial u} \\\\  \\frac{\\partial y}{\\partial v} &= 1 + \\frac{\\partial g}{\\partial x}\\frac{\\partial x}{\\partial v} + \\frac{\\partial g}{\\partial v}  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  \\frac{\\partial x}{\\partial u} &= 1 - \\frac{\\partial f}{\\partial x}\\frac{\\partial x}{\\partial u} \\\\  \\frac{\\partial x}{\\partial v} &= -\\frac{\\partial f}{\\partial x}\\frac{\\partial x}{\\partial v} -\\frac{\\partial f}{\\partial v} \\\\  \\frac{\\partial y}{\\partial u} &= \\frac{\\partial g}{\\partial x}\\frac{\\partial x}{\\partial u} \\\\  \\frac{\\partial y}{\\partial v} &= 1 + \\frac{\\partial g}{\\partial x}\\frac{\\partial x}{\\partial v} + \\frac{\\partial g}{\\partial v}  \\end{aligned}  \" /></div>
<p>Re-arranging:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++%5Cfrac%7B%5Cpartial+x%7D%7B%5Cpartial+u%7D%281+%2B+%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+x%7D%29+%26%3D+1+%5C%5C++%5Cfrac%7B%5Cpartial+x%7D%7B%5Cpartial+v%7D%281+%2B+%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+x%7D%29+%26%3D+-%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+v%7D+%5C%5C++%5Cfrac%7B%5Cpartial+y%7D%7B%5Cpartial+u%7D+-%5Cfrac%7B%5Cpartial+g%7D%7B%5Cpartial+x%7D%5Cfrac%7B%5Cpartial+x%7D%7B%5Cpartial+u%7D+%26%3D+0+%5C%5C++%5Cfrac%7B%5Cpartial+y%7D%7B%5Cpartial+v%7D+-+%5Cfrac%7B%5Cpartial+g%7D%7B%5Cpartial+x%7D%5Cfrac%7B%5Cpartial+x%7D%7B%5Cpartial+v%7D+%26%3D+1+%2B+%5Cfrac%7B%5Cpartial+g%7D%7B%5Cpartial+v%7D++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  \\frac{\\partial x}{\\partial u}(1 + \\frac{\\partial f}{\\partial x}) &= 1 \\\\  \\frac{\\partial x}{\\partial v}(1 + \\frac{\\partial f}{\\partial x}) &= -\\frac{\\partial f}{\\partial v} \\\\  \\frac{\\partial y}{\\partial u} -\\frac{\\partial g}{\\partial x}\\frac{\\partial x}{\\partial u} &= 0 \\\\  \\frac{\\partial y}{\\partial v} - \\frac{\\partial g}{\\partial x}\\frac{\\partial x}{\\partial v} &= 1 + \\frac{\\partial g}{\\partial v}  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  \\frac{\\partial x}{\\partial u}(1 + \\frac{\\partial f}{\\partial x}) &= 1 \\\\  \\frac{\\partial x}{\\partial v}(1 + \\frac{\\partial f}{\\partial x}) &= -\\frac{\\partial f}{\\partial v} \\\\  \\frac{\\partial y}{\\partial u} -\\frac{\\partial g}{\\partial x}\\frac{\\partial x}{\\partial u} &= 0 \\\\  \\frac{\\partial y}{\\partial v} - \\frac{\\partial g}{\\partial x}\\frac{\\partial x}{\\partial v} &= 1 + \\frac{\\partial g}{\\partial v}  \\end{aligned}  \" /></div>
<p>Pulling everything together in matrix form:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Bbmatrix%7D++1+%2B+%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+x%7D+%26+0+%5C%5C++-%5Cfrac%7B%5Cpartial+g%7D%7B%5Cpartial+x%7D+%26+1++%5Cend%7Bbmatrix%7D++%5C%2C++%5Cbegin%7Bbmatrix%7D++%5Cfrac%7B%5Cpartial+x%7D%7B%5Cpartial+u%7D+%26+%5Cfrac%7B%5Cpartial+x%7D%7B%5Cpartial+v%7D+%5C%5C++%5Cfrac%7B%5Cpartial+y%7D%7B%5Cpartial+u%7D+%26+%5Cfrac%7B%5Cpartial+y%7D%7B%5Cpartial+v%7D++%5Cend%7Bbmatrix%7D++%3D++%5Cbegin%7Bbmatrix%7D++1+%26+-%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+v%7D+%5C%5C++0+%26+1+%2B+%5Cfrac%7B%5Cpartial+g%7D%7B%5Cpartial+v%7D++%5Cend%7Bbmatrix%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{bmatrix}  1 + \\frac{\\partial f}{\\partial x} & 0 \\\\  -\\frac{\\partial g}{\\partial x} & 1  \\end{bmatrix}  \\,  \\begin{bmatrix}  \\frac{\\partial x}{\\partial u} & \\frac{\\partial x}{\\partial v} \\\\  \\frac{\\partial y}{\\partial u} & \\frac{\\partial y}{\\partial v}  \\end{bmatrix}  =  \\begin{bmatrix}  1 & -\\frac{\\partial f}{\\partial v} \\\\  0 & 1 + \\frac{\\partial g}{\\partial v}  \\end{bmatrix}  \" class=\"latex\" title=\"\\displaystyle  \\begin{bmatrix}  1 + \\frac{\\partial f}{\\partial x} & 0 \\\\  -\\frac{\\partial g}{\\partial x} & 1  \\end{bmatrix}  \\,  \\begin{bmatrix}  \\frac{\\partial x}{\\partial u} & \\frac{\\partial x}{\\partial v} \\\\  \\frac{\\partial y}{\\partial u} & \\frac{\\partial y}{\\partial v}  \\end{bmatrix}  =  \\begin{bmatrix}  1 & -\\frac{\\partial f}{\\partial v} \\\\  0 & 1 + \\frac{\\partial g}{\\partial v}  \\end{bmatrix}  \" /></div>
<p>Now substitute in the functions for the Euler symplectic method and we obtain</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Bbmatrix%7D++1+%2B+hH_%7Bqp%7D+%26+0+%5C%5C++-hG_%7Bpp%7D+%26+1++%5Cend%7Bbmatrix%7D++%5C%2C++%5Cfrac%7B%5Cpartial+%5Cbig%28p_%7Bn%2B1%7D%2Cq_%7Bn%2B1%7D%5Cbig%29%7D%7B%5Cpartial+%5Cbig%28p_%7Bn%7D%2Cq_%7Bn%7D%5Cbig%29%7D++%3D++%5Cbegin%7Bbmatrix%7D++1+%26+-hH_%7Bqq%7D+%5C%5C++0+%26+1+%2B+hH_%7Bqp%7D++%5Cend%7Bbmatrix%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{bmatrix}  1 + hH_{qp} & 0 \\\\  -hG_{pp} & 1  \\end{bmatrix}  \\,  \\frac{\\partial \\big(p_{n+1},q_{n+1}\\big)}{\\partial \\big(p_{n},q_{n}\\big)}  =  \\begin{bmatrix}  1 & -hH_{qq} \\\\  0 & 1 + hH_{qp}  \\end{bmatrix}  \" class=\"latex\" title=\"\\displaystyle  \\begin{bmatrix}  1 + hH_{qp} & 0 \\\\  -hG_{pp} & 1  \\end{bmatrix}  \\,  \\frac{\\partial \\big(p_{n+1},q_{n+1}\\big)}{\\partial \\big(p_{n},q_{n}\\big)}  =  \\begin{bmatrix}  1 & -hH_{qq} \\\\  0 & 1 + hH_{qp}  \\end{bmatrix}  \" /></div>
<p>The reader can then check by a straightforward but tedious calculation that</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B%5Cpartial+%5Cbig%28p_%7Bn%2B1%7D%2Cq_%7Bn%2B1%7D%5Cbig%29%7D%7B%5Cpartial+%5Cbig%28p_%7Bn%7D%2Cq_%7Bn%7D%5Cbig%29%7D%5E%5Ctop+J+%5Cfrac%7B%5Cpartial+%5Cbig%28p_%7Bn%2B1%7D%2Cq_%7Bn%2B1%7D%5Cbig%29%7D%7B%5Cpartial+%5Cbig%28p_%7Bn%7D%2Cq_%7Bn%7D%5Cbig%29%7D+%3D+J++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\frac{\\partial \\big(p_{n+1},q_{n+1}\\big)}{\\partial \\big(p_{n},q_{n}\\big)}^\\top J \\frac{\\partial \\big(p_{n+1},q_{n+1}\\big)}{\\partial \\big(p_{n},q_{n}\\big)} = J  \" class=\"latex\" title=\"\\displaystyle  \\frac{\\partial \\big(p_{n+1},q_{n+1}\\big)}{\\partial \\big(p_{n},q_{n}\\big)}^\\top J \\frac{\\partial \\big(p_{n+1},q_{n+1}\\big)}{\\partial \\big(p_{n},q_{n}\\big)} = J  \" /></div>
<p>where</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++J++%3D++%5Cbegin%7Bbmatrix%7D++0+%26+1+%5C%5C++-1+%26+0++%5Cend%7Bbmatrix%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  J  =  \\begin{bmatrix}  0 & 1 \\\\  -1 & 0  \\end{bmatrix}  \" class=\"latex\" title=\"\\displaystyle  J  =  \\begin{bmatrix}  0 & 1 \\\\  -1 & 0  \\end{bmatrix}  \" /></div>
<p>Thus the symplectic Euler method really is symplectic.</p>
<p>On the other hand for the explicit Euler for this particular example we have</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B%5Cpartial+%5Cbig%28p_%7Bn%2B1%7D%2Cq_%7Bn%2B1%7D%5Cbig%29%7D%7B%5Cpartial+%5Cbig%28p_%7Bn%7D%2Cq_%7Bn%7D%5Cbig%29%7D++%3D++%5Cbegin%7Bbmatrix%7D++1+%26+h+%2F+ml%5E2+%5C%5C++-hmglcos%5Ctheta_n+%26+1++%5Cend%7Bbmatrix%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\frac{\\partial \\big(p_{n+1},q_{n+1}\\big)}{\\partial \\big(p_{n},q_{n}\\big)}  =  \\begin{bmatrix}  1 & h / ml^2 \\\\  -hmglcos\\theta_n & 1  \\end{bmatrix}  \" class=\"latex\" title=\"\\displaystyle  \\frac{\\partial \\big(p_{n+1},q_{n+1}\\big)}{\\partial \\big(p_{n},q_{n}\\big)}  =  \\begin{bmatrix}  1 & h / ml^2 \\\\  -hmglcos\\theta_n & 1  \\end{bmatrix}  \" /></div>
<p>And a simple calculation shows that</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B%5Cpartial+%5Cbig%28p_%7Bn%2B1%7D%2Cq_%7Bn%2B1%7D%5Cbig%29%7D%7B%5Cpartial+%5Cbig%28p_%7Bn%7D%2Cq_%7Bn%7D%5Cbig%29%7D%5E%5Ctop+J+%5Cfrac%7B%5Cpartial+%5Cbig%28p_%7Bn%2B1%7D%2Cq_%7Bn%2B1%7D%5Cbig%29%7D%7B%5Cpartial+%5Cbig%28p_%7Bn%7D%2Cq_%7Bn%7D%5Cbig%29%7D++%3D++%5Cbegin%7Bbmatrix%7D++0+%26+1+%2B+h%5E2%5Ccos%5Ctheta%5C%5C++-1+-+h%5E2%5Ccos%5Ctheta+%26+0++%5Cend%7Bbmatrix%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\frac{\\partial \\big(p_{n+1},q_{n+1}\\big)}{\\partial \\big(p_{n},q_{n}\\big)}^\\top J \\frac{\\partial \\big(p_{n+1},q_{n+1}\\big)}{\\partial \\big(p_{n},q_{n}\\big)}  =  \\begin{bmatrix}  0 & 1 + h^2\\cos\\theta\\\\  -1 - h^2\\cos\\theta & 0  \\end{bmatrix}  \" class=\"latex\" title=\"\\displaystyle  \\frac{\\partial \\big(p_{n+1},q_{n+1}\\big)}{\\partial \\big(p_{n},q_{n}\\big)}^\\top J \\frac{\\partial \\big(p_{n+1},q_{n+1}\\big)}{\\partial \\big(p_{n},q_{n}\\big)}  =  \\begin{bmatrix}  0 & 1 + h^2\\cos\\theta\\\\  -1 - h^2\\cos\\theta & 0  \\end{bmatrix}  \" /></div>
<p>Thus the explicit Euler method is not symplectic i.e., does not preserve areas. Thus the path traversed is not an integral curve of the Hamiltonian vector field. We can see this in the diagram: the path spirals outwards. More details and examples can be found in [@IAUS:152:407Y; @Cross:2005:SIOC].</p>
<h2 id=\"planetary-motion\">Planetary Motion</h2>
<p>Normally we would express the gravitational constant in SI units but to be consistent with [@hairer2010geometric] we use units in which distances are expressed in astronomical units, masses are measured relative to the sun and time is measured in earth days.</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Cmathbb+H%7D+%3D+%5Cfrac%7B1%7D%7B2%7D%5Csum_%7Bi%3D0%7D%5En+%5Cfrac%7Bp_i%5E%5Ctop+p_i%7D%7Bm_i%7D+-+%5Cfrac%7BG%7D%7B2%7D%5Csum_%7Bi%3D0%7D%5En%5Csum_%7Bj+%5Cneq+i%7D+%5Cfrac%7Bm_i+m_j%7D%7B%5C%7Cq_i+-+q_j%5C%7C%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  {\\mathbb H} = \\frac{1}{2}\\sum_{i=0}^n \\frac{p_i^\\top p_i}{m_i} - \\frac{G}{2}\\sum_{i=0}^n\\sum_{j \\neq i} \\frac{m_i m_j}{\\|q_i - q_j\\|}  \" class=\"latex\" title=\"\\displaystyle  {\\mathbb H} = \\frac{1}{2}\\sum_{i=0}^n \\frac{p_i^\\top p_i}{m_i} - \\frac{G}{2}\\sum_{i=0}^n\\sum_{j \\neq i} \\frac{m_i m_j}{\\|q_i - q_j\\|}  \" /></div>
<p>Applying Hamilton’s equations we obtain</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++%5Cdot%7Bq_k%5Ea%7D+%26%3D+%5Cfrac%7B%5Cpartial%5Cmathbb%7BH%7D%7D%7B%5Cpartial+p_k%5Ea%7D+%3D+%5Cfrac%7Bp_k%5Ea%7D%7Bm_k%7D+%5C%5C++%5Cdot%7Bp_k%5Ea%7D+%26%3D+-%5Cfrac%7B%5Cpartial%5Cmathbb%7BH%7D%7D%7B%5Cpartial+q_k%5Ea%7D+%3D+G%5Csum_%7Bj+%5Cneq+k%7Dm_k+m_i+%5Cfrac%7Bq_k%5Ea+-+q_j%5Ea%7D%7B%5C%7Cq_k+-+q_j%5C%7C%5E3%7D++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  \\dot{q_k^a} &= \\frac{\\partial\\mathbb{H}}{\\partial p_k^a} = \\frac{p_k^a}{m_k} \\\\  \\dot{p_k^a} &= -\\frac{\\partial\\mathbb{H}}{\\partial q_k^a} = G\\sum_{j \\neq k}m_k m_i \\frac{q_k^a - q_j^a}{\\|q_k - q_j\\|^3}  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  \\dot{q_k^a} &= \\frac{\\partial\\mathbb{H}}{\\partial p_k^a} = \\frac{p_k^a}{m_k} \\\\  \\dot{p_k^a} &= -\\frac{\\partial\\mathbb{H}}{\\partial q_k^a} = G\\sum_{j \\neq k}m_k m_i \\frac{q_k^a - q_j^a}{\\|q_k - q_j\\|^3}  \\end{aligned}  \" /></div>
<p>In this case it easy to see that these are the same as Newton’s laws of motion.</p>
<p>Applying the Euler symplectic method we obtain:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++q_k%5E%7Bn%2B1%7D+%26%3D+q_k%5En+%2B+h+%5Cfrac%7Bp_k%5En%7D%7Bm_k%7D+%5C%5C++p_k%5E%7Bn%2B1%7D+%26%3D+p_k%5En+%2B+h+G%5Csum_%7Bj+%5Cneq+k%7Dm_k+m_i+%5Cfrac%7Bq_k%5E%7Bn%2B1%7D+-+q_j%5E%7Bn%2B1%7D%7D%7B%5C%7Cq_k%5E%7Bn%2B1%7D+-+q_j%5E%7Bn%2B1%7D%5C%7C%5E3%7D++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  q_k^{n+1} &= q_k^n + h \\frac{p_k^n}{m_k} \\\\  p_k^{n+1} &= p_k^n + h G\\sum_{j \\neq k}m_k m_i \\frac{q_k^{n+1} - q_j^{n+1}}{\\|q_k^{n+1} - q_j^{n+1}\\|^3}  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  q_k^{n+1} &= q_k^n + h \\frac{p_k^n}{m_k} \\\\  p_k^{n+1} &= p_k^n + h G\\sum_{j \\neq k}m_k m_i \\frac{q_k^{n+1} - q_j^{n+1}}{\\|q_k^{n+1} - q_j^{n+1}\\|^3}  \\end{aligned}  \" /></div>
<h3 id=\"repa-implementation\">Repa Implementation</h3>
<p>We use <a href=\"http://hackage.haskell.org/package/repa\" title=\"Hackage\">repa</a> represent our positions and momenta as 2-dimensional arrays, each planet is given a 3-dimensional position vector and a 3-dimensional momentum vector.</p>
<pre><code>> <span style=\"color: blue; font-weight: bold;\">newtype</span> PositionP a <span style=\"color: red;\">=</span> QP <span style=\"color: red;\">{</span> positionP <span style=\"color: red;\">::</span> Array a DIM2 Double <span style=\"color: red;\">}</span>
> <span style=\"color: blue; font-weight: bold;\">newtype</span> MomentaP  a <span style=\"color: red;\">=</span> PP <span style=\"color: red;\">{</span> momentaP <span style=\"color: red;\">::</span> Array a DIM2 Double <span style=\"color: red;\">}</span>
> <span style=\"color: blue; font-weight: bold;\">newtype</span> MassP     a <span style=\"color: red;\">=</span> MP <span style=\"color: red;\">{</span> massP <span style=\"color: red;\">::</span> Array a DIM1 Double <span style=\"color: red;\">}</span>
</code>
<code>> stepPositionP <span style=\"color: red;\">::</span> <span style=\"color: blue; font-weight: bold;\">forall</span> a b c m .
>                  <span style=\"color: red;\">(</span> Monad m
>                  <span style=\"color: red;\">,</span> Source a Double
>                  <span style=\"color: red;\">,</span> Source b Double
>                  <span style=\"color: red;\">,</span> Source c Double
>                  <span style=\"color: red;\">)</span> <span style=\"color: red;\">=></span>
>                  Double <span style=\"color: red;\">-></span>
>                  PositionP a <span style=\"color: red;\">-></span>
>                  MassP b <span style=\"color: red;\">-></span>
>                  MomentaP c <span style=\"color: red;\">-></span>
>                  m <span style=\"color: red;\">(</span>PositionP U<span style=\"color: red;\">)</span>
> stepPositionP h qs ms ps <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   <span style=\"color: blue; font-weight: bold;\">do</span> newQs <span style=\"color: red;\"><-</span> computeP $ <span style=\"color: red;\">(</span>positionP qs<span style=\"color: red;\">)</span> +^ <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>momentaP ps<span style=\"color: red;\">)</span> *^ h3 /^ ms2<span style=\"color: red;\">)</span>
>      return $ QP newQs
>     <span style=\"color: blue; font-weight: bold;\">where</span>
>       <span style=\"color: red;\">(</span>Z :. i :. j<span style=\"color: red;\">)</span> <span style=\"color: red;\">=</span> extent $ momentaP ps
>
>       h3  <span style=\"color: red;\">=</span> extend <span style=\"color: red;\">(</span>Any :. i :. j<span style=\"color: red;\">)</span> $ fromListUnboxed Z <span style=\"color: red;\">[</span>h<span style=\"color: red;\">]</span>
>       ms2 <span style=\"color: red;\">=</span> extend <span style=\"color: red;\">(</span>Any :. j<span style=\"color: red;\">)</span> $ massP ms
</code></pre>
<p>Each planet produces forces on every other planet so we work with 3-dimsenional arrays and explicitly set the force of a planet on itself to zero. Once the forces on each planet have been calculated, we sum them to produce a resultant force which we then use to step the momentum forward.</p>
<pre><code>> stepMomentumP <span style=\"color: red;\">::</span> <span style=\"color: blue; font-weight: bold;\">forall</span> a b c m .
>                  <span style=\"color: red;\">(</span> Monad m
>                  <span style=\"color: red;\">,</span> Source a Double
>                  <span style=\"color: red;\">,</span> Source b Double
>                  <span style=\"color: red;\">,</span> Source c Double
>                  <span style=\"color: red;\">)</span> <span style=\"color: red;\">=></span>
>                  Double <span style=\"color: red;\">-></span>
>                  Double <span style=\"color: red;\">-></span>
>                  PositionP a <span style=\"color: red;\">-></span>
>                  MassP b <span style=\"color: red;\">-></span>
>                  MomentaP c <span style=\"color: red;\">-></span>
>                  m <span style=\"color: red;\">(</span>MomentaP U<span style=\"color: red;\">)</span>
> stepMomentumP gConst h qs ms ps <span style=\"color: red;\">=</span>
>   <span style=\"color: blue; font-weight: bold;\">do</span> fs <span style=\"color: red;\"><-</span> sumP $ transpose $ zeroDiags fss
>      newPs <span style=\"color: red;\"><-</span> computeP $ <span style=\"color: red;\">(</span>momentaP ps<span style=\"color: red;\">)</span> +^ <span style=\"color: red;\">(</span>fs *^ dt2<span style=\"color: red;\">)</span>
>      return $ PP newPs
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     is <span style=\"color: red;\">=</span> repDim2to3Outer $ prodPairsMasses $ massP ms
>     qDiffs <span style=\"color: red;\">=</span> pointDiffs $ positionP qs
>     preDs <span style=\"color: red;\">=</span> Repa.map <span style=\"color: red;\">(</span>^<span class=\"hs-num\">3</span><span style=\"color: red;\">)</span> $
>             Repa.map sqrt $
>             sumS $
>             Repa.map <span style=\"color: red;\">(</span>^<span class=\"hs-num\">2</span><span style=\"color: red;\">)</span> $
>             qDiffs
>     ds    <span style=\"color: red;\">=</span> repDim2to3Outer preDs
>     preFs <span style=\"color: red;\">=</span> Repa.map <span style=\"color: red;\">(</span>* <span style=\"color: red;\">(</span>negate gConst<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> $
>             qDiffs /^ ds
>     fss <span style=\"color: red;\">=</span> is *^ preFs
>     Z :.i :. <span class=\"hs-sel\">_j</span> :. k <span style=\"color: red;\">=</span> extent fss
>     dt2              <span style=\"color: red;\">=</span> extend <span style=\"color: red;\">(</span>Any :. i :. k<span style=\"color: red;\">)</span> $ fromListUnboxed Z <span style=\"color: red;\">[</span>h<span style=\"color: red;\">]</span>
>
>     repDim2to3Outer a <span style=\"color: red;\">=</span> extend <span style=\"color: red;\">(</span>Any :. I.spaceDim<span style=\"color: red;\">)</span> a
>
>     zeroDiags x <span style=\"color: red;\">=</span> traverse x id f
>       <span style=\"color: blue; font-weight: bold;\">where</span>
>         f <span style=\"color: blue; font-weight: bold;\">_</span> <span style=\"color: red;\">(</span>Z :. i :. j :. k<span style=\"color: red;\">)</span> <span style=\"color: red;\">|</span> i == j    <span style=\"color: red;\">=</span> <span class=\"hs-num\">0.0</span>
>                                <span style=\"color: red;\">|</span> otherwise <span style=\"color: red;\">=</span> x!<span style=\"color: red;\">(</span>Z :. i :. j :. k<span style=\"color: red;\">)</span>
</code>
<code>> stepOnceP <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span> Monad m
>              <span style=\"color: red;\">,</span> Source a Double
>              <span style=\"color: red;\">,</span> Source b Double
>              <span style=\"color: red;\">,</span> Source c Double
>              <span style=\"color: red;\">)</span> <span style=\"color: red;\">=></span>
>              Double <span style=\"color: red;\">-></span>
>              Double <span style=\"color: red;\">-></span>
>              MassP b <span style=\"color: red;\">-></span>
>              PositionP a <span style=\"color: red;\">-></span>
>              MomentaP c <span style=\"color: red;\">-></span>
>              m <span style=\"color: red;\">(</span>PositionP U<span style=\"color: red;\">,</span> MomentaP U<span style=\"color: red;\">)</span>
> stepOnceP gConst h ms qs ps <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   newPs <span style=\"color: red;\"><-</span> stepMomentumP gConst h qs ms ps
>   newQs <span style=\"color: red;\"><-</span> stepPositionP h qs ms newPs
>   return <span style=\"color: red;\">(</span>newQs<span style=\"color: red;\">,</span> newPs<span style=\"color: red;\">)</span>
</code>
<code>> kineticEnergyP <span style=\"color: red;\">::</span> MassP U <span style=\"color: red;\">-></span> MomentaP U <span style=\"color: red;\">-></span> IO <span style=\"color: red;\">(</span>Array D DIM0 Double<span style=\"color: red;\">)</span>
> kineticEnergyP ms ps <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   preKes <span style=\"color: red;\"><-</span> sumP $ <span style=\"color: red;\">(</span>momentaP ps<span style=\"color: red;\">)</span> *^ <span style=\"color: red;\">(</span>momentaP ps<span style=\"color: red;\">)</span>
>   ke     <span style=\"color: red;\"><-</span> sumP $ preKes /^ <span style=\"color: red;\">(</span>massP ms<span style=\"color: red;\">)</span>
>   return $ Repa.map <span style=\"color: red;\">(</span>* <span class=\"hs-num\">0.5</span><span style=\"color: red;\">)</span> ke
>
> potentialEnergyP <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span>
>                     MassP U <span style=\"color: red;\">-></span>
>                     PositionP U <span style=\"color: red;\">-></span>
>                     IO <span style=\"color: red;\">(</span>Array U DIM1 Double<span style=\"color: red;\">)</span>
> potentialEnergyP gConst ms qs <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   ds2 <span style=\"color: red;\"><-</span> sumP $ Repa.map <span style=\"color: red;\">(</span>^<span class=\"hs-num\">2</span><span style=\"color: red;\">)</span> $ pointDiffs $ positionP qs
>   <span style=\"color: blue; font-weight: bold;\">let</span> ds   <span style=\"color: red;\">=</span> Repa.map sqrt ds2
>       is   <span style=\"color: red;\">=</span> prodPairsMasses $ massP ms
>       pess <span style=\"color: red;\">=</span> zeroDiags $ Repa.map <span style=\"color: red;\">(</span>* <span style=\"color: red;\">(</span><span class=\"hs-num\">0.5</span> * negate gConst<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> $ is /^ ds
>   pes <span style=\"color: red;\"><-</span> sumP pess
>   return pes
>
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>
>     zeroDiags x <span style=\"color: red;\">=</span> traverse x id f
>       <span style=\"color: blue; font-weight: bold;\">where</span>
>         f <span style=\"color: blue; font-weight: bold;\">_</span> <span style=\"color: red;\">(</span>Z :. i :. j<span style=\"color: red;\">)</span> <span style=\"color: red;\">|</span> i == j    <span style=\"color: red;\">=</span> <span class=\"hs-num\">0.0</span>
>                           <span style=\"color: red;\">|</span> otherwise <span style=\"color: red;\">=</span> x!<span style=\"color: red;\">(</span>Z :. i :. j<span style=\"color: red;\">)</span>
</code>
<code>> hamiltonianP <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span>
>                 MassP U <span style=\"color: red;\">-></span>
>                 PositionP U <span style=\"color: red;\">-></span>
>                 MomentaP U <span style=\"color: red;\">-></span>
>                 IO Double
> hamiltonianP gConst ms qs ps <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   ke <span style=\"color: red;\"><-</span> kineticEnergyP ms ps
>   pes <span style=\"color: red;\"><-</span> potentialEnergyP gConst ms qs
>   pe  <span style=\"color: red;\"><-</span> sumP pes
>   te <span style=\"color: red;\">::</span> Array U DIM0 Double <span style=\"color: red;\"><-</span> computeP $ ke +^ pe
>   return $ head $ toList te
</code>
<code>> prodPairsMasses <span style=\"color: red;\">::</span> Source a Double <span style=\"color: red;\">=></span>
>                    Array a DIM1 Double <span style=\"color: red;\">-></span>
>                    Array D DIM2 Double
> prodPairsMasses ms <span style=\"color: red;\">=</span> ns *^ <span style=\"color: red;\">(</span>transpose ns<span style=\"color: red;\">)</span>
>
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     <span style=\"color: red;\">(</span>Z :. i<span style=\"color: red;\">)</span> <span style=\"color: red;\">=</span> extent ms
>     ns <span style=\"color: red;\">=</span> extend <span style=\"color: red;\">(</span>Any :. i :. All<span style=\"color: red;\">)</span> ms
</code>
<code>>
> pointDiffs <span style=\"color: red;\">::</span> Source a Double <span style=\"color: red;\">=></span>
>               Array a DIM2 Double <span style=\"color: red;\">-></span>
>               Array D DIM3 Double
> pointDiffs qs <span style=\"color: red;\">=</span> qss -^ <span style=\"color: red;\">(</span>transposeOuter qss<span style=\"color: red;\">)</span>
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>
>     qss <span style=\"color: red;\">=</span> replicateRows qs
>
>     transposeOuter qs <span style=\"color: red;\">=</span> backpermute <span style=\"color: red;\">(</span>f e<span style=\"color: red;\">)</span> f qs
>       <span style=\"color: blue; font-weight: bold;\">where</span>
>         e <span style=\"color: red;\">=</span> extent qs
>         f <span style=\"color: red;\">(</span>Z :. i :. i' :. j<span style=\"color: red;\">)</span> <span style=\"color: red;\">=</span> Z :. i' :. i :. j
>
>     replicateRows <span style=\"color: red;\">::</span> Source a Double <span style=\"color: red;\">=></span>
>                      Array a DIM2 Double <span style=\"color: red;\">-></span>
>                      Array D DIM3 Double
>     replicateRows a <span style=\"color: red;\">=</span> extend <span style=\"color: red;\">(</span>Any :. i :. All<span style=\"color: red;\">)</span> a
>       <span style=\"color: blue; font-weight: bold;\">where</span> <span style=\"color: red;\">(</span>Z :. i :. <span class=\"hs-sel\">_j</span><span style=\"color: red;\">)</span> <span style=\"color: red;\">=</span> extent a
</code></pre>
<p>Using the single step udate, we can step as many times as we wish.</p>
<pre><code>> stepN <span style=\"color: red;\">::</span> <span style=\"color: blue; font-weight: bold;\">forall</span> m . Monad m <span style=\"color: red;\">=></span>
>          Int <span style=\"color: red;\">-></span>
>          Double <span style=\"color: red;\">-></span>
>          Double <span style=\"color: red;\">-></span>
>          MassP U <span style=\"color: red;\">-></span>
>          PositionP U <span style=\"color: red;\">-></span>
>          MomentaP U <span style=\"color: red;\">-></span>
>          m <span style=\"color: red;\">(</span>PositionP U<span style=\"color: red;\">,</span> MomentaP U<span style=\"color: red;\">)</span>
> stepN n gConst dt masses <span style=\"color: red;\">=</span> curry updaterMulti
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     updaterMulti <span style=\"color: red;\">=</span> foldr <span style=\"color: red;\">(</span>>=><span style=\"color: red;\">)</span> return updaters
>     updaters <span style=\"color: red;\">=</span> replicate n <span style=\"color: red;\">(</span>uncurry <span style=\"color: red;\">(</span>stepOnceP gConst dt masses<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span>
</code></pre>
<p>Sometimes we need all the intermediate steps e.g. for plotting.</p>
<pre><code>> stepNs <span style=\"color: red;\">::</span> Monad m <span style=\"color: red;\">=></span>
>           Int <span style=\"color: red;\">-></span>
>           Double <span style=\"color: red;\">-></span>
>           Double <span style=\"color: red;\">-></span>
>           MassP U <span style=\"color: red;\">-></span>
>           PositionP U <span style=\"color: red;\">-></span>
>           MomentaP U <span style=\"color: red;\">-></span>
>           m <span style=\"color: red;\">[</span><span style=\"color: red;\">(</span>PositionP U<span style=\"color: red;\">,</span> MomentaP U<span style=\"color: red;\">)</span><span style=\"color: red;\">]</span>
> stepNs n gConst dt ms rs vs <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   rsVs <span style=\"color: red;\"><-</span> stepAux n rs vs
>   return $ <span style=\"color: red;\">(</span>rs<span style=\"color: red;\">,</span> vs<span style=\"color: red;\">)</span> : rsVs
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     stepAux <span class=\"hs-num\">0</span>  <span style=\"color: blue; font-weight: bold;\">_</span>  <span style=\"color: blue; font-weight: bold;\">_</span> <span style=\"color: red;\">=</span> return []
>     stepAux n rs vs <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>       <span style=\"color: red;\">(</span>newRs<span style=\"color: red;\">,</span> newVs<span style=\"color: red;\">)</span> <span style=\"color: red;\"><-</span> stepOnceP gConst dt ms rs vs
>       rsVs <span style=\"color: red;\"><-</span> stepAux <span style=\"color: red;\">(</span>n<span style=\"color: green;\">-</span><span class=\"hs-num\">1</span><span style=\"color: red;\">)</span> newRs newVs
>       return $ <span style=\"color: red;\">(</span>newRs<span style=\"color: red;\">,</span> newVs<span style=\"color: red;\">)</span> : rsVs
</code></pre>
<h3 id=\"yarr-implementation\">Yarr Implementation</h3>
<p>We use <a href=\"http://hackage.haskell.org/package/yarr\" title=\"Hackage\">yarr</a> represent our positions and momenta as 1-dimensional arrays, each planet is given a 3-dimensional position vector and a 3-dimensional momentum vector.</p>
<pre><code>> vZero <span style=\"color: red;\">::</span> VecList N3 Double
> vZero <span style=\"color: red;\">=</span> V.replicate <span class=\"hs-num\">0</span>
</code>
<code>> <span style=\"color: blue; font-weight: bold;\">type</span> ArrayY <span style=\"color: red;\">=</span> UArray F L S.Dim1
</code>
<code>> <span style=\"color: blue; font-weight: bold;\">newtype</span> PositionY  <span style=\"color: red;\">=</span> QY <span style=\"color: red;\">{</span> positionY <span style=\"color: red;\">::</span> VecList N3 Double <span style=\"color: red;\">}</span>
>   <span style=\"color: blue; font-weight: bold;\">deriving</span> <span style=\"color: red;\">(</span>Show<span style=\"color: red;\">,</span> Storable<span style=\"color: red;\">)</span>
> <span style=\"color: blue; font-weight: bold;\">newtype</span> MomentumY <span style=\"color: red;\">=</span> PY <span style=\"color: red;\">{</span> momentumY <span style=\"color: red;\">::</span> VecList N3 Double <span style=\"color: red;\">}</span>
>   <span style=\"color: blue; font-weight: bold;\">deriving</span> <span style=\"color: red;\">(</span>Show<span style=\"color: red;\">,</span> Storable<span style=\"color: red;\">)</span>
> <span style=\"color: blue; font-weight: bold;\">type</span> MomentaY     <span style=\"color: red;\">=</span> ArrayY MomentumY
> <span style=\"color: blue; font-weight: bold;\">type</span> PositionsY   <span style=\"color: red;\">=</span> ArrayY PositionY
> <span style=\"color: blue; font-weight: bold;\">type</span> MassesY      <span style=\"color: red;\">=</span> ArrayY Mass
> <span style=\"color: blue; font-weight: bold;\">type</span> ForceY       <span style=\"color: red;\">=</span> VecList N3 Double
> <span style=\"color: blue; font-weight: bold;\">type</span> ForcesY      <span style=\"color: red;\">=</span> ArrayY ForceY
</code>
<code>> stepPositionY <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span> PositionsY <span style=\"color: red;\">-></span> MassesY <span style=\"color: red;\">-></span> MomentaY <span style=\"color: red;\">-></span> IO ()
> stepPositionY h qs ms ps <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   loadS S.fill <span style=\"color: red;\">(</span>dzip3 upd qs ms ps<span style=\"color: red;\">)</span> qs
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     upd <span style=\"color: red;\">::</span> PositionY <span style=\"color: red;\">-></span> Mass <span style=\"color: red;\">-></span> MomentumY <span style=\"color: red;\">-></span> PositionY
>     upd q m p <span style=\"color: red;\">=</span> QY $ V.zipWith <span style=\"color: red;\">(</span>+<span style=\"color: red;\">)</span>
>                 <span style=\"color: red;\">(</span>positionY q<span style=\"color: red;\">)</span>
>                 <span style=\"color: red;\">(</span>V.map <span style=\"color: red;\">(</span>* <span style=\"color: red;\">(</span>h / m<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>momentumY p<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span>
</code></pre>
<p>Note the requirement to fill the forces array with zeros before using it.</p>
<pre><code>> stepMomentumY <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span>
>                  Double <span style=\"color: red;\">-></span>
>                  PositionsY <span style=\"color: red;\">-></span>
>                  MassesY <span style=\"color: red;\">-></span>
>                  MomentaY <span style=\"color: red;\">-></span>
>                  IO ()
> stepMomentumY gConst h qs ms ps <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   <span style=\"color: blue; font-weight: bold;\">let</span> nBodies <span style=\"color: red;\">=</span> Y.extent ms
>   fs <span style=\"color: red;\">::</span> ForcesY <span style=\"color: red;\"><-</span> Y.new nBodies
>   S.fill <span style=\"color: red;\">(</span><span style=\"color: red;\">\\</span><span style=\"color: blue; font-weight: bold;\">_</span> <span style=\"color: red;\">-></span> return vZero<span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>Y.write fs<span style=\"color: red;\">)</span> <span class=\"hs-num\">0</span> nBodies
>   <span style=\"color: blue; font-weight: bold;\">let</span> forceBetween i pos1 mass1 j
>         <span style=\"color: red;\">|</span> i == j <span style=\"color: red;\">=</span> return vZero
>         <span style=\"color: red;\">|</span> otherwise <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>           pos2 <span style=\"color: red;\"><-</span> qs `Y.index` j
>           mass2 <span style=\"color: red;\"><-</span> ms `Y.index` j
>           <span style=\"color: blue; font-weight: bold;\">let</span> deltas <span style=\"color: red;\">=</span> V.zipWith <span style=\"color: red;\">(</span><span style=\"color: green;\">-</span><span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>positionY pos1<span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>positionY pos2<span style=\"color: red;\">)</span>
>               dist2  <span style=\"color: red;\">=</span> V.sum $ V.map <span style=\"color: red;\">(</span>^ <span class=\"hs-num\">2</span><span style=\"color: red;\">)</span> deltas
>               a <span style=\"color: red;\">=</span> <span class=\"hs-num\">1.0</span> / dist2
>               b <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span>negate gConst<span style=\"color: red;\">)</span> * mass1 * mass2 * a * <span style=\"color: red;\">(</span>sqrt a<span style=\"color: red;\">)</span>
>           return $ V.map <span style=\"color: red;\">(</span>* b<span style=\"color: red;\">)</span> deltas
>       forceAdd <span style=\"color: red;\">::</span> Int <span style=\"color: red;\">-></span> Int <span style=\"color: red;\">-></span> ForceY <span style=\"color: red;\">-></span> IO ()
>       forceAdd i <span style=\"color: blue; font-weight: bold;\">_</span> f <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>         f0 <span style=\"color: red;\"><-</span> fs `Y.index` i
>         Y.write fs i <span style=\"color: red;\">(</span>V.zipWith <span style=\"color: red;\">(</span>+<span style=\"color: red;\">)</span> f0 f<span style=\"color: red;\">)</span>
>       force i pos <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>         mass <span style=\"color: red;\"><-</span> ms `Y.index` i
>         S.fill <span style=\"color: red;\">(</span>forceBetween i pos mass<span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>forceAdd i<span style=\"color: red;\">)</span> <span class=\"hs-num\">0</span> nBodies
>       upd momentum force <span style=\"color: red;\">=</span>
>         PY $ V.zipWith <span style=\"color: red;\">(</span>+<span style=\"color: red;\">)</span>
>         <span style=\"color: red;\">(</span>momentumY momentum<span style=\"color: red;\">)</span>
>         <span style=\"color: red;\">(</span>V.map <span style=\"color: red;\">(</span><span style=\"color: red;\">\\</span>f <span style=\"color: red;\">-></span> f * h<span style=\"color: red;\">)</span> force<span style=\"color: red;\">)</span>
>   S.fill <span style=\"color: red;\">(</span>Y.index qs<span style=\"color: red;\">)</span> force <span class=\"hs-num\">0</span> nBodies
>   loadS S.fill <span style=\"color: red;\">(</span>dzip2 upd ps fs<span style=\"color: red;\">)</span> ps
</code>
<code>> stepOnceY <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span>
>              Double <span style=\"color: red;\">-></span>
>              MassesY <span style=\"color: red;\">-></span>
>              PositionsY <span style=\"color: red;\">-></span>
>              MomentaY <span style=\"color: red;\">-></span>
>              IO ()
> stepOnceY gConst h ms qs ps <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   stepMomentumY gConst h qs ms ps
>   stepPositionY h qs ms ps
</code>
<code>> potentialEnergyY <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span>
>                     MassesY <span style=\"color: red;\">-></span>
>                     PositionsY <span style=\"color: red;\">-></span>
>                     IO <span style=\"color: red;\">(</span>ArrayY Double<span style=\"color: red;\">)</span>
> potentialEnergyY gConst ms qs <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   <span style=\"color: blue; font-weight: bold;\">let</span> nBodies <span style=\"color: red;\">=</span> Y.extent ms
>   pes <span style=\"color: red;\">::</span> ArrayY Double <span style=\"color: red;\"><-</span> Y.new nBodies
>   S.fill <span style=\"color: red;\">(</span><span style=\"color: red;\">\\</span><span style=\"color: blue; font-weight: bold;\">_</span> <span style=\"color: red;\">-></span> return <span class=\"hs-num\">0.0</span><span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>Y.write pes<span style=\"color: red;\">)</span> <span class=\"hs-num\">0</span> nBodies
>   <span style=\"color: blue; font-weight: bold;\">let</span> peOnePairParticles <span style=\"color: red;\">::</span> Int <span style=\"color: red;\">-></span>
>                             Int <span style=\"color: red;\">-></span>
>                             IO Double
>       peOnePairParticles i j
>         <span style=\"color: red;\">|</span> i == j <span style=\"color: red;\">=</span> return <span class=\"hs-num\">0.0</span>
>         <span style=\"color: red;\">|</span> otherwise <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>           q1 <span style=\"color: red;\"><-</span> qs `Y.index` i
>           m1 <span style=\"color: red;\"><-</span> ms `Y.index` i
>           q2 <span style=\"color: red;\"><-</span> qs `Y.index` j
>           m2 <span style=\"color: red;\"><-</span> ms `Y.index` j
>           <span style=\"color: blue; font-weight: bold;\">let</span> qDiffs <span style=\"color: red;\">=</span> V.zipWith <span style=\"color: red;\">(</span><span style=\"color: green;\">-</span><span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>positionY q1<span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>positionY q2<span style=\"color: red;\">)</span>
>               dist2  <span style=\"color: red;\">=</span> V.sum $ V.map <span style=\"color: red;\">(</span>^<span class=\"hs-num\">2</span><span style=\"color: red;\">)</span> qDiffs
>               a      <span style=\"color: red;\">=</span> <span class=\"hs-num\">1.0</span> / dist2
>               b      <span style=\"color: red;\">=</span> <span class=\"hs-num\">0.5</span> * <span style=\"color: red;\">(</span>negate gConst<span style=\"color: red;\">)</span> * m1 * m2 * <span style=\"color: red;\">(</span>sqrt a<span style=\"color: red;\">)</span>
>           return b
>       peAdd i <span style=\"color: blue; font-weight: bold;\">_</span> pe <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>         peDelta <span style=\"color: red;\"><-</span> pes `Y.index` i
>         Y.write pes i <span style=\"color: red;\">(</span>pe + peDelta<span style=\"color: red;\">)</span>
>       peFn i <span style=\"color: blue; font-weight: bold;\">_</span> <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>         S.fill <span style=\"color: red;\">(</span>peOnePairParticles i<span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>peAdd i<span style=\"color: red;\">)</span> <span class=\"hs-num\">0</span> nBodies
>   S.fill <span style=\"color: red;\">(</span>Y.index qs<span style=\"color: red;\">)</span> peFn <span class=\"hs-num\">0</span> nBodies
>   return pes
</code>
<code>> kineticEnergyY <span style=\"color: red;\">::</span> MassesY <span style=\"color: red;\">-></span> MomentaY<span style=\"color: red;\">-></span> IO Double
> kineticEnergyY ms ps <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   <span style=\"color: blue; font-weight: bold;\">let</span> nakedPs <span style=\"color: red;\">=</span> Y.delay $ Y.dmap momentumY ps
>   <span style=\"color: blue; font-weight: bold;\">let</span> preKes <span style=\"color: red;\">=</span> Y.dmap V.sum $ dzip2 <span style=\"color: red;\">(</span>V.zipWith <span style=\"color: red;\">(</span>*<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> nakedPs nakedPs
>       kes     <span style=\"color: red;\">=</span> dzip2 <span style=\"color: red;\">(</span>/<span style=\"color: red;\">)</span> preKes <span style=\"color: red;\">(</span>Y.delay ms<span style=\"color: red;\">)</span>
>   ke <span style=\"color: red;\"><-</span> W.walk <span style=\"color: red;\">(</span>W.reduceL S.foldl <span style=\"color: red;\">(</span>+<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>return <span class=\"hs-num\">0</span><span style=\"color: red;\">)</span> kes
>   return $ <span class=\"hs-num\">0.5</span> * ke
</code>
<code>> hamiltonianY <span style=\"color: red;\">::</span> Double <span style=\"color: red;\">-></span> MassesY <span style=\"color: red;\">-></span> PositionsY <span style=\"color: red;\">-></span> MomentaY<span style=\"color: red;\">-></span> IO Double
> hamiltonianY gConst ms qs ps <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   ke  <span style=\"color: red;\"><-</span> kineticEnergyY ms ps
>   pes <span style=\"color: red;\"><-</span> potentialEnergyY gConst ms qs
>   pe  <span style=\"color: red;\"><-</span> W.walk <span style=\"color: red;\">(</span>W.reduceL S.foldl <span style=\"color: red;\">(</span>+<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>return <span class=\"hs-num\">0</span><span style=\"color: red;\">)</span> pes
>   return $ pe + ke
</code></pre>
<h2 id=\"the-outer-solar-system\">The Outer Solar System</h2>
<p>We convert the starting positions and momenta for the planets into repa and yarr friendly representations.</p>
<pre><code>> mosssP <span style=\"color: red;\">::</span> MassP U
> mosssP <span style=\"color: red;\">=</span> MP $ fromListUnboxed <span style=\"color: red;\">(</span>Z :. n<span style=\"color: red;\">)</span> I.massesOuter
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     n <span style=\"color: red;\">=</span> length I.massesOuter
>
> mosssY <span style=\"color: red;\">::</span> IO MassesY
> mosssY <span style=\"color: red;\">=</span> YIO.fromList n I.massesOuter
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     n <span style=\"color: red;\">=</span> length I.massesOuter
>
> qosss <span style=\"color: red;\">::</span> PositionP U
> qosss <span style=\"color: red;\">=</span> QP $ fromListUnboxed <span style=\"color: red;\">(</span>Z :. n :. I.spaceDim<span style=\"color: red;\">)</span> xs
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     xs <span style=\"color: red;\">=</span> concat I.initQsOuter
>     n  <span style=\"color: red;\">=</span> length xs `div` I.spaceDim
>
> qosssY <span style=\"color: red;\">::</span> IO PositionsY
> qosssY <span style=\"color: red;\">=</span> YIO.fromList nBodies $ Prelude.map f <span style=\"color: red;\">[</span><span class=\"hs-num\">0</span> <span style=\"color: red;\">..</span> nBodies <span style=\"color: green;\">-</span> <span class=\"hs-num\">1</span><span style=\"color: red;\">]</span>
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     nBodies <span style=\"color: red;\">=</span> length I.initQsOuter
>     f <span style=\"color: red;\">::</span> Int <span style=\"color: red;\">-></span> PositionY
>     f i <span style=\"color: red;\">=</span> QY $
>           V.vl_3 <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>I.initQsOuter!!i<span style=\"color: red;\">)</span>!!<span class=\"hs-num\">0</span><span style=\"color: red;\">)</span>
>                  <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>I.initQsOuter!!i<span style=\"color: red;\">)</span>!!<span class=\"hs-num\">1</span><span style=\"color: red;\">)</span>
>                  <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>I.initQsOuter!!i<span style=\"color: red;\">)</span>!!<span class=\"hs-num\">2</span><span style=\"color: red;\">)</span>
>
> posss <span style=\"color: red;\">::</span> MomentaP U
> posss <span style=\"color: red;\">=</span> PP $ fromListUnboxed <span style=\"color: red;\">(</span>Z :. n :. I.spaceDim<span style=\"color: red;\">)</span> xs
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     xs <span style=\"color: red;\">=</span> concat I.initPsOuter
>     n  <span style=\"color: red;\">=</span> length xs `div` I.spaceDim
>
> posssY <span style=\"color: red;\">::</span> IO MomentaY
> posssY <span style=\"color: red;\">=</span> YIO.fromList nBodies $ Prelude.map f <span style=\"color: red;\">[</span><span class=\"hs-num\">0</span> <span style=\"color: red;\">..</span> nBodies <span style=\"color: green;\">-</span> <span class=\"hs-num\">1</span><span style=\"color: red;\">]</span>
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     nBodies <span style=\"color: red;\">=</span> length I.initPsOuter
>     f <span style=\"color: red;\">::</span> Int <span style=\"color: red;\">-></span> MomentumY
>     f i <span style=\"color: red;\">=</span> PY $
>           V.vl_3 <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>I.initPsOuter!!i<span style=\"color: red;\">)</span>!!<span class=\"hs-num\">0</span><span style=\"color: red;\">)</span>
>                  <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>I.initPsOuter!!i<span style=\"color: red;\">)</span>!!<span class=\"hs-num\">1</span><span style=\"color: red;\">)</span>
>                  <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>I.initPsOuter!!i<span style=\"color: red;\">)</span>!!<span class=\"hs-num\">2</span><span style=\"color: red;\">)</span>
</code></pre>
<p>Rather arbitrarily we run the outer planets for 2000 steps with a step length of 100 days.</p>
<pre><code>> outerPlanets <span style=\"color: red;\">::</span> <span style=\"color: red;\">[</span><span style=\"color: red;\">[</span><span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> Double<span style=\"color: red;\">)</span><span style=\"color: red;\">]</span><span style=\"color: red;\">]</span>
> outerPlanets <span style=\"color: red;\">=</span> runIdentity $ <span style=\"color: blue; font-weight: bold;\">do</span>
>   rsVs <span style=\"color: red;\"><-</span> stepNs <span class=\"hs-num\">2000</span> I.gConstAu <span class=\"hs-num\">100</span> mosssP qosss posss
>   <span style=\"color: blue; font-weight: bold;\">let</span> qs <span style=\"color: red;\">=</span> Prelude.map fst rsVs
>       xxs <span style=\"color: red;\">=</span> Prelude.map
>             <span style=\"color: red;\">(</span><span style=\"color: red;\">\\</span>i <span style=\"color: red;\">-></span> Prelude.map <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>!<span style=\"color: red;\">(</span>Z :. <span style=\"color: red;\">(</span>i <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span> :. <span style=\"color: red;\">(</span><span class=\"hs-num\">0</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> .
>                                 positionP<span style=\"color: red;\">)</span> qs<span style=\"color: red;\">)</span>
>             <span style=\"color: red;\">[</span><span class=\"hs-num\">5</span><span style=\"color: red;\">,</span><span class=\"hs-num\">0</span><span style=\"color: red;\">,</span><span class=\"hs-num\">1</span><span style=\"color: red;\">,</span><span class=\"hs-num\">2</span><span style=\"color: red;\">,</span><span class=\"hs-num\">3</span><span style=\"color: red;\">,</span><span class=\"hs-num\">4</span><span style=\"color: red;\">]</span>
>       xys <span style=\"color: red;\">=</span> Prelude.map
>             <span style=\"color: red;\">(</span><span style=\"color: red;\">\\</span>i <span style=\"color: red;\">-></span> Prelude.map <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>!<span style=\"color: red;\">(</span>Z :. <span style=\"color: red;\">(</span>i <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span> :. <span style=\"color: red;\">(</span><span class=\"hs-num\">1</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> .
>                                 positionP<span style=\"color: red;\">)</span> qs<span style=\"color: red;\">)</span>
>             <span style=\"color: red;\">[</span><span class=\"hs-num\">5</span><span style=\"color: red;\">,</span><span class=\"hs-num\">0</span><span style=\"color: red;\">,</span><span class=\"hs-num\">1</span><span style=\"color: red;\">,</span><span class=\"hs-num\">2</span><span style=\"color: red;\">,</span><span class=\"hs-num\">3</span><span style=\"color: red;\">,</span><span class=\"hs-num\">4</span><span style=\"color: red;\">]</span>
>   return $ zipWith zip xxs xys
</code></pre>
<p>Plotting the results, we can see that we have a simulation which, as we expect, conserves energy.</p>
<div style=\"text-align: center;\">
<p><img src=\"http://idontgetoutmuch.files.wordpress.com/2013/08/49ddf2abcabc480eec452f2ec6cbd211.png?w=450\" alt=\"\" /></p>
</div>
<h2 id=\"performance\">Performance</h2>
<p>Let’s see how repa and yarr perform against each other.</p>
<pre><code>> <span style=\"color: blue; font-weight: bold;\">data</span> YarrOrRepa <span style=\"color: red;\">=</span> Repa <span style=\"color: red;\">|</span> Yarr
>   <span style=\"color: blue; font-weight: bold;\">deriving</span> Show
>
> <span style=\"color: blue; font-weight: bold;\">data</span> Options <span style=\"color: red;\">=</span> Options  <span style=\"color: red;\">{</span> optYarr <span style=\"color: red;\">::</span> YarrOrRepa
>                         <span style=\"color: red;\">}</span>
>
> startOptions <span style=\"color: red;\">::</span> Options
> startOptions <span style=\"color: red;\">=</span> Options  <span style=\"color: red;\">{</span> optYarr <span style=\"color: red;\">=</span> Repa
>                         <span style=\"color: red;\">}</span>
>
> options <span style=\"color: red;\">::</span> <span style=\"color: red;\">[</span>OptDescr <span style=\"color: red;\">(</span>Options <span style=\"color: red;\">-></span> IO Options<span style=\"color: red;\">)</span><span style=\"color: red;\">]</span>
> options <span style=\"color: red;\">=</span> <span style=\"color: red;\">[</span>
>   Option <span style=\"color: red;\">[</span><span style=\"color: teal;\">'Y'</span><span style=\"color: red;\">]</span> <span style=\"color: red;\">[</span><span style=\"color: teal;\">\"yarr\"</span><span style=\"color: red;\">]</span> <span style=\"color: red;\">(</span>NoArg <span style=\"color: red;\">(</span><span style=\"color: red;\">\\</span>opt <span style=\"color: red;\">-></span> return opt <span style=\"color: red;\">{</span> optYarr <span style=\"color: red;\">=</span> Yarr <span style=\"color: red;\">}</span><span style=\"color: red;\">)</span><span style=\"color: red;\">)</span>
>          <span style=\"color: teal;\">\"Use yarr\"</span>
>   <span style=\"color: red;\">]</span>
</code>
<code>> main <span style=\"color: red;\">::</span> IO ()
> main <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   args <span style=\"color: red;\"><-</span> getArgs
>   <span style=\"color: blue; font-weight: bold;\">let</span> <span style=\"color: red;\">(</span>actions<span style=\"color: red;\">,</span> <span class=\"hs-sel\">_nonOpts</span><span style=\"color: red;\">,</span> <span class=\"hs-sel\">_msgs</span><span style=\"color: red;\">)</span> <span style=\"color: red;\">=</span> getOpt RequireOrder options args
>   opts <span style=\"color: red;\"><-</span> foldl <span style=\"color: red;\">(</span>>>=<span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>return startOptions<span style=\"color: red;\">)</span> actions
>   <span style=\"color: blue; font-weight: bold;\">case</span> optYarr opts <span style=\"color: blue; font-weight: bold;\">of</span>
>     Repa <span style=\"color: red;\">-></span> <span style=\"color: blue; font-weight: bold;\">do</span>
>       hPre <span style=\"color: red;\"><-</span> hamiltonianP I.gConstAu mosssP qosss posss
>       putStrLn $ show hPre
>       <span style=\"color: red;\">(</span>qsPost<span style=\"color: red;\">,</span> psPost<span style=\"color: red;\">)</span> <span style=\"color: red;\"><-</span> stepN I.nStepsOuter I.gConstAu I.stepOuter
>                           mosssP qosss posss
>       hPost <span style=\"color: red;\"><-</span> hamiltonianP I.gConstAu mosssP qsPost psPost
>       putStrLn $ show hPost
>     Yarr <span style=\"color: red;\">-></span> <span style=\"color: blue; font-weight: bold;\">do</span>
>       ms <span style=\"color: red;\">::</span> MassesY <span style=\"color: red;\"><-</span> mosssY
>       ps <span style=\"color: red;\"><-</span> posssY
>       qs <span style=\"color: red;\"><-</span> qosssY
>       hPre <span style=\"color: red;\"><-</span> hamiltonianY I.gConstAu ms qs ps
>       putStrLn $ show hPre
>       S.fill <span style=\"color: red;\">(</span><span style=\"color: red;\">\\</span><span style=\"color: blue; font-weight: bold;\">_</span> <span style=\"color: red;\">-></span> return ()<span style=\"color: red;\">)</span>
>              <span style=\"color: red;\">(</span><span style=\"color: red;\">\\</span><span style=\"color: blue; font-weight: bold;\">_</span> <span style=\"color: blue; font-weight: bold;\">_</span> <span style=\"color: red;\">-></span> stepOnceY I.gConstAu I.stepOuter ms qs ps<span style=\"color: red;\">)</span>
>              <span style=\"color: red;\">(</span><span class=\"hs-num\">0</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span> I.nStepsOuter
>       hPost <span style=\"color: red;\"><-</span> hamiltonianY I.gConstAu ms qs ps
>       putStrLn $ show hPost
</code></pre>
<p>With 200,000 steps we get the following for repa.</p>
<pre><code>$ time ./Symplectic
-3.215453183208164e-8
-3.139737384661333e-8
real	0m18.400s
user	0m18.245s
sys	0m0.154s</code></pre>
<p>And a significant speed up with yarr.</p>
<pre><code>$ time ./Symplectic -Y
-3.215453183208164e-8
-3.13973738466838e-8
real	0m0.553s
user	0m0.539s
sys	0m0.013s</code></pre>
<p>With 2,000,000 steps (about 548,000 years) we get the following with yarr.</p>
<pre><code>$ time ./Symplectic -Y
-3.215453183208164e-8
-3.2144315777817145e-8
real	0m5.477s
user	0m5.369s
sys	0m0.107s</code></pre>
<p>It would be interesting to compare this against a C implementation.</p>
<h2 id=\"appendices\">Appendices</h2>
<h3 id=\"appendix-a-jupiter-earth-and-sun\">Appendix A: Jupiter, Earth and Sun</h3>
<p>We need some initial conditions to start our simulation. Instead of taking real data, let’s make up something which is realistic but within our control.</p>
<p>Following [@Fitz:Newtonian:Dynamics] we can write Kepler’s laws as</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Baligned%7D++r+%26%3D+%5Cfrac%7Ba%281+-+e%5E2%29%7D%7B1+-+e%5Ccos%5Ctheta%7D+%5C%5C++r%5E2%5Cdot%7B%5Ctheta%7D+%26%3D+%5Csqrt%7B%281+-+e%5E2%29%7Dna%5E2+%5C%5C++GM_%7B%5Crm+Sun%7D+%26%3D+n%5E2a%5E3++%5Cend%7Baligned%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\begin{aligned}  r &= \\frac{a(1 - e^2)}{1 - e\\cos\\theta} \\\\  r^2\\dot{\\theta} &= \\sqrt{(1 - e^2)}na^2 \\\\  GM_{\\rm Sun} &= n^2a^3  \\end{aligned}  \" class=\"latex\" title=\"\\displaystyle  \\begin{aligned}  r &= \\frac{a(1 - e^2)}{1 - e\\cos\\theta} \\\\  r^2\\dot{\\theta} &= \\sqrt{(1 - e^2)}na^2 \\\\  GM_{\\rm Sun} &= n^2a^3  \\end{aligned}  \" /></div>
<p>where <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" /> is the period of the orbit, <img src=\"http://s0.wp.com/latex.php?latex=n+%3D+2%5Cpi+%2F+T&bg=ffffff&fg=333333&s=0\" alt=\"n = 2\\pi / T\" class=\"latex\" title=\"n = 2\\pi / T\" /> is the mean angular orbital velocity, <img src=\"http://s0.wp.com/latex.php?latex=a&bg=ffffff&fg=333333&s=0\" alt=\"a\" class=\"latex\" title=\"a\" /> is the major radius of the elliptical orbit (Kepler’s first law: “The orbit of every planet is an ellipse with the Sun at one of the two foci”), <img src=\"http://s0.wp.com/latex.php?latex=G&bg=ffffff&fg=333333&s=0\" alt=\"G\" class=\"latex\" title=\"G\" /> is the gravitational constant and <img src=\"http://s0.wp.com/latex.php?latex=M_%7B%5Crm+Sun%7D&bg=ffffff&fg=333333&s=0\" alt=\"M_{\\rm Sun}\" class=\"latex\" title=\"M_{\\rm Sun}\" /> is the mass of the sun and <img src=\"http://s0.wp.com/latex.php?latex=e&bg=ffffff&fg=333333&s=0\" alt=\"e\" class=\"latex\" title=\"e\" /> is the eccentricity of a planet’s orbit.</p>
<p>We can calculate the mean angular orbital velocity of Jupiter:</p>
<pre><code>> nJupiter <span style=\"color: red;\">::</span> Double
> nJupiter <span style=\"color: red;\">=</span> sqrt $ I.gConst * I.sunMass / I.jupiterMajRad^<span class=\"hs-num\">3</span>
</code></pre>
<p>Let us calculate the initial conditions assuming that Jupiter starts at its perihelion. The angular velocity at that point is entirely in the negative <img src=\"http://s0.wp.com/latex.php?latex=y&bg=ffffff&fg=333333&s=0\" alt=\"y\" class=\"latex\" title=\"y\" /> direction.</p>
<p>With the Leapfrog Method we need the velocity to be half a time step before the perihelion.</p>
<p>If we take <img src=\"http://s0.wp.com/latex.php?latex=%280.0%2C+-v_p%2C+0.0%29&bg=ffffff&fg=333333&s=0\" alt=\"(0.0, -v_p, 0.0)\" class=\"latex\" title=\"(0.0, -v_p, 0.0)\" /> to be the velocity of Jupiter at the perihelion then if <img src=\"http://s0.wp.com/latex.php?latex=%5Cdelta%5Ctheta&bg=ffffff&fg=333333&s=0\" alt=\"\\delta\\theta\" class=\"latex\" title=\"\\delta\\theta\" /> is the angle with respect to the negative y-axis at half a time step before Jupiter reaches the perihelion then the velocity of Jupiter at this point is given by simple trigonometry:<br />
<span class=\"math\">( − <em>v</em><sub><em>p</em></sub>sin(<em>δ</em><em>θ</em>),  − <em>v</em><sub><em>p</em></sub>cos(<em>δ</em><em>θ</em>), 0. 0) ≈ ( − <em>v</em><sub><em>p</em></sub><em>δ</em><em>θ</em>,  − <em>v</em><sub><em>p</em></sub>(1 − <em>δ</em><em>θ</em><sup>2</sup> / 2), 0. 0)</span></p>
<p>In Haskell, we get the following initial conditions:</p>
<pre><code>> jupiterThetaDotP <span style=\"color: red;\">::</span> Double
> jupiterThetaDotP <span style=\"color: red;\">=</span>
>   nJupiter *
>   I.jupiterMajRad^<span class=\"hs-num\">2</span> *
>   sqrt <span style=\"color: red;\">(</span><span class=\"hs-num\">1</span> <span style=\"color: green;\">-</span> I.jupiterEccentrity^<span class=\"hs-num\">2</span><span style=\"color: red;\">)</span> / I.jupiterPerihelion^<span class=\"hs-num\">2</span>
>
> jupiterDeltaThetaP <span style=\"color: red;\">::</span> Double
> jupiterDeltaThetaP <span style=\"color: red;\">=</span> jupiterThetaDotP * I.stepTwoPlanets / <span class=\"hs-num\">2</span>
>
> jupiterVPeri <span style=\"color: red;\">::</span> Speed
> jupiterVPeri <span style=\"color: red;\">=</span> jupiterThetaDotP * I.jupiterPerihelion
>
> jupiterInitX <span style=\"color: red;\">::</span> Speed
> jupiterInitX <span style=\"color: red;\">=</span> negate $ jupiterVPeri * jupiterDeltaThetaP
>
> jupiterInitY <span style=\"color: red;\">::</span> Speed
> jupiterInitY <span style=\"color: red;\">=</span> negate $ jupiterVPeri * <span style=\"color: red;\">(</span><span class=\"hs-num\">1</span> <span style=\"color: green;\">-</span> jupiterDeltaThetaP^<span class=\"hs-num\">2</span> / <span class=\"hs-num\">2</span><span style=\"color: red;\">)</span>
>
> jupiterV <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span>Speed<span style=\"color: red;\">,</span> Speed<span style=\"color: red;\">,</span> Speed<span style=\"color: red;\">)</span>
> jupiterV <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span>jupiterInitX<span style=\"color: red;\">,</span> jupiterInitY<span style=\"color: red;\">,</span> <span class=\"hs-num\">0.0</span><span style=\"color: red;\">)</span>
>
> jupiterR <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span>Distance<span style=\"color: red;\">,</span> Distance<span style=\"color: red;\">,</span> Distance<span style=\"color: red;\">)</span>
> jupiterR <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span>negate I.jupiterPerihelion<span style=\"color: red;\">,</span> <span class=\"hs-num\">0.0</span><span style=\"color: red;\">,</span> <span class=\"hs-num\">0.0</span><span style=\"color: red;\">)</span>
</code></pre>
<p>We can do the same for Earth but we assume the earth is at its perihelion on the opposite side of the Sun to Jupiter.</p>
<pre><code>> nEarth <span style=\"color: red;\">::</span> Double
> nEarth <span style=\"color: red;\">=</span> sqrt $ I.gConst * I.sunMass / I.earthMajRad^<span class=\"hs-num\">3</span>
>
> earthThetaDotP <span style=\"color: red;\">::</span> Double
> earthThetaDotP <span style=\"color: red;\">=</span> nEarth *
>                  I.earthMajRad^<span class=\"hs-num\">2</span> *
>                  sqrt <span style=\"color: red;\">(</span><span class=\"hs-num\">1</span> <span style=\"color: green;\">-</span> I.earthEccentrity^<span class=\"hs-num\">2</span><span style=\"color: red;\">)</span> / I.earthPerihelion^<span class=\"hs-num\">2</span>
>
> earthDeltaThetaP <span style=\"color: red;\">::</span> Double
> earthDeltaThetaP <span style=\"color: red;\">=</span> earthThetaDotP * I.stepTwoPlanets / <span class=\"hs-num\">2</span>
>
> earthVPeri <span style=\"color: red;\">::</span> Speed
> earthVPeri <span style=\"color: red;\">=</span> earthThetaDotP * I.earthPerihelion
>
> earthInitX <span style=\"color: red;\">::</span> Speed
> earthInitX <span style=\"color: red;\">=</span> earthVPeri * earthDeltaThetaP
>
> earthInitY <span style=\"color: red;\">::</span> Speed
> earthInitY <span style=\"color: red;\">=</span> earthVPeri * <span style=\"color: red;\">(</span><span class=\"hs-num\">1</span> <span style=\"color: green;\">-</span> earthDeltaThetaP^<span class=\"hs-num\">2</span> / <span class=\"hs-num\">2</span><span style=\"color: red;\">)</span>
>
> earthV <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span>Speed<span style=\"color: red;\">,</span> Speed<span style=\"color: red;\">,</span> Speed<span style=\"color: red;\">)</span>
> earthV <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span>earthInitX<span style=\"color: red;\">,</span> earthInitY<span style=\"color: red;\">,</span> <span class=\"hs-num\">0.0</span><span style=\"color: red;\">)</span>
>
> earthR <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span>Distance<span style=\"color: red;\">,</span> Distance<span style=\"color: red;\">,</span> Distance<span style=\"color: red;\">)</span>
> earthR <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span>I.earthPerihelion<span style=\"color: red;\">,</span> <span class=\"hs-num\">0.0</span><span style=\"color: red;\">,</span> <span class=\"hs-num\">0.0</span><span style=\"color: red;\">)</span>
</code></pre>
<p>For completeness we give the Sun’s starting conditions.</p>
<pre><code>> sunV <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span>Speed<span style=\"color: red;\">,</span> Speed<span style=\"color: red;\">,</span> Speed<span style=\"color: red;\">)</span>
> sunV <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span><span class=\"hs-num\">0.0</span><span style=\"color: red;\">,</span> <span class=\"hs-num\">0.0</span><span style=\"color: red;\">,</span> <span class=\"hs-num\">0.0</span><span style=\"color: red;\">)</span>
>
> sunR <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span>Distance<span style=\"color: red;\">,</span> Distance<span style=\"color: red;\">,</span> Distance<span style=\"color: red;\">)</span>
> sunR <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span><span class=\"hs-num\">0.0</span><span style=\"color: red;\">,</span> <span class=\"hs-num\">0.0</span><span style=\"color: red;\">,</span> <span class=\"hs-num\">0.0</span><span style=\"color: red;\">)</span>
</code>
<code>> initVs <span style=\"color: red;\">::</span> Array U DIM2 Speed
> initVs <span style=\"color: red;\">=</span> fromListUnboxed <span style=\"color: red;\">(</span>Z :. nBodies :. I.spaceDim<span style=\"color: red;\">)</span> $ concat xs
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     nBodies <span style=\"color: red;\">=</span> length xs
>     xs <span style=\"color: red;\">=</span> <span style=\"color: red;\">[</span> <span style=\"color: red;\">[</span>earthX<span style=\"color: red;\">,</span>   earthY<span style=\"color: red;\">,</span>   earthZ<span style=\"color: red;\">]</span>
>          <span style=\"color: red;\">,</span> <span style=\"color: red;\">[</span>jupiterX<span style=\"color: red;\">,</span> jupiterY<span style=\"color: red;\">,</span> jupiterZ<span style=\"color: red;\">]</span>
>          <span style=\"color: red;\">,</span> <span style=\"color: red;\">[</span>sunX<span style=\"color: red;\">,</span>     sunY<span style=\"color: red;\">,</span>     sunZ<span style=\"color: red;\">]</span>
>          <span style=\"color: red;\">]</span>
>     <span style=\"color: red;\">(</span>earthX<span style=\"color: red;\">,</span>   earthY<span style=\"color: red;\">,</span>   earthZ<span style=\"color: red;\">)</span>   <span style=\"color: red;\">=</span> earthV
>     <span style=\"color: red;\">(</span>jupiterX<span style=\"color: red;\">,</span> jupiterY<span style=\"color: red;\">,</span> jupiterZ<span style=\"color: red;\">)</span> <span style=\"color: red;\">=</span> jupiterV
>     <span style=\"color: red;\">(</span>sunX<span style=\"color: red;\">,</span>     sunY<span style=\"color: red;\">,</span>     sunZ<span style=\"color: red;\">)</span>     <span style=\"color: red;\">=</span> sunV
</code>
<code>> initPs <span style=\"color: red;\">::</span> MomentaP U
> initPs <span style=\"color: red;\">=</span> PP $ runIdentity $ computeP $ ms2 *^ initVs
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     <span style=\"color: red;\">(</span>Z :. <span class=\"hs-sel\">_i</span> :. j<span style=\"color: red;\">)</span> <span style=\"color: red;\">=</span> extent initVs
>     ms2 <span style=\"color: red;\">=</span> extend <span style=\"color: red;\">(</span>Any :. j<span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>massP masses<span style=\"color: red;\">)</span>
</code>
<code>> initQs <span style=\"color: red;\">::</span> PositionP U
> initQs <span style=\"color: red;\">=</span> QP $ fromListUnboxed <span style=\"color: red;\">(</span>Z :. nBodies :. I.spaceDim<span style=\"color: red;\">)</span> $ concat xs
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     nBodies <span style=\"color: red;\">=</span> length xs
>     xs <span style=\"color: red;\">=</span> <span style=\"color: red;\">[</span> <span style=\"color: red;\">[</span>earthX<span style=\"color: red;\">,</span>   earthY<span style=\"color: red;\">,</span>   earthZ<span style=\"color: red;\">]</span>
>          <span style=\"color: red;\">,</span> <span style=\"color: red;\">[</span>jupiterX<span style=\"color: red;\">,</span> jupiterY<span style=\"color: red;\">,</span> jupiterZ<span style=\"color: red;\">]</span>
>          <span style=\"color: red;\">,</span> <span style=\"color: red;\">[</span>sunX<span style=\"color: red;\">,</span>     sunY<span style=\"color: red;\">,</span>     sunZ<span style=\"color: red;\">]</span>
>          <span style=\"color: red;\">]</span>
>     <span style=\"color: red;\">(</span>earthX<span style=\"color: red;\">,</span>   earthY<span style=\"color: red;\">,</span>   earthZ<span style=\"color: red;\">)</span>   <span style=\"color: red;\">=</span> earthR
>     <span style=\"color: red;\">(</span>jupiterX<span style=\"color: red;\">,</span> jupiterY<span style=\"color: red;\">,</span> jupiterZ<span style=\"color: red;\">)</span> <span style=\"color: red;\">=</span> jupiterR
>     <span style=\"color: red;\">(</span>sunX<span style=\"color: red;\">,</span>     sunY<span style=\"color: red;\">,</span>     sunZ<span style=\"color: red;\">)</span>     <span style=\"color: red;\">=</span> sunR
</code>
<code>> masses <span style=\"color: red;\">::</span> MassP U
> masses <span style=\"color: red;\">=</span> MP $ fromListUnboxed <span style=\"color: red;\">(</span>Z :. nBodies<span style=\"color: red;\">)</span> I.massesTwoPlanets
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     nBodies <span style=\"color: red;\">=</span> length I.massesTwoPlanets
</code>
<code>> jupiterEarth <span style=\"color: red;\">::</span> <span style=\"color: red;\">[</span><span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> Double<span style=\"color: red;\">)</span><span style=\"color: red;\">,</span>
>                   <span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> Double<span style=\"color: red;\">)</span><span style=\"color: red;\">,</span>
>                   <span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> Double<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span><span style=\"color: red;\">]</span>
> jupiterEarth <span style=\"color: red;\">=</span> runIdentity $ <span style=\"color: blue; font-weight: bold;\">do</span>
>   rsVs <span style=\"color: red;\"><-</span> stepNs I.nStepsTwoPlanets I.gConst I.stepTwoPlanets
>                  masses initQs initPs
>   <span style=\"color: blue; font-weight: bold;\">let</span> qs <span style=\"color: red;\">=</span> Prelude.map fst rsVs
>       exs <span style=\"color: red;\">=</span> Prelude.map <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>!<span style=\"color: red;\">(</span>Z :. <span style=\"color: red;\">(</span><span class=\"hs-num\">0</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span> :. <span style=\"color: red;\">(</span><span class=\"hs-num\">0</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> .
>                          positionP<span style=\"color: red;\">)</span> qs
>       eys <span style=\"color: red;\">=</span> Prelude.map <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>!<span style=\"color: red;\">(</span>Z :. <span style=\"color: red;\">(</span><span class=\"hs-num\">0</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span> :. <span style=\"color: red;\">(</span><span class=\"hs-num\">1</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> .
>                          positionP<span style=\"color: red;\">)</span> qs
>       jxs <span style=\"color: red;\">=</span> Prelude.map <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>!<span style=\"color: red;\">(</span>Z :. <span style=\"color: red;\">(</span><span class=\"hs-num\">1</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span> :. <span style=\"color: red;\">(</span><span class=\"hs-num\">0</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> .
>                          positionP<span style=\"color: red;\">)</span> qs
>       jys <span style=\"color: red;\">=</span> Prelude.map <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>!<span style=\"color: red;\">(</span>Z :. <span style=\"color: red;\">(</span><span class=\"hs-num\">1</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span> :. <span style=\"color: red;\">(</span><span class=\"hs-num\">1</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> .
>                          positionP<span style=\"color: red;\">)</span> qs
>       sxs <span style=\"color: red;\">=</span> Prelude.map <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>!<span style=\"color: red;\">(</span>Z :. <span style=\"color: red;\">(</span><span class=\"hs-num\">2</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span> :. <span style=\"color: red;\">(</span><span class=\"hs-num\">0</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> .
>                          positionP<span style=\"color: red;\">)</span> qs
>       sys <span style=\"color: red;\">=</span> Prelude.map <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>!<span style=\"color: red;\">(</span>Z :. <span style=\"color: red;\">(</span><span class=\"hs-num\">2</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span> :. <span style=\"color: red;\">(</span><span class=\"hs-num\">1</span> <span style=\"color: red;\">::</span> Int<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> .
>                          positionP<span style=\"color: red;\">)</span> qs
>   return $ zip3 <span style=\"color: red;\">(</span>zip exs eys<span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>zip jxs jys<span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>zip sxs sys<span style=\"color: red;\">)</span>
</code></pre>
<p>Plotting the results we can see a reasonable picture for Jupiter’s and Earth’s orbits.</p>
<div style=\"text-align: center;\">
<p><img src=\"http://idontgetoutmuch.files.wordpress.com/2013/08/bff53ea397264e7102dcbfea33be1e22.png?w=450\" alt=\"\" /></p>
</div>
<h3 id=\"appendix-b-the-canonical-symplectic-form-for-the-cotangent-bundle\">Appendix B: The Canonical Symplectic Form for the Cotangent Bundle</h3>
<p>There are plenty of symplectic manifolds besides <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5E%7B2n%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathbb{R}^{2n}\" class=\"latex\" title=\"\\mathbb{R}^{2n}\" />. The cotangent bundle has a canonical symplectic 2-form and hence is a symplectic manifold.</p>
<p><em>Proof</em></p>
<p>Let <img src=\"http://s0.wp.com/latex.php?latex=%5Cpi+%3A+T%5E%2A+M+%5Clongrightarrow+M&bg=ffffff&fg=333333&s=0\" alt=\"\\pi : T^* M \\longrightarrow M\" class=\"latex\" title=\"\\pi : T^* M \\longrightarrow M\" /> be the projection function from the cotangent bundle to the base manifold, that is, <img src=\"http://s0.wp.com/latex.php?latex=%5Cpi%28x%2C%5Cxi%29+%3D+x&bg=ffffff&fg=333333&s=0\" alt=\"\\pi(x,\\xi) = x\" class=\"latex\" title=\"\\pi(x,\\xi) = x\" />. Then <img src=\"http://s0.wp.com/latex.php?latex=%5Cpi_%2A+%3A+T%28T%5E%2AM%29+%5Clongrightarrow+TM&bg=ffffff&fg=333333&s=0\" alt=\"\\pi_* : T(T^*M) \\longrightarrow TM\" class=\"latex\" title=\"\\pi_* : T(T^*M) \\longrightarrow TM\" /> and we can define a 1-form (the canonical or tautological 1-form) on <img src=\"http://s0.wp.com/latex.php?latex=v+%5Cin+T_%7B%28x%2C%5Cxi%29%7D%28T%5E%2A+M%29&bg=ffffff&fg=333333&s=0\" alt=\"v \\in T_{(x,\\xi)}(T^* M)\" class=\"latex\" title=\"v \\in T_{(x,\\xi)}(T^* M)\" /> as</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctheta_%7B%28x%2C%5Cxi%29%7D+%28v%29+%3D+%5Cxi%28%5Cpi_%2A+v%29++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\theta_{(x,\\xi)} (v) = \\xi(\\pi_* v)  \" class=\"latex\" title=\"\\displaystyle  \\theta_{(x,\\xi)} (v) = \\xi(\\pi_* v)  \" /></div>
<p>By definition:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpi_%2A+%5Cbigg%28%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+x_i%7D%5Cbigg%29%28f%29+%3D+%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+x_i%7D%28f+%5Ccirc+%5Cpi%29+%3D+%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+x_i%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\pi_* \\bigg(\\frac{\\partial}{\\partial x_i}\\bigg)(f) = \\frac{\\partial}{\\partial x_i}(f \\circ \\pi) = \\frac{\\partial f}{\\partial x_i}  \" class=\"latex\" title=\"\\displaystyle  \\pi_* \\bigg(\\frac{\\partial}{\\partial x_i}\\bigg)(f) = \\frac{\\partial}{\\partial x_i}(f \\circ \\pi) = \\frac{\\partial f}{\\partial x_i}  \" /></div>
<p>and</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpi_%2A+%5Cbigg%28%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+%5Cxi_i%7D%5Cbigg%29%28f%29+%3D+%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+%5Cxi_i%7D%28f+%5Ccirc+%5Cpi%29+%3D+0++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\pi_* \\bigg(\\frac{\\partial}{\\partial \\xi_i}\\bigg)(f) = \\frac{\\partial}{\\partial \\xi_i}(f \\circ \\pi) = 0  \" class=\"latex\" title=\"\\displaystyle  \\pi_* \\bigg(\\frac{\\partial}{\\partial \\xi_i}\\bigg)(f) = \\frac{\\partial}{\\partial \\xi_i}(f \\circ \\pi) = 0  \" /></div>
<p>If we then write <img src=\"http://s0.wp.com/latex.php?latex=v+%5Cin+T_%7B%28x%2C%5Cxi%29%7D%28T%5E%2AM%29&bg=ffffff&fg=333333&s=0\" alt=\"v \\in T_{(x,\\xi)}(T^*M)\" class=\"latex\" title=\"v \\in T_{(x,\\xi)}(T^*M)\" /> in co-ordinate form:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++v+%3D+a%5Ei%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+x_i%7D+%2B+%5Calpha%5Ei%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+%5Cxi_i%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  v = a^i\\frac{\\partial}{\\partial x_i} + \\alpha^i\\frac{\\partial}{\\partial \\xi_i}  \" class=\"latex\" title=\"\\displaystyle  v = a^i\\frac{\\partial}{\\partial x_i} + \\alpha^i\\frac{\\partial}{\\partial \\xi_i}  \" /></div>
<p>we have</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpi_%2Av+%3D+a%5Ei%5Cpi_%2A%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+x_i%7D+%2B+%5Calpha%5Ei%5Cpi_%2A%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+%5Cxi_i%7D+%3D+a%5Ei%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+x_i%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\pi_*v = a^i\\pi_*\\frac{\\partial}{\\partial x_i} + \\alpha^i\\pi_*\\frac{\\partial}{\\partial \\xi_i} = a^i\\frac{\\partial}{\\partial x_i}  \" class=\"latex\" title=\"\\displaystyle  \\pi_*v = a^i\\pi_*\\frac{\\partial}{\\partial x_i} + \\alpha^i\\pi_*\\frac{\\partial}{\\partial \\xi_i} = a^i\\frac{\\partial}{\\partial x_i}  \" /></div>
<p>Taking <img src=\"http://s0.wp.com/latex.php?latex=%5Cxi+%3D+%5Cxi_i+dx%5Ei&bg=ffffff&fg=333333&s=0\" alt=\"\\xi = \\xi_i dx^i\" class=\"latex\" title=\"\\xi = \\xi_i dx^i\" /> we have that</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cxi%28%5Cpi_%2Av%29+%3D+%5Cxi_i+a%5Ei++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\xi(\\pi_*v) = \\xi_i a^i  \" class=\"latex\" title=\"\\displaystyle  \\xi(\\pi_*v) = \\xi_i a^i  \" /></div>
<p>Thus we have:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctheta_%7B%28x%2C%5Cxi%29%7D+%3D+%5Cxi_i+dx%5Ei++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\theta_{(x,\\xi)} = \\xi_i dx^i  \" class=\"latex\" title=\"\\displaystyle  \\theta_{(x,\\xi)} = \\xi_i dx^i  \" /></div>
<p>We then have a closed 2-form</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Comega+%3D+d%5Ctheta++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\omega = d\\theta  \" class=\"latex\" title=\"\\displaystyle  \\omega = d\\theta  \" /></div>
<p>In co-ordinate terms:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Comega+%3D+d%5Ctheta+%3D+d+%28%5Cxi_i+dx%5Ei%29+%3D+d%5Cxi%5Ei+%5Cwedge+dx%5Ei++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\omega = d\\theta = d (\\xi_i dx^i) = d\\xi^i \\wedge dx^i  \" class=\"latex\" title=\"\\displaystyle  \\omega = d\\theta = d (\\xi_i dx^i) = d\\xi^i \\wedge dx^i  \" /></div>
<h3 id=\"bibliography\">Bibliography</h3>
<p>Cross, Matthew I. 2006. <em>Symplectic integrators and optimal control</em>. UK.</p>
<p>Fitzpatrick, Richard. 1996. “Newtonian Dynamics.” <a href=\"http://farside.ph.utexas.edu/teaching/336k/lectures\" title=\"http://farside.ph.utexas.edu/teaching/336k/lectures\">http://farside.ph.utexas.edu/teaching/336k/lectures</a>.</p>
<p>Hairer, E., C. Lubich, and G. Wanner. 2010. <em>Geometric Numerical Integration: Structure-Preserving Algorithms for Ordinary Differential Equations</em>. <em>Springer Series in Computational Mathematics</em>. Springer. <a href=\"http://books.google.co.uk/books?id=ssrFQQAACAAJ\" title=\"http://books.google.co.uk/books?id=ssrFQQAACAAJ\">http://books.google.co.uk/books?id=ssrFQQAACAAJ</a>.</p>
<p>Hudak, Paul, John Hughes, Simon Peyton Jones, and Philip Wadler. 2007. “A history of Haskell: being lazy with class.” In <em>Proceedings of the third ACM SIGPLAN conference on History of programming languages</em>, 12–1. New York, NY, USA: ACM. <a href=\"http://doi.acm.org/10.1145/1238844.1238856\" title=\"http://doi.acm.org/10.1145/1238844.1238856\">http://doi.acm.org/10.1145/1238844.1238856</a>.</p>
<p>O’Neill, B. 1983. <em>Semi-Riemannian Geometry With Applications to Relativity, 103</em>. <em>Pure and Applied Mathematics</em>. Elsevier Science. <a href=\"http://books.google.co.uk/books?id=CGk1eRSjFIIC\" title=\"http://books.google.co.uk/books?id=CGk1eRSjFIIC\">http://books.google.co.uk/books?id=CGk1eRSjFIIC</a>.</p>
<p>Yoshida, H. 1992. “Symplectic Integrators for Hamiltonian Systems: Basic Theory.” In <em>Chaos, Resonance, and Collective Dynamical Phenomena in the Solar System</em>, ed. S. Ferraz-Mello, 152:407.</p>
<br />  <a href=\"http://feeds.wordpress.com/1.0/gocomments/idontgetoutmuch.wordpress.com/509/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/idontgetoutmuch.wordpress.com/509/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=idontgetoutmuch.wordpress.com&blog=2944309&post=509&subd=idontgetoutmuch&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "6dddfdcecf6f2201b6df924b9e2272de") (349 (20993 4255 704407) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_5726\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_8428\"></span> time, whereas using the categorical functor takes time <span id=\"tex_7825\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_6307\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "76206ea2d1bc5e8cc074847f2b755e89") (348 (20992 64918 813420) "http://wadler.blogspot.com/2013/08/functional-programming-comes-to.html" "Philip Wadler: Functional Programming comes to the Edinburgh Festival" "noreply@blogger.com (Philip Wadler)" "Tue, 06 Aug 2013 10:22:37 +0000" "<div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://3.bp.blogspot.com/-OIAfcUUZ0W4/UgC9gq0BrqI/AAAAAAAAFVo/hC8IcNoOCtQ/s1600/richardcarlsson2.jpg\"><img src=\"http://3.bp.blogspot.com/-OIAfcUUZ0W4/UgC9gq0BrqI/AAAAAAAAFVo/hC8IcNoOCtQ/s1600/richardcarlsson2.jpg\" border=\"0\" /></a><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://1.bp.blogspot.com/-6KlPyD3entQ/UgC9jKLUQPI/AAAAAAAAFVw/oXsrVDPQktI/s1600/danmacklin2.jpeg\"><img src=\"http://1.bp.blogspot.com/-6KlPyD3entQ/UgC9jKLUQPI/AAAAAAAAFVw/oXsrVDPQktI/s1600/danmacklin2.jpeg\" border=\"0\" /></a><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://3.bp.blogspot.com/-4j5XvQ-NJ_k/UgC9li7DFKI/AAAAAAAAFV4/RKZ_x2-QMUM/s1600/duncancoutts2.jpg\"><img src=\"http://3.bp.blogspot.com/-4j5XvQ-NJ_k/UgC9li7DFKI/AAAAAAAAFV4/RKZ_x2-QMUM/s1600/duncancoutts2.jpg\" border=\"0\" /></a></div><br /><div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://1.bp.blogspot.com/-E1a2-O5mHuA/UgC9pJMxHBI/AAAAAAAAFWA/n3gqcF66NtU/s1600/josevalim2.jpeg\"><img src=\"http://1.bp.blogspot.com/-E1a2-O5mHuA/UgC9pJMxHBI/AAAAAAAAFWA/n3gqcF66NtU/s1600/josevalim2.jpeg\" border=\"0\" /></a><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://3.bp.blogspot.com/-8T2lWlHsU-M/UgC9rYhFn3I/AAAAAAAAFWI/jcfDSqJXGPM/s1600/ericmerritt2.jpeg\"><img src=\"http://3.bp.blogspot.com/-8T2lWlHsU-M/UgC9rYhFn3I/AAAAAAAAFWI/jcfDSqJXGPM/s1600/ericmerritt2.jpeg\" border=\"0\" /></a><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://2.bp.blogspot.com/-VIpd_PKov20/UgC9tI4JU-I/AAAAAAAAFWQ/QNGyrwSNRJM/s1600/gordonguthrie2.jpeg\"><img src=\"http://2.bp.blogspot.com/-VIpd_PKov20/UgC9tI4JU-I/AAAAAAAAFWQ/QNGyrwSNRJM/s1600/gordonguthrie2.jpeg\" border=\"0\" /></a></div><div style=\"clear: both; text-align: center;\" class=\"separator\"></div><br /><a href=\"http://mostlyfunctional.com/\">Mostly Functional</a>, a one-day event under the auspices of the <a href=\"http://turingfestival.com/\">Turing Festival</a>, comes to Edinburgh on 22 August. Talks by Richard Carlsson, Dan Macklin, Duncan Coutts, Jose Valim, Eric Merritt, Gordon Guthrie, and others.<br /><div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://3.bp.blogspot.com/-2yFv2TXetcc/UgC-uH-GFOI/AAAAAAAAFWg/QmvAaT1UkfQ/s1600/Screenshot-2.png\"><img src=\"http://3.bp.blogspot.com/-2yFv2TXetcc/UgC-uH-GFOI/AAAAAAAAFWg/QmvAaT1UkfQ/s640/Screenshot-2.png\" height=\"601\" border=\"0\" width=\"640\" /></a></div><br />" nil nil "d221fc34848848449b36c70dcd0b78a1") (347 (20992 64918 745197) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_3894\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_8423\"></span> time, whereas using the categorical functor takes time <span id=\"tex_8827\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_5001\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "529ca5fa87e0f8f55bfc26a1602267ed") (346 (20992 43976 719922) "http://kenta.blogspot.com/2013/08/wpjnajrx-type-inference-with-unknown.html" "Ken T Takusagawa: [wpjnajrx] Type inference with unknown number of parameters" "noreply@blogger.com (Ken)" "Mon, 05 Aug 2013 19:54:00 +0000" "<p dir=\"ltr\">Consider a concise programming language which not only permits omitting type signatures of functions but also omitting the parameters.  The parameters pop into existence when referred to by number within the body of the function, vaguely similar to Perl's @_ array within a sub.  (But we do not permit indexing into the list of parameters by a value not known at compile time.)</p><p dir=\"ltr\">How difficult is Hindley-Milner type inference in this situation?  Probably not much more difficult than the ordinary: simply find the largest parameter referred in the body (say 3), and start inference from a1 -> a2 -> a3 -> a4, with a4 potentially a function type.</p>" nil nil "665357dc46d65fd3ca4299dd833493b3") (345 (20992 43976 719514) "http://feedproxy.google.com/~r/blogspot/hSASX/~3/FIzkwQV1zBg/i-believe-that-code-infected-with.html" "Thiago Negri: Code infected with exceptions" "noreply@blogger.com (Thiago Negri)" "Mon, 05 Aug 2013 19:44:34 +0000" "<p>I believe that code infected with exceptions is bad. Imagine the following harmless code:
</p><pre>public static Foo newFoo(int bar) {
switch (bar) {
case 1:
return new FooOne();
case 2:
return new FooTwo();
default:
throw new IllegalArgumentException(\"invalid bar code: \" + bar);
}
}
</pre>
<p></p>
<p>You use it in the middle of your business code with ease. The code compiles and everybody is happy:
</p><pre>public static List<BazFoo> getAllBazFoo() {
List<BazFoo> result = new ArrayList<>();
List<Baz> allBaz = BazDAO.getAllBaz();
for (Baz baz : allBaz) {
int id = baz.getId();
int bar = baz.getBar();
Foo foo = Foo.newFoo(bar);
BazFoo e = new BazFoo(id, foo);
result.add(e);
}
return result;
}
</pre>
<p></p>
<p>The problem is that the call <tt>Foo.newFoo(bar)</tt> can throw an <tt>IllegalArgumentException</tt> and when this happens you will have no clue of which <tt>Baz</tt> was invalid.</p>
<p>To address this and make the message more useful, we have to remember to add a <tt>try/catch</tt> in the code:
</p><pre>public static List<BazFoo> getAllBazFoo() {
List<BazFoo> result = new ArrayList<>();
List<Baz> allBaz = BazDAO.getAllBaz();
for (Baz baz : allBaz) {
int id = baz.getId();
int bar = baz.getBar();
Foo foo;
try {
foo = Foo.newFoo(bar);
} catch (IllegalArgumentException e) {
throw new IllegalArgumentException(\"invalid baz: \" + id, e);
}
BazFoo e = new BazFoo(id, foo);
result.add(e);
}
return result;
}
</pre>
<p></p>
<p>Add multiple layers of abstraction to your application and you'r ready: spaghetti with an exceptional taste. You add an exception at some point and you will have to review the entire stack of abstractions you have to ensure that the exception does no harm to anyone and has a useful message for future maintenance.</p>
<p>Haskell solves much of the need for exceptions using returns that symbolize failures, e.g. <tt>Maybe</tt> and <tt>Either</tt>, and the use of <tt>Monad</tt> eliminates the need to check the results at each step.</p>
<p>However, there are exceptions in Haskell, why? I can not understand the reason for preferring exceptions rather than special results. In which situations is it better to use exceptions? They look like a modern <tt>goto</tt> to me.</p>
<img src=\"http://feeds.feedburner.com/~r/blogspot/hSASX/~4/FIzkwQV1zBg\" height=\"1\" width=\"1\" />" nil nil "9580526395a7cc1d08cf887bfe0fbe90") (344 (20992 43976 711953) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_2574\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_1530\"></span> time, whereas using the categorical functor takes time <span id=\"tex_7448\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_1053\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "f2092de9d97f96646e1f9d5d8db6cf63") (343 (20991 51037 366215) "http://feedproxy.google.com/~r/CartesianClosedComic/~3/mMGrYoWeRuM/21.html" "Cartesian Closed Comic: A question will be asked" nil "Sun, 04 Aug 2013 23:00:00 +0000" "<a href=\"http://ro-che.info/ccc/21.html\"><img src=\"http://ro-che.info/ccc/images/doctor.png\" /></a><br />
Seriously though, <a href=\"http://www.haskell.org/haskellwiki/Functor-Applicative-Monad_Proposal\">we're pretty close</a>
<img src=\"http://feeds.feedburner.com/~r/CartesianClosedComic/~4/mMGrYoWeRuM\" height=\"1\" width=\"1\" />" nil nil "143b724feb00a388b3aff4f1cf016816") (342 (20991 51037 281683) "http://feedproxy.google.com/~r/CartesianClosedComic/~3/Pc8C-6IJguk/20.html" "Cartesian Closed Comic: Weird language" nil "Sat, 13 Jul 2013 23:00:00 +0000" "<a href=\"http://ro-che.info/ccc/20.html\"><img src=\"http://ro-che.info/ccc/images/language.png\" /></a><br />
<img src=\"http://feeds.feedburner.com/~r/CartesianClosedComic/~4/Pc8C-6IJguk\" height=\"1\" width=\"1\" />" nil nil "8a2bf978c076ca1bfd5ea511c9ec5846") (341 (20991 47281 752806) "http://chrisdone.com/posts/esqueleto-haskelldb" "Christopher Done: Comparison: Esqueleto from a HaskellDB perspective" nil "Mon, 05 Aug 2013 00:00:00 +0000" "<p>Esqueleto looks pretty good, I’m considering using it as a modern replacement for HaskellDB. From what I’ve been able to gather, it’s different in the following ways:</p>
<ul>
<li>Seems to be a monad, but I’m not sure in what flavour</li>
<li>Doesn’t have an extensible record system (instead you use tuples)</li>
</ul>
<p>But does have the other good stuff of HaskellDB:</p>
<ul>
<li>Efficient joins</li>
<li>Can query things like COUNT(*)</li>
<li>Can do projection (good for not pulling the whole row into memory just to get one field)</li>
<li>Can be extended with functions and values (e.g. postgresql’s date/time functions, full text support, etc.)</li>
<li>It’s based on persistent so I presume it can do enums</li>
</ul>
<p>And something that HaskellDB doesn’t do:</p>
<ul>
<li>Using proper data types, so pattern matching can be used and such, rather than the HList approach in HDB</li>
</ul>
<p>As an <a href=\"http://chrisdone.com/posts/haskelldb-tutorial\">avid haskellDB user</a>, I’m serious about switching to esqueleto, so I sent the differences that I garnered above to Felipe Lessa to document somewhere, so that the next Haskeller doesn’t have to figure out the difference.</p>
<p><strong>Update:</strong> Felipe got back to me, linked me <a href=\"http://blog.felipe.lessa.nom.br/?p=68\">this</a>, I’ll summarize that and the above I wrote in a pull request for the package description later today.</p>" nil nil "8de7dc008063b7d027a53d3a206e0d75") (340 (20991 43500 818601) "http://chrisdone.com/posts/esqueleto-haskelldb" "Christopher Done: Comparison: Esqueleto from a HaskellDB perspective" nil "Mon, 05 Aug 2013 00:00:00 +0000" "<p>Esqueleto looks pretty good, I’m considering using it as a modern replacement for HaskellDB. From what I’ve been able to gather, it’s different in the following ways:</p>
<ul>
<li>Not a monad (less easy to compose)</li>
<li>Doesn’t have an extensible record system (instead you use tuples)</li>
</ul>
<p>But does have the other good stuff of HaskellDB:</p>
<ul>
<li>Efficient joins</li>
<li>Can query things like COUNT(*)</li>
<li>Can do projection (good for not pulling the whole row into memory just to get one field)</li>
<li>Can be extended with functions and values (e.g. postgresql’s date/time functions, full text support, etc.)</li>
<li>It’s based on persistent so I presume it can do enums</li>
</ul>
<p>And something that HaskellDB doesn’t do:</p>
<ul>
<li>Using proper data types, so pattern matching can be used and such, rather than the HList approach in HDB</li>
</ul>
<p>As an <a href=\"http://chrisdone.com/posts/haskelldb-tutorial\">avid haskellDB user</a>, I’m serious about switching to esqueleto, so I sent the differences that I garnered above to Felipe Lessa to document somewhere, so that the next Haskeller doesn’t have to figure out the difference.</p>" nil nil "56ffefba4f019e51cce70d7adf0645e2") (339 (20991 43500 812783) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_2115\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_7575\"></span> time, whereas using the categorical functor takes time <span id=\"tex_6447\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_6105\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "6fbb33d15759b442a2941d0c3a3c0d96") (338 (20991 33592 418937) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_7076\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_6067\"></span> time, whereas using the categorical functor takes time <span id=\"tex_9612\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_3927\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "c9addcb3baa527d6ae9d6fc17c74f797") (337 (20991 23986 430619) "https://www.fpcomplete.com/blog/2013/08/snap-happstack-anything-else" "FP Complete: Snap, Happstack and anything else" nil "Mon, 05 Aug 2013 13:30:00 +0000" "<p>This post contains fragments of active Haskell code, best viewed and executed at
<a href=\"https://www.fpcomplete.com/blog/2013/08/snap-happstack-anything-else\">https://www.fpcomplete.com/blog/2013/08/snap-happstack-anything-else</a>
</p>
<p>One of our primary goals when designing the School of Haskell was making it convenient to write up tutorials on web development.
As I’m sure many people can guess, I personally think that web development is an important domain to give proper coverage to.
And for those of you on our beta program, you’ve probably already seen that this web support extends to our IDE as well.</p><p>Since we’ve published a few tutorials on using Yesod, some people got the impression that our system supported only one web framework.
I'm here to tell you that, on the contrary, we have first class support for the two other most popular Haskell web frameworks and,
in addition, explain how our system supports web applications, and why we made the technical decisions we did.</p><p>So let's get started easily. Mike Meyer, our senior support engineer, has written up
<a href=\"https://www.fpcomplete.com/school/how-to-use-the-school-of-haskell/fpco-web\">a very straight-forward tutorial</a>
demonstrating how to run Snap and Happstack applications in the SoH. The short description is that we provide a package
called web-fpco that provides some wrapper functions to launch your code in our environment.
The FP Haskell Center (FPHC) library set provides a full complement of Happstack and Snap dependencies, so you should be able to
just change a few import statements and run your existing applications on our system.</p><p>But that really begs the question: what's the magic behind the scenes? The only real trick is that we need to
know which port the application will receive HTTP requests on, and then set up reverse HTTP proxying to forward
requests from the outside world to that user application. One approach would be to standardize on some specific
port number, or allow the user to annotate a program to let FPHC know which port to reverse proxy to. However,
that leads to two issues:</p><ul><li>There would be no way to run two servers in the same network stack. This isn't actually a problem for us at
the moment, since each user is given his/her own network stack. But it does limit our ability to scale things
in the future.</li><li>What happens when you relaunch an application? If for some reason the old version of your code didn't die
(e.g., it double-forked) and is still holding onto the old socket, you will still be talking to the old version.</li></ul><p>Instead, we went with the opposite approach: FPHC sets the <code>PORT</code> environment variable when running user code
to tell the application which port number it should listen on. This is a technique I've used in that past, and is
how both the Yesod development server and the Keter deployment system work. (And yes, we could bikeshed on the actual name
of the environment variable...)
So if you <a href=\"https://github.com/fpco/web-fpco/blob/master/Happstack/Server/Env.hs\">look at the source code for web-fpco</a>,
you'll notice that all it does is check for the <code>PORT</code> variable and then call out to the standard functions for Snap and Happstack.</p><p>FPHC sets one additional environment variable: <code>APPROOT</code> gives the base URL for the application, so that you can generate
absolute URLs from your application. The approot consists of the scheme and domain name; for FP Complete's main site,
the approot would be <code>https://www.fpcomplete.com</code> (note the lack of trailing slash).</p><p>There was one other approach I considered (I think Gregory Collins first mentioned it to me): systemd style
<a href=\"http://www.freedesktop.org/software/systemd/man/systemd.socket.html\">socket activation</a>.
Essentially, FPHC would create a listening socket for the application, <code>dup2</code> it to a well-known file descriptor like 3,
and then start the application, which would then start accepting connections from that file descriptor.
There are a few reasons we ended up going with the <code>PORT</code> environment variable approach instead:</p><ul><li>When using the School of Haskell tutorials, or the IDE built-in running of code, we use a GHCi-style execution model.
Due to the way the interpreted code is run, it would be very difficult to implement socket activation.
Our deployment system, on the other hand, could handle this just fine.
However, we want the development and deployment of applications to be as similar to each other as possible to
simplify the testing cycle for users writing code.</li><li>Our IDE automatically detects whether a piece of code runs a web interface or not, by checking if it is listening on the <code>PORT</code>
it was assigned. If FPHC started listening on the port for you, we'd have no ability to do that.
Additionally, our deployment server checks if an application has started up properly based on whether it can answer HTTP requests.
With the <code>PORT</code> approach, we can simply check if the port is being listened on. With socket activation, we'd have to make a full HTTP request.</li><li>Existing web frameworks do not have built-in support for socket activation, while they do have support for setting arbitrary port numbers.
I'm fairly certain this would be trivial to add to Warp, and I'd imagine the same is true for Snap and Happstack,
but it would make the barrier to entry for writing a web app on our system just a little bit higher.</li></ul><p>I think our system makes it easy to get up and running with web development in Haskell.
And since the underpinnings are so simple, it would even be possible to develop your own
web server on FPHC. As a trivial example, here's a <code>network-conduit</code>-based snippet
that will answer a single HTTP request.</p><pre><code class=\"haskell active web\">{-# LANGUAGE OverloadedStrings #-}
import Data.Conduit
import Data.Conduit.Network
import System.Environment
main :: IO ()
main = do
port <- fmap read $ getEnv \"PORT\"
runTCPServer (serverSettings port HostAny) $ \\appData -> do
appSource appData $$ await -- grab and ignore the request from the client
yield \"HTTP/1.0 200 OK\\r\\nContent-Type: text/plain\\r\\n\\r\\nHello World!!!\\r\\n\"
$$ appSink appData</code></pre>" nil nil "47e88759248ff0dea906b88a93f0ba96") (336 (20991 23986 429226) "http://fuuzetsu.co.uk/blog/posts/2013-08-05-adding-markup-to-Haddock.html" "Mateusz Kowalczyk: Adding bold to Haddock (part 1)" nil "Mon, 05 Aug 2013 00:00:00 +0000" "<div class=\"info\">
Posted on August  5, 2013

by Fūzetsu

</div>
<p>Today I’m going to talk about and go through implementing <strong>bold</strong> support to Haddock. I am going to be writing this as I implement it, hopefully exposing the relevant parts and order in which I do so.</p>
<p>The aim of this post is to document the process and to serve as a reference to anyone in the future wishing to add such constructs, saving them time from looking what to change and where. This post will cover adding the new element to the parser, generating tests and making the new element pass the Hspec tests. Back-end changes will be covered in a future post.</p>
<h2 id=\"adding-the-type\">Adding the type</h2>
<p>First we need to add the appropriate type to Haddock. Haddock comments are all parsed into a Doc type, conveniently residing in <code>Haddock.Types</code>.</p>
<pre class=\"sourceCode haskell\"><code class=\"sourceCode haskell\"><span class=\"kw\">data</span> <span class=\"dt\">Doc</span> <span class=\"fu\">id</span>
<span class=\"fu\">=</span> <span class=\"dt\">DocEmpty</span>
<span class=\"fu\">|</span> <span class=\"dt\">DocAppend</span> (<span class=\"dt\">Doc</span> <span class=\"fu\">id</span>) (<span class=\"dt\">Doc</span> <span class=\"fu\">id</span>)
<span class=\"fu\">|</span> <span class=\"dt\">DocString</span> <span class=\"dt\">String</span>
<span class=\"fu\">|</span> <span class=\"dt\">DocParagraph</span> (<span class=\"dt\">Doc</span> <span class=\"fu\">id</span>)
<span class=\"fu\">|</span> <span class=\"dt\">DocIdentifier</span> <span class=\"fu\">id</span>
<span class=\"fu\">|</span> <span class=\"dt\">DocIdentifierUnchecked</span> (<span class=\"dt\">ModuleName</span>, <span class=\"dt\">OccName</span>)
<span class=\"fu\">|</span> <span class=\"dt\">DocModule</span> <span class=\"dt\">String</span>
<span class=\"fu\">|</span> <span class=\"dt\">DocWarning</span> (<span class=\"dt\">Doc</span> <span class=\"fu\">id</span>)
<span class=\"fu\">|</span> <span class=\"dt\">DocEmphasis</span> (<span class=\"dt\">Doc</span> <span class=\"fu\">id</span>)
<span class=\"fu\">|</span> <span class=\"dt\">DocMonospaced</span> (<span class=\"dt\">Doc</span> <span class=\"fu\">id</span>)
<span class=\"fu\">|</span> <span class=\"dt\">DocUnorderedList</span> [<span class=\"dt\">Doc</span> <span class=\"fu\">id</span>]
<span class=\"fu\">|</span> <span class=\"dt\">DocOrderedList</span> [<span class=\"dt\">Doc</span> <span class=\"fu\">id</span>]
<span class=\"fu\">|</span> <span class=\"dt\">DocDefList</span> [(<span class=\"dt\">Doc</span> <span class=\"fu\">id</span>, <span class=\"dt\">Doc</span> <span class=\"fu\">id</span>)]
<span class=\"fu\">|</span> <span class=\"dt\">DocCodeBlock</span> (<span class=\"dt\">Doc</span> <span class=\"fu\">id</span>)
<span class=\"fu\">|</span> <span class=\"dt\">DocHyperlink</span> <span class=\"dt\">Hyperlink</span>
<span class=\"fu\">|</span> <span class=\"dt\">DocPic</span> <span class=\"dt\">Picture</span>
<span class=\"fu\">|</span> <span class=\"dt\">DocAName</span> <span class=\"dt\">String</span>
<span class=\"fu\">|</span> <span class=\"dt\">DocProperty</span> <span class=\"dt\">String</span>
<span class=\"fu\">|</span> <span class=\"dt\">DocExamples</span> [<span class=\"dt\">Example</span>]
<span class=\"kw\">deriving</span> (<span class=\"kw\">Functor</span>)</code></pre>
<p>I’ll just add <code>DocBold (Doc id)</code> and be on my way.</p>
<p>The next logical step would be to add some tests. As I wrote before, there are two test suites: <a href=\"http://hspec.github.io/\">Hspec</a> tests, which are nice, quick to run, and test that the chunks of text parse into the Doc we want, and there are HTML tests which make sure that whole files parse into what we want (acting as XHTML back-end tests). Currently there are no tests for the LaTeX back-end.</p>
<p>In <code>test/Haddock/ParseSpec.hs</code>, I’ll quickly add a few rather trivial tests that are consistent with other markup. This is effectively where you have to decide on the behaviour you want to get out of your new construct as well as the delimiters. I decided for bold to use double-underscores, <code>__</code>, as opposed to <code>*</code> or a single <code>_</code> because</p>
<ul>
<li><p>It’s consistent with pretty much all common Markdown flavours as can be seen on John MacFarlane’s brilliant <a href=\"http://johnmacfarlane.net/babelmark2/?text=__hello+world__%0A%0A*hello+world*%0A%0A_hello+world_\">Babelmark 2</a></p></li>
<li><p>Double underscores are far less common in regular text. Escaping <code>*</code> and <code>_</code> everywhere would get really tedious, really fast.</p></li>
</ul>
<p>Hopefully any bike-shedding can be avoided although don’t hesitate to <a href=\"http://fuuzetsu.co.uk/contact.html\">contact me</a> if you have some great reasons for why it shouldn’t be <code>__</code>.</p>
<p>So with that, and a quick use of <a href=\"https://github.com/magnars/multiple-cursors.el\">multiple-cursors</a> on existing emphasis tests, we now have <code>102 examples, 4 failures</code>. Before I proceed, HTML tests are in order as back-ends have to be updated for new elements, else they won’t know how to render them. We have to put some Haskell source files containing Haddock comments with bold in <code>html-test/src</code> and the expected XHTML source in <code>html-test/ref</code>. The files generated during the testing are put in <code>html-test/out</code>.</p>
<p>In this case we are lucky: emphasis is already implemented and has the same rules for where it can be position. This means we can simply write the test with emphasis, have Haddock generate the file with the right structure for us and then change all the <code><em></code> tags to <code><strong></code> tags without much fear of breaking anything.</p>
<p>So we start with this:</p>
<div class=\"figure\">
<img src=\"http://fuuzetsu.co.uk/images/bold_raw.png\" alt=\"Simple emphasis doc\" /><p class=\"caption\">Simple emphasis doc</p>
</div>
<p>and get out a HTML file that reflects the structure we want. Just change the tags in the <code>out</code> file, move it to <code>ref</code> and update our test case doc.</p>
<div class=\"figure\">
<img src=\"http://fuuzetsu.co.uk/images/bold_test.png\" alt=\"Updated doc\" /><p class=\"caption\">Updated doc</p>
</div>
<p>and with this we get a (not so nice) failing HTML test diff:</p>
<pre><code>64,66c64
< 	    >Some <strong
< 	      >bold text</strong
< 	      >.
---
> 	    >Some __bold text__.
70,72c68
< 	      > <strong
< 		>Bold</strong
< 		> in a list
---
> 	      > __Bold__ in a list
77,79c73
< 	      ><strong
< 		>bold in a definition</strong
< 		></dt
---
> 	      >__bold in a definition__</dt
85,89c79
< 	    > bold <strong
< 	      >in</strong
< 	      > a <strong
< 	      >code</strong
< 	      > block</pre
---
> 	    > bold __in__ a __code__ block</pre</code></pre>
<h2 id=\"implementation\">Implementation</h2>
<p>This time we’ll only make changes in the parser. Back-end changes will be covered in the future.</p>
<p>Let us jump to the parser first. As I mentioned before, <strong>bold</strong> is very similar to <em>emphasis</em> in where it can appear. For reference, here’s code from the current emphasis element parser</p>
<pre class=\"sourceCode haskell\"><code class=\"sourceCode haskell\">    <span class=\"co\">-- | Emphasis parser.</span>
<span class=\"co\">-- </span>
<span class=\"co\">-- >>> parseOnly emphasis \"/Hello world/\"</span>
<span class=\"co\">-- Right (DocEmphasis (DocString \"Hello world\"))</span>
<span class=\"ot\">    emphasis ::</span> <span class=\"dt\">Parser</span> (<span class=\"dt\">Doc</span> <span class=\"dt\">RdrName</span>)
emphasis <span class=\"fu\">=</span> <span class=\"dt\">DocEmphasis</span> <span class=\"fu\">.</span> <span class=\"dt\">DocString</span> <span class=\"fu\">.</span> decodeB
<span class=\"fu\"><$></span> (<span class=\"st\">\"/\"</span> <span class=\"fu\">*></span> takeWhile1 (<span class=\"ot\">`notElem`</span> <span class=\"st\">\"/\\n\"</span>) <span class=\"fu\"><*</span> <span class=\"st\">\"/\"</span>)</code></pre>
<p>With this spell in hand, let’s try to write a parser for bold:</p>
<pre class=\"sourceCode haskell\"><code class=\"sourceCode haskell\">    <span class=\"co\">-- | Bold parser.</span>
<span class=\"fu\">--</span>
<span class=\"co\">-- >>> parseOnly bold \"/Hello world/\"</span>
<span class=\"co\">-- Right (DocBold (DocString \"Hello world\"))</span>
<span class=\"ot\">    bold ::</span> <span class=\"dt\">Parser</span> (<span class=\"dt\">Doc</span> <span class=\"dt\">RdrName</span>)
bold <span class=\"fu\">=</span> <span class=\"dt\">DocBold</span> <span class=\"fu\">.</span> <span class=\"dt\">DocString</span> <span class=\"fu\">.</span> decodeB
<span class=\"fu\"><$></span> (<span class=\"st\">\"__\"</span> <span class=\"fu\">*></span> takeWhile1 (<span class=\"ot\">`notElem`</span> <span class=\"st\">\"_\\n\"</span>) <span class=\"fu\"><*</span> <span class=\"st\">\"__\"</span>)</code></pre>
<p>There’s a rather obvious problem with this (and the emphasis parser): we can’t have bold text with an underscore inside of it, even if you were to escape it (escaping strings is done during parsing and not as post-processing). Unfortunately, this is to keep consistent with the old parser: it will eat up everything as a plain string until the first character of its delimiter. You can see this behaviour easily if you try to use <code>]</code> in a title of a definition list or try to include <code>></code> in a URL that uses the <code><url></code> syntax. I am considering changing this behaviour but not until I can gather more information about already existing documentation and whether any of it would change because of this. Perhaps I’ll even make a blog post with pretty pictures and diagrams.</p>
<p>Next we actually include the parser in the same places where emphasis is allowed:</p>
<pre class=\"sourceCode haskell\"><code class=\"sourceCode haskell\"><span class=\"ot\">p ::</span> <span class=\"dt\">Parser</span> (<span class=\"dt\">Doc</span> <span class=\"dt\">RdrName</span>)
p <span class=\"fu\">=</span> mconcat <span class=\"fu\"><$></span> some (charEscape <span class=\"fu\"><|></span> monospace d <span class=\"fu\"><|></span> anchor <span class=\"fu\"><|></span> identifier d
<span class=\"fu\"><|></span> moduleName <span class=\"fu\"><|></span> picture <span class=\"fu\"><|></span> url <span class=\"fu\"><|></span> bold
<span class=\"fu\"><|></span> emphasis <span class=\"fu\"><|></span> encodedChar <span class=\"fu\"><|></span> string' <span class=\"fu\"><|></span> skipChar)</code></pre>
<p>where <code>p</code> is just a function bound in a <code>where</code> inside of a larger parser.</p>
<p>Let’s run Hspec tests.</p>
<pre><code>102 examples, 0 failures</code></pre>
<p>Awesome. With this we need to dive into the back-ends, which will be covered in a future post. Look forward to it.</p>" nil nil "3a1dccbf6bbd3d3dabc60050da3b4cbf") (335 (20991 23986 427582) "http://www.well-typed.com/blog/81" "Well-Typed.Com: Status update on GHC maintenance" nil "Sun, 04 Aug 2013 14:45:03 +0000" "<p>As many in the community are aware, our long-time colleague and co-founder Ian Lynagh is leaving for new challenges. We are of course sad to see him go and wish him all the best with his new endeavours. Since he and I founded the company together five years ago he has worked tirelessly to make it a success. It has been a privilege to work with him. It has also been great fun.</p><p>Ian has of course played an important role in the Haskell community as one of the pillars of GHC development. It is understandable that people in the community have concerns about what his departure means, so I want to give everyone an update on our plans which I hope will allay concerns.</p><p>As a company, Well-Typed is fully committed to GHC and helping Simon PJ with its development and maintenance. We are currently in the <a href=\"http://www.well-typed.com/blog//blog/80\">process of recruiting</a>. In addition, our colleague <a href=\"http://www.well-typed.com/blog//people/edsko\">Edsko</a> has already started working on GHC and he will continue during the transition period and perhaps also in the longer term.</p><p>Our plan is actually to have two people work on GHC, each about half-time. This is partly because GHC work requires a wide range of specialised skills and partly to provide a bit of variety for the people working on GHC. Ian worked primarily on GHC for seven years, but he is a bit superhuman in that respect.</p><p>Once we have determined who will be working on GHC we will make further announcements. There will inevitably be a lull in activity as Edsko gets up to speed and the new people come on board, but I am reasonably confident that this will not be too significant.</p><p>The first big challenge will be to manage the process of the GHC 7.8 release. The target is to have a release candidate available shortly before ICFP in late September, and then a final release a month or two later.</p><p>I also want to reiterate what <a href=\"http://www.haskell.org/pipermail/ghc-devs/2013-August/001818.html\">Simon has been saying recently</a>, that we have to see GHC as being owned by the community and that community involvement in GHC development and maintenance is vital. Well-Typed's roll in GHC maintenance is not to do it on behalf of the community. It is better to think of our role as like that of a full-time maintainer. A maintainer can help volunteers get their patches reviewed and merged. They provide continuity, knowledge of the codebase, can help make decisions, and can organise volunteer efforts and processes like releases.</p><p>Ian has of course shaped and defined the role, but it is not fixed in stone. Our new people working on GHC maintenance will have some scope to define the role, in consultation with Simon and the community.</p><p>I should also say that the number of volunteers working on GHC has increased noticeably since Simon PJ called on the community to get more involved following Simon Marlow's departure. This is a very promising sign and we will play our part to assist those volunteers and to encourage more people.</p><p>So all in all, <a href=\"http://www.haskell.org/pipermail/ghc-devs/2013-August/001818.html\">we agree with Simon</a> that the future of the Glorious Haskell Compiler is indeed glorious!
</p>" nil nil "812d1776a4d5435899b078cef70b540b") (334 (20991 23986 427005) "http://feedproxy.google.com/~r/blogspot/hSASX/~3/c5j8j0wtxio/book-code-simplicity.html" "Thiago Negri: Book: Code Simplicity" "noreply@blogger.com (Thiago Negri)" "Sun, 04 Aug 2013 13:52:48 +0000" "<p>I just read the book \"<a href=\"http://www.amazon.com/Code-Simplicity-The-Fundamentals-Software/dp/1449313892/ref=sr_1_1?ie=UTF8&qid=1373131429&sr=8-1&keywords=code+simplicity\">Code Simplicity: The Fundamentals of Software</a>\".</p>
<p>The author tries to build up a sciente of software development. There are about 90 pages that discuss important details of this engineering without touching a single line of code.</p>
<p>Among the issues cited by the author, the one that impressed me most was the formula for the cost of a change in software.</p>
<p>
</p><div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://4.bp.blogspot.com/-IpozUNSxcBc/Udhx3gp_9EI/AAAAAAAAATg/cy50f_L8FDE/s1600/formula.jpg\"><img src=\"http://4.bp.blogspot.com/-IpozUNSxcBc/Udhx3gp_9EI/AAAAAAAAATg/cy50f_L8FDE/s320/formula.jpg\" border=\"0\" /></a></div>
<p></p>
<p>This formula, when applied to time, makes it clear that the future value plus the cost of maintenance of a change will have a much higher weight than the immediate cost and value. As time goes by, the effort put into maintaining a feature far outweighs the initial effort to code it. I'll not go into too much detail, if you are curious: <em>go read the book.</em></p>
<p>
</p><div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://4.bp.blogspot.com/-TZEcaVVYlso/Udhx-Rm5TyI/AAAAAAAAATo/cvfjYC2OHLU/s1600/tabela1.jpg\"><img src=\"http://4.bp.blogspot.com/-TZEcaVVYlso/Udhx-Rm5TyI/AAAAAAAAATo/cvfjYC2OHLU/s320/tabela1.jpg\" border=\"0\" /></a></div>
<p></p>
<p>It was a very enjoyable read. I'm sad that I got into this book by chance, no one pointed it to me. I feel that I could have avoided a good amount of frustration that I had as a developer. The author's ideas seems to fit with all the insights I had developing and maintaining code.</p>
<p>I leave here my statement for all who work in the software field: <em>you need to read this book!</em> Regardless of writing code or not, you will have a much better basis for making decisions that affect your product.</p>
<p>If you've read, leave your comments about what you think.</p>
<img src=\"http://feeds.feedburner.com/~r/blogspot/hSASX/~4/c5j8j0wtxio\" height=\"1\" width=\"1\" />" nil nil "79760f899dda48be7b083ec36ab2b22b") (333 (20991 23986 426562) "http://feedproxy.google.com/~r/CartesianClosedComic/~3/mMGrYoWeRuM/21.html" "Cartesian Closed Comic: A question will be asked" nil "Sun, 04 Aug 2013 00:00:00 +0000" "<a href=\"http://ro-che.info/ccc/21.html\"><img src=\"http://ro-che.info/ccc/thumbs/doctor.png\" /></a><br />
Seriously though, <a href=\"http://www.haskell.org/haskellwiki/Functor-Applicative-Monad_Proposal\">we're pretty close</a>
<img src=\"http://feeds.feedburner.com/~r/CartesianClosedComic/~4/mMGrYoWeRuM\" height=\"1\" width=\"1\" />" nil nil "8d7d203ab608be88db3472bb7e9919a1") (332 (20991 23986 425932) "http://fuuzetsu.co.uk/blog/posts/2013-08-04-adding-markup-to-Haddock.html" "Mateusz Kowalczyk: Adding bold to Haddock (part 1)" nil "Sun, 04 Aug 2013 00:00:00 +0000" "<div class=\"info\">
Posted on August  4, 2013

by Fūzetsu

</div>
<p>Today I’m going to talk about and go through implementing <strong>bold</strong> support to Haddock. I am going to be writing this as I implement it, hopefully exposing the relevant parts and order in which I do so.</p>
<p>The aim of this post is to document the process and to serve as a reference to anyone in the future wishing to add such constructs, saving them time from looking what to change and where. This post will cover adding the new element to the parser, generating tests and making the new element pass the Hspec tests. Back-end changes will be covered in a future post.</p>
<h2 id=\"adding-the-type\">Adding the type</h2>
<p>First we need to add the appropriate type to Haddock. Haddock comments are all parsed into a Doc type, conveniently residing in <code>Haddock.Types</code>.</p>
<pre class=\"sourceCode haskell\"><code class=\"sourceCode haskell\"><span class=\"kw\">data</span> <span class=\"dt\">Doc</span> <span class=\"fu\">id</span>
<span class=\"fu\">=</span> <span class=\"dt\">DocEmpty</span>
<span class=\"fu\">|</span> <span class=\"dt\">DocAppend</span> (<span class=\"dt\">Doc</span> <span class=\"fu\">id</span>) (<span class=\"dt\">Doc</span> <span class=\"fu\">id</span>)
<span class=\"fu\">|</span> <span class=\"dt\">DocString</span> <span class=\"dt\">String</span>
<span class=\"fu\">|</span> <span class=\"dt\">DocParagraph</span> (<span class=\"dt\">Doc</span> <span class=\"fu\">id</span>)
<span class=\"fu\">|</span> <span class=\"dt\">DocIdentifier</span> <span class=\"fu\">id</span>
<span class=\"fu\">|</span> <span class=\"dt\">DocIdentifierUnchecked</span> (<span class=\"dt\">ModuleName</span>, <span class=\"dt\">OccName</span>)
<span class=\"fu\">|</span> <span class=\"dt\">DocModule</span> <span class=\"dt\">String</span>
<span class=\"fu\">|</span> <span class=\"dt\">DocWarning</span> (<span class=\"dt\">Doc</span> <span class=\"fu\">id</span>)
<span class=\"fu\">|</span> <span class=\"dt\">DocEmphasis</span> (<span class=\"dt\">Doc</span> <span class=\"fu\">id</span>)
<span class=\"fu\">|</span> <span class=\"dt\">DocMonospaced</span> (<span class=\"dt\">Doc</span> <span class=\"fu\">id</span>)
<span class=\"fu\">|</span> <span class=\"dt\">DocUnorderedList</span> [<span class=\"dt\">Doc</span> <span class=\"fu\">id</span>]
<span class=\"fu\">|</span> <span class=\"dt\">DocOrderedList</span> [<span class=\"dt\">Doc</span> <span class=\"fu\">id</span>]
<span class=\"fu\">|</span> <span class=\"dt\">DocDefList</span> [(<span class=\"dt\">Doc</span> <span class=\"fu\">id</span>, <span class=\"dt\">Doc</span> <span class=\"fu\">id</span>)]
<span class=\"fu\">|</span> <span class=\"dt\">DocCodeBlock</span> (<span class=\"dt\">Doc</span> <span class=\"fu\">id</span>)
<span class=\"fu\">|</span> <span class=\"dt\">DocHyperlink</span> <span class=\"dt\">Hyperlink</span>
<span class=\"fu\">|</span> <span class=\"dt\">DocPic</span> <span class=\"dt\">Picture</span>
<span class=\"fu\">|</span> <span class=\"dt\">DocAName</span> <span class=\"dt\">String</span>
<span class=\"fu\">|</span> <span class=\"dt\">DocProperty</span> <span class=\"dt\">String</span>
<span class=\"fu\">|</span> <span class=\"dt\">DocExamples</span> [<span class=\"dt\">Example</span>]
<span class=\"kw\">deriving</span> (<span class=\"kw\">Functor</span>)</code></pre>
<p>I’ll just add <code>DocBold (Doc id)</code> and be on my way.</p>
<p>The next logical step would be to add some tests. As I wrote before, there are two test suites: <a href=\"http://hspec.github.io/\">Hspec</a> tests, which are nice, quick to run, and test that the chunks of text parse into the Doc we want, and there are HTML tests which make sure that whole files parse into what we want (acting as XHTML back-end tests). Currently there are no tests for the LaTeX back-end.</p>
<p>In <code>test/Haddock/ParseSpec.hs</code>, I’ll quickly add a few rather trivial tests that are consistent with other markup. This is effectively where you have to decide on the behaviour you want to get out of your new construct as well as the delimiters. I decided for bold to use double-underscores, <code>__</code>, as opposed to <code>*</code> or a single <code>_</code> because</p>
<ul>
<li><p>It’s consistent with pretty much all common Markdown flavours as can be seen on John MacFarlane’s brilliant <a href=\"http://johnmacfarlane.net/babelmark2/?text=__hello+world__%0A%0A*hello+world*%0A%0A_hello+world_\">Babelmark 2</a></p></li>
<li><p>Double underscores are far less common in regular text. Escaping <code>*</code> and <code>_</code> everywhere would get really tedious, really fast.</p></li>
</ul>
<p>Hopefully any bike-shedding can be avoided although don’t hesitate to <a href=\"http://fuuzetsu.co.uk/contact.html\">contact me</a> if you have some great reasons for why it shouldn’t be <code>__</code>.</p>
<p>So with that, and a quick use of <a href=\"https://github.com/magnars/multiple-cursors.el\">multiple-cursors</a> on existing emphasis tests, we now have <code>102 examples, 4 failures</code>. Before I proceed, HTML tests are in order as back-ends have to be updated for new elements, else they won’t know how to render them. We have to put some Haskell source files containing Haddock comments with bold in <code>html-test/src</code> and the expected XHTML source in <code>html-test/ref</code>. The files generated during the testing are put in <code>html-test/out</code>.</p>
<p>In this case we are lucky: emphasis is already implemented and has the same rules for where it can be position. This means we can simply write the test with emphasis, have Haddock generate the file with the right structure for us and then change all the <code><em></code> tags to <code><strong></code> tags without much fear of breaking anything.</p>
<p>So we start with this:</p>
<div class=\"figure\">
<img src=\"http://fuuzetsu.co.uk/images/bold_raw.png\" alt=\"Simple emphasis doc\" /><p class=\"caption\">Simple emphasis doc</p>
</div>
<p>and get out a HTML file that reflects the structure we want. Just change the tags in the <code>out</code> file, move it to <code>ref</code> and update our test case doc.</p>
<div class=\"figure\">
<img src=\"http://fuuzetsu.co.uk/images/bold_test.png\" alt=\"Updated doc\" /><p class=\"caption\">Updated doc</p>
</div>
<p>and with this we get a (not so nice) failing HTML test diff:</p>
<pre><code>64,66c64
< 	    >Some <strong
< 	      >bold text</strong
< 	      >.
---
> 	    >Some __bold text__.
70,72c68
< 	      > <strong
< 		>Bold</strong
< 		> in a list
---
> 	      > __Bold__ in a list
77,79c73
< 	      ><strong
< 		>bold in a definition</strong
< 		></dt
---
> 	      >__bold in a definition__</dt
85,89c79
< 	    > bold <strong
< 	      >in</strong
< 	      > a <strong
< 	      >code</strong
< 	      > block</pre
---
> 	    > bold __in__ a __code__ block</pre</code></pre>
<h2 id=\"implementation\">Implementation</h2>
<p>This time we’ll only make changes in the parser. Back-end changes will be covered in the future.</p>
<p>Let us jump to the parser first. As I mentioned before, <strong>bold</strong> is very similar to <em>emphasis</em> in where it can appear. For reference, here’s code from the current emphasis element parser</p>
<pre class=\"sourceCode haskell\"><code class=\"sourceCode haskell\">    <span class=\"co\">-- | Emphasis parser.</span>
<span class=\"co\">-- </span>
<span class=\"co\">-- >>> parseOnly emphasis \"/Hello world/\"</span>
<span class=\"co\">-- Right (DocEmphasis (DocString \"Hello world\"))</span>
<span class=\"ot\">    emphasis ::</span> <span class=\"dt\">Parser</span> (<span class=\"dt\">Doc</span> <span class=\"dt\">RdrName</span>)
emphasis <span class=\"fu\">=</span> <span class=\"dt\">DocEmphasis</span> <span class=\"fu\">.</span> <span class=\"dt\">DocString</span> <span class=\"fu\">.</span> decodeB
<span class=\"fu\"><$></span> (<span class=\"st\">\"/\"</span> <span class=\"fu\">*></span> takeWhile1 (<span class=\"ot\">`notElem`</span> <span class=\"st\">\"/\\n\"</span>) <span class=\"fu\"><*</span> <span class=\"st\">\"/\"</span>)</code></pre>
<p>With this spell in hand, let’s try to write a parser for bold:</p>
<pre class=\"sourceCode haskell\"><code class=\"sourceCode haskell\">    <span class=\"co\">-- | Bold parser.</span>
<span class=\"fu\">--</span>
<span class=\"co\">-- >>> parseOnly bold \"/Hello world/\"</span>
<span class=\"co\">-- Right (DocBold (DocString \"Hello world\"))</span>
<span class=\"ot\">    bold ::</span> <span class=\"dt\">Parser</span> (<span class=\"dt\">Doc</span> <span class=\"dt\">RdrName</span>)
bold <span class=\"fu\">=</span> <span class=\"dt\">DocBold</span> <span class=\"fu\">.</span> <span class=\"dt\">DocString</span> <span class=\"fu\">.</span> decodeB
<span class=\"fu\"><$></span> (<span class=\"st\">\"__\"</span> <span class=\"fu\">*></span> takeWhile1 (<span class=\"ot\">`notElem`</span> <span class=\"st\">\"_\\n\"</span>) <span class=\"fu\"><*</span> <span class=\"st\">\"__\"</span>)</code></pre>
<p>There’s a rather obvious problem with this (and the emphasis parser): we can’t have bold text with an underscore inside of it, even if you were to escape it (escaping strings is done during parsing and not as post-processing). Unfortunately, this is to keep consistent with the old parser: it will eat up everything as a plain string until the first character of its delimiter. You can see this behaviour easily if you try to use <code>]</code> in a title of a definition list or try to include <code>></code> in a URL that uses the <code><url></code> syntax. I am considering changing this behaviour but not until I can gather more information about already existing documentation and whether any of it would change because of this. Perhaps I’ll even make a blog post with pretty pictures and diagrams.</p>
<p>Next we actually include the parser in the same places where emphasis is allowed:</p>
<pre class=\"sourceCode haskell\"><code class=\"sourceCode haskell\"><span class=\"ot\">p ::</span> <span class=\"dt\">Parser</span> (<span class=\"dt\">Doc</span> <span class=\"dt\">RdrName</span>)
p <span class=\"fu\">=</span> mconcat <span class=\"fu\"><$></span> some (charEscape <span class=\"fu\"><|></span> monospace d <span class=\"fu\"><|></span> anchor <span class=\"fu\"><|></span> identifier d
<span class=\"fu\"><|></span> moduleName <span class=\"fu\"><|></span> picture <span class=\"fu\"><|></span> url <span class=\"fu\"><|></span> bold
<span class=\"fu\"><|></span> emphasis <span class=\"fu\"><|></span> encodedChar <span class=\"fu\"><|></span> string' <span class=\"fu\"><|></span> skipChar)</code></pre>
<p>where <code>p</code> is just a function bound in a <code>where</code> inside of a larger parser.</p>
<p>Let’s run Hspec tests.</p>
<pre><code>102 examples, 0 failures</code></pre>
<p>Awesome. With this we need to dive into the back-ends, which will be covered in a future post. Look forward to it.</p>" nil nil "dec8607f0bdf46e9dc1f674346d6d37e") (331 (20991 23986 424138) "http://gentoohaskell.wordpress.com/2013/08/01/ghc-7-6-weak-symbols-and-ghci/" "The Gentoo Haskell Team: ghc-7.6: weak symbols and ghci" nil "Sat, 03 Aug 2013 08:08:59 +0000" "<p>Time to time internetz stumble upon a <strong>ghci</strong> bug which is seen as inability to load <strong>base</strong> <strong>haskell</strong> package:</p>
<pre><code>Loading package ghc-prim ... linking ... done.
Loading package integer-gmp ... linking ... done.
Loading package base ... linking ... ghc: /usr/lib64/ghc-7.4.2/base-4.5.1.0/HSbase-4.5.1.0.o: unknown symbol `stat'
ghc: unable to load package `base'</code></pre>
<p>But the bug was most popular across rare <strong>gentoo</strong> users. An interesting correlation!</p>
<p>This post is about the root of this problem: the gory implementation details of <strong>ghci</strong> dynamic loader down to <strong>libC</strong> and even <strong>ELF</strong> symbols!</p>
<p>Not scared? Fasten your belts and Read On!</p>
<p><span id=\"more-89\"></span></p>
<p><strong>GHC</strong> (<a href=\"http://www.haskell.org/ghc/\">this one</a>) is both:</p>
<ol style=\"\">
<li>a compiler (<strong>ghc</strong> binary)</li>
<li>and <strong>REPL</strong> (<strong>ghci</strong> binary)</li>
</ol>
<p>To put simplistic <strong>ghc</strong> allows you to create final binaries out of haskell sources while <strong>ghci</strong> allows runtime loading of haskell sources.</p>
<p>Typical session starts like that:</p>
<pre><code>$ ghci
GHCi, version 7.6.3: http://www.haskell.org/ghc/  <img src=\"http://s1.wp.com/wp-includes/images/smilies/icon_confused.gif\" alt=\":?\" class=\"wp-smiley\" />  for help
Loading package ghc-prim ... linking ... done.
Loading package integer-gmp ... linking ... done.
Loading package base ... linking ... done.
Prelude> <some code to evaluate></code></pre>
<p><strong>ghci</strong>‘s implementation allows loading arbitrary shared library:</p>
<pre><code>$ ghci -lpcre
GHCi, version 7.6.3: http://www.haskell.org/ghc/  <img src=\"http://s1.wp.com/wp-includes/images/smilies/icon_confused.gif\" alt=\":?\" class=\"wp-smiley\" />  for help
Loading package ghc-prim ... linking ... done.
Loading package integer-gmp ... linking ... done.
Loading package base ... linking ... done.
Loading object (dynamic) /usr/lib/gcc/x86_64-pc-linux-gnu/4.8.1/../../../../lib64/libpcre.so ... done
final link ... done
Prelude></code></pre>
<p>and even object file:</p>
<pre><code>$ echo 'void foo(){}' > a.c &&
gcc -c a.c -o a.o &&
ghci a.o
GHCi, version 7.6.3: http://www.haskell.org/ghc/  <img src=\"http://s1.wp.com/wp-includes/images/smilies/icon_confused.gif\" alt=\":?\" class=\"wp-smiley\" />  for help
Loading package ghc-prim ... linking ... done.
Loading package integer-gmp ... linking ... done.
Loading package base ... linking ... done.
Loading object (static) a.o ... done
final link ... done
Prelude></code></pre>
<p><strong>ghci</strong> libraries are basically the same object files built of many source files.</p>
<p>It took me a while reproduce the bug mentioned in the very start of the post. First time I’ve heard of a bug was in December 2012 by nand but I had no idea where it comes from.</p>
<p>First I though it was a problem of missing headers somewhere in <strong>C</strong> code due to <strong>glibc</strong> upgrade, but no matter what combinations of <strong>binutils</strong>/<strong>gcc</strong>/<strong>glibc</strong> I tried bug did not want to show up.</p>
<p>6 months after after some <a href=\"http://bugs.gentoo.org/452442\">bugs</a> got collected I’ve noticed dreadful <strong>CFLAGS=-Os</strong> common amongst reporters which was a trigger.</p>
<p>Let’s explore exported symbol difference of 2 files:</p>
<ol style=\"\">
<li>CFLAGS=-O2 <strong>/usr/lib64/ghc-7.6.3/base-4.6.0.1/HSbase-4.6.0.1.o</strong></li>
<li>CFLAGS=-Os <strong>/usr/lib64/ghc-7.6.3/base-4.6.0.1/HSbase-4.6.0.1.o</strong></li>
</ol>
<pre><code>$ nm --undefined-only /usr/lib64/ghc-7.6.3/base-4.6.0.1/HSbase-4.6.0.1.o > base-O2
$ nm --undefined-only /gentoo/chroots/amd64-unstable//usr/lib64/ghc-7.6.3/base-4.6.0.1/HSbase-4.6.0.1.o > base-Os
$ diff -U0 base-O2 base-Os
-                 U __fxstat
+                 U fstat
-                 U __lxstat
+                 U lstat
-                 U memset
-                 U __xstat
+                 U stat</code></pre>
<p>Do you see it?</p>
<p><strong>-Os</strong> build has <strong>stat</strong> call while <strong>-O2</strong> has <strong>__xstat</strong>. It was the right track.</p>
<p>Let’s try simpler example:</p>
<pre><code>cat >stat-test.c <<-EOF
#include <sys/types.h>
#include <sys/stat.h>
#include <unistd.h>
int f()
{
struct stat s;
return stat(\"/\", &s);
}
EOF</code></pre>
<pre><code>$ gcc -c stat-test.c -Os -o stat-test-Os.o
$ gcc -c stat-test.c -O2 -o stat-test-O2.o
$ nm --undefined-only stat-test-O[2s].o
stat-test-O2.o:
U __xstat
stat-test-Os.o:
U stat</code></pre>
<p>The symbols differ on different types of optimization. Let’s see if <strong>ghci</strong> treats them differently:</p>
<pre><code>$ ghci stat-test-O2.o
...
Loading object (static) stat-test-Os.o ... done
final link ... done
$ ghci stat-test-Os.o
...
final link ... ghc: a.o: unknown symbol `stat'
linking extra libraries/objects failed</code></pre>
<p>And it does! It means that <strong>__xstat</strong> comes from <strong>libc.so.6</strong>, but <strong>stat</strong> codes from somewhere else.</p>
<p>After some investivation I’ve found it’s definition:</p>
<pre><code>$ nm --defined-only --extern-only /usr/lib/libc_nonshared.a
...
stat.oS:
00000000 T __i686.get_pc_thunk.bx
00000000 W stat
00000000 T __stat
...</code></pre>
<p>We see here the file defining two symbols for us:</p>
<ol style=\"\">
<li>global weak <strong>stat</strong> (the one we really need)</li>
<li>global <strong>__stat</strong> (useless and potentially harmful as it might lead to symbol collision)</li>
</ol>
<p>Now we can build-up working <strong>stat-test-Os.o</strong> by linking that weak <strong>stat</strong> symbol to our <strong>ghci</strong>:</p>
<pre><code>$ ar x /usr/lib/libc_nonshared.a
$ mv stat.oS stat.o # ghci dislikes non-'*.o' extensions for object files
$ ghci a.o stat.o
Loading object (static) a.o ... done
Loading object (static) stat.o ... done
final link ... ghc: stat.o: unknown symbol `stat'</code></pre>
<p>Almost works! Well, no. Nothing changed. But the reason is missing support for loading weak symbols to <strong>ghci</strong>. Whick is known as <a href=\"http://ghc.haskell.org/trac/ghc/ticket/3333\">bug 3333</a>.</p>
<p>I’ve pulled series of patches by <strong>akio</strong> and actualized it to <strong>ghc-7.6.3</strong> (<a href=\"https://github.com/gentoo-haskell/gentoo-haskell/blob/master/dev-lang/ghc/files/ghc-7.6.3-trac-3333-weak-syms.patch\">the result</a>)</p>
<p>After pulling that patch into <strong>ghc</strong> I’ve got previous example to load on <strong>x86_64</strong>:</p>
<pre><code>$ ar x /usr/lib/libc_nonshared.a
$ mv stat.oS stat.o # ghci dislikes non-'*.o' extensions for object files
$ ghci a.o stat.o
Loading object (static) a.o ... done
Loading object (static) stat.o ... done
final link ... done</code></pre>
<p>Ideally, I should load all those and only those <strong>libc_nonshared.a</strong> symbols into <strong>ghci</strong> as a first library. I’ve decided to biggyback on <strong>ghc-prim</strong> module and stuff all those nonshared symbols <a href=\"https://github.com/gentoo-haskell/gentoo-haskell/blob/master/dev-lang/ghc/ghc-7.6.3-r1.ebuild#L632\">there</a>.</p>
<p>Perhaps, that bit of shell is the worst piece of code I have ever written. It weakens all needed symbols, localizes all the rest, and merges the result into <strong>ghc-prim</strong>. It also known to break on <strong>i386</strong> as I have hidden <strong>GOT</strong> and module base required for <strong>PIC</strong> code.</p>
<p><strong>ghci</strong>‘s loader interface used not only for interactive use but also for <strong>TemplateHaskell</strong> (where we have seen <strong>vector</strong> package failing to compile) thus.</p>
<p>This post is a great example why using native system’s loader is a good idea proposed in <a href=\"http://ghc.haskell.org/trac/ghc/ticket/4244\">bug 4244</a>.</p>
<p>I don’t know if it fixes all our cases but it will be way more clean than it is now.</p>
<p>If the workaround will show itself as too fragile I’ll have to roll back to force <strong>CFLAGS=-O2</strong> when building <strong>ghc</strong>.</p>
<p><strong>UPDATE:</strong> Now <strong>x86</strong> works as well: <strong>libc_nonshared.a</strong> contained <strong>PIC</strong> code thus I’ve picked implementation from <strong>libc.a</strong> <a href=\"https://github.com/gentoo-haskell/gentoo-haskell/commit/18a4a5a96c5c663799d899caab7ead6cb6534ac9\">directly</a>.</p>
<p>Our workaround even passes test from <a href=\"http://ghc.haskell.org/trac/ghc/ticket/7072\">bug 7072</a>!</p>
<br />  <a href=\"http://feeds.wordpress.com/1.0/gocomments/gentoohaskell.wordpress.com/89/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/gentoohaskell.wordpress.com/89/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=gentoohaskell.wordpress.com&blog=7667502&post=89&subd=gentoohaskell&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "5ee363253e96cd6934644eebfbc90769") (330 (20991 23986 422688) "http://winterkoninkje.dreamwidth.org/86236.html" "wren ng thornton: Commutative by construction" nil "Sat, 03 Aug 2013 06:03:16 +0000" "<p>Recently gelisam posted an article on <a href=\"http://gelisam.blogspot.ca/2013/07/the-commutative-monad.html\">a combinatorial approach to provably commutative binary operators</a>, which has <a href=\"http://www.reddit.com/r/haskell/comments/1jegxb/the_commutative_monad\">a decent discussion</a> on reddit. Here, I'm going to generalize that idea.</p>
<p><i>Edit (2013-08-03T05:06:58Z):</i> Okay, I should be done tweaking things now.</p>
<p><i>Edit (2013-08-03T06:02:40Z):</i> See also <a href=\"http://winterkoninkje.dreamwidth.org/86282.html\">the followup post</a>.</p>
<h3>Preliminary Definitions</h3>
<p>Let <code>A</code> and <code>B</code> be arbitrary types, and let κ be any non-zero cardinal number (we only really care about finite cardinals, or maybe at most aleph-naught). Let the notation <b><code>A^{κ}</code></b> denote a multiset of elements drawn from <code>A</code> with cardinality exactly κ. And let the notation <b><code>A^{<κ}</code></b> denote a non-empty multiset of elements drawn from <code>A</code> with cardinality not greater than κ.</p>
<h3>Commutative operators</h3>
<p>A <b>κ-commutative operator</b> from <code>A</code> to <code>B</code> can be thought of as a function of type <code>A^{κ} →  B</code>. For example:
</p><ul>
<li>The 1-commutative functions are all the functions of type <code>A → B</code>.</li>
<li>The 2-commutative functions are commutative binary functions, thus a subtype of <code>A → A → B</code>.</li>
<li>The 3-commutative functions are ternary functions which return the same result for all permutation orders of their arguments, thus a subtype of <code>A → A → A → B</code>.</li>
</ul><p></p>
<p>A <b>(<κ)-commutative operator</b> from <code>A</code> to <code>B</code> can be thought of as a function of type <code>A^{<κ} →  B</code>, i.e., a polymorphic function of type <code>∀λ. 0<λ<κ ⇒ A^{λ} →  B</code>. Thus, the (<κ)-commutative functions can be thought of as a family of λ-commutative functions, for all non-zero λ not greater than κ, satisfying suitable coherence conditions. However, for finite κ, a simpler representation is to think of them in terms of folds over non-empty multisets; that is, as 4-tuples:
</p><blockquote><code><pre>(C, h:A→C, f:A→C→C, g:C→B)
such that
∀a,a'∈A, c∈C. f a (f a' c) == f a' (f a c)
∀a,a'∈A.      f a (h a')   == f a' (h a)</pre></code></blockquote><p></p>
<p>Alternatively, if you are willing to include the case where <code>λ=0</code>, then use 4-tuples:
</p><blockquote><code><pre>(C, c0:C, f:A→C→C, g:C→B)
such that
∀a,a'∈A, c∈C. f a (f a' c) == f a' (f a c)</pre></code></blockquote><p></p>
<h3>Quasi-unordering pairs</h3>
<p>Gelisam's solution to the higher-order problem is to generalize unordered pairs to <b>quasi-unordered pairs</b>: which are, either an unordered pair or else some summary information about a pair which can't be unordered. The way we do this is to have an observation function we apply to each argument. If that observation function can distinguish the arguments, then we can pass the arguments to the function in a canonical order such that we do not betray the original order of the inputs. However, if we cannot distinguish the two arguments, then the best we can do is to return the observation we made on both of them— since, if we returned the actual arguments themselves then we'd betray their input order. Rather than hard-coding the choice of <code>Bool</code> as gelisam did, we can <a href=\"http://www.reddit.com/r/haskell/comments/1jegxb/the_commutative_monad/cbf4nm2\">generalize to any totally ordered set of observations</a>:
</p><blockquote><code><pre>distinguish :: Ord r ⇒ (a → r) → Commutative a (Either r (a,a))
distinguish f = Commutative $ \\ x y ↦
let fx = f x
fy = f y
in
case compare fx fy of
LT ↦ Right (x,y)
EQ ↦ Left fx
GT ↦ Right (y,x)</pre></code></blockquote><p></p>
<h3>Quasi-unordering multisets</h3>
<p>Now, we want to generalize this to multisets with any non-zero cardinality. Note, because the observations <code>r</code> are totally ordered, the observation function induces an almost-linear partial order on the original domain <code>a</code>. Assume we have some suitable <b>abstract implementation of multisets: <code>Confusion a</code></b>, which implements <code>a^{<κ}</code> for some particular κ. Because the observation function induces an order on our original domain, there exists a function:
</p><blockquote><code><pre>observe_0 :: Ord r ⇒ (a → r) → Confusion a → [Confusion a]
such that
∀ r f xs0. isOrdered (observe_0 f xs0)
where
isOrdered (xs:xss) =
(∀x,x'∈xs. f x == f x')
⋀ case xss of
[]   ↦ True
ys:_ ↦
(∀ x∈xs, y∈ys. f x < f y)
⋀ isOrdered xss</pre></code></blockquote>
That is, every element of the result is a multiset of elements which are equivalent under the observation function, and the elements of previous multisets precede the elements of subsequent multisets. That is, we can take the input multiset which is inherently unordered and return a nearly-linear DAG.<p></p>
<p>As written <code>observe_0</code> doesn't get us that far, since the implementation of multisets is abstract, and all we've done is break one multiset up into a bunch of multisets. Now, assume our multisets support the function <b><code>isSingleton :: Confusion a → Maybe a</code></b> which tells us whether a multiset is a singleton or not, and gives us the element if it is. Using this, we can strengthen our observing function to:
</p><blockquote><code><pre>observe_1 :: Ord r ⇒ (a → r) → Confusion a → [Either (Confusion a) a]
observe_1 f
= map (\\xs ↦ maybe (Left xs) Right (isSingleton xs))
. observe_0 f</pre></code></blockquote><p></p>
<p>That gets us pretty much what we want. However, in order to gain the full functionality we had in the binary case, we'd like to have some way to eliminate the remaining multisets. Probably the most general way is to define the following function which also returns the shared observation for classes of inputs which are still confused:
</p><blockquote><code><pre>observe_2 :: Ord r ⇒ (a → r) → Confusion a → [Either (r, Confusion a) a]
-- or, even better
observe_2' :: Ord r ⇒ (a → r) → Confusion a → [(r, Either (Confusion a) a)]</pre></code></blockquote>
We could implement this in terms of <code>observe_0</code>, however, that means we'd be calling the observation function redundantly since <code>observe_0</code> throws away the results. Thus, it's more efficient to just implement this version directly, in lieu of implementing <cocd>observe_0 at all. The overall complexity will be the same and this version is strictly more powerful.</cocd><p></p>
<p>If we're returning the result of observing those confusion sets, then why bother returning the confusion set too? The reason is that this way we can apply our observing function again in order to further distinguish those confusion sets. Therefore, this version is complete for composition of observation functions whereas the version that discards the confusion set is not.</p>
<p>And, as a final note, we'd also want to ensure that our multisets support the operation <b><code>size :: Confusion a → Cardinal</code></b>; otherwise, we need to return a triple of the multiset, its size, and its observation. The binary case could avoid this detail since there all confusion sets must be of cardinality 2.</p><br /><br /><img src=\"http://www.dreamwidth.org/tools/commentcount?user=winterkoninkje&ditemid=86236\" alt=\"comment count unavailable\" height=\"12\" style=\"vertical-align: middle;\" width=\"30\" /> comments" nil nil "1933b4e09d9917203d0741f106571c75") (329 (20991 23986 421217) "http://winterkoninkje.dreamwidth.org/86282.html" "wren ng thornton: More commutative operators" nil "Sat, 03 Aug 2013 06:02:14 +0000" "<h3>The final API for (<κ)-commutative operators</h3>
<a href=\"http://winterkoninkje.dreamwidth.org/86236.html\">Last time</a> I talked about generalizing the notion of quasi-unordered pairs to the notion of quasi-unordered multisets. The final API from last time was:
<blockquote><code><pre>type Confusion :: * → *
isSingleton :: Confusion a → Maybe a
size :: Confusion a → Cardinal
observe :: Ord r ⇒ (a → r) → Confusion a → [(r, Either (Confusion a) a)]</pre></code></blockquote>
<p>Now, every function of type <code>Confusion a → b</code> is guaranteed to be a (<κ)-commutative operator, where κ is implicitly given by the definition of <code>Confusion</code>. However, we have no way to construct the arguments to those functions! We need to add a function <b><code>confuse :: ∀λ. 0<λ<κ ⇒ Vector a λ → Confusion a</code></b> so that we can construct arguments for our (<κ)-commutative operators. Of course, rather than using bounded quantification and the <code>Vector</code> type, it'd be a lot easier to just define a type which incorporates this quantification directly:
</p><blockquote><code><pre>data BoundedList (a::*) :: Nat → * where
BLNil  :: BoundedList a n
BLCons :: a → BoundedList a n → BoundedList a (1+n)
data NonEmptyBoundedList (a::*) :: Nat → * where
NEBLSingleton :: a → NonEmptyBoundedList a 1
NEBLCons      :: a → NonEmptyBoundedList a n → NonEmptyBoundedList a (1+n)</pre></code></blockquote>
Now we have:
<blockquote><code><pre>confuse :: NonEmptyBoundedList a κ → Confusion a
type Commutative a b = Confusion a → b
runCommutative :: Commutative a b → NonEmptyBoundedList a κ → b
runCommutative f xs = f (confuse xs)</pre></code></blockquote><p></p>
<p>Ideally, we'd like to take this a step further and have a version of <code>runCommutative</code> which returns a variadic function of type <code>a → ... a → b</code> for the appropriate number of arguments. This way we'd be able to call them like regular curried functions rather than needing to call them as uncurried functions. There are a number of ways to do variadic functions in Haskell, but discussing them would take us too far afield. Naturally, implementing them will amount to taking advantage of the 4-tuple for folding over multisets, which was defined last time.</p>
<h3>Handling κ-commutative operators</h3>
<p>Continuing the theme, suppose we really want to handle the case of κ-commutative operators rather than (<κ)-commutative operators. For simplicity, let's restrict ourselves to finite κ, and let's pretend that Haskell has full dependent types. If so, then we can use the following API:
</p><blockquote><code><pre>type Confusion :: * → Nat → *
extractSingleton :: Confusion a 1 → a
size :: Confusion a n → Nat
size _ = n
data ConfusionList (r, a :: *) :: Nat → * where
CLNil  :: ConfusionList r a 0
CLCons :: r → Confusion a n → ConfusionList r a m → ConfusionList r a (n+m)
observe :: Ord r ⇒ (a → r) → Confusion a n → ConfusionList r a n
confuse :: Vector a (1+n) → Confusion a (1+n)
type Commutative a n b = Confusion a n → b
runCommutative :: Commutative a n b → Vector a n → b
runCommutative f xs = f (confuse xs)</pre></code></blockquote><p></p><br /><br /><img src=\"http://www.dreamwidth.org/tools/commentcount?user=winterkoninkje&ditemid=86282\" alt=\"comment count unavailable\" height=\"12\" style=\"vertical-align: middle;\" width=\"30\" /> comments" nil nil "0782a277f0d66ae9d9ef46c8aeb1f47e") (328 (20991 23986 368093) "http://chrisdone.com/posts/haskell-homepage-thoughts" "Christopher Done: Haskell Home Page: Food for Thought" nil "Sat, 03 Aug 2013 00:00:00 +0000" "<p><strong>Update</strong>: It seems that we are in agreement on the theme. I’ve begun <a href=\"http://www.haskell.org/haskellwiki/Brand\">a HaskellWiki page</a> prescribing the brand, and guides of how to migrate or design existing sites in this theme.</p>
<p>There are points that need to be agreed upon by the community:</p>
<ul>
<li>The palette</li>
<li>The target audience</li>
</ul>
<h2 id=\"palette-theme\">Palette & Theme</h2>
<p>We used to have a palette of green and purple:</p>
<ul>
<li><a href=\"http://www.haskell.org/haskell-symposium/Images/HaskellLogo.gif\">Old logo</a> — old palette</li>
<li><a href=\"http://haskellwebnews.files.wordpress.com/2009/12/haskell-logo-variation.png?w=500\">New logo</a> — old palette</li>
<li><a href=\"http://www.haskell.org/wikiupload/7/7d/Platform.png\">Haskell Platform logo</a> — subdued old palette</li>
</ul>
<p>Now we have randomness:</p>
<ul>
<li><a href=\"http://www.haskell.org/wikistatic/haskellwiki_logo.png\">New logo, haskell.org</a> — grey palette</li>
<li><a href=\"http://www.haskell.org/platform/\">New logo, haskell.org/platform</a> — blue palette</li>
</ul>
<p>Haskell sites have no consistent common palette or theme:</p>
<ul>
<li><a href=\"http://www.haskell.org/haskellwiki/Haskell\">Haskell.org</a> — grey, blue and orange</li>
<li><a href=\"http://hackage.haskell.org/packages/archive/lens/3.9.0.2/doc/html/Control-Exception-Lens.html\">Haddock</a> — grey, blue and orange</li>
<li><a href=\"http://hackage.haskell.org/packages/hackage.html\">Hackage</a> — no particular palette</li>
<li><a href=\"http://lpaste.net/\">λ Paste</a> — old palette</li>
<li><a href=\"http://tryhaskell.org/\">Try Haskell</a> — old palette</li>
<li><a href=\"http://haskellnews.org/\">Haskell News</a> — bootstrap palette</li>
<li><a href=\"http://www.haskell.org/onlinereport/haskell2010/\">Language report</a> — zero palette</li>
<li><a href=\"http://www.haskell.org/hoogle/\">Hoogle</a> — purple</li>
<li><a href=\"http://holumbus.fh-wedel.de/hayoo/hayoo.html\">Hayoo</a> — google</li>
<li><a href=\"http://planet.haskell.org/\">Planet Haskell</a> — no particular theme</li>
<li><a href=\"http://haskellers.com/\">Haskellers</a> — red and blue</li>
</ul>
<h2 id=\"audience\">Audience</h2>
<p>The target audience can be:</p>
<ul>
<li>Existing Haskell users</li>
<li>Programmers interested in Haskell</li>
<li>Businesses interested in Haskell</li>
</ul>
<p>Our existing sites target:</p>
<ul>
<li>Haskell.org — programmers interested in Haskell</li>
<li>Haddock — our haddocks mostly target experiences Haskellers, with little tutorial or example in the general</li>
<li>Hackage — seems to target Haskell newbies who’ve never heard of Cabal</li>
<li>λ Paste — general functional programmers wanting to paste something</li>
<li>Try Haskell — complete Haskell newbies</li>
<li>Haskell News — anyone interested in Haskell</li>
<li>Language report — unclear, anyone?</li>
<li>Hoogle — people who are new to Hoogle, but already know Haskell</li>
<li>Hayoo — general Haskellers</li>
<li>Planet Haskell — anyone interested in Haskell</li>
<li>Haskellers — business</li>
<li>FP Complete — business</li>
</ul>
<h2 id=\"next-steps\">Next steps</h2>
<p>The next steps are:</p>
<ul>
<li>Decide on a theme</li>
<li>Use that theme across the board</li>
<li>Consolidate the audiences and make clear navigation paths between the subsites</li>
<li>Make haskell.org sell itself better to the audience we decide it should aim at</li>
</ul>
<p>Here is Bootstrap (which serves as a very good template for testing themes), re-themed with whatever I’ve been able to garner—which sopvop says is called Ocean—as being a theme (colors, some borders and heading font) from haskell.org:</p>
<ul>
<li><a href=\"http://tryhaskell.org/ocean/\">Ocean</a></li>
</ul>
<p><a href=\"http://tryhaskell.org/haskell-font/\">Here is an icon font for Haskell.</a></p>
<h2 id=\"layout\">Layout</h2>
<p>The layout of the page is something that can come later and follow naturally from the two points outlined above.</p>" nil nil "52349a7079c494c7b46e4a20620cb413") (327 (20991 23986 366775) "http://fuuzetsu.co.uk/blog/posts/2013-07-30-first-month-with-haddock.html" "Mateusz Kowalczyk: First month with Haddock" nil "Tue, 30 Jul 2013 00:00:00 +0000" "<div class=\"info\">
Posted on July 30, 2013

by Fūzetsu

</div>
<p>As per the <a href=\"https://gist.github.com/Fuuzetsu/81253ba7d0c51ac88052\">original proposal</a>, over the last couple of weeks I have been hacking on Haddock. I will talk a bit on where we currently stand, what has been achieved, what hasn’t and what’s next. While the proposal wasn’t originally my idea, I will do my best to expose the reasoning behind it.</p>
<p>Note: This is written in from of me talking about my personal experience with Haddock. If all you want are some hard facts on what’s implemented, what isn’t, what’s planned, I recommend you skip to the <a href=\"http://fuuzetsu.co.uk/blog/atom.xml#shortversion\">overview</a>. The <a href=\"http://fuuzetsu.co.uk/blog/atom.xml#tests\">Tests</a> subsection might also interest you. This first post is long because it outlines a large chunk of time. Future posts should be considerably shorter and about a specific area of the project rather than about the project as a whole.</p>
<p>The first couple of weeks were spent on reading the source. Unfortunately Haddock is quite tightly bound to GHC which means that I had to do a lot of GHC source diving as well just to get my grips on the situation. I recommend reading the <a href=\"http://ghc.haskell.org/trac/ghc/wiki/Commentary\">GHC commentary</a> if you haven’t already as it’s fairly informative. I think the main surprise to me was that Haddock gets comment strings right from GHC. I guess that I always thought that Haddock was simply ripping these right out of the source files.</p>
<h1 id=\"parser-change\">Parser change</h1>
<p>The very first point of the proposal was to re-implement the existing parser with a new, more powerful one. Alex and Happy are currently used to generate the lexer and the parser at compile time. There are following problems:</p>
<ul>
<li><p>Both Alex and Happy work using grammars. While grammars are nice things to use, they aren’t very nice things to modify. We have to specify a grammar for both, the lexer and the parser separately, and any changes we want to make have often have to be reflected in both. Worse, the lexer and parser grammars don’t have a clear overlap in structure so it’s difficult to decide where the grammar has to change to accommodate our needs.</p></li>
<li><p>Backtracking is rather limited. There were previously attempts to implement auto-linking and from what I can gather, the implementation was too complex to actually be worth the time and effort. With a new parser, this limitation would be removed and we could freely look back at the just-parsed sections and even run additional parsers on these.</p></li>
</ul>
<p>With these two main points in mind, Attoparsec was chosen with hopes that parser combinators will provide a cleaner, more maintainable and extendable implementation. As a downside, it depends on Data.Text which is currently not in in GHC boot library. Fortunately, it also has a ByteString version which lets us avoid the problem.</p>
<p>A word of advice: if you ever move around modules in an existing project, or even add some new ones, make sure to update your cabal file because all you’re going to get are weird linker errors at the end of the build with no indication of what’s wrong.</p>
<p><a id=\"tests\"></a></p>
<h2 id=\"tests\">Tests</h2>
<p>When time to code actually came and I got GHC HEAD going (this is unfortunately a must for Haddock hacking. On an upside, you get all the cool HEAD stuff like TypeHoles), I very quickly realised that running tests was a major pain. There are two test suites: HTML tests and Hspec tests. HTML tests are just short Haskell modules that we compile, generate documentation for and diff with reference, known-good HTML files. This means going to the shell, compiling haddock, running‘cabal test’, waiting for the other test-suite to run first and examining output. Even worse, if anything is actually wrong, you don’t even get told which file it’s in and you have to grep for the elements of the output.</p>
<p>Hspec tests are the nice kind. The kind that you can load into GHCi and whenever you’re ready, simply ‘:r’ and ‘main’ to get a coloured output and clear indication of what’s failing. The downside is that there were only about 5 cases there which means that you often passed these only to fail on HTML tests later. If at all possible, it’d be nice to fail early, before going out to the shell and doing all the tedious stuff. My first remedy to this was less-than-pretty.</p>
<p>I added trace statements to the part of the program that takes in strings and outputs our internal format (nested ‘Doc’ structure). With this, and a couple of minutes with emacs macros, I soon had hundreds of (rather redundant) Hspec tests without going out to the shell. I have later removed the redundancies and split them up into nice categories. This way we actually had some tests. I should note that there’s one more type of testing I like to do and that is to download existing, large libraries that compile both with HEAD and stable, generating docs for them and then diffing the two. If this passes then I feel fairly confident that nothing major got broken. <a href=\"http://hackage.haskell.org/package/hxt\">HXT</a> was pretty good for this. Any problems discovered this way would go right into Hspec tests which is how the test-suite has naturally grown into ~75 reasonable test cases.</p>
<h1 id=\"implementation\">Implementation</h1>
<p>My first one-pass attempt failed horribly. I could not reproduce the behaviour of the original program. A lot of the grammar seems to have been written for Alex and Happy: that is, the syntax was designed for easy parsing to those rather than coming up with the syntax first, independently of the tool used.</p>
<p>Defeated and already a fair amount of time into the coding stage, I have changed my approach. The initial attempt at this resulted in what was very much a grammar implementation using Attoparsec using some custom combinators for state transition (for the lexing) and backtracking with lists (for the parser). As you can imagine, this doesn’t gain us much over the original program but the hopes were that it will be easier to transition from this into a single pass than it would be to do so straight away. While implementing a few new features with this parser and writing few more tests for those, the time came where a single-pass parser was necessary. I have met with the same problems as initially (trying to combine two grammars into a single-pass parser combinator implementation) but have recently received guidance which made a large amount of these issues go away and made the implementation far more idiomatic in respect to using parser combinator approach. This parser is nearly finished (and probably would have been if I didn’t choose to write this post instead). It’s worth noting that this parser will bring a couple of changes and will therefore no longer be 100% compatible with the old one. More syntax will be allowed and no old syntax will be disallowed which means that old documentation should be safe to generate with this new parser without fear of breaking it.</p>
<p>While I have spent a huge majority of my time in the parser part of the program, I suspect that features such as GADTs and type families which are scheduled to be added in the future will take me well outside this area, potentially into the GHC source again. You can expect blog posts about those if they turn out to be interesting enough to post about.</p>
<p><a id=\"shortversion\"></a></p>
<h1 id=\"overview\">Overview</h1>
<p>Note that everything denoted below is not yet in the Haddock tree. Announcement will be made when the changes are pushed upstream.</p>
<ul>
<li><p>A 100% compatible parser has been written. This unfortunately suffers from poor implementation and split into a lexer and parser.</p></li>
<li><p>New, single-pass parser (Attoparsec) nearly complete. As of writing, there are 5 more test cases failing. This is simply because I started writing this version about 20 hours ago and it’s missing some features. Should be done very soon. This parser no longer has the same behaviour as the original, extending and changing the syntax and its rules. All old documentation should render as it did before unless it happens to hit any of the new additions. It should not be an issue at all.</p></li>
<li><p>Tens of new test cases were added. Travis CI was set up to help with the testing but is currently not running due to lack of GHC HEAD binaries. It is unreliable to try and build GHC HEAD during the testing stage.</p></li>
<li><p>Couple of no-longer-relevant on Haddock Trac were closed.</p></li>
<li><p>List entries no longer have to be separated by empty lines. Note that different kinds of lists <em>do</em> have to be separated by empty lines, by design.</p></li>
<li><p>Not preceding an example or birdtracks by an empty line block is no longer a parse error: they will simply be rendered as regular strings.</p></li>
<li><p>Opening a definition list with a square bracket and not closing it on the same line (therefore forming a valid definition list) is no longer a parse error. The square bracket will be treated as a regular character and will not need to be escaped.</p></li>
<li><p>You can now specify titles for your images as you would with URLs. The old <code><<foo.png>></code> image syntax now denotes an image without a title. <code><<foo.png bar>></code> denotes an image ‘foo.png’ with a title ‘bar’. Changes to the HTML and LaTeX backends were made to accommodate this. The markup generated for images without a title is identical to what it was before (no empty <code>title</code> attributes).</p></li>
<li><p>Naive URL auto-linking is now in place. Any text starting with <code>ssh://</code>, <code>http://</code>, <code>https://</code>, <code>ftp://</code> or <code>gopher://</code> until a first white space character will be treated as a URL. It is not possible to give such URL a title. No validation is done on the URL, to keep the parser simple (but it has been coded and if this simple approach proves problematic, might be put in) save for splitting trailing single-character punctuation. This is only in effect wherever URLs with the <code><example.com title></code> syntax are accepted.</p></li>
<li><p>Module names (that is, strings between double quotes) are now only accepted if they clearly aren’t syntactically incorrect. That is, enclosing strings that contain spaces or don’t start with a capital letter in double quotes will no longer result in a hyperlink being created. Note that these aren’t checked for actual validity or existence by GHC so links to non-existent modules are still possible.</p></li>
</ul>
<h2 id=\"plans\">Plans</h2>
<ul>
<li><p>GADT support is still planned as per the proposal.</p></li>
<li><p>Markdown support is still planned as per the proposal.</p></li>
<li><p>Bold text</p></li>
<li><p>The module header will no longer require that the fields are in strict order. If you know why this limitation was imposed save for implementation convenience, please <a href=\"http://fuuzetsu.co.uk/contact.html\">contact me</a>.</p></li>
<li><p>The proposal states support for type families will be implemented. While I don’t have plans to back out of this, there was some code committed by GHC HQ recently to do with type families. I have not reviewed the code carefully yet but I believe it makes this job easier.</p></li>
<li><p>The proposal states that the image tags should be made relative and that flags should be created to allow us to provide these separately. I have to admit that this is of lower priority to me than other tasks and I haven’t heard much (or any) demand for this feature.</p></li>
<li><p>Documentation has to be updated. All the new features have to be documented and even some old features which still aren’t (such as the <code><<img>></code> tag) and uploaded on haskell.org.</p></li>
</ul>
<p>Any syntax extensions are unlikely to break any existing documentation.</p>" nil nil "bda30f92234b1e0fdfe03046c652f9d0") (326 (20991 23986 364429) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_2569\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_9920\"></span> time, whereas using the categorical functor takes time <span id=\"tex_5158\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_4936\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "05f3280c525c92c3ecd108d6d860c96f") (325 (20991 23986 359907) "https://www.fpcomplete.com/blog/2013/07/academic-accounts" "FP Complete: FP Complete Announces Free Academic Accounts" nil "Thu, 25 Jul 2013 19:30:00 +0000" "<p>We are pleased to announce our free academic program where faculty members and students from accredited institutions can use <a href=\"http://feeds.feedburner.com/business/haskell-center/overview\"><b>FP Haskell Center</b></a> for free. You can get your free account through a simple web sign-up form starting in mid-August, right before FP Haskell Center becomes generally available in early September.  If you haven’t already, you can get started now by <a href=\"http://feeds.feedburner.com/business/designer-ide\"><b>signing up</b></a> for the Beta.</p><p>With many tutorials and sample code included in the product, <a href=\"http://feeds.feedburner.com/business/haskell-center/overview\"><b>FP Haskell Center</b></a> provides both teachers and students with an accessible cloud-based platform to teach/learn, perform Haskell research, and develop real-world solutions.</p><p>FP Haskell Center is an integrated development and deployment environment written in Haskell. It consists of two components: the FP Development Environment and the FP Application Server. The FP Development Environment includes a Haskell compiler and a continually updated set of vetted, tested and supported libraries and code templates. There is no need to run Cabal or other installers. The FP Application Server is used to deploy and run Haskell applications directly in the cloud.</p><p>Crescat scientia; vita excolatur!*</p><p>* \"Let knowledge grow; life is perfected.\"</p>" nil nil "2bbb719bb863b99685e15b01cb73f582") (324 (20991 23986 354160) "https://www.fpcomplete.com/blog/2013/07/ide-stackage" "FP Complete: IDE and Stackage" nil "Wed, 17 Jul 2013 20:00:00 +0000" "<p>As most of you know by now, at FP Complete we’ve just launched the beta
of the FP Haskell Center, our integrated development and deployment
environment. We’ve been letting people onto the system over the past few
weeks. For those of you waiting for your beta invitation, you can get a
more immediate idea of what we’re offering by viewing the
screencast. But in this blog post, I want to talk about
some of the work that’s going on behind the scenes, what it means for
our users, and how it will benefit the greater Haskell community.</p><p>Not interested in my analysis of the problems, and just want to hear how
we’ll solve them? Feel free to <a href=\"http://feeds.feedburner.com/fpcomplete#vision\">skip ahead</a>.</p><h1>Current issues</h1><p>The set of functionality that we’ve included in our product has not been
randomly thrown together. Gregg has spent a lot of time talking with
people with existing Haskell setups to ascertain the major pain points,
and we’ve tailored our offering to solve as many of those problems as
possible.</p><p>You’ve already seen a few of our solutions: an integrated development
environment paired with an application deployment server, an interactive
learning system, and a higher emphasis on user-friendly documentation
and code samples. I’d like to talk right now about a different set of
issues we’re trying to solve, a set that probably isn’t so obvious at
first glance.</p><h2>Dependency conflicts (“Cabal hell”)</h2><p>Almost anyone who has been using Haskell for any length of time has run
into some kind of library dependency conflict. These situations often
get labeled as “Cabal hell,” but to be fair the issue is rarely related
to Cabal itself. Managing dependencies between many different libraries
is a difficult task. This isn’t Haskell specific; these problems exist
in other languages as well.</p><p>Nonetheless, getting a set of packages built and coexisting that can all
be used simultaneously can be a daunting task, and is something we want
to provide a solution to.</p><h2>Libraries are fast-moving targets</h2><p>One of the great strengths of the Haskell community is the tendency to
solve problems the right way. If a problem is found with an existing
approach, the default response tends to be to fix the library, even if
it means a breaking change. This leads to fast iteration and high
quality libraries. The downside is it can be a pain to stay on top of
the latest version of all libraries. (And related to the previous point,
it can be difficult to get all downstream dependencies to update to the
newest version of an upstream package.)</p><p>The solution for end users could be to just stick with old versions of
libraries. That, however, brings us to our next point.</p><h2>Lack of bugfixes for older releases</h2><p>Virtually every package on Hackage is volunteer maintained. It is
difficult enough to maintain a single version of your library.
Maintaining older versions as well can be overwhelming. But that’s
exactly what people need: stable versions of libraries which still
receive backported bugfixes. This is commonplace in many parts of the
software world, both open and closed source. We simply haven’t gotten to
that point in the Haskell world yet.</p><h2>Non-trivial to get started</h2><p>Assuming you could solve all the other problems listed, getting set up
to start coding can be non-trivial. You need to install your tool chain
correctly, which presents a number of questions:</p><ol><li>Do you use your distribution’s copy of GHC, or install your own
copy?</li><li>Do you use the Haskell Platform, or just cabal install all your
dependencies?</li><li>Should you use plain cabal, cabal-dev, or hsenv?</li></ol><p>And you’ll almost certainly need to perform some task for which you
don’t know which library is the right library. How do you determine
which one to use? How do you know that it will be compatible with the
rest of your library set?</p><h1 id=\"vision\">Our vision for customers</h1><p>We’ve thought long and hard about how to make Haskell an easier language
to get up-and-running with, and have started putting together a vision
for our customers. Let me share this vision, and then nail down <a href=\"http://feeds.feedburner.com/fpcomplete#how-we-get-there\">the
concrete steps we’ll take to get to that point</a>.</p><h2>Stable libraries</h2><p>Since the launch of the School of Haskell, we’ve provided a large and
growing set of libraries on our servers. This library set is going to be
available for all of our IDE users as well. The important thing to note
is that at no point did you have to manually install any packages.
System libraries are available, dependencies installed, and conflicting
versions resolved.</p><p>The final component which is missing is stability. Currently, our
libraries update on a regular basis. We will be taking snapshots of this
library set and providing them as options to our users. We will only
include bug fixes into these libraries as necessary. This will provide
users with the ability to start developing software and not worry that
they’ll have to rewrite their code to stay up-to-date with security and
bug fixes.</p><h2>Bleeding edge for those who want it</h2><p>While we will recommend these stable libraries for most users, we will
continue to offer our bleeding-edge library set as well. This will allow
users to try out the newest versions of libraries. This will also allow
our system to remain as inclusive as possible. Anyone who wants to get a
new library into our system just needs to <a href=\"https://github.com/fpco/stackage/wiki/Maintainers-Agreement\">send a pull
request</a>,
and at our next bleeding-edge build, the library will be available. And
any packages that make it into our bleeding edge will also be
snapshotted at our next stable library build.</p><p>Note that there are a few reasons why a library may not be included on
our system even after a pull request. The most obvious is if the package
doesn’t build. But more subtle issues are licensing concerns, security
flaws, or naming conflicts with existing code. These situations are
rare, however, and can usually be worked around easily.</p><h2>Recommendations/tutorials (for those who need it)</h2><p>While we try to provide as many packages as possible in our
environments, we’re also aware that this much choice can be
overwhelming. Therefore, we will be selecting some libraries to be our
recommended solutions to some problem domains. The purpose here is
not to tell seasoned Haskellers how to write their code. Instead, we
want new users to have a simple path to follow from “I have a problem”
to “I have a solution.”</p><p>In addition to the <a href=\"https://www.fpcomplete.com/school/ide-tutorials/recommended-libraries\">recommended library
list</a>,
we will be providing two other advantages to sticking with our
recommended libraries: a higher level of customer support (including bug
fixing), and more training material on using these libraries.</p><p><a href=\"http://feeds.feedburner.com/fpcomplete\"></a></p><h1 id=\"how-we-get-there\">How we get there</h1><p>You know the problems we want to solve, and you know how we want the
solutions to look. The question remaining is how to implement them.</p><h2>Stackage</h2><p>The most publicly-visible work we’ve done towards solving the problems
listed has been the Stackage project. Stackage is a project aiming to
make it possible to build stable, vetted sets of packages. You can read
more about the project and its goals in the <a href=\"http://www.yesodweb.com/blog/2012/11/stable-vetted-hackage\">Stackage release
announcement.</a></p><p>For a while I’ve wanted to share more details about how we’re using
Stackage and how I see it fitting into the existing ecosystem, but I’ve
waited until things of settled down and the answer could be reliable.
Fortunately we’re at that point now.</p><p>Stackage is really two things in one:</p><ol><li>A set of tools for building and testing a set of libraries.</li><li>A community driven ecosystem for creating a list of libraries that
should be installable together, and the communication infrastructure
for letting package authors know when there’s a problem.</li></ol><p>We use Stackage internally to build all of our package databases.
Stackage itself, however, is not such a database. Said another way,
Stackage is not a competitor to something like Debian’s Haskell
packages; instead, Stackage is a tool that could be used to build the
Debian package set. Stackage is also not a competitor to the Haskell
Platform; the HP is a set of vetted and reviewed packages. Stackage is a
community process that allows any package to be included, and only cares
about the coexistence.</p><p>Just as a member of the Haskell community and a package maintainer, I
think Stackage has been a big success. There are currently over 400
packages built by Stackage. Numerous bugs and incompatibilities have
been reported back to upstream maintainers, giving maintainers more
prompt and reliable feedback, and improving the quality of packages
across the board for Haskellers. If Stackage did nothing more than it
does today, I think it would have earned its keep.</p><p>But I do hope to see it continue improving. I’ve discussed having
Stackage used as part of the distribution maintainer toolset in the
past, and while those conversations have stalled, I hope they resume. I
also hope the community gets more involved. At the time of writing,
there are 5292 packages available on Hackage. I’d like to see
more of them included in Stackage, so if you maintain any
Hackage packages that aren’t on Stackage, I encourage you to submit
them.</p><h2>Working with upstream</h2><p>My work on Stackage has put me in a position to interact quite regularly
with upstream package maintainers. I want to clarify exactly how we’ll
be interacting with the community.</p><h3>Monitor security problems</h3><p>We take security very seriously, and are constantly taking measures to
improve the security of our toolset. One problematic area is the fact
that Hackage allows anyone to upload any package, without any warnings.
While this will be solved by Hackage 2, we are currently vulnerable.</p><p>For the past month, I’ve started monitoring the package upload logs, and
signaling alerts when a new uploader uploads a package for the first
time. For example, if Alice uploads the package alice-package, and Bob
uploads a new version a few days later, I’ll get a warning and contact
Alice. (And internally, we won’t build any new library sets until the
problem has been resolved.)</p><p>I think this kind of review is vital to keeping the Haskell ecosystem
safe. So if you get an email from me about this, you’ll know why.</p><h3>Report bugs</h3><p>We automatically run test suites each time we perform a Stackage build,
which has uncovered a number of regressions in upstream packages. We
file these reports upstream as soon as possible, and (due to the
wonderful nature of the Haskell community) bugs tend to be fixed very
quickly.</p><p>As our user base grows, we anticipate more bug reports coming from our
users. We’re looking forward to working with upstream providers to get
these bugs triaged and fixed. And as part of our stable library plans,
we have infrastructure in place to maintain patchsets against older
versions of packages, to simplify the task of backporting fixes.</p><h3>Notify of outdated dependencies</h3><p>The most common interaction we have with the community has been to
notify of outdated dependencies. Since Stackage has started, the number
of emails I send about this topic has decreased drastically. I’m sure
there are many factors at play here, but I see this as a sign that the
Haskell ecosystem is beginning to stabilize. Previously, it was to be
expected that breaking releases would happen on a regular basis. In the
past six months, I’ve seen this happen very infrequently for any of the
most heavily used packages.</p><h3>Identify possible library improvements</h3><p>As we get user feedback about libraries, we hope to share this
information with the rest of the community. Some sample feedback we
expect to be sharing is:</p><ol><li>Tasks that could be made easier in a library with some convenience
functions.</li><li>Places where documentation (especially tutorials) are lacking.</li><li>Functionality which simply isn’t covered by existing packages.</li></ol><h2>Internal work at FP Complete</h2><p>Our main goal at FP Complete will be to continue building and polishing
our end user tools. It’s my sincere belief that by providing these
resources, we can drastically boost Haskell’s adoption, which will have
a profound effect on the Haskell community.</p><p>In addition, we intend to take part in community efforts. Our main focus
has been on the documentation front. The School of Haskell was entirely
about improving the documentation infrastructure for the community. Our
recent announcement of tutorial and code sample contests is designed to
get high quality tutorials produced as quickly as possible.</p><p>For the most part, we have not felt the need to participate very much in
the production of libraries. The open source community has done a
fantastic job at creating a large, high-quality library ecosystem.
However, as we build up libraries for our own purposes, or identify gaps
in the existing library ecosystem, we intend to get involved: in the
former case, releasing our code to the community, and in the latter,
either working with community members to produce a suitable library, or
providing one ourselves.</p><h1>Unified product vision</h1><p>I hope the above discussion gives a good idea of how we’re hoping to
work with the community to make everyone’s lives better. I just want to
close with a summarized view of what our upcoming product (the FP
Haskell Center) will be providing to users.</p><ol><li>IDE: fully loaded with the tools you need</li><li>Libraries: no need to configure or build, just start coding</li><li>Tutorials tie in for easy learning on the job</li><li>Develop and deploy from the cloud</li></ol>" nil nil "39912619f1d763998efe69d1a48e1e8e") (323 (20991 23986 352285) "https://www.fpcomplete.com/blog/2013/07/beta-refresh-one" "FP Complete: FP Haskell Center Beta Refresh" nil "Wed, 17 Jul 2013 20:00:00 +0000" "<p><b>FP Haskell Center Beta Refresh Announcement</b> </p><p>We are excited to share some updates we’ve made and new features we’ve added to our Beta. Here are some of the things we’ve done to improve your experience with the FP Haskell Center:</p><ul><li><p>Made numerous bug fixes since the first Beta release</p></li><li><p>Added a new “setup profile” page</p></li><li><p>Updated User Interface for IDE:</p><ul><li>List modules</li><li>Search for modules</li><li>More intuitive module controls for adding, removing, and modifying module settings</li><li>Better help integration</li><li>Additional code templates</li></ul></li><li><p>Made changes to Git handling to improve performance and accommodate large projects</p></li><li><p>Fixed bug that prevented the arranging of content in display groups</p></li><li><p>Added interface for editing projects title/description</p></li><li><p>Included interface to delete projects</p></li><li><p>Added support for Hlint (a tool that reads Haskell programs and suggests changes that make them easier to read)</p></li><li><p>Added support for Stylish Haskell code formatting:</p><ul><li>Aligns and sorts import statements</li><li>Groups and wraps {-# LANGUAGE #-} pragmas, can remove (some) redundant pragmas</li><li>Removes trailing whitespace</li><li>Replaces tabs by four spaces (turned off by default)</li><li>Replaces some ASCII sequences by their Unicode equivalents</li></ul></li></ul><p>The feedback we’ve been receiving has been extremely valuable to us. We appreciate your help in making FP Haskell Center a true asset to the Haskell community.  If you haven’t signed up for a free account to our FP Haskell Center Beta, there is still time. </p>" nil nil "5bd79805541986523a32d0758adb9f7c") (322 (20991 23986 350305) "https://www.fpcomplete.com/blog/2013/07/competition-announcement" "FP Complete: FP Complete Launches FP Haskell Competition with $1,000 Cash Prize Each Month" nil "Tue, 16 Jul 2013 19:51:00 +0000" "<p><b>FP Complete Launches FP Haskell Competition with $1,000 Cash Prize Each Month</b></p><p>I’m very excited to announce our competition for sample Haskell code and tutorials of real-world engineering and business solutions. The winning entry each month will get $1,000 cash prize, with a maximum of 3 runner-up prizes of $500 each. There may be multiple prizes each month or none at all if none meet the winning criteria. There are no limits on how many prizes each individual, team or group can win in any month or the duration of the contest.  In other words, <b>you can make some serious play money here!</b></p><p>Each entry consists of a working solution to an applied problem, plus accompanying tutorial material to teach others how to build similar programs.  Entries must be built or build on FP Haskell Center.  Anyone not affiliated with FP Complete is eligible to enter.  The competition starts August 2013. </p><p>The <a href=\"https://www.fpcomplete.com/business/competition/competition-overview\">details and rules of the competition are here</a>.. Entries may be based on new or pre-existing content and code, as long as they haven’t been published before and you’re willing to share it with the community. Understandable, well-organized, tutorial documentation and reusable code--often in conjunction with other languages--are <b><i>more</i></b> important than advanced programming techniques or theoretical purity. Your program must solve an applied problem or class of problems. </p><p>Since Entries must be built or build on FP Haskell Center, you need to <a href=\"https://www.fpcomplete.com/business/designer-ide\">sign up</a> for its Beta, if you haven’t already. </p><p>Why are we doing this?  Simple: because the Haskell community needs to vastly expand for Haskell to become a mainstream language. To do this we must show people how to use this amazing language in solving real-world business problems. People tell us they need to see running and documented examples of real-world problems and solutions, so they can quickly see how to design their own working solutions. They also want material to show their colleagues and bosses just how useful Haskell is today.  This contest intends to crowd source programming recipes into an applied Haskell cookbook. </p><p>We really believe in this program as a key driver to greater Haskell adoption, which is good for the Haskell-functional programming communities and FP Complete.  So we want to incentivize the collective energy and talent of the community to produce content to promote our common cause.  So, get your creative and competitive juices going, and make some extra money for rent, a trip to Hawaii, building your own drone or whatever else turns you on.</p><p><a href=\"https://www.fpcomplete.com/business/competition/competition-rules\">Official rules</a>.  After you’ve submitted your Entry, <a href=\"https://www.fpcomplete.com/business/competition/competition-form\">register here</a></p>" nil nil "4758e5beac6a51afb99d58437897f4d2") (321 (20987 54925 175129) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_7097\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_3201\"></span> time, whereas using the categorical functor takes time <span id=\"tex_8380\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_8650\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "409a74386e3ffa7f325bea9b1c3a453d") (320 (20987 38220 76640) "http://apfelmus.nfshost.com/blog/2013/08/02-reactive-banana-threepenny.html" "apfelmus: FRP GUI - reactive-banana + threepenny-gui = awesome" nil "Fri, 02 Aug 2013 10:05:46 +0000" "<p>Just two weeks ago, I made the first public release of <a href=\"http://hackage.haskell.org/package/threepenny-gui\">threepenny-gui</a>, a cheap and simple library to satisfy your immediate GUI needs in Haskell. It uses the web browser as a display and is very easy to install.</p>
<p>Of course, it was clear that if I release a GUI library, then this would soon be followed by a binding to my functional reactive programming library <a href=\"http://www.haskell.org/haskellwiki/Reactive-banana\">reactive-banana</a>. And indeed: Today, I am pleased to announce the release of <em><a href=\"http://hackage.haskell.org/package/reactive-banana-threepenny\">reactive-banana-threepenny</a></em> together with a new snapshot release v0.2 of <em><a href=\"http://hackage.haskell.org/package/threepenny-gui\">threepenny-gui</a></em>.</p>
<h2 id=\"reactive-banana-threepenny\">Reactive-banana-threepenny</h2>
<p>The <em><a href=\"http://hackage.haskell.org/package/reactive-banana-threepenny\">reactive-banana-threepenny</a></em> library provides a small amount of glue code that makes it easy to bind to the GUI library. It is similar to and supersedes my previous bindings to wxHaskell.</p>
<p>In addition, it provides a lot of examples, which are now very easy to install via hackage. While the threepenny-gui libary is still in early development, I have implemented just enough functionality to make all examples run. In particular, here’s a screenshot from the Asteroids game:</p>
<div class=\"figure\">
<img src=\"http://apfelmus.nfshost.com/blog/2013/08/02-reactive-banana-threepenny/asteroids.png\" />
</div>
<p>That’s right, this thing is displayed in the web browser, but it’s written completely in Haskell and uses FRP. It works and it’s easy to install. Isn’t that awesome?</p>
<ul>
<li><a href=\"http://hackage.haskell.org/package/reactive-banana-threepenny\">reactive-banana-threepenny</a> - get the library on <strong>hackage</strong></li>
<li><a href=\"http://www.haskell.org/haskellwiki/Reactive-banana/Examples\">example code</a> with screenshots</li>
<li><a href=\"https://github.com/HeinrichApfelmus/reactive-banana/tree/master/reactive-banana-threepenny\">source code</a> on github</li>
</ul>
<p><br /></p>
<p>While the new library makes it possible to implement cheap GUIs with FRP in Haskell today, the FRP code is still fairly separate from the GUI code. This can be a good thing because it allows us to switch GUI frameworks easily, but it can also be a bad thing because it involves a small but noticeable amount of boilerplate code. My goal is to make GUI programming easy, so I will hopefully find ways to make the integration much tighter.</p>
<h2 id=\"advertisment\">Advertisment</h2>
<div style=\"float: left;\">
<img src=\"https://github.com/HeinrichApfelmus/reactive-banana/raw/develop/banana.png\" />
</div>
<p>Howdy, cowboy, it’s advertisment time! If you like the reactive-banana project, you can support me with a small donation: <a href=\"http://flattr.com/thing/384682/reactive-banana\"><img src=\"http://api.flattr.com/button/flattr-badge-large.png\" alt=\"Flattr this!\" /></a>. If you link your github account to your Flattr account, you can simply star a project on github in order to flattr it.</p>
<hr /><p><a href=\"https://flattr.com/thing/29608/apfelmus-website\"><img src=\"http://api.flattr.com/button/flattr-badge-large.png\" alt=\"Flattr this\" border=\"0\" title=\"Flattr this\" /></a></p>" nil nil "17ca05451fe7d012d0956b3b90329ac1") (319 (20987 38220 66283) "http://apfelmus.nfshost.com/blog/2013/07/21-threepenny-gui-0-1.html" "apfelmus: GUI - Initial release of the threepenny-gui library, version 0.1.0.0" nil "Sun, 21 Jul 2013 12:29:40 +0000" "<p>> And the shark, he has teeth,<br />> And he wears them in (his) face.<br />> And Macheath, he has a knife,<br />> (But) yes the knife, no-one sees.</p>
<p>After an obligatory cryptical quotation from a famous writer, I am pleased to announce the first public release of <em><a href=\"http://hackage.haskell.org/package/threepenny-gui\">threepenny-gui</a></em>, a cheap and simple library to satisfy your immediate GUI needs in Haskell.</p>
<p>Want to write a small GUI thing but forgot to sacrifice to the giant rubber duck in the sky before trying to install <a href=\"http://www.haskell.org/haskellwiki/Wxhaskell\">wxHaskell</a> or <a href=\"http://projects.haskell.org/gtk2hs/\">Gtk2Hs</a>? Then this library is for you!</p>
<p>Threepenny-gui is easy to install (!!) because it uses the web browser as a display. Internally, we implement a small web server that communicates with the browser to display GUI elements. Consequently, you can use HTML and CSS to design the user interface. You can freely manipulate the HTML DOM and handle browser events by writing Haskell code.</p>
<ul>
<li><a href=\"http://hackage.haskell.org/package/threepenny-gui\">threepenny-gui</a> - get the library on <strong>hackage</strong></li>
<li><a href=\"https://github.com/HeinrichApfelmus/threepenny-gui#examples\">example code</a></li>
<li><a href=\"https://github.com/HeinrichApfelmus/threepenny-gui\">source code</a> on github</li>
</ul>
<p>Many thanks to Daniel Austin for collaborating with me on this project and to Chris Done for implementing the Ji library which is the basis for this effort.</p>
<hr />
<p>On that note, the threepenny API for creating and manipulating GUI elements departs from earlier traditions. Do you like the new look and feel of the API? What do you think could be improved? Try it out and <a href=\"https://github.com/HeinrichApfelmus/threepenny-gui/issues\">send us your feedback</a>!</p>
<hr /><p><a href=\"https://flattr.com/thing/29608/apfelmus-website\"><img src=\"http://api.flattr.com/button/flattr-badge-large.png\" alt=\"Flattr this\" border=\"0\" title=\"Flattr this\" /></a></p>" nil nil "835897a2d27509ed11384cac96e8df57") (318 (20987 32119 464664) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_8859\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_6542\"></span> time, whereas using the categorical functor takes time <span id=\"tex_3465\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_8757\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "2fb05a2195fc4fcffced25737b4ffe77") (317 (20987 26873 521961) "http://gentoohaskell.wordpress.com/2013/08/01/ghc-7-6-weak-symbols-and-ghci/" "The Gentoo Haskell Team: ghc-7.6: weak symbols and ghci" nil "Thu, 01 Aug 2013 19:56:06 +0000" "<p>Time to time internetz stumble upon a <strong>ghci</strong> bug which is seen as inability to load <strong>base</strong> <strong>haskell</strong> package:</p>
<pre><code>Loading package ghc-prim ... linking ... done.
Loading package integer-gmp ... linking ... done.
Loading package base ... linking ... ghc: /usr/lib64/ghc-7.4.2/base-4.5.1.0/HSbase-4.5.1.0.o: unknown symbol `stat'
ghc: unable to load package `base'</code></pre>
<p>But the bug was most popular across rare <strong>gentoo</strong> users. An interesting correlation!</p>
<p>This post is about the root of this problem: the gory implementation details of <strong>ghci</strong> dynamic loader down to <strong>libC</strong> and even <strong>ELF</strong> symbols!</p>
<p>Not scared? Fasten your belts and Read On!</p>
<p><span id=\"more-89\"></span></p>
<p><strong>GHC</strong> (<a href=\"http://www.haskell.org/ghc/\">this one</a>) is both:</p>
<ol style=\"\">
<li>a compiler (<strong>ghc</strong> binary)</li>
<li>and <strong>REPL</strong> (<strong>ghci</strong> binary)</li>
</ol>
<p>To put simplistic <strong>ghc</strong> allows you to create final binaries out of haskell sources while <strong>ghci</strong> allows runtime loading of haskell sources.</p>
<p>Typical session starts like that:</p>
<pre><code>$ ghci
GHCi, version 7.6.3: http://www.haskell.org/ghc/  <img src=\"http://s1.wp.com/wp-includes/images/smilies/icon_confused.gif\" alt=\":?\" class=\"wp-smiley\" />  for help
Loading package ghc-prim ... linking ... done.
Loading package integer-gmp ... linking ... done.
Loading package base ... linking ... done.
Prelude> <some code to evaluate></code></pre>
<p><strong>ghci</strong>‘s implementation allows loading arbitrary shared library:</p>
<pre><code>$ ghci -lpcre
GHCi, version 7.6.3: http://www.haskell.org/ghc/  <img src=\"http://s1.wp.com/wp-includes/images/smilies/icon_confused.gif\" alt=\":?\" class=\"wp-smiley\" />  for help
Loading package ghc-prim ... linking ... done.
Loading package integer-gmp ... linking ... done.
Loading package base ... linking ... done.
Loading object (dynamic) /usr/lib/gcc/x86_64-pc-linux-gnu/4.8.1/../../../../lib64/libpcre.so ... done
final link ... done
Prelude></code></pre>
<p>and even object file:</p>
<pre><code>$ echo 'void foo(){}' > a.c &&
gcc -c a.c -o a.o &&
ghci a.o
GHCi, version 7.6.3: http://www.haskell.org/ghc/  <img src=\"http://s1.wp.com/wp-includes/images/smilies/icon_confused.gif\" alt=\":?\" class=\"wp-smiley\" />  for help
Loading package ghc-prim ... linking ... done.
Loading package integer-gmp ... linking ... done.
Loading package base ... linking ... done.
Loading object (static) a.o ... done
final link ... done
Prelude></code></pre>
<p><strong>ghci</strong> libraries are basically the same object files built of many source files.</p>
<p>It took me a while reproduce the bug mentioned in the very start of the post. First time I’ve heard of a bug was in December 2012 by nand but I had no idea where it comes from.</p>
<p>First I though it was a problem of missing headers somewhere in <strong>C</strong> code due to <strong>glibc</strong> upgrade, but no matter what combinations of <strong>binutils</strong>/<strong>gcc</strong>/<strong>glibc</strong> I tried bug did not want to show up.</p>
<p>6 months after after some <a href=\"http://bugs.gentoo.org/452442\">bugs</a> got collected I’ve noticed dreadful <strong>CFLAGS=-Os</strong> common amongst reporters which was a trigger.</p>
<p>Let’s explore exported symbol difference of 2 files:</p>
<ol style=\"\">
<li>CFLAGS=-O2 <strong>/usr/lib64/ghc-7.6.3/base-4.6.0.1/HSbase-4.6.0.1.o</strong></li>
<li>CFLAGS=-Os <strong>/usr/lib64/ghc-7.6.3/base-4.6.0.1/HSbase-4.6.0.1.o</strong></li>
</ol>
<pre><code>$ nm --undefined-only /usr/lib64/ghc-7.6.3/base-4.6.0.1/HSbase-4.6.0.1.o > base-O2
$ nm --undefined-only /gentoo/chroots/amd64-unstable//usr/lib64/ghc-7.6.3/base-4.6.0.1/HSbase-4.6.0.1.o > base-Os
$ diff -U0 base-O2 base-Os
-                 U __fxstat
+                 U fstat
-                 U __lxstat
+                 U lstat
-                 U memset
-                 U __xstat
+                 U stat</code></pre>
<p>Do you see it?</p>
<p><strong>-Os</strong> build has <strong>stat</strong> call while <strong>-O2</strong> has <strong>__xstat</strong>. It was the right track.</p>
<p>Let’s try simpler example:</p>
<pre><code>cat >stat-test.c <<-EOF
#include <sys/types.h>
#include <sys/stat.h>
#include <unistd.h>
int f()
{
struct stat s;
return stat(\"/\", &s);
}
EOF</code></pre>
<pre><code>$ gcc -c stat-test.c -Os -o stat-test-Os.o
$ gcc -c stat-test.c -O2 -o stat-test-O2.o
$ nm --undefined-only stat-test-O[2s].o
stat-test-O2.o:
U __xstat
stat-test-Os.o:
U stat</code></pre>
<p>The symbols differ on different types of optimization. Let’s see if <strong>ghci</strong> treats them differently:</p>
<pre><code>$ ghci stat-test-O2.o
...
Loading object (static) stat-test-Os.o ... done
final link ... done
$ ghci stat-test-Os.o
...
final link ... ghc: a.o: unknown symbol `stat'
linking extra libraries/objects failed</code></pre>
<p>And it does! It means that <strong>__xstat</strong> comes from <strong>libc.so.6</strong>, but <strong>stat</strong> codes from somewhere else.</p>
<p>After some investivation I’ve found it’s definition:</p>
<pre><code>$ nm --defined-only --extern-only /usr/lib/libc_nonshared.a
...
stat.oS:
00000000 T __i686.get_pc_thunk.bx
00000000 W stat
00000000 T __stat
...</code></pre>
<p>We see here the file defining two symbols for us:</p>
<ol style=\"\">
<li>global weak <strong>stat</strong> (the one we really need)</li>
<li>global <strong>__stat</strong> (useless and potentially harmful as it might lead to symbol collision)</li>
</ol>
<p>Now we can build-up working <strong>stat-test-Os.o</strong> by linking that weak <strong>stat</strong> symbol to our <strong>ghci</strong>:</p>
<pre><code>$ ar x /usr/lib/libc_nonshared.a
$ mv stat.oS stat.o # ghci dislikes non-'*.o' extensions for object files
$ ghci a.o stat.o
Loading object (static) a.o ... done
Loading object (static) stat.o ... done
final link ... ghc: stat.o: unknown symbol `stat'</code></pre>
<p>Almost works! Well, no. Nothing changed. But the reason is missing support for loading weak symbols to <strong>ghci</strong>. Whick is known as <a href=\"http://ghc.haskell.org/trac/ghc/ticket/3333\">bug 3333</a>.</p>
<p>I’ve pulled series of patches by <strong>akio</strong> and actualized it to <strong>ghc-7.6.3</strong> (<a href=\"https://github.com/gentoo-haskell/gentoo-haskell/blob/master/dev-lang/ghc/files/ghc-7.6.3-trac-3333-weak-syms.patch\">the result</a>)</p>
<p>After pulling that patch into <strong>ghc</strong> I’ve got previous example to load on <strong>x86_64</strong>:</p>
<pre><code>$ ar x /usr/lib/libc_nonshared.a
$ mv stat.oS stat.o # ghci dislikes non-'*.o' extensions for object files
$ ghci a.o stat.o
Loading object (static) a.o ... done
Loading object (static) stat.o ... done
final link ... done</code></pre>
<p>Ideally, I should load all those and only those <strong>libc_nonshared.a</strong> symbols into <strong>ghci</strong> as a first library. I’ve decided to biggyback on <strong>ghc-prim</strong> module and stuff all those nonshared symbols <a href=\"https://github.com/gentoo-haskell/gentoo-haskell/blob/master/dev-lang/ghc/ghc-7.6.3-r1.ebuild#L632\">there</a>.</p>
<p>Perhaps, that bit of shell is the worst piece of code I have ever written. It weakens all needed symbols, localizes all the rest, and merges the result into <strong>ghc-prim</strong>. It also known to break on <strong>i386</strong> as I have hidden <strong>GOT</strong> and module base required for <strong>PIC</strong> code.</p>
<p><strong>ghci</strong>‘s loader interface used not only for interactive use but also for <strong>TemplateHaskell</strong> (where we have seen <strong>vector</strong> package failing to compile) thus.</p>
<p>This post is a great example why using native system’s loader is a good idea proposed in <a href=\"http://ghc.haskell.org/trac/ghc/ticket/4244\">bug 4244</a>.</p>
<p>I don’t know if it fixes all our cases but it will be way more clean than it is now.</p>
<p>If the workaround will show itself as too fragile I’ll have to roll back to force <strong>CFLAGS=-O2</strong> when building <strong>ghc</strong>.</p>
<br />  <a href=\"http://feeds.wordpress.com/1.0/gocomments/gentoohaskell.wordpress.com/89/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/gentoohaskell.wordpress.com/89/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=gentoohaskell.wordpress.com&blog=7667502&post=89&subd=gentoohaskell&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "f7ff55aef3cae2822a0c1bc7679d1c08") (316 (20987 26873 520268) "http://fuuzetsu.co.uk/blog/posts/2013-07-30-first-month-with-haddock.html" "Mateusz Kowalczyk: First month with Haddock" nil "Tue, 30 Jul 2013 00:00:00 +0000" "<div class=\"info\">
Posted on July 30, 2013

by Fūzetsu

</div>
<p>As per the <a href=\"https://gist.github.com/Fuuzetsu/81253ba7d0c51ac88052\">original proposal</a>, over the last couple of weeks I have been hacking on Haddock. I will talk a bit on where we currently stand, what has been achieved, what hasn’t and what’s next. While the proposal wasn’t originally my idea, I will do my best to expose the reasoning behind it.</p>
<p>Note: This is written in from of me talking about my personal experience with Haddock. If all you want are some hard facts on what’s implemented, what isn’t, what’s planned, I recommend you skip to the <a href=\"http://people.bath.ac.uk/mk440/blog/atom.xml#shortversion\">overview</a>. The <a href=\"http://people.bath.ac.uk/mk440/blog/atom.xml#tests\">Tests</a> subsection might also interest you. This first post is long because it outlines a large chunk of time. Future posts should be considerably shorter and about a specific area of the project rather than about the project as a whole.</p>
<p>The first couple of weeks were spent on reading the source. Unfortunately Haddock is quite tightly bound to GHC which means that I had to do a lot of GHC source diving as well just to get my grips on the situation. I recommend reading the <a href=\"http://ghc.haskell.org/trac/ghc/wiki/Commentary\">GHC commentary</a> if you haven’t already as it’s fairly informative. I think the main surprise to me was that Haddock gets comment strings right from GHC. I guess that I always thought that Haddock was simply ripping these right out of the source files.</p>
<h1 id=\"parser-change\">Parser change</h1>
<p>The very first point of the proposal was to re-implement the existing parser with a new, more powerful one. Alex and Happy are currently used to generate the lexer and the parser at compile time. There are following problems:</p>
<ul>
<li><p>Both Alex and Happy work using grammars. While grammars are nice things to use, they aren’t very nice things to modify. We have to specify a grammar for both, the lexer and the parser separately, and any changes we want to make have often have to be reflected in both. Worse, the lexer and parser grammars don’t have a clear overlap in structure so it’s difficult to decide where the grammar has to change to accommodate our needs.</p></li>
<li><p>Backtracking is rather limited. There were previously attempts to implement auto-linking and from what I can gather, the implementation was too complex to actually be worth the time and effort. With a new parser, this limitation would be removed and we could freely look back at the just-parsed sections and even run additional parsers on these.</p></li>
</ul>
<p>With these two main points in mind, Attoparsec was chosen with hopes that parser combinators will provide a cleaner, more maintainable and extendable implementation. As a downside, it depends on Data.Text which is currently not in in GHC boot library. Fortunately, it also has a ByteString version which lets us avoid the problem.</p>
<p>A word of advice: if you ever move around modules in an existing project, or even add some new ones, make sure to update your cabal file because all you’re going to get are weird linker errors at the end of the build with no indication of what’s wrong.</p>
<p><a id=\"tests\"></a></p>
<h2 id=\"tests\">Tests</h2>
<p>When time to code actually came and I got GHC HEAD going (this is unfortunately a must for Haddock hacking. On an upside, you get all the cool HEAD stuff like TypeHoles), I very quickly realised that running tests was a major pain. There are two test suites: HTML tests and Hspec tests. HTML tests are just short Haskell modules that we compile, generate documentation for and diff with reference, known-good HTML files. This means going to the shell, compiling haddock, running‘cabal test’, waiting for the other test-suite to run first and examining output. Even worse, if anything is actually wrong, you don’t even get told which file it’s in and you have to grep for the elements of the output.</p>
<p>Hspec tests are the nice kind. The kind that you can load into GHCi and whenever you’re ready, simply ‘:r’ and ‘main’ to get a coloured output and clear indication of what’s failing. The downside is that there were only about 5 cases there which means that you often passed these only to fail on HTML tests later. If at all possible, it’d be nice to fail early, before going out to the shell and doing all the tedious stuff. My first remedy to this was less-than-pretty.</p>
<p>I added trace statements to the part of the program that takes in strings and outputs our internal format (nested ‘Doc’ structure). With this, and a couple of minutes with emacs macros, I soon had hundreds of (rather redundant) Hspec tests without going out to the shell. I have later removed the redundancies and split them up into nice categories. This way we actually had some tests. I should note that there’s one more type of testing I like to do and that is to download existing, large libraries that compile both with HEAD and stable, generating docs for them and then diffing the two. If this passes then I feel fairly confident that nothing major got broken. <a href=\"http://hackage.haskell.org/package/hxt\">HXT</a> was pretty good for this. Any problems discovered this way would go right into Hspec tests which is how the test-suite has naturally grown into ~75 reasonable test cases.</p>
<h1 id=\"implementation\">Implementation</h1>
<p>My first one-pass attempt failed horribly. I could not reproduce the behaviour of the original program. A lot of the grammar seems to have been written for Alex and Happy: that is, the syntax was designed for easy parsing to those rather than coming up with the syntax first, independently of the tool used.</p>
<p>Defeated and already a fair amount of time into the coding stage, I have changed my approach. The initial attempt at this resulted in what was very much a grammar implementation using Attoparsec using some custom combinators for state transition (for the lexing) and backtracking with lists (for the parser). As you can imagine, this doesn’t gain us much over the original program but the hopes were that it will be easier to transition from this into a single pass than it would be to do so straight away. While implementing a few new features with this parser and writing few more tests for those, the time came where a single-pass parser was necessary. I have met with the same problems as initially (trying to combine two grammars into a single-pass parser combinator implementation) but have recently received guidance which made a large amount of these issues go away and made the implementation far more idiomatic in respect to using parser combinator approach. This parser is nearly finished (and probably would have been if I didn’t choose to write this post instead). It’s worth noting that this parser will bring a couple of changes and will therefore no longer be 100% compatible with the old one. More syntax will be allowed and no old syntax will be disallowed which means that old documentation should be safe to generate with this new parser without fear of breaking it.</p>
<p>While I have spent a huge majority of my time in the parser part of the program, I suspect that features such as GADTs and type families which are scheduled to be added in the future will take me well outside this area, potentially into the GHC source again. You can expect blog posts about those if they turn out to be interesting enough to post about.</p>
<p><a id=\"shortversion\"></a></p>
<h1 id=\"overview\">Overview</h1>
<p>Note that everything denoted below is not yet in the Haddock tree. Announcement will be made when the changes are pushed upstream.</p>
<ul>
<li><p>A 100% compatible parser has been written. This unfortunately suffers from poor implementation and split into a lexer and parser.</p></li>
<li><p>New, single-pass parser (Attoparsec) nearly complete. As of writing, there are 5 more test cases failing. This is simply because I started writing this version about 20 hours ago and it’s missing some features. Should be done very soon. This parser no longer has the same behaviour as the original, extending and changing the syntax and its rules. All old documentation should render as it did before unless it happens to hit any of the new additions. It should not be an issue at all.</p></li>
<li><p>Tens of new test cases were added. Travis CI was set up to help with the testing but is currently not running due to lack of GHC HEAD binaries. It is unreliable to try and build GHC HEAD during the testing stage.</p></li>
<li><p>Couple of no-longer-relevant on Haddock Trac were closed.</p></li>
<li><p>List entries no longer have to be separated by empty lines. Note that different kinds of lists <em>do</em> have to be separated by empty lines, by design.</p></li>
<li><p>Not preceding an example or birdtracks by an empty line block is no longer a parse error: they will simply be rendered as regular strings.</p></li>
<li><p>Opening a definition list with a square bracket and not closing it on the same line (therefore forming a valid definition list) is no longer a parse error. The square bracket will be treated as a regular character and will not need to be escaped.</p></li>
<li><p>You can now specify titles for your images as you would with URLs. The old <code><<foo.png>></code> image syntax now denotes an image without a title. <code><<foo.png bar>></code> denotes an image ‘foo.png’ with a title ‘bar’. Changes to the HTML and LaTeX backends were made to accommodate this. The markup generated for images without a title is identical to what it was before (no empty <code>title</code> attributes).</p></li>
<li><p>Naive URL auto-linking is now in place. Any text starting with <code>ssh://</code>, <code>http://</code>, <code>https://</code>, <code>ftp://</code> or <code>gopher://</code> until a first white space character will be treated as a URL. It is not possible to give such URL a title. No validation is done on the URL, to keep the parser simple (but it has been coded and if this simple approach proves problematic, might be put in) save for splitting trailing single-character punctuation. This is only in effect wherever URLs with the <code><example.com title></code> syntax are accepted.</p></li>
<li><p>Module names (that is, strings between double quotes) are now only accepted if they clearly aren’t syntactically incorrect. That is, enclosing strings that contain spaces or don’t start with a capital letter in double quotes will no longer result in a hyperlink being created. Note that these aren’t checked for actual validity or existence by GHC so links to non-existent modules are still possible.</p></li>
</ul>
<h2 id=\"plans\">Plans</h2>
<ul>
<li><p>GADT support is still planned as per the proposal.</p></li>
<li><p>Markdown support is still planned as per the proposal.</p></li>
<li><p>Bold text</p></li>
<li><p>The module header will no longer require that the fields are in strict order. If you know why this limitation was imposed save for implementation convenience, please <a href=\"http://people.bath.ac.uk/contact.html\">contact me</a>.</p></li>
<li><p>The proposal states support for type families will be implemented. While I don’t have plans to back out of this, there was some code committed by GHC HQ recently to do with type families. I have not reviewed the code carefully yet but I believe it makes this job easier.</p></li>
<li><p>The proposal states that the image tags should be made relative and that flags should be created to allow us to provide these separately. I have to admit that this is of lower priority to me than other tasks and I haven’t heard much (or any) demand for this feature.</p></li>
<li><p>Documentation has to be updated. All the new features have to be documented and even some old features which still aren’t (such as the <code><<img>></code> tag) and uploaded on haskell.org.</p></li>
</ul>
<p>Any syntax extensions are unlikely to break any existing documentation.</p>" nil nil "8c28eb522a4b3d8e394ddeccbd2c8bcf") (315 (20987 26873 517841) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_6891\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_3522\"></span> time, whereas using the categorical functor takes time <span id=\"tex_1933\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_2470\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "54da5a06b2a644e5c0212c9ae54acd9f") (314 (20986 24913 142743) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_8524\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_2455\"></span> time, whereas using the categorical functor takes time <span id=\"tex_7388\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_2403\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "b2cbbd649669ba3744c37aa6ca4ca26e") (313 (20986 14089 533019) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_5478\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_9798\"></span> time, whereas using the categorical functor takes time <span id=\"tex_6098\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_52\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "ac797dfcbadef253e007099f15cb8698") (312 (20986 6542 8328) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_4358\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_1031\"></span> time, whereas using the categorical functor takes time <span id=\"tex_6012\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_8459\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "bebf15f4ad7a2e1f78c2b091e15f2298") (311 (20985 13713 781777) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_3231\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_2289\"></span> time, whereas using the categorical functor takes time <span id=\"tex_4988\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_2074\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "65a6d3cfcf339bcd2dadfee68071a133") (310 (20985 8801 319259) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_6027\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_3572\"></span> time, whereas using the categorical functor takes time <span id=\"tex_5651\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_8537\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "214e73be0085208692ffd1e52c73da99") (309 (20984 63139 891623) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_7222\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_4671\"></span> time, whereas using the categorical functor takes time <span id=\"tex_5428\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_5148\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "e321ebbe15f4df399dd53b2cbbdc88a1") (308 (20984 60852 85500) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_596\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_5897\"></span> time, whereas using the categorical functor takes time <span id=\"tex_3162\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_7082\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "5152df55c0aa44be46055cf79e0ecf67") (307 (20984 50467 501613) "http://neilmitchell.blogspot.com/2013/07/standard-chartered-are-hiring.html" "Neil Mitchell: Standard Chartered are hiring" "noreply@blogger.com (Neil Mitchell)" "Tue, 30 Jul 2013 21:39:14 +0000" "<i>Summary: Haskell programmer willing to relocate to Singapore? Come work for Standard Chartered!</i><br /><br /><a href=\"http://www.standardchartered.com/\">Standard Chartered</a>, the bank where I work, is hiring again.  We're looking for a programmer in Singapore to use Haskell full time (or more specifically, the <a href=\"http://www.youtube.com/watch?v=hgOzYZDrXL0\">Mu Haskell</a> dialect), with the results used by many people, often the very next day. We write compilers, libraries, applications, web servers, DSLs and much more besides. All of the work is for use in house, and is usually geared towards finance, but no finance background is required. Standard Chartered has been using Haskell for over five years, and has hired lots of well-known Haskell programmers, including Lennart Augustsson, Ravi Nanavati, Malcolm Wallace, Roman Leshchinskiy, Don Stewart and Andy Adams-Moran.<br /><br />To apply, send a CV to neil.mitchell AT sc DOT com, and make sure the CV includes links to anything you've written on programming (Twitter, StackOverflow, blogs, academic papers) and links to any open-source software you have written (GitHub, Hackage). We are ideally looking for:<br /><br /><ul><li>An expert Haskell programmer - someone who can quickly write top-quality code. We have a large existing Haskell code base, which lots of people are continually developing, so experience with larger Haskell projects would be a plus.</li><li>Someone who can proactively talk to our users, understand their problems, find out what they are asking for, then deliver what they really want. We make releases nightly and rely on constant feedback.</li><li>Someone who takes responsibility for their code and keeps it in good shape. That includes testing it, refining it over time and documenting the surprising bits. We can only iterate rapidly by keeping the code clean and testable, or we would end up breaking things.</li><li>Someone who is prepared to work weekdays 9am-6pm in an office in Singapore (telecommuting is not currently an option). The work we do directly impacts many people on very short time scales, which is demanding, but also rewarding.</li></ul>" nil nil "6347b853fb0e9cf6b3c891139695c37e") (306 (20984 50467 501171) "http://jpmoresmau.blogspot.com/2013/07/eclipsefp-254-released.html" "JP Moresmau: EclipseFP 2.5.4 released" "noreply@blogger.com (JP Moresmau)" "Tue, 30 Jul 2013 20:07:49 +0000" "Hello folks, a new bug-fixing release of <a href=\"http://eclipsefp.github.io/install.html\">EclipseFP</a>. Nothing major, mainly fixed a big bug that caused the plugin to randomly not start properly in Kepler, and few little enhancements to make life easier. The full <a href=\"https://sourceforge.net/projects/eclipsefp/files/EclipseFP%202%20branch/2.5.4/\">release notes</a> have all the details.<br /><br />I'm also pleased to announce a new contributor, <a href=\"https://github.com/neothemachine\">Maik Riechert</a>, who contributed a hyperlink detector so that hyperlinks in source files can be followed.<br /><br />As usual, just update from within Eclipse using update site http://eclipsefp.sf.net/updates.<br /><br />Happy Haskell Hacking!" nil nil "fb10fa74e423a26e8ff55ab7833026e3") (305 (20984 50467 500226) "http://izbicki.me/blog/functors-and-monads-for-analyzing-data?utm_source=rss&utm_medium=rss&utm_campaign=functors-and-monads-for-analyzing-data" "Mike Izbicki: Functors and monads for analyzing data" nil "Mon, 29 Jul 2013 15:26:23 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"size-full wp-image-2651 alignright\" width=\"300\" />Functors and monads are powerful design patterns used in Haskell. They give us two cool tricks for analyzing data.  First, <strong>we can “preprocess” data after we’ve already trained a model</strong>.  The model will be automatically updated to reflect the changes.  Second, this whole process happens <strong>asymptotically faster</strong> than the standard method of preprocessing.  In some cases, you can do it in constant time no matter how many data points you have!</p>
<p>This post focuses on how to use functors and monads in practice with the <a href=\"https://github.com/mikeizbicki/hlearn\">HLearn library</a>.  We won’t talk about their <a href=\"http://www.stephendiehl.com/posts/monads.html\">category theoretic foundations</a>; instead, we’ll go through <strong>ten concrete examples</strong> involving the <a href=\"https://en.wikipedia.org/wiki/Categorical_distribution\">categorical distribution</a>. This distribution is somewhat awkwardly named for our purposes because it has nothing to do with category theory—it is the most general distribution over non-numeric (i.e. categorical) data. It’s simplicity should make the examples a little easier to follow.  Some more complicated models (e.g. the kernel density estimator and Bayesian classifier) also have functor and monad instances, but we’ll save those for another post.<br />
<span id=\"more-2638\"></span></p>
<h3>Setting up the problem</h3>
<p>Before we dive into using functors and monads, we need to set up our code and create some data. Let’s install the packages:</p>
<pre>$ cabal install HLearn-distributions-1.1</pre>
<p>Import our modules:</p>
<pre>> import Control.ConstraintKinds.Functor
> import Control.ConstraintKinds.Monad
> import Prelude hiding (Functor(..), Monad (..))
>
> import HLearn.Algebra
> import HLearn.Models.Distributions</pre>
<p>For efficiency reasons we’ll be using the Functor and Monad instances provided by the <a href=\"https://github.com/mikeizbicki/ConstraintKinds\">ConstraintKinds</a> package and language extension. From the user’s perspective, everything works the same as normal monads.</p>
<p>Now let’s create a simple marble data type, and a small bag of marbles for our data set.</p>
<pre>> data Marble = Red | Pink | Green | Blue | White
>   deriving (Read,Show,Eq,Ord)
>
> bagOfMarbles = [ Pink,Green,Red,Blue,Green,Red,Green,Pink,Blue,White ]</pre>
<p>This is a very small data set just to make things easy to visualize. Everything we’ll talk about works just as well on arbitrarily large data sets.</p>
<p>We train a categorical distribution on this data set using the <strong>train</strong> function:</p>
<pre>> marblesDist = train bagOfMarbles :: Categorical Double Marble</pre>
<p>The <strong>Categorical</strong> type takes two parameters. The first is the type of our probabilities, and the second is the type of our data points.  If you stick your hand into the bag and draw a random marble, this distribution tells you the probability of drawing each color.</p>
<p>Let’s plot our distribution:</p>
<pre>ghci> plotDistribution (plotFile \"marblesDist\" $ PNG 400 300) marblesDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/marblesDist-mod5.png\" alt=\"marblesDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2651\" width=\"300\" /></p>
<h3>Functors</h3>
<p>Okay. Now we’re ready for the juicy bits. We’ll start by talking about the list functor.  This will motivate the advantages of the categorical distribution functor.</p>
<p>A functor is a container that lets us “map” a function onto every element of the container.  Lists are a functor, and so we can apply a function to our data set using the <strong>map</strong> function.</p>
<pre>map :: (a -> b) -> [a] -> [b]</pre>
<p><strong>Example 1:</strong></p>
<p>Let’s say instead of a distribution over the marbles’ colors, I want a distribution over the marbles’ weights. I might have a function that associates a weight with each type of marble:</p>
<pre>> marbleWeight :: Marble -> Int -- weight in grams
> marbleWeight Red   = 3
> marbleWeight Pink  = 2
> marbleWeight Green = 3
> marbleWeight Blue  = 6
> marbleWeight White = 2</pre>
<p>I can generate my new distribution by first transforming my data set, and then training on the result.  Notice that the type of our distribution has changed.  It is no longer a categorical distribution over marbles; it’s a distribution over ints.</p>
<pre>> weightsDist = train $ map marbleWeight bagOfMarbles :: Categorical Double Int</pre>
<pre>ghci> plotDistribution (plotFile \"weightsDist\" $ PNG 400 300) weightsDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/weightsDist-mod1.png\" alt=\"weightsDist-mod\" height=\"230\" class=\"aligncenter size-full wp-image-2657\" width=\"300\" /></p>
<p>This is the standard way of preprocessing data. But we can do better because the categorical distribution is also a functor. Functors have a function called <strong>fmap</strong> that is analogous to calling map on a list.  This is its type signature specialized for the Categorical type:</p>
<pre>fmap :: (Ord dp0, Ord dp1) => (dp0 -> dp1) -> Categorical prob dp0 -> Categorical prob dp1</pre>
<p>We can use fmap to apply the marbleWeights function directly to the distribution:</p>
<pre>> weightDist' = fmap marbleWeight marblesDist</pre>
<p>This is guaranteed to generate the same exact answer, but it is much faster. <strong>It takes only constant time to call Categorical’s fmap, no matter how much data we have!</strong></p>
<p>Let me put that another way. Below is a diagram showing the two possible ways to generate a model on a preprocessed data set.  Every arrow represents a function application.</p>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/blog-categorical-functor.png\" alt=\"blog-categorical-functor\" height=\"279\" class=\"aligncenter size-full wp-image-2676\" width=\"400\" /></p>
<p>The normal way to preprocess data is to take the bottom left path.  But because our model is a functor, the top right path becomes available.  This path is better because it has the shorter run time.</p>
<p>Furthermore, let’s say we want to experiment with <span id=\"tex_3007\"></span> different preprocessing functions.  The standard method will take <span id=\"tex_5957\"></span> time, whereas using the categorical functor takes time <span id=\"tex_9722\"></span>.</p>
<p><em>Note: The diagram treats the number of different categories (m) as a constant because it doesn’t depend on the number of data points.  In our case, we have 5 types of marbles, so m=5.  Every function call in the diagram is really multiplied by m.</em></p>
<p><strong>Example 2:</strong></p>
<p>For another example, what if we don’t want to differentiate between red and pink marbles? The following function converts all the pink marbles to red.</p>
<pre>> pink2red :: Marble -> Marble
> pink2red Pink = Red
> pink2red dp   = dp</pre>
<p>Let’s apply it to our distribution, and plot the results:</p>
<pre>> nopinkDist = fmap pink2red marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist\" $ PNG 400 300) nopinkDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist-mod.png\" alt=\"nopinkDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>That’s about all that a Functor can do by itself. When we call fmap, we can only process individual data points.  We can’t change the number of points in the resulting distribution or do other complex processing. Monads give us this power.</p>
<h3>Monads</h3>
<p>Monads are functors with two more functions. The first is called <strong>return</strong>. Its type signature is</p>
<pre>return :: (Ord dp) => dp -> Categorical prob dp</pre>
<p>We’ve actually seen this function already in <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">previous posts</a>. It’s equivalent to the <strong>train1dp</strong> function found in the <strong>HomTrainer</strong> type class. All it does is train a categorical distribution on a single data point.</p>
<p>The next function is called <strong>join.</strong> It’s a little bit trickier, and it’s where all the magic lies. Its type signature is:</p>
<pre>join :: (Ord dp) => Categorical prob (Categorical prob dp) -> Categorical prob dp</pre>
<p>As input, join takes a categorical distribution whose data points are other categorical distributions. It then “flattens” the distribution into one that does not take other distributions as input.</p>
<p><strong>Example 3</strong></p>
<p>Let’s write a function that removes all the pink marbles from our data set.  Whenever we encounter a pink marble, we’ll replace it with an empty categorical distribution; if the marble is not pink, we’ll create a singleton distribution from it.</p>
<pre>> forgetPink :: (Num prob) => Marble -> Categorical prob Marble
> forgetPink Pink = mempty
> forgetPink dp   = train1dp dp
>
> nopinkDist2 = join $ fmap forgetPink marblesDist</pre>
<pre>ghci> plotDistribution (plotFile \"nopinkDist2\" $ PNG 400 300) nopinkDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/nopinkDist2-mod.png\" alt=\"nopinkDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2666\" width=\"300\" /></p>
<p>This idiom of <strong>join ( fmap … )</strong> is used a lot. For convenience, the<strong> >>=</strong> operator (called <strong>bind</strong>) combines these steps for us.  It is defined as:</p>
<pre>(>>=) :: Categorical prob dp0 -> (dp0 -> Categorical prob dp1) -> Categorical prob dp1
dist >>= f = join $ fmap f dist</pre>
<p>Under this notation, our new distribution can be defined as:</p>
<pre>> nopinkDist2' = marblesDist >>= forgetPink</pre>
<p><strong>Example 4<br />
</strong></p>
<p>Besides removing data points, we can also add new ones. Let’s double the number of pink marbles in our training data:</p>
<pre>> doublePink :: (Num prob) => Marble -> Categorical prob Marble
> doublePink Pink = 2 .* train1dp Pink
> doublePink dp   = train1dp dp
>
> doublepinkDist = marblesDist >>= doublePink</pre>
<pre>ghci> plotDistribution (plotFile \"doublepinkDist\" $ PNG 400 300) doublepinkDist</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/doublepinkDist-mod1.png\" alt=\"doublepinkDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2668\" width=\"300\" /></p>
<p><strong>Example 5<br />
</strong></p>
<p>Mistakes are often made when collecting data. One common machine learning task is to preprocess data sets to account for these mistakes. In this example, we’ll assume that our sampling process suffers from uniform noise.  Specifically, if one of our data points is red, we will assume there is only a 60% chance that the marble was actually red, and a 10% chance each that it was one of the other colors.  We will define a function to add this noise to our data set, increasing the accuracy of our final distribution.</p>
<p>Notice that we are using fractional weights for our noise, and that the weights are carefully adjusted so that the total number of marbles in the distribution still sums to one.  We don’t want to add or remove marbles while adding noise.</p>
<pre>> addNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> addNoise dp = 0.5 .* train1dp dp <> 0.1 .* train [ Red,Pink,Green,Blue,White ]
>
> noiseDist = marblesDist >>= addNoise</pre>
<pre>ghci> plotDistribution (plotFile \"noiseDist\" $ PNG 400 300) noiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/noiseDist-mod1.png\" alt=\"noiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2735\" width=\"300\" /></p>
<p>Adding uniform noise just made all our probabilities closer together.</p>
<p><strong>Example 6<br />
</strong></p>
<p>Of course, the amount of noise we add to each sample doesn’t have to be the same everywhere. If I suffer from red-green color blindness, then I might use this as my noise function:</p>
<pre>> rgNoise :: (Fractional prob) => Marble -> Categorical prob Marble
> rgNoise Red   = trainW [(0.7,Red),(0.3,Green)]
> rgNoise Green = trainW [(0.1,Red),(0.9,Green)]
> rgNoise dp    = train1dp dp
>
> rgNoiseDist = marblesDist >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist\" $ PNG 400 300) rgNoiseDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist-mod1.png\" alt=\"rgNoiseDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2736\" width=\"300\" /></p>
<p>Because of my color blindness, the probability of drawing a red marble from the bag is higher than drawing a green marble.  This is despite the fact that we observed more green marbles in our training data.</p>
<p><strong>Example 7<br />
</strong></p>
<p>In the real world, we can never know exactly how much error we have in the samples. Luckily, we can try to learn it by conducting a second experiment. We’ll first experimentally determine how red-green color blind I am, then we’ll use that to update our already trained distribution.</p>
<p>To determine the true error rate, we need some unbiased source of truth. In this case, we can just use someone with good vision. They will select ten red marbles and ten green marbles, and I will guess what color they are.</p>
<p>Let’s train a distribution on what I think green marbles look like:</p>
<pre>> greenMarbles = [Green,Red,Green,Red,Green,Red,Red,Green,Green,Green]
> greenDist = train greenMarbles  :: Categorical Double Marble</pre>
<p>and what I think red marbles look like:</p>
<pre>> redMarbles = [Red,Green,Red,Green,Red,Red,Green,Green,Red,Red]
> redDist = train redMarbles :: Categorical Double Marble</pre>
<p>Now we’ll create the noise function based off of our empirical data. The <strong>(/.)</strong> function is scalar division, and we can use it because the <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical distribution is a vector space</a>. We’re dividing by the number of data points in the distribution so that the distribution we output has an effective training size of one. This ensures that we’re not accidentally creating new data points when applying our function to another distribution.</p>
<pre>> rgNoise2 :: Marble -> Categorical Double Marble
> rgNoise2 Green = greenDist /. numdp greenDist
> rgNoise2 Red   = redDist /. numdp redDist
> rgNoise2 dp    = train1dp dp
>
> rgNoiseDist2  = marblesDist >>= rgNoise2</pre>
<pre>ghci> plotDistribution (plotFile \"rgNoiseDist2\" $ PNG 400 300) rgNoiseDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/rgNoiseDist2-mod2.png\" alt=\"rgNoiseDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2788\" width=\"300\" /></p>
<p><strong>Example 8<br />
</strong></p>
<p>We can chain our preprocessing functions together in arbitrary ways.</p>
<pre>> allDist = marblesDist >>= forgetPink >>= addNoise >>= rgNoise</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist-mod.png\" alt=\"allDist-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2734\" width=\"300\" /></p>
<p>But wait!  Where’d that pink come from?  Wasn’t the call to forgetPink supposed to remove it?  The answer is that we did remove it, but then we added it back in with our noise functions.  When using monadic functions, we must be careful about the order we apply them in.  This is just as true when using regular functions.</p>
<p>Here’s another distribution created from those same functions in a different order:</p>
<pre>> allDist2 = marblesDist >>= addNoise >>= rgNoise >>= forgetPink</pre>
<pre>ghci> plotDistribution (plotFile \"allDist\" $ PNG 400 300) allDist2</pre>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/allDist2-mod.png\" alt=\"allDist2-mod\" height=\"210\" class=\"size-full wp-image-2733 aligncenter\" width=\"300\" /></p>
<p>We can also use Haskell’s do notation to accomplish the same exact thing:</p>
<pre>>allDist2' :: Categorical Double Marble
>allDist2' = do
>    dp <- train bagOfMarbles
>    dp <- addNoise dp
>    dp <- rgNoise dp
>    dp <- forgetPink dp
>    return dp</pre>
<p>(Since we’re using a custom Monad definition, do notation requires the RebindableSyntax extension.)</p>
<p><strong>Example 9<br />
</strong></p>
<p>Do notation gives us a convenient way to preprocess multiple data sets into a single data set. Let’s create two new data sets and their corresponding distributions for us to work with:</p>
<pre>> bag1 = [Red,Pink,Green,Blue,White]
> bag2 = [Red,Blue,White]
>
> bag1dist = train bag1 :: Categorical Double Marble
> bag2dist = train bag2 :: Categorical Double Marble</pre>
<p>Now, we’ll create a third data set that is a weighted combination of bag1 and bag2. We will do this by repeated sampling. On every iteration, with a 20% probability we’ll sample from bag1, and with an 80% probability we’ll sample from bag2. Imperative pseudo-code for this algorithm is:</p>
<pre>let comboDist be an empty distribution
loop until desired accuracy achieved:
let r be a random number from 0 to 1
if r > 0.2:
sample dp1 from bag1
add dp1 to comboDist
else:
sample dp2 from bag2
add dp2 to comboDist</pre>
<p>This sampling procedure will obviously not give us an exact answer. But since the categorical distribution supports weighted data points, we can use this simpler pseudo-code to generate an exact answer:</p>
<pre>let comboDist be an empty distribution
foreach datapoint dp1 in bag1:
foreach datapoint dp2 in bag2:
add dp1 with weight 0.2 to comboDist
add dp2 with weight 0.8 to comboDist</pre>
<p>Using do notation, we can express this as:</p>
<pre>> comboDist :: Categorical Double Marble
> comboDist = do
>   dp1 <- bag1dist
>   dp2 <- bag2dist
>   trainW [(0.2,dp1),(0.8,dp2)]</pre>
<pre>plotDistribution (plotFile \"comboDist\" $ PNG 400 300) comboDist</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist-mod1.png\" alt=\"comboDist-mod\" height=\"210\" class=\"aligncenter\" width=\"300\" /></p>
<p>And because the Categorical functor takes constant time, constructing comboDist also takes constant time. The naive imperative algorithm would have taken time <span id=\"tex_6650\"></span>.</p>
<p>When combining multiple distributions this way, the number of data points in our final distribution will be the product of the number of data points in the initial distributions:</p>
<pre>ghci> numdp combination
15</pre>
<p><strong>Example 10<br />
</strong></p>
<p>Finally, arbitrarily complex preprocessing functions can be written using Haskell’s do notation. And remember, no matter how complicated these functions are, their run time never depends on the number of elements in the initial data set.</p>
<p>This function adds uniform sampling noise to our bagOfMarbles, but only on those marbles that are also contained in bag2 above.</p>
<pre>> comboDist2 :: Categorical Double Marble
> comboDist2 = do
>   dp1 <- marblesDist
>   dp2 <- bag2dist
>   if dp1==dp2
>       then addNoise dp1
>       else return dp1</pre>
<pre>plotDistribution (plotFile \"comboDist2\" $ PNG 400 300) comboDist2</pre>
<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/07/comboDist2-mod1.png\" alt=\"comboDist2-mod\" height=\"210\" class=\"aligncenter size-full wp-image-2793\" width=\"300\" /></p>
<h3>Conclusion</h3>
<p>This application of monads to machine learning generalizes the monad used in <a href=\"http://www.haskell.org/haskellwiki/Probabilistic_Functional_Programming\">probabilistic functional programming</a>.  The main difference is that PFP focused on manipulating already known distributions, not training them from data.  Also, if you enjoy this kind of thing, you might be interested in the <a href=\"http://golem.ph.utexas.edu/category/2007/09/category_theory_in_machine_lea.html\">n-category cafe</a> discussion on category theory in machine learning from a few years back.</p>
<p>In future posts, we’ll look at functors and monads for continuous distributions, multivariate distributions, and classifiers.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2638\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "801d365063d26d9a29ed99efedc49a45") (304 (20984 50467 497412) "http://gsoc2013cwithmobiledevices.blogspot.com/2013/07/api-for-communicating-through-mpns.html" "Marcos Pividori: API for communicating through MPNS" "noreply@blogger.com (Marcos)" "Mon, 29 Jul 2013 13:32:29 +0000" "I developed an API for communicating through MPNS with Windows Phone mobile devices (<a href=\"https://github.com/MarcosPividori/GSoC-Communicating-with-mobile-devices/tree/master/push-notify/Network/PushNotify/Mpns\">[1]</a>). For this, I designed a way of building the messages, sending them and handling the result.<br />To communicate with MPNS servers, I need to send POST requests, so I decided to use Conduit, as I have done with GCM. The MPNS Api looks like this:<br /><br />MPNS let you send notification in an authenticated or unauthenticated mode, so you can configure this with  MPNSAppConfig:<br /><pre style=\"background-color: #f0f0f0; border: 1px dashed rgb(204, 204, 204); height: auto; overflow: auto; padding: 0px;\"><code style=\"font-family: arial; font-size: 12px; line-height: 20px;\"> </code><span style=\"background-color: transparent; font-size: 12px; line-height: 20px;\">data MPNSAppConfig = MPNSAppConfig{<br />        numRet       :: Int      -- def = 5<br />    ,   useSecure    :: Bool     -- def = False<br />    ,   certificate  :: String   -- def = \"\"<br />    ,   privateKey   :: String   -- def = \"\"<br />    }</span></pre>To build messages, I developed a data type \"<span style=\"font-size: 12px; line-height: 20px;\">MPNSmessage</span>\"<br /><pre style=\"background-color: #f0f0f0; border: 1px dashed rgb(204, 204, 204); height: auto; overflow: auto; padding: 0px;\"><code style=\"font-family: arial; font-size: 12px; line-height: 20px;\"> </code><span style=\"background-color: transparent;\"><span style=\"font-size: 12px; line-height: 20px;\">data MPNSmessage = MPNSmessage{<br />        deviceURIs          :: [DeviceURI]  -- destinations<br />    ,   batching_interval   :: MPNSInterval -- Immediate | Sec450 | Sec900<br />    ,   target              :: MPNSType     -- Toast     | Raw    | Tile<br />    ,   restXML             :: Document     -- the XML data to be sent<br />    }</span></span></pre><div>For sending notifications:<br /><pre style=\"background-color: #f0f0f0; border: 1px dashed rgb(204, 204, 204); height: auto; overflow: auto; padding: 0px;\"><span style=\"font-size: 12px; line-height: 20px;\">sendMPNS :: Manager -> MPNSAppConfig -> MPNSmessage -> IO MPNSresult</span></pre></div><div>Last, for handling the result:</div><div><pre style=\"background-color: #f0f0f0; border: 1px dashed rgb(204, 204, 204); height: auto; overflow: auto; padding: 0px;\"><code style=\"font-family: arial; font-size: 12px; line-height: 20px;\"> </code><span style=\"background-color: transparent; font-size: 12px; line-height: 20px;\">data MPNSresult = MPNSresult{<br />        sucessfullResults :: [(DeviceURI,MPNSinfo)]<br />    ,   errorException    :: [(DeviceURI,CE.SomeException)]<br />    }</span></pre></div><div><br /></div><div>The code is available on GitHub:</div> <b>- </b>The MPNS Api : <a href=\"https://github.com/MarcosPividori/GSoC-Communicating-with-mobile-devices/tree/master/push-notify/Network/PushNotify/Mpns\">[1]</a><br /> <b>- </b>Test example for MPNS: <a href=\"https://github.com/MarcosPividori/GSoC-Communicating-with-mobile-devices/tree/master/push-notify/test\">[2]</a><br /><br />For more information about:<br /> <b>- </b>The MPNS Service: <a href=\"http://msdn.microsoft.com/en-us/library/windowsphone/develop/ff402558(v=vs.105).aspx\">[3]</a><br /> <b>- </b>The communication with MPNS servers:  <a href=\"http://msdn.microsoft.com/en-us/library/windowsphone/develop/hh202945(v=vs.105).aspx\">[4]</a>" nil nil "e6ab4ad0eb67378dea5659b84f9d5126") (303 (20984 50467 496653) "http://parenz.wordpress.com/2013/07/29/ghc-packagedb/" "Daniil Frumin: Adding a package database to the GHC API session" nil "Mon, 29 Jul 2013 13:04:56 +0000" "<p><em>The second post in the series.</em></p>
<h1 id=\"intro\">Intro</h1>
<p>It’s hard to get into writing code that uses GHC API. It’s huge there are so many options around and not a lot of introduction-level tutorials.</p>
<p>In this series of blog posts I’ll elaborate on some of the peculiar, interesting problems I’ve encountered during my experience writing code that uses GHC API and also provide various tips I find useful.</p>
<p>I have built for myself a small layer of helper functions that helped me with using GHC API for the <code>interactive-diagrams</code> project. The source can be found on <a href=\"http://github.com/co-dan/interactive-diagrams\">GitHub</a> and I plan on refactoring the code and releasing it separately.</p>
<p>One particular thing I had to do was to add a GHC package database to the GHC API session.</p>
<p>For those familiar with the structure of the interactive-diagrams project: since the workers run in a separate environment, each of them has it’s own chroot jail including each own package database. I had to manually set up a path to package database for each worker so it would pick up the necessary packages.</p>
<h1 id=\"package-databases\">Package databases</h1>
<p>A <em>package database</em> is a directory where the information about your installed packages is stored. For each package registered in the database there is a .conf file with the package details. The .conf file contains the package description (just like in the .cabal file) as well as path to binaries and a list of resolved dependencies:</p>
<pre><code>$ cat aeson-0.6.1.0.1-5a107a6c6642055d7d5f98c65284796a.conf
name: aeson
version: 0.6.1.0.1
id: aeson-0.6.1.0.1-5a107a6c6642055d7d5f98c65284796a
import-dirs: /home/dan/.cabal/lib/aeson-0.6.1.0.1/ghc-7.7.20130722
library-dirs: /home/dan/.cabal/lib/aeson-0.6.1.0.1/ghc-7.7.20130722
depends: attoparsec-0.10.4.0-acffb7126aca47a107cf7722d75f1f5e
base-4.7.0.0-b67b4d8660168c197a2f385a9347434d
blaze-builder-0.3.1.1-9fd49ac1608ca25e284a8ac6908d5148
bytestring-0.10.3.0-66e3f5813c3dc8ef9647156d1743f0ef
</code></pre>
<p>You can use <code>ghc-pkg</code> to manage installed packages on your system. For example, to list all the packages you’ve installed run <code>ghc-pkg list</code>. To list all the package databases that are automatically picked up by <code>ghc-pkg</code> do the following:</p>
<pre><code>$ ghc-pkg nonexistentpkg
/home/dan/ghc/lib/ghc-7.7.20130722/package.conf.d
/home/dan/.ghc/i386-linux-7.7.20130722/package.conf.d</code></pre>
<p>See <code>ghc-pkg --help</code> or the <a href=\"http://www.haskell.org/ghc/docs/latest/html/users_guide/packages.html#package-management\">online documentation</a> for more details.</p>
<h1 id=\"adding-a-package-db\">Adding a package db</h1>
<p>By default GHC knows only about two package databases: the global package database (usually <code>/usr/lib/ghc-something/</code> on Linux) and the user-specific database (usually <code>~/.ghc/lib</code>). In order to pick up a package that resides in a different package database you have to employ some tricks.</p>
<p>For some reason GHC API does not export an clear and easy-to-use function that would allow you to do that, although the code we need is present in the GHC sources.</p>
<p>The way this whole thing works is the following:</p>
<ol style=\"\">
<li>GHC calls <a href=\"http://co-dan.github.io/ghc-docs/Packages.html#v:initPackages\">initPackages</a>, which reads the database files and sets up the <a href=\"http://co-dan.github.io/ghc-docs/Packages.html#t:PackageState\">internal table</a> of package information</li>
<li>The reading of package databases is performed via the <a href=\"http://co-dan.github.io/ghc-docs/Packages.html#v:initPackages\">readPackageConfigs</a> function. It reads the user package database, the global package database, the “GHC_PACKAGE_PATH” environment variable, and <em>applies the extraPkgConfs function</em>, which is a dynflag and has the following type: <code>extraPkgConfs :: [PkgConfRef] -> [PkgConfRef]</code> (<a href=\"http://co-dan.github.io/ghc-docs/DynFlags.html#t:PkgConfRef\">PkgConfRef</a> is a type representing the package database). The <code>extraPkgConf</code> flag is supposed to represent the <code>-package-db</code> command line option.</li>
<li>Once the database is parsed, the loaded packages are stored in the <code>pkgDatabase</code> dynflag which is a list of <a href=\"http://co-dan.github.io/ghc-docs/PackageConfig.html#t:PackageConfig\">PackageConfig</a>s</li>
</ol>
<p>So, in order to add a package database to the current session we have to simply modify the <code>extraPkgConfs</code> dynflag. Actually, there is already a function <a href=\"http://co-dan.github.io/ghc-docs/src/DynFlags.html\">present</a> in the GHC source that does exactly what we need: <code>addPkgConfRef :: PkgConfRef -> DynP ()</code>. Unfortunately it’s not exported so we can’t use it in our own code. I rolled my own functions that I am using in the interactive-diagrams project, feel free to copy them:</p>
<pre class=\"sourceCode haskell\"><code class=\"sourceCode haskell\"><span style=\"color: green;\">-- | Add a package database to the Ghc monad</span>
#if __GLASGOW_HASKELL_ >= 707
addPkgDb <span style=\"color: red;\">::</span> GhcMonad m <span style=\"color: red;\">=></span> FilePath <span style=\"color: red;\">-></span> m ()
#else
addPkgDb <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span>MonadIO m<span style=\"color: red;\">,</span> GhcMonad m<span style=\"color: red;\">)</span> <span style=\"color: red;\">=></span> FilePath <span style=\"color: red;\">-></span> m ()
#endif
addPkgDb fp <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
dfs <span style=\"color: red;\"><-</span> getSessionDynFlags
<span style=\"color: blue; font-weight: bold;\">let</span> pkg  <span style=\"color: red;\">=</span> PkgConfFile fp
<span style=\"color: blue; font-weight: bold;\">let</span> dfs' <span style=\"color: red;\">=</span> dfs <span style=\"color: red;\">{</span> extraPkgConfs <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span>pkg:<span style=\"color: red;\">)</span> . extraPkgConfs dfs <span style=\"color: red;\">}</span>
setSessionDynFlags dfs'
#if __GLASGOW_HASKELL_ >= 707
<span style=\"color: blue; font-weight: bold;\">_</span> <span style=\"color: red;\"><-</span> initPackages dfs'
#else
<span style=\"color: blue; font-weight: bold;\">_</span> <span style=\"color: red;\"><-</span> liftIO $ initPackages dfs'
#endif
return ()
<span style=\"color: green;\">-- | Add a list of package databases to the Ghc monad</span>
<span style=\"color: green;\">-- This should be equivalen to  </span>
<span style=\"color: green;\">-- > addPkgDbs ls = mapM_ addPkgDb ls</span>
<span style=\"color: green;\">-- but it is actaully faster, because it does the package</span>
<span style=\"color: green;\">-- reintialization after adding all the databases</span>
#if __GLASGOW_HASKELL_ >= 707
addPkgDbs <span style=\"color: red;\">::</span> GhcMonad m <span style=\"color: red;\">=></span> <span style=\"color: red;\">[</span>FilePath<span style=\"color: red;\">]</span> <span style=\"color: red;\">-></span> m ()
#else
addPkgDbs <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span>MonadIO m<span style=\"color: red;\">,</span> GhcMonad m<span style=\"color: red;\">)</span> <span style=\"color: red;\">=></span> <span style=\"color: red;\">[</span>FilePath<span style=\"color: red;\">]</span> <span style=\"color: red;\">-></span> m ()
#endif
addPkgDbs fps <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
dfs <span style=\"color: red;\"><-</span> getSessionDynFlags
<span style=\"color: blue; font-weight: bold;\">let</span> pkgs <span style=\"color: red;\">=</span> map PkgConfFile fps
<span style=\"color: blue; font-weight: bold;\">let</span> dfs' <span style=\"color: red;\">=</span> dfs <span style=\"color: red;\">{</span> extraPkgConfs <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span>pkgs ++<span style=\"color: red;\">)</span> . extraPkgConfs dfs <span style=\"color: red;\">}</span>
setSessionDynFlags dfs'
#if __GLASGOW_HASKELL_ >= 707
<span style=\"color: blue; font-weight: bold;\">_</span> <span style=\"color: red;\"><-</span> initPackages dfs'
#else
<span style=\"color: blue; font-weight: bold;\">_</span> <span style=\"color: red;\"><-</span> liftIO $ initPackages dfs'
#endif
return ()</code></pre>
<h2 id=\"links\">Links</h2>
<ul>
<li><a href=\"http://co-dan.github.io/ghc-docs/Packages.html\">Packages</a> module, contains other functions that modify/make use of <code>extraPkgConfs</code></li>
</ul>
<h1 id=\"outro\">Outro</h1>
<p>This was the second post in the series and we have seen how to add a package database to the GHC session. Stay tuned for more brief posts and updates.</p>
<br /> Tagged: <a href=\"http://parenz.wordpress.com/tag/ghc/\">ghc</a>, <a href=\"http://parenz.wordpress.com/tag/haskell-2/\">haskell</a>, <a href=\"http://parenz.wordpress.com/tag/soc/\">soc</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/parenz.wordpress.com/109/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/parenz.wordpress.com/109/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=parenz.wordpress.com&blog=26722965&post=109&subd=parenz&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "a078455f31a7a154d2e3b100a1db8620") (302 (20984 50467 495238) "http://gsoc2013cwithmobiledevices.blogspot.com/2013/07/microsoft-push-notification-service.html" "Marcos Pividori: Microsoft Push Notification Service" "noreply@blogger.com (Marcos)" "Mon, 29 Jul 2013 12:41:05 +0000" "<div style=\"margin-bottom: 0cm;\"><div style=\"font-style: normal; font-variant: normal; font-weight: normal; line-height: 100%; margin-bottom: 0cm;\"><div style=\"margin-bottom: 0cm;\"><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\">The Microsoft Push Notification Service in Windows Phone is an asynchronous, best-effort service that offers third-party developers a channel to send data to a Windows Phone app from a cloud service in a power-efficient manner.</span></span></div><div style=\"margin-bottom: 0cm; text-align: center;\"><span style=\"color: black;\"><a href=\"http://i.msdn.microsoft.com/dynimg/IC627802.png\"><img src=\"http://i.msdn.microsoft.com/dynimg/IC627802.png\" name=\"graphics1\" align=\"BOTTOM\" height=\"176\" width=\"320\" border=\"0\" /></a></span></div><div align=\"CENTER\" style=\"margin-bottom: 0cm;\"><span style=\"font-size: xx-small;\"><a href=\"http://i.msdn.microsoft.com/dynimg/IC627802.png\"><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\">(from : </span></span></a><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\"><a href=\"http://i.msdn.microsoft.com/dynimg/IC627802.png\">http://i.msdn.microsoft.com/dynimg/IC627802.png</a>)</span></span></span></div><div align=\"CENTER\" style=\"margin-bottom: 0cm;\"><br /></div><div style=\"margin-bottom: 0cm;\"><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\">The process of registration is very similar to the rest of push services. The app requests a push notification URI from the Push client service, and then it sends it to your cloud service.</span></span></div><div style=\"margin-bottom: 0cm;\"><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\">When you have info to send, you use the notification URI to send a push notification to MPNS servers, and </span></span><span style=\"font-family: 'Abyssinica SIL';\">MPNS</span><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\"> routes the push notification to your app.</span></span></div><div style=\"margin-bottom: 0cm;\"><br /></div><div style=\"margin-bottom: 0cm;\"><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\">Depending on the format of the push notification and the payload attached to it, the info is delivered as raw data to the app, the app's Tile is visually updated, or a toast notification is displayed.</span></span></div><div style=\"margin-bottom: 0cm;\"><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\">MPNS returns a response code to your cloud service after a push notification is sent indicating that the notification has been received and will be delivered to the device at the next possible opportunity.</span></span><br /><div style=\"margin-bottom: 0cm;\"><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\">Also, in a response code, you can get information about the state of the device (Connected / Temp Disconnected / Disconnected). For more information: <a href=\"http://msdn.microsoft.com/en-us/library/windowsphone/develop/ff402558(v=vs.105).aspx\">[1]</a></span></span></div><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\"><br /></span></span></div><div style=\"margin-bottom: 0cm;\"><span style=\"font-family: 'Abyssinica SIL';\">When communicating with MPNS servers, you have to send POST messages for each Windows Phone device to which you want to send a notification. You have to specify the appropriate notification type (Raw / Tile / Toast), the destination Uri, and the rest of information in a XML format.</span></div><div style=\"line-height: normal; margin-bottom: 0cm;\"><div style=\"line-height: 16px; margin-bottom: 0cm;\"><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\">If you want to send multiple notifications, you must create separate POST messages for each notification. This is one of the differences with GCM, where you can send multicast messages in a single POST request.</span></span></div></div></div><div style=\"margin-bottom: 0cm;\"><br /><div style=\"line-height: 100%; margin-bottom: 0cm;\"><br /></div></div></div>" nil nil "aca2de60f2170de5eb8dd16fd9baadad") (301 (20984 50467 494549) "http://feedproxy.google.com/~r/ezyang/~3/YnvYUomvfvw/" "Edward Z. Yang: OPLSS lecture notes" nil "Mon, 29 Jul 2013 04:02:10 +0000" "<div class=\"document\">
<p>I write in from sunny Oregon, where the sun floods into your room at seven in the morning and the <a href=\"http://www.cs.uoregon.edu/research/summerschool/summer13/index.html\" class=\"reference external\">Oregon Programming Languages Summer School</a> is in session.  So far, it’s been a blast—with lectures covering Coq, Agda, homotopy type theory, linear logic, logical relations—and we’ve still got another week to go!</p>
<p>If you were not able to make it, fear not: you can go to the <a href=\"http://www.cs.uoregon.edu/research/summerschool/summer13/curriculum.html\" class=\"reference external\">curriculum</a> page and pick up not only videos (I hear they are still quite large; we’ve been trying to convince the organizers to upload them to YouTube) but <strong>lecture notes</strong> from yours truly. (<a href=\"http://www.cs.uoregon.edu/research/summerschool/summer13/lectures/ahmed-1.pdf\" class=\"reference external\">Sample from the logical relations lectures</a>.) The earlier notes are a little iffy, but I get a bit more detailed on the later ones.</p>
<p>One technical note: I have heard that some folks on Macs are having trouble viewing the PDFs on the default PDF viewers; the text doesn’t show up. I have also heard that Chrome’s PDF viewer as well as Acrobat Reader are able to read the PDFs. Whatever the problem is, it is likely some trouble with Xournal’s PDF export functionality. If someone has a method of fixing this without losing metadata (e.g. the ability to copy/paste the text), I’d be all ears.</p>
</div>
<img src=\"http://feeds.feedburner.com/~r/ezyang/~4/YnvYUomvfvw\" height=\"1\" width=\"1\" />" nil nil "779f0280a59edb99c3081dff08d3ffcf") (300 (20984 50467 494126) "http://parenz.wordpress.com/2013/07/28/quick-update/" "Daniil Frumin: Quick update" nil "Sun, 28 Jul 2013 09:47:52 +0000" "<p>I’ve updated the online documentation for the Git versions of GHC and base to the 2013.07.22 version:</p>
<ul>
<li><a href=\"http://co-dan.github.io/ghc-docs/index.html\">ghc-7.7.20130722 docs</a></li>
<li><a href=\"http://co-dan.github.io/base-docs/index.html\">base-4.7.0.0 docs</a></li>
</ul>
<p>I don’t always rebuild GHC, but when I do I upload the docs online.</p>
<br /> Tagged: <a href=\"http://parenz.wordpress.com/tag/ghc/\">ghc</a>, <a href=\"http://parenz.wordpress.com/tag/haskell-2/\">haskell</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/parenz.wordpress.com/107/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/parenz.wordpress.com/107/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=parenz.wordpress.com&blog=26722965&post=107&subd=parenz&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "c9f183b0f864495f19c02ff5fa9b514c") (299 (20984 50467 493833) "http://chrisdone.com/posts/haskell-news" "Christopher Done: Haskell News" nil "Fri, 26 Jul 2013 00:00:00 +0000" "<p>As a consumer of Haskell content I neither have the time nor inclination to follow haskell-cafe and other various mailing lists, the reddits, the google+ community, planet haskell, hackage releases, twitter, youtube and whatever other submission places I haven’t heard of.</p>
<p>I wrote this <a href=\"http://www.haskell.org/pipermail/haskell-cafe/2013-February/104898.html\">to Haskell-Cafe</a> four months ago. Only one person responded, which was <a href=\"http://www.haskell.org/pipermail/haskell-cafe/2013-February/104899.html\">Daniel Díaz Casanueva</a>, the producer of <a href=\"http://contemplatecode.blogspot.it/\">Haskell Weekly News</a>. Naturally this would be a great resource for him, as it would summarize everything of the past few days in one place.</p>
<p>Shortly after this post I went ahead and implemented <a href=\"http://haskellnews.org/\">Haskell News</a> for which you can find <a href=\"https://github.com/chrisdone/haskellnews/\">the source code here on GitHub</a>.</p>
<p>It has two views: grouped and mixed. Grouped lists all the items according to their source, and mixed lists everything in a flat stream. The mixed view polls for updates every ten minutes, so that users can leave it open in a tab a la Twitter. There is also <a href=\"http://haskellnews.org/feed\">an RSS feed</a>, because I heard you like feeds, so I put a feed in your feed so you can subscribe while you subscribe.</p>
<p>The sources, as of writing, are:</p>
<ul>
<li>Reddit: /r/haskell and /r/programming posts containing the word “haskell”</li>
<li>Haskell-Cafe</li>
<li>Stack Overflow: questions tagged “haskell”</li>
<li>Pastes: pastes made to the #haskell channel</li>
<li>GitHub: updates for projects that contain Haskell code</li>
<li>Planet Haskell</li>
<li>Google+: posts to the Haskell community</li>
<li>Twitter: posts tagged “#haskell” or containing “Haskell”</li>
<li>Hackage</li>
<li>IRC Quotes: things that have been @remember’d in the #haskell channel</li>
<li>Vimeo: various Haskell related feeds</li>
<li>HaskellWiki: updates to the wiki</li>
</ul>
<p>I think this paints a fairly comprehensive picture of the Haskell community’s public activities. Certainly, if you want Haskell news, here is the best place online to go.</p>
<p>All the feeds are updated every ten minutes. All of the feeds are taken from RSS or Atom feeds, with the exception of three, which I scraped with tagsoup:</p>
<ul>
<li>Google+, which provides no RSS feed (but they do provide an API, which I could look into if I had nothing better to do)</li>
<li>Twitter, which no longer provides an RSS feed (but they do provide an API, which I could look into if I had nothing better to do)</li>
<li>Github, which does not provide an RSS feed for language-specific project updates (I don’t know if they have an API, nor care too much)</li>
</ul>
<p>All feed items are stored in a database forever. There are currently 17k entries from 4 months of running. Feeds are unparseable for the feed library from time to time.</p>" nil nil "8314ddef1b6ad6d468f4d6fc89ac3f11") (298 (20984 50467 493234) "http://feedproxy.google.com/~r/FpComplete/~3/0WBJNIMzHHA/academic-accounts" "FP Complete: FP Complete Announces Free Academic Accounts" nil "Thu, 25 Jul 2013 19:30:00 +0000" "<p>We are pleased to announce our free academic program where faculty members and students from accredited institutions can use <a href=\"http://feeds.feedburner.com/business/haskell-center/overview\"><b>FP Haskell Center</b></a> for free. You can get your free account through a simple web sign-up form starting in mid-August, right before FP Haskell Center becomes generally available in early September.  If you haven’t already, you can get started now by <a href=\"http://feeds.feedburner.com/business/designer-ide\"><b>signing up</b></a> for the Beta.</p><p>With many tutorials and sample code included in the product, <a href=\"http://feeds.feedburner.com/business/haskell-center/overview\"><b>FP Haskell Center</b></a> provides both teachers and students with an accessible cloud-based platform to teach/learn, perform Haskell research, and develop real-world solutions.</p><p>FP Haskell Center is an integrated development and deployment environment written in Haskell. It consists of two components: the FP Development Environment and the FP Application Server. The FP Development Environment includes a Haskell compiler and a continually updated set of vetted, tested and supported libraries and code templates. There is no need to run Cabal or other installers. The FP Application Server is used to deploy and run Haskell applications directly in the cloud.</p><p>Crescat scientia; vita excolatur!*</p><p>* \"Let knowledge grow; life is perfected.\"</p><div class=\"feedflare\">
<a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=0WBJNIMzHHA:Cjmwrw7LEvs:yIl2AUoC8zA\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=yIl2AUoC8zA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=0WBJNIMzHHA:Cjmwrw7LEvs:V_sGLiPBpWU\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=0WBJNIMzHHA:Cjmwrw7LEvs:V_sGLiPBpWU\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=0WBJNIMzHHA:Cjmwrw7LEvs:qj6IDK7rITs\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=qj6IDK7rITs\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=0WBJNIMzHHA:Cjmwrw7LEvs:gIN9vFwOqvQ\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=0WBJNIMzHHA:Cjmwrw7LEvs:gIN9vFwOqvQ\" border=\"0\" /></a>
</div><img src=\"http://feeds.feedburner.com/~r/FpComplete/~4/0WBJNIMzHHA\" height=\"1\" width=\"1\" />" nil nil "7791c67d2e0fd7ea9ed586a44ba945a4") (297 (20984 50467 492441) "http://kpreid.livejournal.com/50726.html" "Kevin Reid (kpreid): Language design idea: pure name-spaces" "kpreid@switchb.org (Kevin Reid (kpreid))" "Wed, 24 Jul 2013 03:32:57 +0000" "<p>One of the nice things about Common Lisp is the pervasive use of (its notion of) symbol objects for names. For those unfamiliar, I'll give a quick introduction to the relevant parts of their semantics before going on to my actual proposal for a “good parts version”.</p>
<p>A CL <dfn>symbol</dfn> is an object (value, if you prefer). A symbol has a name (which is a string). A CL <dfn>package</dfn> is a map from strings to symbols (and the string key is always equal to the symbol's name). A symbol may be in zero or more packages. (Note in particular that symbol names need not be unique except within a single package.)
</p><p>Everywhere in CL that something is <em>named</em> — a variable, a function, a class, etc. — the name is a symbol object. (This is not impractical because the syntax makes it easy to write symbols; in fact, easier than writing strings, because they are unquoted.)
</p><p>The significance of this is that <em>the programmer need never give significance to characters within a string name in order to avoid collisions</em>. Namespacing of explicitly written symbols is handled by packages; namespacing of programmatically generated symbols is handled by simply never putting them in any package (thus, they are accessible only by passing references); these are known as <dfn>gensyms</dfn>.
</p><p>Now, I don't mean to say that CL is perfect; it fails by way of conflating too many different facilities on a single symbol (lexical variables, dynamic variables, global non-lexical definitions, ...), and some of the multiple purposes motivate programmers to use naming conventions. But I think that there is value in the symbol system because it discourages the mistake of providing an interface which requires inventing unique string names.
</p><p>(One thinking along capability lines might ask — why use <em>names</em> rather than references at all? Narrowly, think about method names (selectors, for the Smalltalk/ObjC fans) and module exports; broadly, distribution and bootstrapping.)
</p><hr />
<p>So, here’s my current thought on a “good parts version”, specifically designed for an E-style language with deep equality/immutability and no global mutable state.
</p><p>There is a notion of <dfn>name</dfn>, which includes three concrete types:
</p><ol>
<li>A <dfn>symbol</dfn> is an object which has a string-valued name, and whose identity depends solely on that string.
</li><li>A <dfn>gensym</dfn> also has a name, but has an unique identity (<em>selfish</em>, in E terms). Some applications might reject gensyms since they are not data.
</li><li>A <dfn>space-name</dfn> holds two names and its identity depends solely on that combination. (That is, it is a “pair” or “cons” specifically of names.)
</li></ol>
<p>Note that these three kinds of objects are all immutable, and use no table structures, and yet can produce the same characteristics of names which I mentioned above. (For implementation, the identity of a name as above defined can be turned into pointer identity using hash consing, a generalization of interning.) Some particular examples and notes:
</p><ul>
<li>A CL symbol in a package corresponds to a pair of two symbols, or perhaps a gensym and a symbol. This correspondence is not exact, of course. (In particular, there is no notion here of the set of exported symbols in a package. But that's the sort of thing you have to be willing to give up to obtain a system without global mutable state. And you can still imagine 'linting' for unexpected symbols.)
</li><li>The space-name type means that names can be arbitrary binary trees. If we consistently give the left side a “namespace” interpretation and the right side a “local name” one, then we have a system, I think, where people can carve out all sorts of namespaces without ever fearing collisions or conflicts, should it become necessary. Which probably means it's massively overdesigned (cf. \"worse is better\").
</li><li>Actual use case example: Suppose one wishes to define (for arbitrary use) a subtype of some well-known interface, which adds one method. There is a risk that your choice of name for that method conflicts with someone else's different subtype. Under this system, you can construct a space-name whose two components are a large random number (i.e. a unique ID) acting as the namespace, and a symbol which is your chosen simple name. One can imagine syntax and tools which make it easy to forget about the large random number and merely use the simple name.
</li><li>It's unclear to me how these names would be used inside the lexical variable syntax of a language, if they would at all; I suspect the answer is that they would not be, or mostly confined to machine-generated-code cases. The primary focus here is improving the default characteristics of a straightforwardly written program which uses a map from names to values in some way.
</li></ul>
<p>(This is all very half-baked — I'm just publishing it on the grounds described in my previous post: in the long run I'll have more ideas than I ever implement, and this is statistically likely to be one of them, so I might as well publish it and hope someone else finds some use for it; if nothing else, I can stop feeling any obligation to <em>remember</em> it in full detail.)</p>" nil nil "f2b1fceaac18d8ac31f45da94b658e1b") (296 (20984 50467 446509) "http://joyful.com/blog/2013-07-23-darcs-hub-repo-stats-hledger-balance-sheet.html" "Simon Michael: darcs hub repo stats, hledger balance sheet" nil "Wed, 24 Jul 2013 02:50:00 +0000" "<div style=\"font-style: italic;\">July 24, 2013</div>
<h2>darcs hub repo stats, hledger balance sheet</h2>
<p>
</p><p>Recent activity:</p>
<p>I fixed another clumsy query on darcs hub, making the all repos page faster. Experimented with user and repo counts on the front page. I like it, but haven’t deployed to production yet. It costs about a quarter of a second in page load time (one 50ms couch query to fetch all repos, plus my probably-suboptimal filtering and sorting).</p>
<p>I’ve finally learned how many of those names on the front page have (public) repos behind them (144 out of 319), and how many private repos there are (125, higher than expected!).</p>
<p>Thinking about what is really most useful to have on the front page. Keep listing everything ? Just top 5 in various categories ? Ideas welcome.</p>
<p>Did a bunch of bookkeeping today, which inspired my first hledger commit in a while. I found the balancesheet command (abbreviation: bs) highly useful for a quick snapshot of assets and liabilities to various depths (add –depth N). The Equity section was just a distraction though, and I think it will be to most hledger users for the time being, so I removed it.</p>
<p>
<br />
<em><a href=\"http://joyful.com/tags/haskell.html\">haskell</a>, <a href=\"http://joyful.com/tags/darcs.html\">darcs</a>, <a href=\"http://joyful.com/tags/hledger.html\">hledger</a>, <a href=\"http://joyful.com/tags/finance.html\">finance</a></em></p>" nil nil "e79952f04f3ef0e817ab6d97b5a8a0e6") (295 (20984 50467 445918) "http://parenz.wordpress.com/2013/07/23/on-custom-error-handlers-for-ghc-api/" "Daniil Frumin: On custom error handlers for the GHC API" nil "Tue, 23 Jul 2013 15:55:42 +0000" "<h1 id=\"intro\">Intro</h1>
<p>It’s hard to get into writing code that uses GHC API. It’s huge there are so many options around and not a lot of introduction-level tutorials.</p>
<p>In <a href=\"http://parenz.wordpress.com/tag/ghc\">this series of blog posts</a> I’ll elaborate on some of the peculiar, interesting problems I’ve encountered during my experience writing code that uses GHC API and also provide various tips I find useful.</p>
<p>I have built for myself a small layer of helper functions that helped me with using GHC API for the <code>interactive-diagrams</code> project. The source can be found on <a href=\"http://github.com/co-dan/interactive-diagrams\">GitHub</a> and I plan on refactoring the code and releasing it separately.</p>
<h1 id=\"error-handling\">Error handling</h1>
<p>Today I would like to talk about setting your own error handlers for GHC API. By default you can expect GHC to spew all the errors onto your screen, but for my purposes I wanted to log them.</p>
<p>Naturally at first I tried the following:</p>
<p>I am in need of setting up custom exception handlers when using GHC API to compile modules. Right now I have the following piece of code:</p>
<pre><code><span style=\"color: green;\">-- Main.hs:</span>
<span style=\"color: blue; font-weight: bold;\">import</span> GHC
<span style=\"color: blue; font-weight: bold;\">import</span> GHC.Paths
<span style=\"color: blue; font-weight: bold;\">import</span> MonadUtils
<span style=\"color: blue; font-weight: bold;\">import</span> Exception
<span style=\"color: blue; font-weight: bold;\">import</span> Panic
<span style=\"color: blue; font-weight: bold;\">import</span> Unsafe.Coerce
<span style=\"color: blue; font-weight: bold;\">import</span> System.IO.Unsafe
<span style=\"color: green;\">-- I thought this code would handle the exception</span>
handleException <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span>ExceptionMonad m<span style=\"color: red;\">,</span> MonadIO m<span style=\"color: red;\">)</span>
<span style=\"color: red;\">=></span> m a <span style=\"color: red;\">-></span> m <span style=\"color: red;\">(</span>Either String a<span style=\"color: red;\">)</span>
handleException m <span style=\"color: red;\">=</span>
ghandle <span style=\"color: red;\">(</span><span style=\"color: red;\">\\</span><span style=\"color: red;\">(</span>ex <span style=\"color: red;\">::</span> SomeException<span style=\"color: red;\">)</span> <span style=\"color: red;\">-></span> return <span style=\"color: red;\">(</span>Left <span style=\"color: red;\">(</span>show ex<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> $
handleGhcException <span style=\"color: red;\">(</span><span style=\"color: red;\">\\</span>ge <span style=\"color: red;\">-></span> return <span style=\"color: red;\">(</span>Left <span style=\"color: red;\">(</span>showGhcException ge <span style=\"color: teal;\">\"\"</span><span style=\"color: red;\">)</span><span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> $
flip gfinally <span style=\"color: red;\">(</span>liftIO restoreHandlers<span style=\"color: red;\">)</span> $
m >>= return . Right
<span style=\"color: green;\">-- Initializations, needed if you want to compile code on the fly</span>
initGhc <span style=\"color: red;\">::</span> Ghc ()
initGhc <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
dfs <span style=\"color: red;\"><-</span> getSessionDynFlags
setSessionDynFlags $ dfs <span style=\"color: red;\">{</span> hscTarget <span style=\"color: red;\">=</span> HscInterpreted
<span style=\"color: red;\">,</span> ghcLink <span style=\"color: red;\">=</span> LinkInMemory <span style=\"color: red;\">}</span>
return ()
<span style=\"color: green;\">-- main entry point</span>
main <span style=\"color: red;\">=</span> test >>= print
test <span style=\"color: red;\">::</span> IO <span style=\"color: red;\">(</span>Either String Int<span style=\"color: red;\">)</span>
test <span style=\"color: red;\">=</span> handleException $ runGhc <span style=\"color: red;\">(</span>Just libdir<span style=\"color: red;\">)</span> $ <span style=\"color: blue; font-weight: bold;\">do</span>
initGhc
setTargets =<< sequence <span style=\"color: red;\">[</span> guessTarget <span style=\"color: teal;\">\"file1.hs\"</span> Nothing <span style=\"color: red;\">]</span>
graph <span style=\"color: red;\"><-</span> depanal [] False
loaded <span style=\"color: red;\"><-</span> load LoadAllTargets
<span style=\"color: green;\">-- when (failed loaded) $ throw LoadingException</span>
setContext <span style=\"color: red;\">(</span>map <span style=\"color: red;\">(</span>IIModule . moduleName . ms_mod<span style=\"color: red;\">)</span> graph<span style=\"color: red;\">)</span>
<span style=\"color: blue; font-weight: bold;\">let</span> expr <span style=\"color: red;\">=</span> <span style=\"color: teal;\">\"run\"</span>
res <span style=\"color: red;\"><-</span> unsafePerformIO . unsafeCoerce <$> compileExpr expr
return res
<span style=\"color: green;\">-- file1.hs:</span>
<span style=\"color: blue; font-weight: bold;\">module</span> Main <span style=\"color: blue; font-weight: bold;\">where</span>
main <span style=\"color: red;\">=</span> return ()
run <span style=\"color: red;\">::</span> IO Int
run <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
n <span style=\"color: red;\"><-</span> x
return <span style=\"color: red;\">(</span>n+<span class=\"hs-num\">1</span><span style=\"color: red;\">)</span></code></pre>
<p>The problem is when I run the ‘test’ function above I receive the following output:</p>
<pre><code>h> test
test/file1.hs:4:10: Not in scope: `x'
Left \"Cannot add module Main to context: not a home module\"
it :: Either String Int</code></pre>
<p>What the ..? My exception handler did catch the error, but:</p>
<ol style=\"\">
<li>A strange one</li>
<li>The error I intended to catch got</li>
</ol>
<p>Is there a way to fix this?</p>
<h1 id=\"solution\">Solution</h1>
<p>I even asked this problem on the Haskell-Cafe mailing list, but the folks there don’t seem to be very keen on GHC/GHC API (which is understandable) and I haven’t got any answers.</p>
<p>But thanks to my mentor Luite Stegeman we’ve found the solution.</p>
<p>Errors are handled using the <a href=\"http://co-dan.github.io/ghc-docs/DynFlags.html#t:LogAction\">LogAction</a> specified in the <a href=\"http://co-dan.github.io/ghc-docs/DynFlags.html#t:DynFlags\">DynFlags</a> for your GHC session. So to fix this you need to change ‘log_action’ parameter in dynFlags. For example, you can do this:</p>
<pre><code>initGhc <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
<span style=\"color: red;\">..</span>
ref <span style=\"color: red;\"><-</span> liftIO $ newIORef <span style=\"color: teal;\">\"\"</span>
dfs <span style=\"color: red;\"><-</span> getSessionDynFlags
setSessionDynFlags $ dfs <span style=\"color: red;\">{</span> hscTarget  <span style=\"color: red;\">=</span> HscInterpreted
<span style=\"color: red;\">,</span> ghcLink    <span style=\"color: red;\">=</span> LinkInMemory
<span style=\"color: red;\">,</span> log_action <span style=\"color: red;\">=</span> logHandler ref <span style=\"color: green;\">-- ^ this</span>
<span style=\"color: red;\">}</span>
<span style=\"color: green;\">-- LogAction == DynFlags -> Severity -> SrcSpan -> PprStyle -> MsgDoc -> IO ()</span>
logHandler <span style=\"color: red;\">::</span> IORef String <span style=\"color: red;\">-></span> LogAction
logHandler ref dflags severity srcSpan style msg <span style=\"color: red;\">=</span>
<span style=\"color: blue; font-weight: bold;\">case</span> severity <span style=\"color: blue; font-weight: bold;\">of</span>
SevError <span style=\"color: red;\">-></span>  modifyIORef' ref <span style=\"color: red;\">(</span>++ printDoc<span style=\"color: red;\">)</span>
SevFatal <span style=\"color: red;\">-></span>  modifyIORef' ref <span style=\"color: red;\">(</span>++ printDoc<span style=\"color: red;\">)</span>
<span style=\"color: blue; font-weight: bold;\">_</span>        <span style=\"color: red;\">-></span>  return () <span style=\"color: green;\">-- ignore the rest</span>
<span style=\"color: blue; font-weight: bold;\">where</span> cntx <span style=\"color: red;\">=</span> initSDocContext dflags style
locMsg <span style=\"color: red;\">=</span> mkLocMessage severity srcSpan msg
printDoc <span style=\"color: red;\">=</span> show <span style=\"color: red;\">(</span>runSDoc locMsg cntx<span style=\"color: red;\">)</span></code></pre>
<h1 id=\"outro\">Outro</h1>
<p>That’s the first tip and the first post in the series, stay tuned for more updates.</p>
<br /> Tagged: <a href=\"http://parenz.wordpress.com/tag/ghc/\">ghc</a>, <a href=\"http://parenz.wordpress.com/tag/haskell-2/\">haskell</a>, <a href=\"http://parenz.wordpress.com/tag/soc/\">soc</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/parenz.wordpress.com/103/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/parenz.wordpress.com/103/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=parenz.wordpress.com&blog=26722965&post=103&subd=parenz&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "82a5d7b8bfb1794b7624bbe2812a23b4") (294 (20984 50467 444461) "http://feedproxy.google.com/~r/holdenkarau/iYtm/~3/iOSzJ2vt2OQ/whats-new-in-spark-this-week-3.html" "Holden Karau: Whats new in Spark this week #3" "noreply@blogger.com (Holden Karau)" "Tue, 23 Jul 2013 02:01:29 +0000" "<div style=\"text-align: left;\">
Its been a busy week in the world of Spark with some interesting announcements. First off there is another AMP camp being hosted at Berkeley <a href=\"http://ampcamp.berkeley.edu/amp-camp-three-berkeley-2013\">http://ampcamp.berkeley.edu/amp-camp-three-berkeley-2013</a> from August 29th to 30th . Which, fair warning, is in the middle of burning man for those of you who participate in that. More importantly there is a new Spark stable release (0.7.3) and you can read the release notes at <a href=\"http://spark-project.org/spark-release-0-7-3/\">http://spark-project.org/spark-release-0-7-3/</a>. This release is mostly bug fixes, however heavy users of the spark shell may wish to usenew shell environment variable ADD_JARS to add JARS to the spark shell workers.</div>
<div style=\"text-align: left;\">
In this weeks checkins</div>
<ul>
<li><a href=\"https://github.com/karenfeng\">https://github.com/karenfeng</a> improved the task UI in <a href=\"https://github.com/mesos/spark/commit/872c97ad829ba20e866c4e45054e7d2d05b02042\">https://github.com/mesos/spark/commit/872c97ad829ba20e866c4e45054e7d2d05b02042</a> , <a href=\"https://github.com/mesos/spark/commit/2eea974795dfa2bb79e66496454f36cb499065b0\">https://github.com/mesos/spark/commit/2eea974795dfa2bb79e66496454f36cb499065b0</a> , ...</li>
<li><a href=\"https://github.com/JoshRosen\">https://github.com/JoshRosen</a> fixed a bug which caused the Java sampleStdev to compute the regular stdev instead.</li>
<li><a href=\"https://github.com/viirya\">https://github.com/viirya</a> fixed a bug with Spark in Yarn standalone mode copying JARs causing task failure <a href=\"https://github.com/mesos/spark/commit/a613628c5078cf41feb973d0ee8a06eb69615bcf\">https://github.com/mesos/spark/commit/a613628c5078cf41feb973d0ee8a06eb69615bcf</a></li>
<li><a href=\"https://github.com/shivaram\">https://github.com/shivaram</a> added support for providing an weight vector to the logistic regression functions <a href=\"https://github.com/mesos/spark/commit/84fa20c2a135f54745ddde9abb4f5e60af8856d1\">https://github.com/mesos/spark/commit/84fa20c2a135f54745ddde9abb4f5e60af8856d1</a></li>
<li><a href=\"https://github.com/ScrapCodes\">https://github.com/ScrapCodes</a> upgraded Aka from 2.0.3 to 2.0.5 <a href=\"https://github.com/mesos/spark/pull/708\">https://github.com/mesos/spark/pull/708</a></li>
</ul>
<div class=\"feedflare\">
<a href=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?a=iOSzJ2vt2OQ:Jh483twMsks:yIl2AUoC8zA\"><img src=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?d=yIl2AUoC8zA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?a=iOSzJ2vt2OQ:Jh483twMsks:63t7Ie-LG7Y\"><img src=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?d=63t7Ie-LG7Y\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?a=iOSzJ2vt2OQ:Jh483twMsks:V_sGLiPBpWU\"><img src=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?i=iOSzJ2vt2OQ:Jh483twMsks:V_sGLiPBpWU\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?a=iOSzJ2vt2OQ:Jh483twMsks:7Q72WNTAKBA\"><img src=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?d=7Q72WNTAKBA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?a=iOSzJ2vt2OQ:Jh483twMsks:qj6IDK7rITs\"><img src=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?d=qj6IDK7rITs\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?a=iOSzJ2vt2OQ:Jh483twMsks:gIN9vFwOqvQ\"><img src=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?i=iOSzJ2vt2OQ:Jh483twMsks:gIN9vFwOqvQ\" border=\"0\" /></a>
</div><img src=\"http://feeds.feedburner.com/~r/holdenkarau/iYtm/~4/iOSzJ2vt2OQ\" height=\"1\" width=\"1\" />" nil nil "9870f6febee6d7df8d4d4b7ff3b2900a") (293 (20984 50467 443835) "http://winterkoninkje.dreamwidth.org/85582.html" "wren ng thornton: Dieting update" nil "Tue, 23 Jul 2013 01:08:49 +0000" "<p>It's been three weeks since I <a href=\"http://winterkoninkje.dreamwidth.org/84727.html\">got the bad news</a> about cholesterol and blood-sugar levels. Three weeks since I've started <a href=\"http://www.webmd.com/heart-disease/news/20090608/high-protein-diet-goes-vegetarian\">this crazy diet</a>. So, I figure it's time for an update on how things are going.</p>
<p>First off: I feel amazing! After just one day I felt more energetic than I have in a long time: I had a lot more pep like I'd upgraded to a more-powerful or smoother-running engine, but it felt like the gas tank was on empty. Makes sense, of course. The former feeling has continued, whereas the latter has gone away as I've gotten used to not relying on the quick boost that sugars give. Also, that feeling of getting winded after climbing a steep hill or those slight stomach cramps after a long hike? I haven't had the slightest glimmer of either since starting. Even after I'm done with the dieting per se, this is definitely going to change the way I eat from now on. The difference is just obscene.</p>
<p>One thing I learned, which apparently everyone else already knows, is that it's the protein what makes you feel full. For the first week, I was so full/unhungry that I had to be careful to keep my calories up. For someone of my stature, it's dangerous when you don't feel like eating more than 1000-or-so calories a day. Protein shakes helped a lot here. By the second week it was easier to get enough calories \"naturally\", and still easier during the third week. However, I'm still averaging 444 below my stated goal of 2247 (which would amount to losing around 2 pounds/week); which is better than the 514 below of the second week, but not so good as the 266 below of the first week. Even though 2247 is the stated goal according to my phone app, this last week I've been aiming more for 2000. Still, now that I've run the numbers, it looks like I should add the shakes back in. Lo-cal is good and all, but I don't want my body to trigger starvation mode. That'd suck.</p>
<center><img src=\"http://llama.freegeek.org/~wren/resources/blog/2013-07-22-calories.png\" height=\"218\" width=\"500\" /></center>
<p>So, I've been doing good on calories (as in the graphic above). However, getting the 1::1 balance between protein and carbs has been a lot harder (as in the graphic below). The upswing in carbs and downswing in fat on the right should be taken with a grain of salt. The graphics include today, but I've only entered my breakfast so far. Still, I have been allowing myself some more carbs the last two days, so I should be sure to keep that in check. I've got a solid breakfast recipe which isn't quite 1::1 but it's close, and a few nights back Licia made an amazing lasagne which was exactly 1::1, so I'll try to post those in a couple-few days.</p>
<center><img src=\"http://llama.freegeek.org/~wren/resources/blog/2013-07-22-nutrients.png\" height=\"238\" width=\"500\" /></center><br /><br /><img src=\"http://www.dreamwidth.org/tools/commentcount?user=winterkoninkje&ditemid=85582\" alt=\"comment count unavailable\" height=\"12\" style=\"vertical-align: middle;\" width=\"30\" /> comments" nil nil "be989bfc901819d76482aa2bc7efb517") (292 (20984 50467 443331) "http://joyful.com/blog/2013-07-22-hub-hacking.html" "Simon Michael: hub hacking" nil "Tue, 23 Jul 2013 00:30:00 +0000" "<div style=\"font-style: italic;\">July 23, 2013</div>
<h2>hub hacking</h2>
<p>
</p><p>More darcs hub activity, including some actual app development (yay):</p>
<p>Added news links to the <a href=\"http://hub.darcs.net\">front page</a>.</p>
<p>Cleaned up <a href=\"http://hub.darcs.net/simon/hub.darcs.net\">hub’s docs repo</a> and updated the list of blockers on the <a href=\"http://hub.darcs.net/simon/hub.darcs.net/ROADMAP.md\">roadmap</a>.</p>
<p>Updated/closed a number of issues, including the app-restarting <a href=\"http://hub.darcs.net/simon/darcsden/issue/58\">#58</a>, thanks to a fast highlighting-kate fix by John McFarlane.</p>
<p>Tested and configured the issue-closing commit posthook in the darcsden trunk repo. Commits pushed/merged there whose message contains the regex <code>(closes #([0-9]+)|resolves #([0-9]+)|fixes #([0-9]+))</code> will now close the specified issue, with luck.</p>
<p>Consolidated a number of modules to help with code navigation, to be pushed soon.</p>
<p>Improved the redirect destination when deleting or forking repos or creating/commenting/closing issues.</p>
<p>Fixed a silly whitespace issue when viewing a patch, where the author name and date run together. I’m still confused about the specific code that generates this - the code I expect uses tables but firebug shows divs. A mystery for another day..</p>
<p>
<br />
<em><a href=\"http://joyful.com/tags/darcs.html\">darcs</a>, <a href=\"http://joyful.com/tags/haskell.html\">haskell</a></em></p>" nil nil "3b59fa566ade2f2a7431dfb9c3305574") (291 (20984 50467 442948) "http://chrisdone.com/posts/ircbrowse" "Christopher Done: IRC Browse" nil "Tue, 23 Jul 2013 00:00:00 +0000" "<p>Haven’t blogged in a while, had some time to write now.</p>
<p>Since I last blogged, I made <a href=\"http://ircbrowse.net/\">IRC Browse.</a> It’s a service which allows you to browse the IRC logs of the #haskell and #lisp channels of Freenode. The logs come from <a href=\"http://chrisdone.com/tunes.org/~nef/logs/\">tunes</a>, and, for <a href=\"http://ircbrowse.net/browse/haskell\">Haskell</a>, they go back to 2001. I like IRC. I don’t go on it that frequently anymore, but I like to read the logs and I see it for the useful communication and coordination tool it is. I’ve always wanted a trivial way to view and share IRC logs as a service, so I made one. The source code is <a href=\"https://github.com/chrisdone/ircbrowse\">here</a>.</p>
<p>It boasts these features:</p>
<ul>
<li><a href=\"http://ircbrowse.net/\">A simple summary</a> of statistics on the home page</li>
<li><a href=\"http://ircbrowse.net/browse/haskell\">Browsing, page by page</a>, all the logs</li>
<li><a href=\"http://ircbrowse.net/browse/haskell?q=chrisdone\">Searching</a> the logs</li>
<li><a href=\"http://ircbrowse.net/nick/chrisdone\">Viewing a statistics profile</a> of a particular person</li>
</ul>
<p>It’s written in Haskell, using Snap, PostgreSQL for the database, and Sphinx for search. It’s fast.</p>
<p>I made it ages ago, really, but thought it worth blogging about once.</p>
<h2 id=\"the-irc-summary\">The IRC summary</h2>
<p>The IRC summary is generated upon request, and reveals some possibly interesting insights into channel activity and the top contributors.</p>
<p>Of interest the most is the activity by year, which indicates that 2009 was the apex of the IRC channel’s activity, which has since dwindled, and appears to be continuing to dwindle: despite sustained activity, conversation generally is decreasing.</p>
<p>There are various hypotheses put forth for this. I speculate that</p>
<ul>
<li>People have been moving to other channels, such as #haskell-lens, #haskell-blah, etc.</li>
<li>People are able to read reliable books that are now well publicized in contrast to in the past</li>
<li>Some very active people have moved on</li>
</ul>
<h2 id=\"browsing\">Browsing</h2>
<p>This is where the name “IRC Browse” comes from. There used to be a service at ircbrowse.com, a few years back, providing a similar browsing service. I asked the author of that old site whether I could use the name ircbrowse.net, and they approved and wished me luck.</p>
<p>One thing that bugged me about the old IRC Browse was the speed. It was god-awfully slow. It would take ages just to display one page of logs. What I wanted was to have a log browsing service that would be <em>instantaneous</em> and snappy.</p>
<p>After some learning with PostgreSQL, I discovered some ways to make paginating 26 million rows of a table quite fast. Simply using <code>OFFSET</code>/<code>LIMIT</code> is far too slow—takes about one second to retrieve a result. I couldn’t simply query on the IDs, because there isn’t just one channel, or one pagination type. So I created a separate table to store paging indexes. For every row of the “event” table, I created a corresponding, ordered, row in the index table. After that, it was snappy.</p>
<p>Another thing I discovered is that my pgsql-simple library was a little sluggish. The pages would retrieve in, say, 50ms, rather than, say, 2ms. So I switched the library to postgresql-simple and got the extremely snappy responsiveness that I wanted.</p>
<h2 id=\"searching\">Searching</h2>
<p>For searching I learned how to use the tool called Sphinx. It takes in a configuration and a database, and then populates a search index. From that search index, it provides very fast full text search.</p>
<p>I couldn’t get the Sphinx library to work with the version of Sphinx I was using at the time. I made a trivial wrapper to the command line program instead. That worked. At some point I will replace this with use of the Haskell sphinx library.</p>
<p>Another optimization I can do is split the indexes into #haskell and #lisp.</p>
<h2 id=\"profiles\">Profiles</h2>
<p>Profiles give a nice way to tell when someone probably goes to sleep and is probably available. It also tells whether someone has been active lately. If they haven’t been active lately, you can check their complete history by year, and if you see it dwindling, perhaps they’re not on the IRC anymore.</p>
<p>There are also quotes @remember’d by lambdabot, which can be fun to read.</p>
<h2 id=\"importation\">Importation</h2>
<p>Importing the logs happens daily, at 10:30 UTC time. One day I might update this so that it connects to the IRC directly and updates the logs in real time. But I’m not sure it’s worth it.</p>
<h2 id=\"other-stuff\">Other stuff</h2>
<p>I also did a social graph thing, but it’s not that good and I will probably remove it. There’s a word cloud, which looks pretty enough, I’ll keep that.</p>" nil nil "1393787bda767393eb8ebef8d1de0196") (290 (20984 50467 441975) "http://kenta.blogspot.com/2013/07/abfsttwf-optimizing-iterate.html" "Ken T Takusagawa: [abfsttwf] Optimizing \"iterate\"" "noreply@blogger.com (Ken)" "Mon, 22 Jul 2013 07:55:00 +0000" "<p dir=\"ltr\">The logistic map becomes interestingly chaotic for multipliers greater than 3.56995.  However, for our purposes, it is just an example of an endomorphic function.</p><pre>logistic_chaos :: Double -> Double;
logistic_chaos x = 3.57 * x * (1-x);
</pre><p dir=\"ltr\">As an example of a computationally expensive task, we seek the value of the billionth iteration of this function initialized at 0.5.  This post will explore various implementations of iterateN.  Compiler was ghc 7.6.3 on amd64 with compilation flag -O2.</p><pre>result :: Double;
result = iterateN 1000000000 logistic_chaos 0.5;
iterateN :: Int -> (a -> a) -> a -> a;
</pre><p dir=\"ltr\">The \"model\" implementation fails due to a space leak:</p><pre>iterateN_1 n f start = (iterate f start) !! n;
</pre><p>Hopefully, someday the GHC strictness analyzer will be able to prevent the space leak.  It seems unfortunate that the obvious implementation of a simple and common task fails so badly.</p><p>Making the evaluated function strict still fails with a space leak:</p><pre>{-# LANGUAGE BangPatterns #-}
strict_chaos :: Double -> Double;
strict_chaos !x = 3.57 * x * (1-x);
</pre> <p dir=\"ltr\">We go back to the non-strict version. This one also fails due to a space leak:</p><pre>iterateN_2 n f = last . (take (1+n)) . (iterate f);
</pre><p dir=\"ltr\">We reimplement the Prelude function \"iterate\" by inserting \"seq\".  There were two ways of doing it, so I tried both.  Putting the \"seq\" in the tail was slower, completing in 17.0 seconds.</p><pre>iterateN_3 n f start = let {
seq_iterate :: (a -> a) -> a -> [a];
seq_iterate f start = start : (seq start (seq_iterate f (f start)))
} in (seq_iterate f start) !! n;
</pre><p dir=\"ltr\">Putting the \"seq\" around the whole list was faster, completing in 14.5 seconds:</p><pre>iterateN_4 n f start = let {
seq_iterate :: (a -> a) -> a -> [a];
seq_iterate f start = seq start (start : (seq_iterate f (f start)))
} in (seq_iterate f start) !! n;
</pre><p>Not passing \"f\" into the inner function but instead relying on scope cut the runtime to 10.9 and 10.8 seconds.  However, this is an undesirable solution as we would like to make seq_iterate a global library function.</p><pre>{-# LANGUAGE ScopedTypeVariables #-}
iterateN_5 :: forall a . Int -> (a -> a) -> a -> a;
iterateN_5 n f start = let {
seq_iterate :: a -> [a];
seq_iterate start = start : (seq start (seq_iterate (f start)))
} in (seq_iterate start) !! n;
iterateN_6 :: forall a . Int -> (a -> a) -> a -> a;
iterateN_6 n f start = let {
seq_iterate :: a -> [a];
seq_iterate start = seq start (start : (seq_iterate (f start)))
} in (seq_iterate start) !! n;
</pre><p dir=\"ltr\">Manually maintaining a counter runs in 9.7 seconds:</p><pre>iterateN_7 n f start = case (compare n 0) of {
LT -> error \"cannot iterate less than zero\";
EQ -> start;
GT -> seq start (iterateN_7 (pred n) f (f start))
};
</pre><p dir=\"ltr\">Using an Integer instead of an Int counter cost an additional 1.14*10^-8 seconds per iteration, so this ran in 21.1 seconds.</p><pre>iterateN_Integer :: Integer -> (a -> a) -> a -> a;
iterateN_Integer n f start = case (compare n 0) of {
LT -> error \"cannot iterate less than zero\";
EQ -> start;
GT -> seq start (iterateN_Integer (pred n) f (f start))
};
</pre><p dir=\"ltr\">A pure C++ version (gcc version 4.6.3 compiled with -O2) runs in 4.1 seconds:<br />
</p><pre>#include <iostream>
int main(){
double x=0.5;
for(int i=0;i<1000000000;++i){
x=3.57*x*(1-x);
}
std::cout<<x<<std::endl;
}
</pre><p><a href=\"http://web.mit.edu/kenta/www/three/iterate/abfsttwf/\">Complete Haskell source code.</a><br />
</p>" nil nil "bd07f106f6bcb4c034380b96f1237989") (289 (20984 50467 441249) "http://winterkoninkje.dreamwidth.org/85357.html" "wren ng thornton: ANN: data-fin" nil "Mon, 22 Jul 2013 07:14:06 +0000" "<h3>data-fin 0.1.0</h3>
<p>The data-fin package offers the family of totally ordered finite sets,
implemented as newtypes of <code>Integer</code>, etc. Thus, you get all the joys of:</p>
<blockquote><code><pre>data Nat = Zero | Succ !Nat
data Fin :: Nat -> * where
FZero :: (n::Nat) -> Fin (Succ n)
FSucc :: (n::Nat) -> Fin n -> Fun (Succ n)</pre></code></blockquote>
<p>But with the efficiency of native types instead of unary encodings.</p>
<h3> Notes </h3>
<p>I wrote this package for a linear algebra system I've been working on, but
it should also be useful for folks working on Agda, Idris, etc, who want
something more efficient to compile down to in Haskell. The package is
still highly experimental, and I welcome any and all feedback.</p>
<p>Note that we implement type-level numbers using [1] and [2], which works
fairly well, but not as nicely as true dependent types since we can't
express certain typeclass entailments. Once the constraint solver for
type-level natural numbers becomes available, we'll switch over to using
that.</p>
<p>[1] Oleg Kiselyov and Chung-chieh Shan. (2007) <a href=\"http://okmij.org/ftp/Haskell/types.html#binary-arithm\">Lightweight static resources: Sexy types for embedded and systems programming</a>. <i>Proc. Trends in Functional Programming.</i> New York, 2–4 April 2007.</p>
<p>[2] Oleg Kiselyov and Chung-chieh Shan. (2004) <a href=\"http://okmij.org/ftp/Haskell/types.html#Prepose\">Implicit configurations: or, type classes reflect the values of types</a>. <i>Proc. ACM SIGPLAN 2004 workshop on Haskell.</i> Snowbird, Utah, USA, 22 September 2004. pp.33–44.</p>
<h3>Links</h3>
<ul>
<li>Homepage: <a href=\"http://code.haskell.org/~wren/\">http://code.haskell.org/~wren/</a></li>
<li>Hackage: <a href=\"http://hackage.haskell.org/package/data-fin\">http://hackage.haskell.org/package/data-fin</a></li>
<li>Darcs: <a href=\"http://community.haskell.org/~wren/data-fin\">http://community.haskell.org/~wren/data-fin</a></li>
<li>Haddock: <a href=\"http://community.haskell.org/~wren/data-fin/dist/doc/html/data-fin/\">Darcs version</a></li>
</ul><br /><br /><img src=\"http://www.dreamwidth.org/tools/commentcount?user=winterkoninkje&ditemid=85357\" alt=\"comment count unavailable\" height=\"12\" style=\"vertical-align: middle;\" width=\"30\" /> comments" nil nil "b37b555ac4a5e3a7f6748b82496daade") (288 (20984 50467 440728) "http://winterkoninkje.dreamwidth.org/85045.html" "wren ng thornton: Notions of powers" nil "Mon, 22 Jul 2013 04:50:52 +0000" "<p>Over on Reddit there's a discussion where one commenter admitted:
</p><blockquote>\"the whole <code>(^)</code> vs <code>(^^)</code> vs <code>(**)</code> [distinction in Haskell] confuses me.\"</blockquote>
It's clear to me, but it's something they don't teach in primary school, and it's something most programming languages fail to distinguish. The main problem, I think, for both primary ed and for other PLs, is that they have an impoverished notion of what \"numbers\" could be, and this leads to artificially conflating things which should be kept distinct. I wrote a reply over on Reddit, hoping to elucidate the distinction, but I thought I should repeat it in more persistent venue so it can reach a wider audience.<p></p>
<p>First, let us recall the basic laws of powers:
</p><blockquote><code><pre>a^0 = e
a^1 = a
(a^x)^y = a^(x*y)
(a^x)*(a^y) = a^(x+y)
(a*b)^x = (a^x)*(b^x)</pre></code></blockquote><p></p>
<p>There are two very important things to notice here. First off, our underlying algebra (the <code>a</code>s and <code>b</code>s) only needs to have the notion of multiplication, <code>(*)</code>, with identity, <code>e</code>. Second, our powers (the <code>x</code>s and <code>y</code>s) have an entirely different structure; in particular, they form at least a semiring <code>(+,0,*,1)</code>. Moreover, if we're willing to give up some of those laws, then we can weaken these requirements. For example, if we get rid of <code>a^0 = e</code> then we no longer need our underlying algebra to be a monoid, being a semigroup is enough. And actually, we don't even need it to be a semigroup. We don't need full associativity, all we need for this to be consistent is <a href=\"http://en.wikipedia.org/wiki/Power_associativity\">power-associativity</a>.</p>
<p>So we can go weaker and more abstract, but let's stick here for now. Any time we have a monoid, we get a notion of powers for free. This notion is simply iterating our multiplication, and we use the commutative semiring <code>(Natural,+,0,*,1)</code>  in order to represent our iteration count. This is the notion of powers that Haskell's <code>(^)</code> operator captures. Unfortunately, since Haskell lacks a standard <code>Natural</code> type (or <code>Semiring</code> class), the type signature for <code>(^)</code> lies and says we could use <code>Integer</code> (or actually, <code>Num</code> which is the closest thing we have to <code>Ring</code>), but the documentation warns that negative powers will throw exceptions.</p>
<p>Moving on to the <code>(^^)</code> operator: suppose our monoid is actually a group, i.e. it has a notion of reciprocals. Now, we need some way to represent those reciprocals; so if we add subtraction to our powers (yielding the commutative ring <code>(Integer,+,-,0,*,1)</code>), we get the law <code>a^(-x) = 1/(a^x)</code>. The important thing here is to recognize that not all monoids form groups. For example, take the monoid of lists with concatenation. We do have a <code>(^)</code> notion of powers, which may be more familiar as the <code>replicate</code> function from the Prelude. But, what is the reciprocal of a string? what is the inverse of concatenation? The <code>replicate</code> function simply truncates things and treats negative powers as if they were zero, which is on par with <code>(^)</code> throwing exceptions. It is because not all monoids are groups that we need a notion of powers for monoids (i.e., <code>(^)</code>) which is different from the notion of powers for groups (i.e., <code>(^^)</code>). And though Haskell fails to do so, we can cleanly capture this difference in the type signatures for these operations.</p>
<p>Further up, we get another notion of powers which Haskell doesn't highlight; namely the notion of powers that arises from the field <code>(Rational,+,-,0,*,/,1)</code>. To get here, we take our group and add to it the ability to take roots. The fractions in powers are now taken to represent the roots, as in the law <code>a^(1/y) = root y a</code>. Again note that there's a vast discrepancy between our underlying algebra which has multiplication, reciprocals, and roots vs our powers which have addition, subtraction, multiplication, and division.</p>
<p>Pulling it back a bit, what if our monoid has a notion of roots, but does not have inverses? Here our powers form a semifield; i.e., a commutative semiring with multiplicative inverses; e.g., the non-negative rationals. This notion is rather obscure, so I don't fault Haskell for lacking it, though it's worth mentioning.</p>
<p>Finally, <code>(**)</code> is another beast altogether. In all the previous examples of powers there is a strong distinction between the underlying algebra and the powers over that algebra. But here, we get exponentiation; that is, our algebra has an <i>internal</i> notion of powers over <i>itself!</i> This is remarkably powerful and should not be confused with the basic notion of powers. Again, this is easiest to see by looking at where it fails. Consider multiplication of (square) matrices over some semiring. This multiplication is associative, so we can trivially implement <code>(^)</code>. Assuming our semiring is actually a commutative ring then almost all (though not all) matrices have inverses, so we can pretend to implement <code>(^^)</code>. For some elements we can even go so far as <a href=\"http://en.wikipedia.org/wiki/Square_root_of_a_matrix\">taking roots</a>, though we run into the problem of there being multiple roots. But as for exponentiation? It's not even clear that <code>(**)</code> should be meaningful on matrices. Or rather, to the extent that it is meaningful, it's not clear that the result should be a matrix.</p>
<p>N.B., I refer to <code>(**)</code> as exponentials in contrast to <code>(^)</code>, <code>(^^)</code>, etc as powers, following the standard distinction in category theory and elsewhere. Do note, however, that this notion of exponentials is different again from the notion of the antilog <code>exp</code>, i.e. the inverse of <code>log</code>. The log and antilog are maps between additive monoids and multiplicative monoids, with all the higher structure arising from that. We can, in fact, give a notion of <a href=\"http://en.wikipedia.org/wiki/Matrix_exponential\">antilog for matrices</a> if we assume enough about the elements of those matrices.</p><br /><br /><img src=\"http://www.dreamwidth.org/tools/commentcount?user=winterkoninkje&ditemid=85045\" alt=\"comment count unavailable\" height=\"12\" style=\"vertical-align: middle;\" width=\"30\" /> comments" nil nil "a6f0eec4eea1372f80954b1f776ed2b4") (287 (20984 50467 439772) "http://joyful.com/blog/2013-07-21-hub-speedups.html" "Simon Michael: hub speedups" nil "Mon, 22 Jul 2013 00:30:00 +0000" "<div style=\"font-style: italic;\">July 22, 2013</div>
<h2>hub speedups</h2>
<p>
</p><p>More <a href=\"http://hub.darcs.net\">darcs hub</a> hacking today.</p>
<ul>
<li><p>Cleaned up some button text & styles</p></li>
<li><p>Started playing around with the front page layout to add a news box. Accidentally deployed it to production briefly. Used <code>make   undeploy-web</code> for the first time.</p></li>
<li><p>Extracted more of darcs hub’s front page into a separate (local) module, DarcsDen.Hub, for easier customisation.</p></li>
<li><p>Worked on optimising page load speed, especially the front page:</p>
<ul>
<li><p>instead of rendering the front page content from markdown on each request, do it only when changed. This saved, oh a good 50ms! But I now have the beginnings of a timing utility.</p></li>
<li><p>load the large codemirror js/css files only on the add/edit file pages</p></li>
<li><p>set a 7-day Expires header on static images. This took about an hour. Here’s the <a href=\"https://gist.github.com/simonmichael/6050387\">code</a> (based on Yesod’s), it might fit well in Snap.</p></li>
<li><p>combine the remaining js/css into one js and one css. This is not committed, I just did it by hand. Try <a href=\"http://lesscss.org/\">less</a> later (only if it’s really simple).</p></li>
</ul>
<p>YSlow now gives us an A grade (score 95), and it feels pretty quick.</p></li>
</ul>
<p>
<br />
<em><a href=\"http://joyful.com/tags/darcs.html\">darcs</a>, <a href=\"http://joyful.com/tags/web.html\">web</a>, <a href=\"http://joyful.com/tags/haskell.html\">haskell</a></em></p>" nil nil "8a0c987296334b39e9278bcc88ea2c10") (286 (20984 50467 439311) "http://joyful.com/blog/2013-07-21-darcsden-1.1-darcs-hub-news.html" "Simon Michael: darcsden 1.1, darcs hub news" nil "Sun, 21 Jul 2013 15:00:00 +0000" "<div style=\"font-style: italic;\">July 21, 2013</div>
<h2>darcsden 1.1, darcs hub news</h2>
<p>
</p><p>I’ve been hacking (mostly on darcsden/hub) but not blogging recently. Must get back to the old 45-15 minute routine.</p>
<ul>
<li><p>banged on hakyll for a while and set up <a href=\"http://joyful.com/tags/\">tag feeds</a> on this blog; joined <a href=\"http://planet.darcs.net\">Planet Darcs</a></p></li>
<li><p>did code review, testing, deployment of <a href=\"http://darcs.net/GSoC/2013-Darcsden\">BSRK Aditya’s GSOC enhancements</a></p></li>
<li><p>spent about 8 hours clarifying darcsden <a href=\"http://hub.darcs.net/simon/darcsden/CHANGES.md\">history</a> and writing release notes/announcement. Seriously ? Apparently yes.</p></li>
<li><p>moved the darcs hub FAQ back to the <a href=\"http://hub.darcs.net\">front page</a>, cleaned it up and added some javascript magic.</p></li>
<li><p><a href=\"http://hub.darcs.net/simon/darcsden/patch/20130720225553-3c3f9\">fixed</a> the slow user list on the front page - it was doing a query for each user. My effective page load time went from ~2 to 1s. Reducing the number of scripts will be a good next step.</p></li>
<li><p>released <a href=\"http://hackage.haskell.org/package/darcsden-1.1\">darcsden 1.1</a> and the first darcs hub news update. Yay!</p>
<p>This packages up what we have been using at hub.darcs.net so that you can run it locally. It’s the first darcsden release installable from hackage, and the first with the UI updates from darcs hub. For now, it still requires CouchDB and Redis to run.</p>
<p>More importantly, this is about communicating the changes and current status of darcs hub, and doing a bit of marketing. Darcs hub hacking is fun, come and help! I include the <a href=\"http://www.mail-archive.com/haskell-cafe@haskell.org/msg107064.html\">announcement</a> below.</p></li>
</ul>
<hr />
<h2 id=\"darcsden-1.1-released\">darcsden 1.1 released</h2>
<p>darcsden 1.1 is now available on hackage! This is the updated version of darcsden which runs hub.darcs.net, so these changes are also relevant to that site’s users. (More darcs hub news below.)</p>
<p>darcsden is a web application for browsing and managing darcs repositories, issues, and users, plus a basic SSH server which lets users push changes without a system login. It is released under the BSD license. You can use it:</p>
<ul>
<li>to browse and manage your local darcs repos with a more comfortable UI</li>
<li>to make your repos browsable online, optionally with issue tracking</li>
<li>to run a multi-user darcs hosting site, like hub.darcs.net</li>
</ul>
<p><a href=\"http://hackage.haskell.org/package/darcsden\">http://hackage.haskell.org/package/darcsden</a> - cabal package<br /><a href=\"http://hub.darcs.net/simon/darcsden\">http://hub.darcs.net/simon/darcsden</a> - source<br /><a href=\"http://hub.darcs.net/simon/darcsden/issues\">http://hub.darcs.net/simon/darcsden/issues</a> - bug tracker</p>
<h3 id=\"release-notes-for-1.1\">Release notes for 1.1</h3>
<p>Fixed:</p>
<ul>
<li><a href=\"http://hub.darcs.net/simon/darcsden/issue/16\">16</a>: Layout of links and navigation places them offscreen</li>
<li><a href=\"http://hub.darcs.net/simon/darcsden/issue/21\">21</a>: anchors on line numbers exist but line numbers not clickable</li>
<li><a href=\"http://hub.darcs.net/simon/darcsden/issue/28\">28</a>: forking then deleting a private repo makes repos unviewable</li>
<li><a href=\"http://hub.darcs.net/simon/darcsden/issue/29\">29</a>: darcs get to an invalid ssh repo url hangs</li>
<li><a href=\"http://hub.darcs.net/simon/darcsden/issue/46\">46</a>: if user kills a push, the lock file is not removed, preventing subsequent pushes</li>
</ul>
<p>New:</p>
<ul>
<li>the signup page security question is case-insensitive (“darcs”)</li>
<li>login redirects to the “my repos” page</li>
<li>a more responsive layout, with content first, buttons at top/right</li>
<li>many other UI updates; font, headings, borders, whitespace, robustness</li>
<li>more context sensitivity in buttons & links</li>
<li>better next/previous page controls</li>
<li>better support for microsoft windows, runs as a service</li>
<li>builds with GHC 7.6 and latest libraries</li>
<li>easier developer builds</li>
</ul>
<p>Brand new, from the Enhancing Darcsden GSOC (some WIP):</p>
<ul>
<li>you can sign up, log in, and link existing accounts with your Google or Github id</li>
<li>you can reset your password</li>
<li>you can edit files through the web</li>
<li>you can “pack” your repositories, allowing faster darcs get</li>
</ul>
<p>Detailed change log: <a href=\"http://hub.darcs.net/simon/darcsden/CHANGES.md\">http://hub.darcs.net/simon/darcsden/CHANGES.md</a></p>
<h3 id=\"how-to-help\">How to help</h3>
<p>darcsden is a small, clean codebase that is fun to hack on. Discussion takes place on the #darcs IRC channel, and useful changes will quickly be deployed at hub.darcs.net, providing a tight dogfooding/feedback loop. Here’s how to contribute a patch there:</p>
<ol style=\"\">
<li>register at hub.darcs.net</li>
<li>add your ssh key in settings so you can push</li>
<li>fork your own branch: <a href=\"http://hub.darcs.net/simon/darcsden\">http://hub.darcs.net/simon/darcsden</a> , fork</li>
<li>copy to your machine: <code>darcs get http://hub.darcs.net/yourname/darcsden</code></li>
<li>make changes, <code>darcs record</code></li>
<li>push to hub: <code>darcs push yourname@hub.darcs.net:darcsden --set-default</code></li>
<li>your change will appear at <a href=\"http://hub.darcs.net/simon/darcsden/patches\">http://hub.darcs.net/simon/darcsden/patches</a></li>
<li>discuss on #darcs, or ping me (sm, simon@joyful.com) to merge it</li>
</ol>
<h3 id=\"credits\">Credits</h3>
<p>Alex Suraci created darcsden. Simon Michael led this release, which includes contributions from Alp Mestanogullari, Jeffrey Chu, Ganesh Sittampalam, and BSRK Aditya (sponsored by Google’s Summer of Code). And last time I forgot to mention two 1.0 contributors: Bertram Felgenhauer and Alex Suraci.</p>
<p>darcsden depends on Darcs, Snap, GHC, and other fine projects from the Haskell ecosystem, as well as Twitter Bootstrap, JQuery, and many more.</p>
<hr />
<h2 id=\"darcs-hub-news-201307\">darcs hub news 2013/07</h2>
<p><a href=\"http://hub.darcs.net\">http://hub.darcs.net</a> , aka darcs hub, is the darcs repository hosting site I operate. It’s like a mini github, but using darcs. You can:</p>
<ul>
<li>browse users, repos, files and changes</li>
<li>publish darcs repos publicly or privately</li>
<li>get, push and pull repos over ssh</li>
<li>grant push access to other members</li>
<li>fork repos, then view and merge upstream and downstream changes</li>
<li>track issues</li>
</ul>
<p>The site was announced on 2012/9/15 (<a href=\"http://thread.gmane.org/gmane.comp.version-control.darcs.user/26556\">http://thread.gmane.org/gmane.comp.version-control.darcs.user/26556</a>). Since then:</p>
<ul>
<li><p>The site has been deploying new darcsden work promptly; it includes all the 1.1 release improvements described above.</p></li>
<li><p>The server’s ram has doubled from 1G to 2G (thanks Linode). This means app restarts due to excessive memory use are less frequent.</p></li>
<li><p>The front page’s user list had become slow and has been optimised, halving the page load time.</p></li>
<li><p>BSRK Aditya is doing his Google Summer of Code project on enhancing darcsden and darcs hub (mentored by darcs developer Ganesh Sittampalam). Find out more at <a href=\"http://darcs.net/GSoC/2013-Darcsden\">http://darcs.net/GSoC/2013-Darcsden</a> .</p></li>
<li><p>The site is being used, with many small projects and a few well-known larger ones. Quick stats as of 2013/07/19:</p>
<pre><code>user accounts                       317
repos                               579
disk usage                            2.5G
uptime last 30 days                  99.48%
average response time last 30 days    1.6s</code></pre></li>
<li><p>The site remains free to use, including private repos. Eventually, some kind of funding will be needed to keep it self-sustaining, and could also enable faster development. Donate button ? Gittip ? Charge for private repos ? Let’s discuss.</p></li>
</ul>
<p>Please try it out, report problems, and contribute patches to make it better.</p>
<hr />
<p>
<br />
<em><a href=\"http://joyful.com/tags/darcs.html\">darcs</a>, <a href=\"http://joyful.com/tags/hakyll.html\">hakyll</a>, <a href=\"http://joyful.com/tags/haskell.html\">haskell</a></em></p>" nil nil "6873908fafc8bfb8a2dee841613b8e7c") (285 (20984 50467 438036) "http://apfelmus.nfshost.com/blog/2013/07/21-threepenny-gui-0-1.html" "apfelmus: GUI - Initial release of the threepenny-gui library, version 0.1.0.0" nil "Sun, 21 Jul 2013 12:29:40 +0000" "<blockquote>
<p>And the shark, he has teeth,<br />And he wears them in (his) face.<br />And Macheath, he has a knife,<br />(But) yes the knife, no-one sees.</p>
</blockquote>
<p>After an obligatory cryptical quotation from a famous writer, I am pleased to announce the first public release of <em><a href=\"http://hackage.haskell.org/package/threepenny-gui\">threepenny-gui</a></em>, a cheap and simple library to satisfy your immediate GUI needs in Haskell.</p>
<p>Want to write a small GUI thing but forgot to sacrifice to the giant rubber duck in the sky before trying to install <a href=\"http://www.haskell.org/haskellwiki/Wxhaskell\">wxHaskell</a> or <a href=\"http://projects.haskell.org/gtk2hs/\">Gtk2Hs</a>? Then this library is for you!</p>
<p>Threepenny-gui is easy to install (!!) because it uses the web browser as a display. Internally, we implement a small web server that communicates with the browser to display GUI elements. Consequently, you can use HTML and CSS to design the user interface. You can freely manipulate the HTML DOM and handle browser events by writing Haskell code.</p>
<ul>
<li><a href=\"http://hackage.haskell.org/package/threepenny-gui\">threepenny-gui</a> - get the library on <strong>hackage</strong></li>
<li><a href=\"https://github.com/HeinrichApfelmus/threepenny-gui#examples\">example code</a></li>
<li><a href=\"https://github.com/HeinrichApfelmus/threepenny-gui\">source code</a> on github</li>
</ul>
<p>Many thanks to Daniel Austin for collaborating with me on this project and to Chris Done for implementing the Ji library which is the basis for this effort.</p>
<hr />
<p>On that note, the threepenny API for creating and manipulating GUI elements departs from earlier traditions. Do you like the new look and feel of the API? What do you think could be improved? Try it out and <a href=\"https://github.com/HeinrichApfelmus/threepenny-gui/issues\">send us your feedback</a>!</p>
<hr /><p><a href=\"https://flattr.com/thing/29608/apfelmus-website\"><img src=\"http://api.flattr.com/button/flattr-badge-large.png\" alt=\"Flattr this\" border=\"0\" title=\"Flattr this\" /></a></p>" nil nil "4eb71d0c77abe5d955490c0d3f549efc") (284 (20984 50467 437616) "http://parenz.wordpress.com/2013/07/20/pastebin-update/" "Daniil Frumin: Pastebin update" nil "Sat, 20 Jul 2013 12:15:01 +0000" "<p>I have updated the pastebin design and added some useful features.</p>
<p>Among with some minor tweaks the main changes are:</p>
<ul>
<li>Author & title field added</li>
<li>Slick bootstrap design including buttons, pills and other web two oh stuff</li>
<li>Gallery of random images from the pastebin database</li>
<li>Two modes for viewing a paste: view mode and edit mode (edit mode still lacks a sophisticated JS editor)</li>
<li>Code highlighting in the view mode</li>
<li>Installed all the <a href=\"http://hackage.haskell.org/packages/archive/pkg-list.html#cat:acme\">Acme</a> packages on the server</li>
</ul>
<p>Check the new website out: <a href=\"http://paste.hskll.org\">http://paste.hskll.org</a></p>
<p>If you have any suggestions regarding the design or the functionality of the web site please don’t hesitate to mail me or leave a comment.</p>
<div style=\"text-align: center;\">
<div class=\"figure\"><img src=\"http://orbt.io/QN5r.png\" alt=\"View mode\" /><p></p>
<p class=\"caption\">View mode</p>
</div>
</div>
<div style=\"text-align: center;\">
<div class=\"figure\"><img src=\"http://orbt.io/QL4Q.png\" alt=\"New paste\" /><p></p>
<p class=\"caption\">New paste</p>
</div>
</div>
<br /> Tagged: <a href=\"http://parenz.wordpress.com/tag/diagrams/\">diagrams</a>, <a href=\"http://parenz.wordpress.com/tag/haskell-2/\">haskell</a>, <a href=\"http://parenz.wordpress.com/tag/interactive-diagrams/\">interactive-diagrams</a>, <a href=\"http://parenz.wordpress.com/tag/soc/\">soc</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/parenz.wordpress.com/89/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/parenz.wordpress.com/89/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=parenz.wordpress.com&blog=26722965&post=89&subd=parenz&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "44c846df0090c02bea5b8d90e41ddca3") (283 (20984 50467 437155) "http://existentialtype.wordpress.com/2013/07/18/what-if-anything-is-a-declarative-language/" "Robert Harper: What, If Anything, Is A Declarative Language?" nil "Fri, 19 Jul 2013 19:18:42 +0000" "<p>Back in the 1980′s it was very fashionable to talk about “declarative” programming languages.  But to my mind there was never a clear definition of a “declarative language”, and hence no way to tell what is declarative and what is not.  Lacking any clear meaning, the term came to refer to the arbitrary conflation of functional with logic programming to such an extent that “functional-and-logic-programming” almost became a Germanic thing-in-itself (<em>ding an sich)</em>.  Later, as the logic programming wave subsided, the term “declarative”,  like “object-oriented”, came to be an expression of approval, and then, mercifully, died out.</p>
<p>Or so I had thought.  Earlier this week I attended a thriller of an NSF-sponsored workshop on high-level programming models for parallelism, where I was surprised by the declarative zombie once again coming to eat our brains.  This got me to thinking, again, about whether the term has any useful meaning.  For what it’s worth, and perhaps to generate useful debate, here’re some things that I think people mean, and why I don’t think they mean very much.<span style=\"white-space: pre;\" class=\"Apple-tab-span\"><br />
</span></p>
<ol>
<li>“Declarative” means “high-level”.  This just seems to replace one vague term by another.</li>
<li>“Declarative” means “not imperative”.  But this flies in the face of reality.  Functional languages embrace and encompass imperative programming as a special case, and even Prolog has imperative features, such as assert and retract, that have imperative meaning.</li>
<li>“Declarative” means “functional”.  OK, but then we don’t really need another word.</li>
<li>“Declarative” means “what, not how”.  But every language has an operational semantics that defines how to execute its programs, and you must be aware of that semantics to understand programs written in it.  Haskell has a definite evaluation order, just as much as ML has a different one, and even Prolog execution is defined by a clear operational semantics that determines the clause order and that can be influenced by “cut”.</li>
<li>“Declarative” means “equational”.  This does not distinguish anything, because there is a well-defined notion of equivalence for <em>any</em> programming language, namely observational equivalence.  Different languages induce different equivalences, of course, but how does one say that one equivalence is “better” than another?  At any rate, I know of no stress on equational properties of logic programs, so either logic programs are not “declarative” or “equational reasoning” is not their defining characteristic.</li>
<li>“Declarative” means “referentially transparent”.  The misappropriation of Quine’s terminology only confuses matters.  All I’ve been able to make of this is that “referentially transparent” means that beta-equivalence is valid.  But beta equivalence is not a property of an arbitrary programming language, nor in any case is it clear why this equivalence is first among equals.  In any case why you would decide <em>a priori</em> on what equivalences you want before you even know what it means to run a program?</li>
<li>“Declarative” means “has a denotation”.  This gets closer to the point, I think, because we might well say that a declarative <em>semantics</em> is one that gives meaning to programs as some kind of mapping between some sort of spaces.  In other words, it would be a synonym for “denotational semantics”.  But every language has a denotational semantics (perhaps by interpretation into a Kripke structure to impose sequencing), so having one does not seem to distinguish a useful class of languages.  Moreover, even in the case of purely functional programs, the usual denotational semantics (as continuous maps) is not fully abstract, and the fully abstract semantics (as games) is highly operational.  Perhaps a language is declarative in proportion to being able to give it semantics in some “familiar” mathematical setting?</li>
<li>“Declarative” means “implicitly <a href=\"http://existentialtype.wordpress.com/2011/03/17/parallelism-is-not-concurrency/\" title=\"Parallelism is not concurrency\">parallelizable</a>“.  This was certainly the sense intended at the NSF meeting, but no two “declarative” languages seemed to have much in common.  Charlie Garrod proposes just “implicit”, which is pretty much synonymous with “high level”, and may be the most precise sense there is to the term.</li>
</ol>
<p>No doubt this list is not exhaustive, but I think it covers many of the most common interpretations.  It seems to me that none of them have a clear meaning or distinguish a well-defined class of languages.  Which leads me to ask, is there any such thing as a declarative programming language?</p>
<p>[Thanks to the late Steve Gould for inspiring the title of this post.]</p>
<p>[<em>Update</em>: wordsmithing.]<em><br />
</em></p>
<p>[<em>Update</em>: add a remark about semantics, add another candidate meaning.]</p>
<p>[<em>Update</em>: added link to previous post.]</p>
<br />Filed under: <a href=\"http://existentialtype.wordpress.com/category/research/\">Research</a>, <a href=\"http://existentialtype.wordpress.com/category/teaching-2/\">Teaching</a> Tagged: <a href=\"http://existentialtype.wordpress.com/tag/declarative-language/\">declarative language</a>, <a href=\"http://existentialtype.wordpress.com/tag/functional-programming/\">functional programming</a>, <a href=\"http://existentialtype.wordpress.com/tag/imperative-programming/\">imperative programming</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/existentialtype.wordpress.com/833/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/existentialtype.wordpress.com/833/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=existentialtype.wordpress.com&blog=2157150&post=833&subd=existentialtype&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "633b16e32171c42f3a08feeb4d3b882d") (282 (20984 50467 434840) "http://feedproxy.google.com/~r/FpComplete/~3/k1JHF4PMPSE/beta-refresh-one" "FP Complete: FP Haskell Center Beta Refresh" nil "Wed, 17 Jul 2013 20:00:00 +0000" "<p><b>FP Haskell Center Beta Refresh Announcement</b> </p><p>We are excited to share some updates we’ve made and new features we’ve added to our Beta. Here are some of the things we’ve done to improve your experience with the FP Haskell Center:</p><ul><li><p>Made numerous bug fixes since the first Beta release</p></li><li><p>Added a new “setup profile” page</p></li><li><p>Updated User Interface for IDE:</p><ul><li>List modules</li><li>Search for modules</li><li>More intuitive module controls for adding, removing, and modifying module settings</li><li>Better help integration</li><li>Additional code templates</li></ul></li><li><p>Made changes to Git handling to improve performance and accommodate large projects</p></li><li><p>Fixed bug that prevented the arranging of content in display groups</p></li><li><p>Added interface for editing projects title/description</p></li><li><p>Included interface to delete projects</p></li><li><p>Added support for Hlint (a tool that reads Haskell programs and suggests changes that make them easier to read)</p></li><li><p>Added support for Stylish Haskell code formatting:</p><ul><li>Aligns and sorts import statements</li><li>Groups and wraps {-# LANGUAGE #-} pragmas, can remove (some) redundant pragmas</li><li>Removes trailing whitespace</li><li>Replaces tabs by four spaces (turned off by default)</li><li>Replaces some ASCII sequences by their Unicode equivalents</li></ul></li></ul><p>The feedback we’ve been receiving has been extremely valuable to us. We appreciate your help in making FP Haskell Center a true asset to the Haskell community.  If you haven’t signed up for a free account to our FP Haskell Center Beta, there is still time. </p><div class=\"feedflare\">
<a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=k1JHF4PMPSE:0lFVBER5fIk:yIl2AUoC8zA\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=yIl2AUoC8zA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=k1JHF4PMPSE:0lFVBER5fIk:V_sGLiPBpWU\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=k1JHF4PMPSE:0lFVBER5fIk:V_sGLiPBpWU\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=k1JHF4PMPSE:0lFVBER5fIk:qj6IDK7rITs\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=qj6IDK7rITs\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=k1JHF4PMPSE:0lFVBER5fIk:gIN9vFwOqvQ\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=k1JHF4PMPSE:0lFVBER5fIk:gIN9vFwOqvQ\" border=\"0\" /></a>
</div><img src=\"http://feeds.feedburner.com/~r/FpComplete/~4/k1JHF4PMPSE\" height=\"1\" width=\"1\" />" nil nil "eeb432c58236281f87a523c4d6bd793e") (281 (20984 50467 431282) "http://gsoc2013cwithmobiledevices.blogspot.com/2013/07/api-for-communicating-through-apns.html" "Marcos Pividori: API for communicating through APNS" "noreply@blogger.com (Marcos)" "Tue, 16 Jul 2013 10:46:37 +0000" "I developed an API for communicating through APNS with iOS mobile devices (<a href=\"https://github.com/MarcosPividori/GSoC-Communicating-with-mobile-devices/tree/master/push-notify/Network/PushNotify/Apns\">[1]</a>).<br />For this, I designed a way of building the messages, sending them and handling the result. <br />One important thing that I had to take into account, was how to maintain the connection. For APNS, I needed to communicate through a streaming SSL connection, so I couldn't use conduit as I 've done with GCM. So, to face this problem, I developed an APNSManager.<br />The API looks like this:<br /><br /><pre style=\"\"><code style=\"color: black;\"> startAPNS     <b>::</b> APNSAppConfig <b>-></b> IO APNSManager  <br /> closeAPNS     <b>::</b> APNSManager   <b>-></b> IO ()  <br /> sendAPNS      <b>::</b> APNSManager   <b>-></b> APNSmessage <b>-></b> IO APNSresult  <br /> feedBackAPNS  <b>::</b> APNSAppConfig <b>-></b> IO APNSFeedBackresult  </code></pre><br />The main idea is:<br /><br /><b>- </b>First of all, the sevice is started with: <b>'startAPNS'</b>.<br />  This function:<br />    * Creates a channel to put the notifications to be sent.<br />    * Starts a worker thread, which maintains the connection with APNS servers, and sends the data it receives through the cannel.<br />    * Returns an APNSManager.<br /><br /><b>- </b>Then, I can use <b>'sendAPNS'</b> to send messages. Every time I call it:<br />    * It puts the message on the channel.<br />    * Wait until the time the message is taken by the worker thread.<br />    * When the message is taken from the channel, the worker thread will send me a duplicate copy of the error channel. So, I will wait for the end of the sending, or an error msg through the error channel.<br />    * I return the appropiate result depending on a successful or not operation.<br /><br /><b>- </b>I stop the service with <b>'closeAPNS'</b>. It kills the worker thread.<br /><br />The worker identifies each message it sends with a number, which is sent to APNS. If an error ocurred, this number is returned in an error messages by the APNS servers, representing the number of the last message that was successfully sent.<br />Then, the worker continually sends messages until it receives an error message. In this case, it resends the error message to the error channel for all the threads waiting for a response, and then it restarts itself, because after an error, APNS servers close the connection.<br />The time we wait for an error response, after having sent all the messages, can be stablished with the timeoutLimit parameter, when creating a Manager.<br /><br />As to use this service, Apple requires you to be an enrolled iOS Developer or something similar, I decided to test the API with a local server. This server was taken from: <a href=\"http://bravenewmethod.wordpress.com/2013/04/20/test-server-for-apple-push-notification-and-feedback-integration/\">[3]</a> . It simulates the APNS servers and I modified it to test different common scenes.<br /><br />The code is available on GitHub:<br /> <b>- </b>The APNS Api : <a href=\"https://github.com/MarcosPividori/GSoC-Communicating-with-mobile-devices/tree/master/push-notify/Network/PushNotify/Apns\">[1]</a><br /> <b>- </b>Test example for APNS: <a href=\"https://github.com/MarcosPividori/GSoC-Communicating-with-mobile-devices/tree/master/push-notify/test/testAPNS\">[2]</a><br /><br />For more information about:<br /> <b>- </b>The APNS Service: <a href=\"http://developer.apple.com/library/ios/#documentation/NetworkingInternet/Conceptual/RemoteNotificationsPG/Chapters/ApplePushService.html#//apple_ref/doc/uid/TP40008194-CH100-SW9\">[4]</a><br /> <b>- </b>The communication between providers and APNS servers:  <a href=\"http://developer.apple.com/library/ios/#documentation/NetworkingInternet/Conceptual/RemoteNotificationsPG/Chapters/CommunicatingWIthAPS.html#//apple_ref/doc/uid/TP40008194-CH101-SW1\">[5]</a><br /><br /><br /><div></div>" nil nil "f09022f48277a87d30c15efe7a40f6e9") (280 (20984 50467 430100) "http://gsoc2013cwithmobiledevices.blogspot.com/2013/06/api-for-communicating-through-gcm.html" "Marcos Pividori: API for communicating through GCM" "noreply@blogger.com (Marcos)" "Tue, 16 Jul 2013 01:40:33 +0000" "<div style=\"clear: both; text-align: center;\" class=\"separator\"></div><div style=\"text-align: left;\"><div style=\"line-height: 114%; margin-bottom: 0cm;\" class=\"western\"><div style=\"font-style: normal; font-variant: normal; font-weight: normal; line-height: 114%; margin-bottom: 0cm;\" class=\"western\"><span style=\"color: black;\"><span style=\"font-family: 'Abyssinica SIL';\"><span style=\"text-decoration: none;\"><span style=\"background-color: transparent;\">At beginning, I started with an API for communicating through GCM with mobile devices running Android. I developed a way of building the messages, sending them and handling the result.</span></span></span></span></div><div align=\"LEFT\" style=\"font-style: normal; font-variant: normal; font-weight: normal; margin-bottom: 0cm;\" class=\"western\"><span style=\"color: black;\"><span style=\"font-family: 'Abyssinica SIL';\">To build the messages, I developed a data type: GCMmessage, where you can customize some parameters for the servers providing the GCM service.</span></span></div><div align=\"LEFT\" style=\"font-style: normal; font-variant: normal; font-weight: normal; margin-bottom: 0cm;\" class=\"western\"><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\">To send the messages you need to establish some server configurations through the data type GCMAppConfig (as the correct Api key provided by Google). Passing this configuration, a GCMmessage and a number of retries as arguments to the function sendGCM, the notifications will be sent to the GCM Servers.</span></span></div><div align=\"LEFT\" style=\"font-style: normal; font-variant: normal; font-weight: normal; margin-bottom: 0cm;\" class=\"western\"><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\">The result is shown in a new data type: GCMresult, which provides some useful information, as selecting the devices that have changed their regIds, or have been unregistered, and so on. The programmer can take his own desitions on how to handle this result in his server.</span></span></div><div align=\"LEFT\" style=\"font-style: normal; font-variant: normal; font-weight: normal; margin-bottom: 0cm;\" class=\"western\"><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\"><br />To show a simple usage of this API for GCM (Network.PushNotify.Gcm), I developed a simple test example of a Yesod server, where devices can register to receive GCM messages and users can send messages through the web service. This is composed of:</span></span></div><div align=\"LEFT\" style=\"font-style: normal; font-variant: normal; font-weight: normal; margin-bottom: 0cm;\" class=\"western\"><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\"><br /><b>+</b> a Yesod app for registering the devices and sending push notifications.</span></span></div><div align=\"LEFT\" style=\"font-style: normal; font-variant: normal; font-weight: normal; margin-bottom: 0cm;\" class=\"western\"><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\"><br /><b>+</b> an Android app for registering on GCM and receiving the notifications.</span></span></div><div align=\"LEFT\" style=\"margin-bottom: 0cm;\" class=\"western\"><span style=\"font-variant: normal;\"><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"><br />It is available on: <a href=\"https://github.com/MarcosPividori/GSoC-Communicating-with-mobile-devices/tree/master/push-notify/test\">https://github.com/MarcosPividori/GSoC-Communicating-with-mobile-devices/tree/master/push-notify/test</a></span></span></span></span></span></div><div align=\"LEFT\" style=\"font-style: normal; font-variant: normal; font-weight: normal; margin-bottom: 0cm;\" class=\"western\"><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\"><br />The picture at the bottom shows the main structure of the Google Cloud Message service. We have 3 main points:</span></span></div><div align=\"LEFT\" style=\"font-style: normal; font-variant: normal; font-weight: normal; margin-bottom: 0cm;\" class=\"western\"><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\"><br /><b>+ </b>The server, which I developed as a Yesod app.</span></span></div><div align=\"LEFT\" style=\"font-style: normal; font-variant: normal; font-weight: normal; margin-bottom: 0cm;\" class=\"western\"><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\"><b>+ </b>The devices, running Android.</span></span></div><div align=\"LEFT\" style=\"font-style: normal; font-variant: normal; font-weight: normal; margin-bottom: 0cm;\" class=\"western\"><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\"><b>+</b> The GCM Servers which provide the service.</span></span></div><div align=\"LEFT\" style=\"font-style: normal; font-variant: normal; font-weight: normal; margin-bottom: 0cm;\" class=\"western\"><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\"><br /><br /><b>About the Yesod App:</b></span></span></div><div align=\"LEFT\" style=\"font-style: normal; font-variant: normal; margin-bottom: 0cm;\" class=\"western\"><div style=\"font-weight: normal;\"><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\"><br />In this example, I show how to handle with the registration of devices. Also, I provide a web service, so users can send notifications to the devices registered. When the server receives a post request to send a notification to a device, uses the GCM apis for sending the notifications and handling the result in order to correctly actualize the DB. This means removing the devices that have been unregistered, changing the regId of the devices that have changed, and resending the notifications that weren't sent because of an internal error in the GCM Servers.</span></span></div><div style=\"font-weight: normal;\"><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\"><br /></span></span></div><span style=\"color: black; font-weight: normal;\"><span style=\"font-family: Abyssinica SIL;\">To try the example:</span></span><span style=\"color: black;\"><span style=\"font-family: Abyssinica SIL;\"><br />+ On an Android device:</span></span><br /><span style=\"font-family: Abyssinica SIL;\">    - Go to settings/applications/ allow unknown sources.<br />    - In the web browser go to: </span><a style=\"line-height: 114%;\" href=\"http://push-notify.yesodweb.com/\">http://push-notify.yesodweb.com/</a> <span style=\"font-family: 'Abyssinica SIL'; line-height: 114%;\">and download the android app from the link at the bottom.</span><br /><span style=\"font-family: Abyssinica SIL;\">    - Install it, enter a username and a password.<br /><br />+ If the registration succeded, when you go to: </span><a style=\"line-height: 114%;\" href=\"http://push-notify.yesodweb.com/\">http://push-notify.yesodweb.com/</a> <span style=\"font-family: 'Abyssinica SIL'; line-height: 114%;\">, you will see your username. And you can start sending notifications through the website.</span><br /><span style=\"font-family: 'Abyssinica SIL'; line-height: 114%;\"><br /></span></div><br /><iframe height=\"350\" src=\"http://push-notify.yesodweb.com/\" width=\"520\"></iframe> <br /><br /><br /><div style=\"clear: both; text-align: center;\" class=\"separator\"><br /></div><div style=\"clear: both; text-align: center;\" class=\"separator\"><span style=\"color: black; margin-left: 1em; margin-right: 1em;\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://www.androidhive.info/wp-content/uploads/2012/10/gcm-a-modr.png\"><img src=\"http://www.androidhive.info/wp-content/uploads/2012/10/gcm-a-modr.png\" height=\"640\" border=\"0\" width=\"452\" /></a></span></div><div style=\"clear: both; text-align: center;\" class=\"separator\"><span style=\"font-size: xx-small;\"><span style=\"background-color: white; color: #333333; font-family: Arial, Tahoma, Helvetica, FreeSans, sans-serif; line-height: 12px;\">(from:</span><a style=\"background-color: white; color: #771100; font-family: Arial, Tahoma, Helvetica, FreeSans, sans-serif; line-height: 12px; text-decoration: none;\" href=\"http://www.androidhive.info/2012/10/android-push-notifications-using-google-cloud-messaging-gcm-php-and-mysql/\">http://www.androidhive.info/2012/10/android-push-notifications-using-google-cloud-messaging-gcm-php-and-mysql/</a>)</span></div></div></div>" nil nil "fd3de49e67c507b2c7385d8a6f5b5240") (279 (20984 50467 428850) "http://gsoc2013cwithmobiledevices.blogspot.com/2013/07/apple-push-notification-service.html" "Marcos Pividori: Apple Push Notification Service" "noreply@blogger.com (Marcos)" "Tue, 16 Jul 2013 01:38:01 +0000" "<div style=\"font-style: normal; font-variant: normal; line-height: 100%; margin-bottom: 0cm;\"><span style=\"font-family: Abyssinica SIL; font-size: small;\"><span style=\"font-family: Abyssinica SIL;\">Apple Push Notification service</span> is a robust and highly efficient service for propagating information to devices iOS. Each device establishes an accredited and encrypted IP connection with the service and receives notifications over this persistent connection.</span></div><div style=\"font-style: normal; font-variant: normal; line-height: 100%; margin-bottom: 0cm;\"><span style=\"font-size: small;\"><br /></span></div><div style=\"font-style: normal; font-variant: normal; line-height: 100%; margin-bottom: 0cm;\"><span style=\"font-family: Abyssinica SIL; font-size: small;\">To send notifications, the provider connects to APNS through a permanent and secure connection. When there is new information to be sent, the provider prepares and sends a notification through the APNS channel, which pushes the notification to the target device.</span></div><div style=\"font-style: normal; font-variant: normal; line-height: 100%; margin-bottom: 0cm;\"><span style=\"font-family: Abyssinica SIL; font-size: xx-small;\"><br /></span></div><table cellpadding=\"0\" align=\"center\" style=\"margin-left: auto; margin-right: auto; text-align: center;\" cellspacing=\"0\" class=\"tr-caption-container\"><tbody><tr><td style=\"text-align: center;\"><a style=\"font-style: normal; font-variant: normal; line-height: 100%; margin-left: auto; margin-right: auto;\" href=\"http://developer.apple.com/library/ios/documentation/NetworkingInternet/Conceptual/RemoteNotificationsPG/Art/remote_notif_simple.jpg\"><img src=\"http://developer.apple.com/library/ios/documentation/NetworkingInternet/Conceptual/RemoteNotificationsPG/Art/remote_notif_simple.jpg\" height=\"55\" border=\"0\" width=\"400\" /></a></td></tr><tr><td style=\"text-align: center;\" class=\"tr-caption\"><span style=\"font-size: xx-small;\"><span style=\"line-height: 32px;\">(</span><a style=\"line-height: 32px;\" href=\"http://developer.apple.com/library/ios/documentation/NetworkingInternet/Conceptual/RemoteNotificationsPG/Art/remote_notif_simple.jpg\">http://developer.apple.com/library/ios/documentation/NetworkingInternet/Conceptual/RemoteNotificationsPG/Art/remote_notif_simple.jpg</a><span style=\"line-height: 32px;\">)</span></span></td></tr></tbody></table><div style=\"font-style: normal; font-variant: normal; margin-bottom: 0cm;\"><span style=\"font-size: small;\"><span style=\"line-height: 32px;\"><br /></span><span style=\"font-family: Abyssinica SIL;\"><span style=\"line-height: 100%;\">A notification is a short message consisting of two main parts of data: the device token and the payload:</span></span></span></div><div style=\"font-style: normal; font-variant: normal; line-height: 100%; margin-bottom: 0cm;\"><span style=\"font-size: small;\"><span style=\"font-family: Abyssinica SIL;\">  * The device token identifies the device and application on the client side.</span></span></div><div style=\"font-style: normal; font-variant: normal; line-height: 100%; margin-bottom: 0cm;\"><span style=\"font-size: small;\"><span style=\"font-family: Abyssinica SIL;\">  * The payload is a JSON-defined property list that specifies how the user of an application on a device is to be alerted.</span></span></div><div style=\"font-style: normal; font-variant: normal; line-height: 100%; margin-bottom: 0cm;\"><span style=\"font-size: small;\"><br /></span></div><div style=\"font-style: normal; font-variant: normal; line-height: 100%; margin-bottom: 0cm;\"><span style=\"font-family: Abyssinica SIL; font-size: small;\">Each provider requires a unique provider certificate and private cryptographic key for validation of its connection to the APN. This certificate, <span style=\"font-family: Abyssinica SIL;\">provisioned by Apple</span>, <span style=\"font-family: Abyssinica SIL;\">must identify the particular topic published by the provider; the topic is the bundle ID of the client application.<br /><br />For more information: <a href=\"http://developer.apple.com/library/ios/#documentation/NetworkingInternet/Conceptual/RemoteNotificationsPG/Chapters/ApplePushService.html#//apple_ref/doc/uid/TP40008194-CH100-SW9\">Apple Developers - Apple Push Notification Service</a><br /></span></span></div>" nil nil "17ceceb4da8db7233d2819a745c04ecd") (278 (20969 2756 219243) "http://parenz.wordpress.com/2013/07/19/type-synonyms/" "Daniil Frumin: Type synonyms" nil "Fri, 19 Jul 2013 08:56:10 +0000" "<p>Note to self: use “point-free” curried type synonyms, eg</p>
<pre class=\"brush: plain; title: ; notranslate\">type ActionH = ActionT StateH</pre>
<p>, not</p>
<pre class=\"brush: plain; title: ; notranslate\">type ActionH a = ActionT StateH a</pre>
<p>. Type synonyms are substituted “as is”, so if you use the latter format you wouldn’t be able to use the type in partially applied setting:</p>
<pre class=\"brush: plain; title: ; notranslate\">ReaderT ActionH a</pre>
<p>won’t type check</p>
<br /> Tagged: <a href=\"http://parenz.wordpress.com/tag/haskell-2/\">haskell</a>, <a href=\"http://parenz.wordpress.com/tag/notes/\">notes</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/parenz.wordpress.com/21/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/parenz.wordpress.com/21/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=parenz.wordpress.com&blog=26722965&post=21&subd=parenz&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "587c486b0fcddb25f393b8bafc497549") (277 (20969 828 733659) "http://www.yesodweb.com/blog/2013/07/four-more-chapters" "Yesod Web Framework: Four more chapters ready" nil "Fri, 19 Jul 2013 09:00:00 +0000" "<p>As I mentioned on Google+, I've just changed the default book link on the site
to point to the new version 1.2. The book is not yet fully migrated over to
version 1.2 of Yesod, but the entire basics section (i.e., the first 11
chapters) are. In addition, as of today, I've just converted four more
chapters:</p><ul><li><a href=\"http://www.yesodweb.com/book/restful-content\">RESTful Content</a></li><li><a href=\"http://www.yesodweb.com/book/yesods-monads\">Yesod’s Monads</a></li><li><a href=\"http://www.yesodweb.com/book/blog-example-advanced\">Blog: i18n, authentication, authorization, and database</a></li><li><a href=\"http://www.yesodweb.com/book/json-web-service\">JSON Web Service</a></li></ul><p>Some comments about notable changes:</p><ul><li><p>RESTful content had a fairly substantial overhaul to reflect the new
<code>TypedContent</code> approach we have. I personally think the new approach (and
therefore the new documentation) is much easier to follow.</p></li><li><p>Similarly, due to the major change in how the monad transformers work,
Yesod's monads is quite different. There are also some explanations for
design decisions towards the end. If you want to understand some of the deeper
parts of Yesod, I'd recommend reading this chapter again.</p></li><li><p>The blog example (finally) has proper formatting, instead of the terrible
\"let's copy some Literate Haskell\" hack that I used previously.</p></li><li><p>JSON web service is mostly unchanged, and is pretty boring. I'll be adding a
fancier JSON example after all the chapters are converted.</p></li></ul>" nil nil "6a45fdac124380ac93af24eadc00c46d") (276 (20968 62352 309416) "http://existentialtype.wordpress.com/2013/07/18/what-if-anything-is-a-declarative-language/" "Robert Harper: What, If Anything, Is A Declarative Language?" nil "Fri, 19 Jul 2013 02:59:23 +0000" "<p>Back in the 1980′s it was very fashionable to talk about “declarative” programming languages.  But to my mind there was never a clear definition of a “declarative language”, and hence no way to tell what is declarative and what is not.  Lacking any clear meaning, the term came to refer to the arbitrary conflation of functional with logic programming to such an extent that “functional-and-logic-programming” almost became a Germanic thing-in-itself (<em>ding an sich)</em>.  Later, as the logic programming wave subsided, the term “declarative”,  like “object-oriented”, came to be an expression of approval, and then, mercifully, died out.</p>
<p>Or so I had thought.  Earlier this week I attended a thriller of an NSF-sponsored workshop on high-level programming models for parallelism, where I was surprised by the declarative zombie once again coming to eat our brains.  This got me to thinking, again, about whether the term has any useful meaning.  For what it’s worth, and perhaps to generate useful debate, here’re some things that I think people mean, and why I don’t think they mean very much.<span style=\"white-space: pre;\" class=\"Apple-tab-span\"><br />
</span></p>
<ol>
<li>“Declarative” means “high-level”.  This just seems to replace one vague term by another.</li>
<li>“Declarative” means “not imperative”.  But this flies in the face of reality.  Functional languages embrace and encompass imperative programming as a special case, and even Prolog has imperative features, such as assert and retract, that have imperative meaning.</li>
<li>“Declarative” means “functional”.  OK, but then we don’t really need another word.</li>
<li>“Declarative” means “what, not how”.  But every language has an operational semantics that defines how to execute its programs, and you must be aware of that semantics to understand programs written in it.  Haskell has a definite evaluation order, just as much as ML has a different one, and even Prolog execution is defined by a clear operational semantics that determines the clause order and that can be influenced by “cut”.</li>
<li>“Declarative” means “equational”.  This does not distinguish anything, because there is a well-defined notion of equivalence for <em>any</em> programming language, namely observational equivalence.  Different languages induce different equivalences, of course, but how does one say that one equivalence is “better” than another?  At any rate, I know of no stress on equational properties of logic programs, so either logic programs are not “declarative” or “equational reasoning” is not their defining characteristic.</li>
<li>“Declarative” means “referentially transparent”.  The misappropriation of Quine’s terminology only confuses matters.  All I’ve been able to make of this is that “referentially transparent” means that beta-equivalence is valid.  But beta equivalence is not a property of an arbitrary programming language, nor in any case is it clear why this equivalence is first among equals.  In any case why you would decide <em>a priori</em> on what equivalences you want before you even know what it means to run a program?</li>
<li>“Declarative” means “has a denotation”.  This gets closer to the point, I think, because we might well say that a declarative <em>semantics</em> is one that gives meaning to programs as some kind of mapping between some sort of spaces.  In other words, it would be a synonym for “denotational semantics”.  But every language has a denotational semantics (perhaps by interpretation into a Kripke structure to impose sequencing), so having one does not seem to distinguish a useful class of languages.  Moreover, even in the case of purely functional programs, the usual denotational semantics (as continuous maps) is not fully abstract, and the fully abstract semantics (as games) is highly operational.  Perhaps a language is declarative in proportion to being able to give it semantics in some “familiar” mathematical setting?</li>
<li>“Declarative” means “implicitly parallelizable”.  This was certainly the sense intended at the NSF meeting, but no two “declarative” languages seemed to have much in common.  Charlie Garrod proposes just “implicit”, which is pretty much synonymous with “high level”, and may be the most precise sense there is to the term.</li>
</ol>
<p>No doubt this list is not exhaustive, but I think it covers many of the most common interpretations.  It seems to me that none of them have a clear meaning or distinguish a well-defined class of languages.  Which leads me to ask, is there any such thing as a declarative programming language?</p>
<p>[Thanks to the late Steve Gould for inspiring the title of this post.]</p>
<p>[<em>Update</em>: wordsmithing.]<em><br />
</em></p>
<p>[<em>Update</em>: add a remark about semantics, add another candidate meaning.]</p>
<br />Filed under: <a href=\"http://existentialtype.wordpress.com/category/research/\">Research</a>, <a href=\"http://existentialtype.wordpress.com/category/teaching-2/\">Teaching</a> Tagged: <a href=\"http://existentialtype.wordpress.com/tag/declarative-language/\">declarative language</a>, <a href=\"http://existentialtype.wordpress.com/tag/functional-programming/\">functional programming</a>, <a href=\"http://existentialtype.wordpress.com/tag/imperative-programming/\">imperative programming</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/existentialtype.wordpress.com/833/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/existentialtype.wordpress.com/833/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=existentialtype.wordpress.com&blog=2157150&post=833&subd=existentialtype&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "1ecc15dad31ed875007e8916b0bae469") (275 (20967 42292 514777) "http://feedproxy.google.com/~r/FpComplete/~3/TVGfEo5JcM8/ide-stackage" "FP Complete: IDE and Stackage" nil "Wed, 17 Jul 2013 20:00:00 +0000" "<p>As most of you know by now, at FP Complete we’ve just launched the beta
of the FP Haskell Center, our integrated development and deployment
environment. We’ve been letting people onto the system over the past few
weeks. For those of you waiting for your beta invitation, you can get a
more immediate idea of what we’re offering by viewing the
screencast. But in this blog post, I want to talk about
some of the work that’s going on behind the scenes, what it means for
our users, and how it will benefit the greater Haskell community.</p><p>Not interested in my analysis of the problems, and just want to hear how
we’ll solve them? Feel free to <a href=\"http://feeds.feedburner.com/fpcomplete#vision\">skip ahead</a>.</p><h1>Current issues</h1><p>The set of functionality that we’ve included in our product has not been
randomly thrown together. Gregg has spent a lot of time talking with
people with existing Haskell setups to ascertain the major pain points,
and we’ve tailored our offering to solve as many of those problems as
possible.</p><p>You’ve already seen a few of our solutions: an integrated development
environment paired with an application deployment server, an interactive
learning system, and a higher emphasis on user-friendly documentation
and code samples. I’d like to talk right now about a different set of
issues we’re trying to solve, a set that probably isn’t so obvious at
first glance.</p><h2>Dependency conflicts (“Cabal hell”)</h2><p>Almost anyone who has been using Haskell for any length of time has run
into some kind of library dependency conflict. These situations often
get labeled as “Cabal hell,” but to be fair the issue is rarely related
to Cabal itself. Managing dependencies between many different libraries
is a difficult task. This isn’t Haskell specific; these problems exist
in other languages as well.</p><p>Nonetheless, getting a set of packages built and coexisting that can all
be used simultaneously can be a daunting task, and is something we want
to provide a solution to.</p><h2>Libraries are fast-moving targets</h2><p>One of the great strengths of the Haskell community is the tendency to
solve problems the right way. If a problem is found with an existing
approach, the default response tends to be to fix the library, even if
it means a breaking change. This leads to fast iteration and high
quality libraries. The downside is it can be a pain to stay on top of
the latest version of all libraries. (And related to the previous point,
it can be difficult to get all downstream dependencies to update to the
newest version of an upstream package.)</p><p>The solution for end users could be to just stick with old versions of
libraries. That, however, brings us to our next point.</p><h2>Lack of bugfixes for older releases</h2><p>Virtually every package on Hackage is volunteer maintained. It is
difficult enough to maintain a single version of your library.
Maintaining older versions as well can be overwhelming. But that’s
exactly what people need: stable versions of libraries which still
receive backported bugfixes. This is commonplace in many parts of the
software world, both open and closed source. We simply haven’t gotten to
that point in the Haskell world yet.</p><h2>Non-trivial to get started</h2><p>Assuming you could solve all the other problems listed, getting set up
to start coding can be non-trivial. You need to install your tool chain
correctly, which presents a number of questions:</p><ol><li>Do you use your distribution’s copy of GHC, or install your own
copy?</li><li>Do you use the Haskell Platform, or just cabal install all your
dependencies?</li><li>Should you use plain cabal, cabal-dev, or hsenv?</li></ol><p>And you’ll almost certainly need to perform some task for which you
don’t know which library is the right library. How do you determine
which one to use? How do you know that it will be compatible with the
rest of your library set?</p><h1 id=\"vision\">Our vision for customers</h1><p>We’ve thought long and hard about how to make Haskell an easier language
to get up-and-running with, and have started putting together a vision
for our customers. Let me share this vision, and then nail down <a href=\"http://feeds.feedburner.com/fpcomplete#how-we-get-there\">the
concrete steps we’ll take to get to that point</a>.</p><h2>Stable libraries</h2><p>Since the launch of the School of Haskell, we’ve provided a large and
growing set of libraries on our servers. This library set is going to be
available for all of our IDE users as well. The important thing to note
is that at no point did you have to manually install any packages.
System libraries are available, dependencies installed, and conflicting
versions resolved.</p><p>The final component which is missing is stability. Currently, our
libraries update on a regular basis. We will be taking snapshots of this
library set and providing them as options to our users. We will only
include bug fixes into these libraries as necessary. This will provide
users with the ability to start developing software and not worry that
they’ll have to rewrite their code to stay up-to-date with security and
bug fixes.</p><h2>Bleeding edge for those who want it</h2><p>While we will recommend these stable libraries for most users, we will
continue to offer our bleeding-edge library set as well. This will allow
users to try out the newest versions of libraries. This will also allow
our system to remain as inclusive as possible. Anyone who wants to get a
new library into our system just needs to <a href=\"https://github.com/fpco/stackage/wiki/Maintainers-Agreement\">send a pull
request</a>,
and at our next bleeding-edge build, the library will be available. And
any packages that make it into our bleeding edge will also be
snapshotted at our next stable library build.</p><p>Note that there are a few reasons why a library may not be included on
our system even after a pull request. The most obvious is if the package
doesn’t build. But more subtle issues are licensing concerns, security
flaws, or naming conflicts with existing code. These situations are
rare, however, and can usually be worked around easily.</p><h2>Recommendations/tutorials (for those who need it)</h2><p>While we try to provide as many packages as possible in our
environments, we’re also aware that this much choice can be
overwhelming. Therefore, we will be selecting some libraries to be our
recommended solutions to some problem domains. The purpose here is
not to tell seasoned Haskellers how to write their code. Instead, we
want new users to have a simple path to follow from “I have a problem”
to “I have a solution.”</p><p>In addition to the <a href=\"https://www.fpcomplete.com/school/ide-tutorials/recommended-libraries\">recommended library
list</a>,
we will be providing two other advantages to sticking with our
recommended libraries: a higher level of customer support (including bug
fixing), and more training material on using these libraries.</p><p><a href=\"http://feeds.feedburner.com/fpcomplete\"></a></p><h1 id=\"how-we-get-there\">How we get there</h1><p>You know the problems we want to solve, and you know how we want the
solutions to look. The question remaining is how to implement them.</p><h2>Stackage</h2><p>The most publicly-visible work we’ve done towards solving the problems
listed has been the Stackage project. Stackage is a project aiming to
make it possible to build stable, vetted sets of packages. You can read
more about the project and its goals in the <a href=\"http://www.yesodweb.com/blog/2012/11/stable-vetted-hackage\">Stackage release
announcement.</a></p><p>For a while I’ve wanted to share more details about how we’re using
Stackage and how I see it fitting into the existing ecosystem, but I’ve
waited until things of settled down and the answer could be reliable.
Fortunately we’re at that point now.</p><p>Stackage is really two things in one:</p><ol><li>A set of tools for building and testing a set of libraries.</li><li>A community driven ecosystem for creating a list of libraries that
should be installable together, and the communication infrastructure
for letting package authors know when there’s a problem.</li></ol><p>We use Stackage internally to build all of our package databases.
Stackage itself, however, is not such a database. Said another way,
Stackage is not a competitor to something like Debian’s Haskell
packages; instead, Stackage is a tool that could be used to build the
Debian package set. Stackage is also not a competitor to the Haskell
Platform; the HP is a set of vetted and reviewed packages. Stackage is a
community process that allows any package to be included, and only cares
about the coexistence.</p><p>Just as a member of the Haskell community and a package maintainer, I
think Stackage has been a big success. There are currently over 400
packages built by Stackage. Numerous bugs and incompatibilities have
been reported back to upstream maintainers, giving maintainers more
prompt and reliable feedback, and improving the quality of packages
across the board for Haskellers. If Stackage did nothing more than it
does today, I think it would have earned its keep.</p><p>But I do hope to see it continue improving. I’ve discussed having
Stackage used as part of the distribution maintainer toolset in the
past, and while those conversations have stalled, I hope they resume. I
also hope the community gets more involved. At the time of writing,
there are 5292 packages available on Hackage. I’d like to see
more of them included in Stackage, so if you maintain any
Hackage packages that aren’t on Stackage, I encourage you to submit
them.</p><h2>Working with upstream</h2><p>My work on Stackage has put me in a position to interact quite regularly
with upstream package maintainers. I want to clarify exactly how we’ll
be interacting with the community.</p><h3>Monitor security problems</h3><p>We take security very seriously, and are constantly taking measures to
improve the security of our toolset. One problematic area is the fact
that Hackage allows anyone to upload any package, without any warnings.
While this will be solved by Hackage 2, we are currently vulnerable.</p><p>For the past month, I’ve started monitoring the package upload logs, and
signaling alerts when a new uploader uploads a package for the first
time. For example, if Alice uploads the package alice-package, and Bob
uploads a new version a few days later, I’ll get a warning and contact
Alice. (And internally, we won’t build any new library sets until the
problem has been resolved.)</p><p>I think this kind of review is vital to keeping the Haskell ecosystem
safe. So if you get an email from me about this, you’ll know why.</p><h3>Report bugs</h3><p>We automatically run test suites each time we perform a Stackage build,
which has uncovered a number of regressions in upstream packages. We
file these reports upstream as soon as possible, and (due to the
wonderful nature of the Haskell community) bugs tend to be fixed very
quickly.</p><p>As our user base grows, we anticipate more bug reports coming from our
users. We’re looking forward to working with upstream providers to get
these bugs triaged and fixed. And as part of our stable library plans,
we have infrastructure in place to maintain patchsets against older
versions of packages, to simplify the task of backporting fixes.</p><h3>Notify of outdated dependencies</h3><p>The most common interaction we have with the community has been to
notify of outdated dependencies. Since Stackage has started, the number
of emails I send about this topic has decreased drastically. I’m sure
there are many factors at play here, but I see this as a sign that the
Haskell ecosystem is beginning to stabilize. Previously, it was to be
expected that breaking releases would happen on a regular basis. In the
past six months, I’ve seen this happen very infrequently for any of the
most heavily used packages.</p><h3>Identify possible library improvements</h3><p>As we get user feedback about libraries, we hope to share this
information with the rest of the community. Some sample feedback we
expect to be sharing is:</p><ol><li>Tasks that could be made easier in a library with some convenience
functions.</li><li>Places where documentation (especially tutorials) are lacking.</li><li>Functionality which simply isn’t covered by existing packages.</li></ol><h2>Internal work at FP Complete</h2><p>Our main goal at FP Complete will be to continue building and polishing
our end user tools. It’s my sincere belief that by providing these
resources, we can drastically boost Haskell’s adoption, which will have
a profound effect on the Haskell community.</p><p>In addition, we intend to take part in community efforts. Our main focus
has been on the documentation front. The School of Haskell was entirely
about improving the documentation infrastructure for the community. Our
recent announcement of tutorial and code sample contests is designed to
get high quality tutorials produced as quickly as possible.</p><p>For the most part, we have not felt the need to participate very much in
the production of libraries. The open source community has done a
fantastic job at creating a large, high-quality library ecosystem.
However, as we build up libraries for our own purposes, or identify gaps
in the existing library ecosystem, we intend to get involved: in the
former case, releasing our code to the community, and in the latter,
either working with community members to produce a suitable library, or
providing one ourselves.</p><h1>Unified product vision</h1><p>I hope the above discussion gives a good idea of how we’re hoping to
work with the community to make everyone’s lives better. I just want to
close with a summarized view of what our upcoming product (the FP
Haskell Center) will be providing to users.</p><ol><li>IDE: fully loaded with the tools you need</li><li>Libraries: no need to configure or build, just start coding</li><li>Tutorials tie in for easy learning on the job</li><li>Develop and deploy from the cloud</li></ol><div class=\"feedflare\">
<a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=TVGfEo5JcM8:Y_ImaSIT6Ro:yIl2AUoC8zA\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=yIl2AUoC8zA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=TVGfEo5JcM8:Y_ImaSIT6Ro:V_sGLiPBpWU\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=TVGfEo5JcM8:Y_ImaSIT6Ro:V_sGLiPBpWU\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=TVGfEo5JcM8:Y_ImaSIT6Ro:qj6IDK7rITs\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=qj6IDK7rITs\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=TVGfEo5JcM8:Y_ImaSIT6Ro:gIN9vFwOqvQ\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=TVGfEo5JcM8:Y_ImaSIT6Ro:gIN9vFwOqvQ\" border=\"0\" /></a>
</div><img src=\"http://feeds.feedburner.com/~r/FpComplete/~4/TVGfEo5JcM8\" height=\"1\" width=\"1\" />" nil nil "22e40c07ce792317b63130e9f828def2") (274 (20967 42292 457556) "http://praisecurseandrecurse.blogspot.com/2013/07/the-polar-game-in-haskell-day-7-towards.html" "Paul Potts: The Polar Game in Haskell, Day 7: Towards a GUI, Continued" "noreply@blogger.com (Paul Potts)" "Wed, 17 Jul 2013 19:52:00 +0000" "<p>So, trying wxHaskell. First, I want to try removing everything that might be left over from yesterday's experiments:</p> <pre>Pauls-Mac-Pro:~ paul$ brew list<br />gettext  libffi  pkg-config xz<br />Pauls-Mac-Pro:~ paul$ brew uninstall gettext libffi pkg-config xz<br />Uninstalling /usr/local/Cellar/gettext/0.18.3...<br />Uninstalling /usr/local/Cellar/libffi/3.0.13...<br />Uninstalling /usr/local/Cellar/pkg-config/0.28...<br />Uninstalling /usr/local/Cellar/xz/5.0.5...<br />Pauls-Mac-Pro:~ paul$ port installed<br />The following ports are currently installed:<br />  libiconv @1.14_0 (active)<br />  pkgconfig @0.28_0 (active)<br />Pauls-Mac-Pro:~ paul$ sudo port uninstall pkgconfig libiconv<br />--->  Deactivating pkgconfig @0.28_0<br />--->  Cleaning pkgconfig<br />--->  Uninstalling pkgconfig @0.28_0<br />--->  Cleaning pkgconfig<br />--->  Deactivating libiconv @1.14_0<br />--->  Cleaning libiconv<br />--->  Uninstalling libiconv @1.14_0<br />--->  Cleaning libiconv</pre> <p>Then install wx: I'm attempting the directions <a href=\"http://www.haskell.org/haskellwiki/WxHaskell/MacOS_X\">here</a>.</p> <b>brew install wxmac --use-llvm --devel</b> <pre>brew install wxmac --devel<br />Warning: It appears you have MacPorts or Fink installed.<br />Software installed with other package managers causes known problems<br />for Homebrew. If a formula fails to build, uninstall MacPorts/Fink<br />and try again.</pre> <p>(There shouldn't be any libraries or binaries in the various paths to interfere, so I'll ignore this). And it seemed to succeed. So, next step from the instructions above: <b>Check your path to make sure you are using your wxWidgets and not the default Mac one. The command <b>which wx-config</b> should not return the file path /usr/bin/wx-config</b> (On my system it returns <b>/usr/local/bin/wx-config</b>). Next, <b>cabal install wx cabal-macosx</b>. That chugs away for a while and I see an unnervingly large number of warnings, but it builds. And then, I saved <a href=\"https://raw.github.com/jodonoghue/wxHaskell/master/samples/wxcore/HelloWorld.hs\">this file</a> as hello-ex.hs and <b>ghc --make HelloWorld.hs</b> and <b>macosx-app hello-wx</b> and <b>./hello-wx.app/Contents/MacOS/hello-wx</b> and the result runs and I get a window, although it pops up off the bottom of my primary display, and the application's main menu does not seem to render its menu items quite right (they say \"Hide H\" and \"Quit H\" instead of the application name). But still -- promising!</p> <p>So -- some code. To facilitate working with a GUI module in a separate <b>.hs</b> file I am now calling the core logic <b>ArcticSlideCore.hs</b>. and that file begins with <b>module ArcticSlideCore where</b>. I don't have very much working yet, but here's what is in my <b>ArcticSlideGui.hs</b> file so far. First I define my module and do my imports:</p> <pre>module Main where<br /><br />import Graphics.UI.WX<br />import ArcticSlideCore</pre> <p>Then I define some bitmaps. For purposes of experimentation I made <b>.png</b> files out of the original Polar game's CICN resources. I want to redraw them -- first, to avoid blatant copyright infringement and second, to make them bigger. But temporarily:</p> <pre>bomb = bitmap \"bomb.png\"<br />heart = bitmap \"heart.png\"<br />house = bitmap \"house.png\"<br />ice = bitmap \"ice_block.png\"<br />tree = bitmap \"tree.png\"</pre> <p>While they are game tiles as such, there are icons for the penguin facing in the four cardinal directions and icons for a breaking ice block and exploding bomb that were used in original animations:</p> <pre>penguin_e = bitmap \"penguin_east.png\"<br />penguin_s = bitmap \"penguin_south.png\"<br />penguin_w = bitmap \"penguin_west.png\"<br />penguin_n = bitmap \"penguin_north.png\"<br /><br />ice_break = bitmap \"ice_block_breaking.png\"<br />bomb_explode = bitmap \"bomb_exploding.png\"</pre> <p>I noticed that wxHaskell's <b>Point</b> type operates in reverse. I'm accustomed to C arrays where the higher-rank indices come first (so y, x or row index, column index for tile positions), but points are backwards. My icons are 24x24 pixels, so I rearrange and scale them like so:</p> <pre>posToPoint :: Pos -> Point<br />posToPoint pos = ( Point ( posX pos * 24 ) ( posY pos * 24 ) )</pre> <p>Now, some convenience function for drawing bitmaps based on Tile type or based on a wxHaskell bitmap. These are two more cases where I was not sure of the type signature, so I wrote the functions without them:</p> <pre>drawBmp dc bmp pos = drawBitmap dc bmp point True []<br />    where point = posToPoint pos<br /><br />drawTile dc tile pos = drawBmp dc bmp pos<br />    where bmp = case tile of Bomb  -> bomb<br />                             Heart -> heart<br />                             House -> house<br />                             Ice   -> ice<br />                             Tree  -> tree</pre> <p>GHCI says:</p> <pre>Prelude Main> :t drawBmp<br />drawBmp<br />  :: Graphics.UI.WXCore.WxcClassTypes.DC a<br />     -> Graphics.UI.WXCore.WxcClassTypes.Bitmap ()<br />     -> ArcticSlideCore.Pos<br />     -> IO ()</pre> <p>That boils down to <b>drawBmp :: DC a -> Bitmap () -> Pos -> IO ()</b>, and the signature for DrawTile similarly boils down to <b>drawTile :: DC a -> Tile -> Pos -> IO ()</b>. Thanks, GHCI!</p> <p>Next, I need a view method. This is just a placeholder test to verify that I can draw all my icons in the bounds where I expect them:</p> <pre>draw dc view<br />    = do<br />        drawTile dc Bomb        ( Pos 0 0  )<br />        drawTile dc Heart       ( Pos 0 1  )<br />        drawTile dc House       ( Pos 0 2  )<br />        drawTile dc Ice         ( Pos 0 3  )<br />        drawTile dc Tree        ( Pos 0 4  )<br />        drawBmp dc penguin_e    ( Pos 1 0  )<br />        drawBmp dc penguin_s    ( Pos 1 1  )<br />        drawBmp dc penguin_w    ( Pos 1 2  )<br />        drawBmp dc penguin_n    ( Pos 1 3  )<br />        drawBmp dc ice_break    ( Pos 0 23 )<br />        drawBmp dc bomb_explode ( Pos 3 23 )</pre> <p>Now, my <b>guy</b> function is where things get interesting and wxHaskell shows off a little. I read this <a href=\"http://legacy.cs.uu.nl/daan/download/papers/wxhaskell.pdf\">paper</a> that talks about some of the layout options and other tricks of the wxHaskell implementation, and discovered that this maps really nicely to defining my window in terms of a grid of icons. <b>space 24 24</b> returns a layout item of the appropriate size, and <b>grid</b> returns a layout item when given spacing values (I want the icons touching, so I use 0 0) and a list of lists for rows and columns. To generate the proper structure of 4 rows of 24 columns I just take what I need from infinite lists: <b>take 4 $ repeat $ take 24 $ repeat $ space 24 24</b> Oh, that's nifty!</p> <pre>gui :: IO ()<br />gui<br />    = do f <- frame [text := \"Arctic Slide\"]<br />         t <- timer f [ interval := 250<br />                      ]<br />         set f [ layout   := grid 0 0 $ take 4 $ repeat $<br />                             take 24 $ repeat $ space 24 24   <br />                ,bgcolor  := white<br />                ,on paint := draw<br />               ]<br />         return ()</pre> <p>And finally, main:</p> <pre>main :: IO ()<br />main<br />  = start gui</pre> <p>To build this for use as a MacOS X GUI app I just do <b>ghc --make ./arcticSlideGui.hs</b>, and if it compiles properly then <b>macosx-app arcticSlideGui; ./arcticSlideGui.app/Contents/MacOS/arcticSlideGui</b> and I have a little GUI window:</p> <div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://3.bp.blogspot.com/-J2ktwHGLxm8/UebxznjXGwI/AAAAAAAADLg/-nmqEScEKSY/s1600/arctic-slide-gui-test-1.tiff\"><img src=\"http://3.bp.blogspot.com/-J2ktwHGLxm8/UebxznjXGwI/AAAAAAAADLg/-nmqEScEKSY/s400/arctic-slide-gui-test-1.tiff\" border=\"0\" /></a></div> <p>Sweet! Now I've got some more thinking to do. There's some plumbing that needs to get hooked up between the core game logic and the GUI layer. The core game logic is mostly factored the way I want it to be -- it gets a world and a penguin move and returns an updated world -- but I need to do a little more than just map the tiles to a series of drawTile calls. I might want to support timed sequences of changes to the GUI representation of the board -- for example, smooth sliding of game pieces and smooth walking of the penguin. The <b>draw</b> method should draw the board pieces and the penguin all at once, with no redundancy if possible. Sound effects would be nice. Animation for crushing an ice block and blowing up a mountain would be nice. I've got some ideas along these lines based on event queues and a timer, and some other pieces of sample code I've been looking at.</p> <p>Meanwhile, if any of you would like to take a crack at redrawing the graphics, please be my guest. It would be nice if the replacement icons would fit on an iPhone or iPod Touch. 48x84 is just a little bit too big -- 48 pixels by 24 icons is 1152 pixels, and the iPhone 4 and 5 screens are 640x960 and 640x1136. 40 pixels wide would fit perfectly on an iPhone 4. Note that the icons don't actually have to be square -- there is room to spare vertically. It might be nice, though, to leave room for a few extra rows, to support game boards that break out of the original 4-row height.</p>" nil nil "9ba65fae6a6dace3ae5229666a6692e0") (273 (20966 20562 549603) "http://praisecurseandrecurse.blogspot.com/2013/07/the-polar-game-in-haskell-day-612.html" "Paul Potts: The Polar Game in Haskell, Day 6/12: Towards a GUI, Continued" "noreply@blogger.com (Paul Potts)" "Tue, 16 Jul 2013 21:47:00 +0000" "<p>OK, so when I left off last time, I was running into a gruesome link error. I found <a href=\"http://stackoverflow.com/questions/2726248/ghc-6-12-and-macports\">this Stack Overflow thread</a> and the first accepted answer fixed the problem. However, it seems that the answer may be to avoid MacPorts versions of the libraries I need. So I'm going to attempt to clean that all out and use Homebrew. So, first:</p> <pre>sudo port -fp uninstall --follow-dependents installed</pre> <p>And then I'm manually cleaning out some of the stuff mentioned <a href=\"http://superuser.com/questions/367434/how-do-you-remove-macports-and-all-the-packages-it-has-installed\">in this article</a>.</p> <p>Next, I'm removing this from my .profile (hey, I'm so pleased that it is clearly marked!</p> <pre># MacPorts Installer addition on 2013-07-16_at_11:57:13:<br />adding an appropriate PATH variable for use with MacPorts.<br />export PATH=/opt/local/bin:/opt/local/sbin:$PATH<br /># Finished adapting your PATH environment variable for <br />use with MacPorts.</pre> <p>Now to install Homebrew:</p> <pre>ruby -e \"$(curl -fsSL https://raw.github.com/mxcl/homebrew/go)\"</pre> <p>I ran brew doctor and wow, I have a mountain of warnings. I got rid of most of them except for several about \"unbrewed\" things -- static libraries, .la files, and dylibs in /usr/local/lib. I get a warning about MacGPG2 but that seems to be fixed by upgrading to the current version. So now I'm trying cabal install --reinstall gtk, and I get:</p> <pre>Configuring gtk-0.12.4...<br />setup: The pkg-config package gthread-2.0 is required but it could not be<br />found.</pre> <p>And so, attempting to follow the directions <a href=\"http://www.haskell.org/haskellwiki/Gtk2Hs/Mac\">here</a>:</p> <pre>brew install glib cairo gtk gettext fontconfig</pre> <p>...and that actually crashes. I get \"confest cannot be opened because of a problem.\" In the console log:</p> <pre>Process:         conftest [12844]<br />Path:            /private/tmp/*/conftest<br />Identifier:      conftest<br />Version:         0<br />Code Type:       X86-64 (Native)<br />Parent Process:  sh [12843]<br />User ID:         501<br /><br />Date/Time:       2013-07-16 15:42:18.117 -0400<br />OS Version:      Mac OS X 10.8.4 (12E55)<br />Report Version:  10<br /><br />Crashed Thread:  0<br /><br />Exception Type:  EXC_BREAKPOINT (SIGTRAP)<br />Exception Codes: 0x0000000000000002, 0x0000000000000000<br /><br />Application Specific Information:<br />dyld: launch, loading dependent libraries<br /><br />Dyld Error Message:<br />  Library not loaded: /usr/local/lib/libintl.8.dylib<br />  Referenced from: /private/tmp/*/conftest<br />  Reason: no suitable image found.  Did find:<br /> /usr/local/lib/libintl.8.dylib:<br />            no matching architecture in universal wrapper<br /> /usr/local/lib/libintl.8.dylib:<br />            no matching architecture in universal wrapper</pre> <p>And I get an error about \"GLib requires a 64 bit type.\" I also had to do some manual clean-out of some files that had the wrong permissions and were interfering with installing pkgconfig. I found a number of people reporting this problem, but none of the solutions they outlined seemed to work for me. So... what else can I try?</p> <p>There's this: <a href=\"http://www.haskell.org/haskellwiki/Gtk2Hs/Mac#GTK.2B_OS_X_Framework\">http://www.haskell.org/haskellwiki/Gtk2Hs/Mac#GTK.2B_OS_X_Framework</a></p> <p>OK! Deep sigh... let's try this!</p> <pre>Pauls-Mac-Pro:Downloads paul$ sh ./gtk-osx-build-setup.sh <br />Checking out jhbuild (07b5a7d) from git...<br />Cloning into 'jhbuild'...<br />remote: Counting objects: 37027, done.<br />remote: Compressing objects: 100% (14715/14715), done.<br />remote: Total 37027 (delta 28610), reused 28612 (delta 22178)<br />Receiving objects: 100% (37027/37027), 7.27 MiB | 2.27 MiB/s, done.<br />Resolving deltas: 100% (28610/28610), done.<br />Switched to a new branch 'stable'<br />Patch is empty.  Was it split wrong?<br />If you would prefer to skip this patch, instead run \"git am --skip\".<br />To restore the original branch and stop patching run \"git am --abort\".<br />Installing jhbuild...<br />gnome-autogen.sh not available<br />yelp-tools not available<br />Configuring jhbuild without autotools<br />Now type `make' to compile jhbuild<br />Installing jhbuild configuration...<br />Installing gtk-osx moduleset files...<br />PATH does not contain /Users/paul/.local/bin, it is recommended that you add that.<br /><br />Done.</pre> <p>Ummm... OK, wow, that installed source in my home directory build tools in a <i>hidden</i> directory (prefaced with a period) under my home directory. There are warning notes about how the build process conflicts with MacPorts and fink. There's also a note that says \"Note: jhbuild requires Python 2.5 to unpack tar files\" (of course it does... that's the simplest and most system-compatible way to unpack tar files, right?) Ugh. Anyway... in <b>~/Source/jhbuild</b> I type <b>~/.local/bin/jhbuild bootstrap</b> and it builds about a bazillion things including <b>cmake</b>. (Talk amongst yourselves, this is going to take a while... time for another snack...)</p> <p>That seemed to work. And so: <b>~/.local/bin/jhbuild build meta-gtk-osx-bootstrap</b> and <b>~/.local/bin/jhbuild build meta-gtk-osx-core</b>. Somewhat to my shock, everything succeeded! I tried to build gimp, but that failed with \"we require Pango with the optional support for Cairo compiled in,\" and I don't want to go too far down that rabbit hole, so I gave up on that. So let's see if I can make that work with GHC. The next step is package-config. Which requires glib. Ummm, wait a minute... oh, crap. That's still broken with homebrew. Ummm. What about package-config from MacPorts, which the instructions for GTK OSX warned me about? Sure, let's try it, what the hell... after all, I've wasted nearly a full day already... so, <b>sudo port selfupdate</b>, <b>sudo port install pkg-config</b>... that seemed to work. So then we download the Gtk2HS tarball... ummm, the link from the instructions is broken. Ummm... from SourceForge <a href=\"http://sourceforge.net/projects/gtk2hs/\">here</a>... but that version is looking much older than the one described <a href=\"http://projects.haskell.org/gtk2hs/archives/2012/11/21/new-gtk2hs-0124-release/\">here</a>. I'm getting a bad feeling about this. But anyway... 0.10.1 it is! Configure away!</p> <pre>checking for pkg-config... /opt/local/bin/pkg-config<br />checking pkg-config is at least version 0.9.0... yes<br />checking for GLIB... no<br />configure: error:<br /><br />The development files for the glib-2.x library were not found.<br />Perhaps you need to install glib or glib-devel</pre> <p>Huh. Well. It's just about the end of my work day; I've got to go downstairs and help my wife get dinner ready. Ummm. So! I hope you've enjoyed this tutorial on how to use the GTK GUI library in Haskell! Please join me next time when I perform brain surgery on myself using a hacksaw, a folding mirror, and a bottle of Scotch!</p> <iframe allowfullscreen=\"allowfullscreen\" frameborder=\"0\" height=\"315\" src=\"http://www.youtube.com/embed/usAXHygEQJU\" width=\"560\"></iframe>" nil nil "6b5304de5659d1303c55770ee8aa674f") (272 (20966 20562 548474) "http://www.joachim-breitner.de/blog/archives/606-Real-World-Haskell-Applications.html" "Joachim Breitner: Real World Haskell Applications" "mail@joachim-breitner.de (nomeata)" "Tue, 16 Jul 2013 20:32:16 +0000" "<p>Today I held a lightning talk at the <a href=\"http://www.meetup.com/The-Karlsruhe-Functional-Programmers-Meetup-Group/events/125224302/\">Karlsruhe Functional Programmer’s Group</a>, where I presented “Real World Haskell” applications, i.e. programs that are written in Haskell, are somewhat mature and well-known and have non-programmers as their target group. Here is the (surely subjective) list that I have come up (also see <a href=\"http://files.meetup.com/4530082/RealWordHaskell.pdf\">the slides</a>):</p>
<ul>
<li><a href=\"http://darcs.net/\">darcs</a> (since 2002, 35 000 loc): Distributed version control system with an innovative focus on changes instead of states.<br /></li>
<li><a href=\"http://xmonad.org/\">xmonad</a> (since 2007, 30000 loc): Well known tiling window manager with a huge library of layout and other plugins. Made it into the list despite its configuration file being a Haskell file.</li>
<li><a href=\"http://hledger.org/\">hledger</a> (since 2007, 9000 loc): Text-file based double-ledger accounting tool, a clone of <a href=\"http://ledger-cli.org/\">ledger</a>.</li>
<li><a href=\"http://raincat.bysusanlin.com/\">Raincat</a> (since 2008, 2000 loc): Platform game with a cat that does not want to get wet.</li>
<li><a href=\"http://arbtt.nomeata.de\">arbtt</a> (since 2009, 2000 loc): My automatic rule-based time tracker. Made it into the list as a shameless plug; probably not that popular. It has now a proper web page contributed by Waldir Pimenta.</li>
<li><a href=\"http://detexify.kirelabs.org/\">detexify</a> (since 2010, 500 loc): The back end of the very useful LaTeX character command finder is written in Haskell.</li>
<li><a href=\"http://git-annex.branchable.com/\">git-annex</a> (since 2010, 28 000 loc): Manages your files and their location, a mixture of dropbox and git. Written by famous Joey Hess, who made a living from it via <a href=\"http://www.kickstarter.com/projects/joeyh/git-annex-assistant-like-dropbox-but-with-your-own\">kickstarter</a> He is currently running a <a href=\"https://campaign.joeyh.name/\">second round of funding</a>!</li>
<li><a href=\"http://joyridelabs.de/\">Nikki and the Robots</a> (since 2010, 18 000 loc): Platform game with Nikki and, well, his robots. It was produced as a commercial independent game and sold via a pay-what-you-like scheme, but the company unfortunately closed down.</li>
<li><a href=\"http://ianwookim.org/hoodle/\">hoodle</a> (since 2011, 13 000 loc): A note-taking and PDF annotation software like <a href=\"http://xournal.sourceforge.net/\">xournal</a>.<br /></li>
<li><a href=\"http://chordify.net/\">Chordify</a> (since 2012, ? loc): Analyses music, e.g. from a YouTube video, and calculates the corresponding guitar chords. Closed software, but supposedly written in Haskell.</li>
</ul>
<p>There is also an impressive list of <a href=\"http://www.haskell.org/haskellwiki/Haskell_in_industry\">industrial users that use Haskell</a> without talking about it much, but that does not work well to show off that you can do any kind of application in Haskell.</p>
<p>If I missed anything important, let me know!<br /></p>" nil nil "195b86f7a72d5f0490cd51763ec33410") (271 (20966 20562 547845) "http://feedproxy.google.com/~r/FpComplete/~3/trf121TrqTg/competition-announcement" "FP Complete: FP Complete Launches FP Haskell Competition with $1,000 Cash Prize Each Month" nil "Tue, 16 Jul 2013 19:51:00 +0000" "<p><b>FP Complete Launches FP Haskell Competition with $1,000 Cash Prize Each Month</b></p><p>I’m very excited to announce our competition for sample Haskell code and tutorials of real-world engineering and business solutions. The winning entry each month will get $1,000 cash prize, with a maximum of 3 runner-up prizes of $500 each. There may be multiple prizes each month or none at all if none meet the winning criteria. There are no limits on how many prizes each individual, team or group can win in any month or the duration of the contest.  In other words, <b>you can make some serious play money here!</b></p><p>Each entry consists of a working solution to an applied problem, plus accompanying tutorial material to teach others how to build similar programs.  Entries must be built or build on FP Haskell Center.  Anyone not affiliated with FP Complete is eligible to enter.  The competition starts August 2013. </p><p>The <a href=\"https://www.fpcomplete.com/business/competition/competition-overview\">details and rules of the competition are here</a>.. Entries may be based on new or pre-existing content and code, as long as they haven’t been published before and you’re willing to share it with the community. Understandable, well-organized, tutorial documentation and reusable code--often in conjunction with other languages--are <b><i>more</i></b> important than advanced programming techniques or theoretical purity. Your program must solve an applied problem or class of problems. </p><p>Since Entries must be built or build on FP Haskell Center, you need to <a href=\"https://www.fpcomplete.com/business/designer-ide\">sign up</a> for its Beta, if you haven’t already. </p><p>Why are we doing this?  Simple: because the Haskell community needs to vastly expand for Haskell to become a mainstream language. To do this we must show people how to use this amazing language in solving real-world business problems. People tell us they need to see running and documented examples of real-world problems and solutions, so they can quickly see how to design their own working solutions. They also want material to show their colleagues and bosses just how useful Haskell is today.  This contest intends to crowd source programming recipes into an applied Haskell cookbook. </p><p>We really believe in this program as a key driver to greater Haskell adoption, which is good for the Haskell-functional programming communities and FP Complete.  So we want to incentivize the collective energy and talent of the community to produce content to promote our common cause.  So, get your creative and competitive juices going, and make some extra money for rent, a trip to Hawaii, building your own drone or whatever else turns you on.</p><p><a href=\"https://www.fpcomplete.com/business/competition/competition-rules\">Official rules</a>.  After you’ve submitted your Entry, <a href=\"https://www.fpcomplete.com/business/competition/competition-form\">register here</a></p><div class=\"feedflare\">
<a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=trf121TrqTg:c_pBAXILPBM:yIl2AUoC8zA\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=yIl2AUoC8zA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=trf121TrqTg:c_pBAXILPBM:V_sGLiPBpWU\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=trf121TrqTg:c_pBAXILPBM:V_sGLiPBpWU\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=trf121TrqTg:c_pBAXILPBM:qj6IDK7rITs\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=qj6IDK7rITs\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=trf121TrqTg:c_pBAXILPBM:gIN9vFwOqvQ\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=trf121TrqTg:c_pBAXILPBM:gIN9vFwOqvQ\" border=\"0\" /></a>
</div><img src=\"http://feeds.feedburner.com/~r/FpComplete/~4/trf121TrqTg\" height=\"1\" width=\"1\" />" nil nil "af641fc1e25bf15b3f9eb864caa502ae") (270 (20966 20562 546940) "http://praisecurseandrecurse.blogspot.com/2013/07/the-polar-game-in-haskell-day-6-towards.html" "Paul Potts: The Polar Game in Haskell, Day 6: Towards a GUI" "noreply@blogger.com (Paul Potts)" "Tue, 16 Jul 2013 18:11:00 +0000" "<p>So, I have some time today to program and I want to see how far I can get in starting to develop a GUI for my game, incomplete as it is. Can I get a window displayed and reacting to mouse or keyboard events, and drive the game logic with it?</p> <p>I came across the paper <a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.25.8446&rep=rep1&type=pdf\">FranTk -- A Declarative GUI Language for Haskell</a> (PDF file link) by Meurig Sage and it looked interesting, so I considered trying FranTk. However, that led to broken links. Moving on...</p> <p>Let's see if I can get somewhere with FG. That needs gtk2hs. Hmmm... cabal update, cabal install gtk2hs-buildtools, cabal install gtk.</p> <pre>[1 of 2] Compiling Gtk2HsSetup<br />    ( Gtk2HsSetup.hs, dist/setup-wrapper/Gtk2HsSetup.o )<br />[2 of 2] Compiling Main<br />    ( SetupMain.hs, dist/setup-wrapper/Main.o )<br />Linking dist/setup-wrapper/setup ...<br />Configuring cairo-0.12.4...<br />setup: The program pkg-config version >=0.9.0 is required but it<br />could not be found.<br />Failed to install cairo-0.12.4</pre> <p>I tried downloading pkg-config-0.28 source from <a href=\"http://pkgconfig.freedesktop.org/releases/\">here</a> and that got me as far as running ./configure --prefix=/usr/local/ and seeing:</p> <pre>configure: error: Either a previously installed<br />pkg-config or \"glib-2.0 >= 2.16\" could not be found.<br />Please set GLIB_CFLAGS and GLIB_LIBS to the correct<br />values or pass --with-internal-glib to configure to use<br />the bundled copy.</pre> <p>So I tried ./configure --prefix=/usr/local/ --with-internal-glib and that seemed to go OK; I was able to do make, make check -- one failure out of 25 tests in \"check-path\" -- and sudo make install. Back to cabal install gtk == nope.</p> <pre>Configuring cairo-0.12.4...<br />setup: The pkg-config package cairo-pdf is required but it<br />could not be found.<br />Failed to install cairo-0.12.4<br /><br />Configuring glib-0.12.4...<br />setup: The pkg-config package glib-2.0 is required but it<br />could not be found.<br />Failed to install glib-0.12.4<br />cabal: Error: some packages failed to install:<br />cairo-0.12.4 failed during the configure step. The exception was:<br />ExitFailure 1<br />gio-0.12.4 depends on glib-0.12.4 which failed to install.<br />glib-0.12.4 failed during the configure step. The exception was:<br />ExitFailure 1<br />gtk-0.12.4 depends on glib-0.12.4 which failed to install.<br />pango-0.12.4 depends on glib-0.12.4 which failed to install.</pre> <p>OK... so I guess it's time to install MacPorts because the Cairo page suggests using it to install cairo. I know there are competing tools -- fink and Homebrew and I've used both of them at some point, years ago, but removed them, for reasons I can no longer remember... I think it had something to do with the way they insisted on installing things under /opt and it was clear to me if they would interfere with each other. But anyway, I'll try the MacPorts installer for 2.13 for Mountain Lion... and then sudo port install cairo... oh, wow, it's installing the universe... bzip2, zlib, libpng, free type, perl5, python27... oh, the humanity...</p> <p>OK, where are we... oh, cabal install gtk again. \"The pkg-config package cairo-pdif is required but it could not be found.\" Let's try glib again.</p> <pre>Pauls-Mac-Pro:Gitit Wiki paul$ sudo port install glib2<br />--->  Computing dependencies for glib2<br />--->  Cleaning glib2<br />--->  Scanning binaries for linking errors: 100.0%<br />--->  No broken files found.</pre> <p>But cabal install gtk is still broken. Is there a MacPorts version of gtk2? Yes, apparently OH GOD IT'S BUILDING THE WHOLE WORLD...</p> <p>(Musical interlude...)</p> <p></p>But then cabal install gtk seems to go OK. A lot of deprecated function warnings. Another twenty minutes go by... what was I doing again? You know, I'm getting all confused, why don't I start with gtk2hs because <i>Real World Haskell</i> uses it... I need to sudo port install glade3... and OH GOD IT'S BUILDING THE WHOLE WORLD AGAIN... aaand welcome to hour three of \"The Polar Game in Haskell, Day 6: Towards a GUI...\"<p></p> <p></p>OK, glade and glade3 don't have any executables in my path. Oh, it's glade-3, how silly of me, even though the port is called glade3. And it says Gtk-WARNING **: cannot open display:. Oh yeah, it's X-Windows JUST SHOOT ME IN THE GODDAMN FACE... oh, I mean now I will happily go down another rabbit hole, thank you sir may I have another? So... the older X server is not supported in Mountain Lion anymore but there's something called XQuartz. XQuartz-2.7.4.dmg... \"you need to log out and log back in to make XQuartz your default X11 server.\" Oh, thanks, I'll just close these FOURTEEN browser tabs, SEVEN bash terminal sessions, and other apps... you know, it's time for a food break anyway...<p></p> <p>...aaand we're back. It launches, but I get \"an error occurred while loading or saving configuration information for glade-3. Some of your configuration settings may not work properly.\" There's a \"Details\" button:</p> <pre>Failed to contact configuration server; the most common<br />cause is a missing or misconfigured D-Bus session bus daemon.<br />See http://projects.gnome.org/gconf/ for information. (Details -<br />1: Failed to get connection to session: Session D-Bus not running.<br />Try running `launchctl load -w <br />/Library/LaunchAgents/org.freedesktop.dbus-session.plist'.)<br />Failed to contact configuration server; the most common cause <br />is a missing or misconfigured D-Bus session bus daemon. See <br />http://projects.gnome.org/gconf/ for information. (Details -<br />1: Failed to get connection to session: Session D-Bus not running. <br />Try running `launchctl load -w <br />/Library/LaunchAgents/org.freedesktop.dbus-session.plist'.)<br />Failed to contact configuration server; the most common cause <br />is a missing or misconfigured D-Bus session bus daemon. See <br />http://projects.gnome.org/gconf/ for information. (Details -<br />1: Failed to get connection to session: Session D-Bus not running. <br />Try running `launchctl load -w <br />/Library/LaunchAgents/org.freedesktop.dbus-session.plist'.)<br />Failed to contact configuration server; the most common cause <br />is a missing or misconfigured D-Bus session bus daemon. See <br />http://projects.gnome.org/gconf/ for information. (Details -<br />1: Failed to get connection to session: Session D-Bus not running.<br />Try running `launchctl load -w <br />/Library/LaunchAgents/org.freedesktop.dbus-session.plist'.)<br />Failed to contact configuration server; the most common cause<br />is a missing or misconfigured D-Bus session bus daemon. See<br />http://projects.gnome.org/gconf/ for information. (Details -<br />1: Failed to get connection to session: Session D-Bus not running.<br />Try running `launchctl load -w <br />/Library/LaunchAgents/org.freedesktop.dbus-session.plist'.)<br /></pre> <p>Gaaah! Well, OK, I can do that... and I'm able to edit a little file. Now to look at some tutorials. I get 404s on http://www.haskell.org/gtk2hs/docs/tutorial/glade/ and also http://dmwit.com/gtk2hs/%7C -- ooof. My first attempt at adapting a little code from <i>Real World Haskell</i> -- not going so well. This tutorial is still available: <a href=\"http://www.haskell.org/haskellwiki/Gtk2Hs/Tutorials/ThreadedGUIs\">http://www.haskell.org/haskellwiki/Gtk2Hs/Tutorials/ThreadedGUIs</a> but as to how useful it is... I'm gonna have to get back to you on that. There's also this tutorial: <a href=\"http://home.telfort.nl/sp969709/gtk2hs/chap2.html\">http://home.telfort.nl/sp969709/gtk2hs/chap2.html</a> so I can create a little GTK GUI entirely in code rather than using a Glade file. Something like this:</p> <pre>import qualified Graphics.UI.Gtk<br /><br />main :: IO ()<br />main = do<br />    Graphics.UI.Gtk.initGUI<br />    window <- Graphics.UI.Gtk.windowNew<br />    Graphics.UI.Gtk.widgetShowAll window<br />    Graphics.UI.Gtk.mainGUI</pre> <p></p>Aaand I get an immediate segmentation fault. Hmmm. I think I read about running with \"-threaded...\"<p></p> <pre>Pauls-Mac-Pro:arctic-slide-haskell paul$ ghci -threaded<br />GHCi, version 7.4.1: http://www.haskell.org/ghc/  :? for help<br />Warning: -debug, -threaded and -ticky are ignored by GHCi</pre> <p>OK, how about GHC?</p> <pre>Pauls-Mac-Pro:arctic-slide-haskell paul$ ghc basic-gui.hs -threaded<br />[1 of 1] Compiling Main             ( basic-gui.hs, basic-gui.o )<br />Linking basic-gui ...<br />Undefined symbols for architecture x86_64:<br />  \"_iconv\", referenced from:<br />      _hs_iconv in libHSbase-4.5.0.0.a(iconv.o)<br />     (maybe you meant: _hs_iconv_open, <br />_base_GHCziIOziEncodingziIconv_iconvEncoding6_info , <br />_hs_iconv , _base_GHCziIOziEncodingziIconv_iconvEncoding4_closure , _base_GHCziIOziEncodingziIconv_iconvEncoding3_info , <br />_base_GHCziIOziEncodingziIconv_iconvEncoding5_closure , <br />_base_GHCziIOziEncodingziIconv_iconvEncoding6_closure , <br />_base_GHCziIOziEncodingziIconv_iconvEncoding3_closure , <br />_base_GHCziIOziEncodingziIconv_iconvEncoding2_closure , <br />_base_GHCziIOziEncodingziIconv_iconvEncoding2_info , <br />_base_GHCziIOziEncodingziIconv_iconvEncoding5_info , <br />_base_GHCziIOziEncodingziIconv_iconvEncoding7_closure , <br />_hs_iconv_close , <br />_base_GHCziIOziEncodingziIconv_iconvEncoding7_info )<br />  \"_iconv_close\", referenced from:<br />      _hs_iconv_close in libHSbase-4.5.0.0.a(iconv.o)<br />     (maybe you meant: _hs_iconv_close)<br />  \"_iconv_open\", referenced from:<br />      _hs_iconv_open in libHSbase-4.5.0.0.a(iconv.o)<br />     (maybe you meant: _hs_iconv_open)<br />  \"_locale_charset\", referenced from:<br />      _localeEncoding in libHSbase-4.5.0.0.a(PrelIOUtils.o)<br />ld: symbol(s) not found for architecture x86_64<br />collect2: ld returned 1 exit status</pre> <p>Hmmm. It seems like this might take longer than I thought...</p>" nil nil "84578704e9231fca83a6ca7c0429d627") (269 (20965 18848 468109) "http://www.joachim-breitner.de/blog/archives/604-Ultimate-Tic-Tac-Toe-is-always-won-by-X.html" "Joachim Breitner: Ultimate Tic Tac Toe is always won by X" "mail@joachim-breitner.de (nomeata)" "Tue, 16 Jul 2013 10:59:21 +0000" "<p>The blog Math with Bad Drawings recently featured an <a href=\"http://mathwithbaddrawings.com/2013/06/16/ultimate-tic-tac-toe/\">article about Ultimate Tic Tac Toe</a>, a variant of Tic Tac Toe where each of the nine fields is a separate game of Tic Tac Toe. To mark a field of the large game as your, you have to win the small game therein. If you chose a field in the small game, this position determines the small field that the other play may play next. See the linked article for a full explanation.</p>
<p>As far as I know, the question of who wins this game was open; at least nothing definite was known <a href=\"https://news.ycombinator.com/item?id=5898506\">on Hacker News</a> or <a href=\"http://boardgames.stackexchange.com/questions/12477/is-ultimate-tic-tac-toe-solved\">on the Board Games StackExchange</a> site. We discussed this a bit in our office, and my coworker Denis Lohner came up with what seems to be a winning strategy.</p>
<p><strong> Update:</strong> Not surprising, but with these variants of the rule, the winning strategy <a href=\"https://www.khanacademy.org/cs/in-tic-tac-toe-ception-perfect/1681243068\">was already known</a>.<br /></p>
<h3>Strategy</h3>
<p>Assume Denis (⨯) plays against me (○). Like most suggestions for a winning strategy for the first player, Denis (X) starts with the middle:</p>
<pre>   │   │
│   │
│   │
───┼───┼───
│   │
│ ⨯ │
│   │
───┼───┼───
│   │
│   │
│   │
</pre>
<p>Now I have to put my ○ in the center field of the center game. No matter where I place it, Denis will send me back ot the middle, until one field of the center game is free. Doing this eight times inevitably puts us in a position like this:
</p>
<pre>   │   │
│ ⨯ │ ⨯
│   │
───┼───┼───
│○○○│
⨯ │○⨯○│ ⨯
│○○○│
───┼───┼───
│   │
⨯ │ ⨯ │ ⨯
│   │
</pre>
<p>The only way I can influence the game is by chosing which ○ I place last; this determines where Denis goes now. But (and please verify that carefully) it will not matter: The only thing required from that field is that there is a second field that, together with the center, forms a row (or column or diagonal); all fields satisfy that. Assume I placed the top-left ○ last, and Denis has to go there. He will send me to that field:</p>
<pre>⨯  │   │
│ ⨯ │ ⨯
│   │
───┼───┼───
│○○○│
⨯ │○⨯○│ ⨯
│○○○│
───┼───┼───
│   │
⨯ │ ⨯ │ ⨯
│   │
</pre>
<p>Now the game of the first field is repeated: Whereever I send him, he will send me back. This works great for all fields but the middle field. The middle field is special: When I send him there, he has the free choice. He will pick the bottom-right game.
</p>
<ul>
<li>If I send him to the center field before I send him to bottom-right, he will put the ⨯ in the top-left corner of that field, sending me back. Once I send him to bottom-right then, he will put the ⨯ in the bottom-right corner of that field.</li>
<li>If I send him to the center field after I sent him to bottom-right, he will put the ⨯ in the bottom-right corner of that field.</li>
</ul>
<p> </p>
<p>In any case we will end up in this situation: I won the center game; I likely have a few ○ in the top-left game. To be precise: I have a ○ there if and only if the he has a ⨯ in the top-left corner of the corresponding game. He also has the diagonal of the lower-right game. For example:</p>
<pre>⨯○○│⨯  │⨯
○○│ ⨯ │ ⨯
○│   │
───┼───┼───
│○○○│⨯
⨯ │○⨯○│ ⨯
│○○○│
───┼───┼───
│   │⨯
⨯ │ ⨯ │ ⨯
│   │  ⨯
</pre>
<p>
I have to put my mark in the lower-right game now. From now on, whereever I go, he will send me to either to the top-left or bottom-right game. I can do nothing about it (I cannot send him to the diagonal any more, and whereever I send him there is at least one of the top-left or bottom-right fields fee), so he wil easily win all the other games by getting the diagonal. Eventually, he wins the whole game with the bottom row or the right column:
</p>
<pre>⨯○○│⨯  │⨯
○○│ ⨯ │ ⨯
○○○│   │
───┼───┼───
⨯  │○○○│⨯
⨯ │○⨯○│ ⨯
│○○○│
───┼───┼───
⨯  │⨯  │⨯
⨯ │ ⨯ │○⨯
⨯│  ⨯│○○⨯
</pre>
<p>This is not a formal proof yet, but hopefully close enough to convince you, or alternatively allow you to precisely describe how you can prevent losing against Denis’ strategy.</p>" nil nil "87ca5fb216b913bd8f808e37ff69afad") (268 (20964 65195 63253) "http://feedproxy.google.com/~r/holdenkarau/iYtm/~3/EAHPWyKCIi0/whats-new-in-spark-this-week-2.html" "Holden Karau: Whats new in Spark this week #2" "noreply@blogger.com (Holden Karau)" "Tue, 16 Jul 2013 01:47:03 +0000" "I've been somewhat distracted and well there has been a several week lapse between updates for what I intended to be weekly (and that is only after the first one). That being said I'm going to take another crack at this at hopefully get a streak of longer than one.<br />
Lets look at what has happened in the past week on spark:<br />
<ul>
<li><a href=\"https://github.com/karenfeng\">karenfeng</a> made a number of UI improvements (<a href=\"https://github.com/mesos/spark/commit/b2aaa1199e7ecd8e1b2a9ddd8356b6393edafe6b\">https://github.com/mesos/spark/commit/b2aaa1199e7ecd8e1b2a9ddd8356b6393edafe6b</a> , <a href=\"https://github.com/mesos/spark/commit/0d78b6d9cd11fc12c546f25fa857ba8b285c062d\">https://github.com/mesos/spark/commit/0d78b6d9cd11fc12c546f25fa857ba8b285c062d</a> , <a href=\"https://github.com/mesos/spark/commit/e3d3e6f0ab34f0fe083ef9feb31b9e9fd257519f\">https://github.com/mesos/spark/commit/e3d3e6f0ab34f0fe083ef9feb31b9e9fd257519f</a> , <a href=\"https://github.com/mesos/spark/commit/39557112501901da7f9b4be6159a5a0be5511b42\">https://github.com/mesos/spark/commit/39557112501901da7f9b4be6159a5a0be5511b42</a> ...)</li>
<li><a href=\"https://github.com/mateiz\">mateiz</a> added a new option, spark.kryo.referenceTracking, which allows users to disable kyro's reference tracking which can be done if you know your objects do not contain any loops. <a href=\"https://github.com/mesos/spark/commit/4698a0d6886905ef21cbd52e108d0dcab3df12df\">https://github.com/mesos/spark/commit/4698a0d6886905ef21cbd52e108d0dcab3df12df</a></li>
<li><a href=\"https://github.com/pwendell\">pwendell</a> has added an Environment tab to the UI to help track down issues with different JARs on the classpath, system properties not being set, and other enviroment related problems <a href=\"https://github.com/mesos/spark/pull/699\">https://github.com/mesos/spark/pull/699</a></li>
<li>Information about the RDD blocks locations was added to the status page <a href=\"https://github.com/mesos/spark/pull/697/\">https://github.com/mesos/spark/pull/697/</a>commits by <a href=\"https://github.com/pwendell\">pwendell</a></li>
<li>takeOrdered was added by <a href=\"https://github.com/Reinvigorate\">Reinvigorate</a> allowing one to get back the first k elements as defined by the provided ordering in <a href=\"https://github.com/mesos/spark/pull/692\">https://github.com/mesos/spark/pull/692</a> & <a href=\"https://github.com/mesos/spark/commit/ee4ce2fc51112387f28d7b422969ca2e9736e95f\">https://github.com/mesos/spark/commit/ee4ce2fc51112387f28d7b422969ca2e9736e95f</a> </li>
<li>The README was updated to reflect that the current version now requires Scala 2.9.3</li>
</ul>
Now to hoping next week I remember to do this again :)
<div class=\"feedflare\">
<a href=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?a=EAHPWyKCIi0:nNhKvZPmq9c:yIl2AUoC8zA\"><img src=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?d=yIl2AUoC8zA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?a=EAHPWyKCIi0:nNhKvZPmq9c:63t7Ie-LG7Y\"><img src=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?d=63t7Ie-LG7Y\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?a=EAHPWyKCIi0:nNhKvZPmq9c:V_sGLiPBpWU\"><img src=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?i=EAHPWyKCIi0:nNhKvZPmq9c:V_sGLiPBpWU\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?a=EAHPWyKCIi0:nNhKvZPmq9c:7Q72WNTAKBA\"><img src=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?d=7Q72WNTAKBA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?a=EAHPWyKCIi0:nNhKvZPmq9c:qj6IDK7rITs\"><img src=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?d=qj6IDK7rITs\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?a=EAHPWyKCIi0:nNhKvZPmq9c:gIN9vFwOqvQ\"><img src=\"http://feeds.feedburner.com/~ff/holdenkarau/iYtm?i=EAHPWyKCIi0:nNhKvZPmq9c:gIN9vFwOqvQ\" border=\"0\" /></a>
</div><img src=\"http://feeds.feedburner.com/~r/holdenkarau/iYtm/~4/EAHPWyKCIi0\" height=\"1\" width=\"1\" />" nil nil "e39cab2a637219b34ed31189157f6755") (267 (20964 65195 62253) "http://parenz.wordpress.com/2013/07/15/interactive-diagrams-gsoc-progress-report/" "Daniil Frumin: Interactive-diagrams GSoC progress report" nil "Mon, 15 Jul 2013 19:05:13 +0000" "<h1 id=\"intro\">Intro</h1>
<p>As some of you may already know, I’ve published the first demo version of the <a href=\"http://github.com/co-dan/interactive-diagrams\">interactive-diagrams</a> online, it can be found at <a href=\"http://paste.hskll.org\">http://paste.hskll.org</a> (thanks to my mentor <a href=\"http://weblog.luite.com/wordpress/\">Luite Stegeman</a> for hosting). It’s not very interactive yet, but it’s a good start. At the same time it took me a while to get everything up and running so in this blog post I would like to describe and discuss the overall structure and design of the project along with some details about the vast number of security restrictions that are being used.</p>
<p>Please note that <a href=\"http://paste.hskll.org\">http://paste.hskll.org</a> is just a demo version and I can guarantee neither the safety of your pastes nor the uptime of the app. The ‘release notes’ can be found <a href=\"https://github.com/co-dan/interactive-diagrams/releases/tag/first-demo\">here</a>.</p>
<p>If you have any suggestions or bug reports don’t hesitate to mail me (difrumin аt gmail dоt com) or use the <a href=\"https://github.com/co-dan/interactive-diagrams/issues\">bugtracker</a>.</p>
<h2 id=\"system-requirements\">System requirements</h2>
<p>GNU/Linux operating system, GHC 7.7 (I think it’s possible to make the whole thing work with GHC 7.6 but I don’t have time to support it and test everything), lots of RAM. In order to use some security restrictions you will also need SELinux and cgroup.</p>
<h1 id=\"high-level-structure\">High-level structure</h1>
<p>The whole program consists of three main components (it would be better to say <em>three main types of components</em> since there are usually multiple workers in the system):</p>
<ul>
<li>The web app (sources can be found in <code>scotty-pastebin</code>), powered by WAI, Scotty and Blaze;</li>
<li>The service app (<code>eval-api/src-service</code>);</li>
<li>Workers (<code>eval-api/src</code>).</li>
</ul>
<p>The web server handles user requests, database logic, and renders the results. Workers are the processes that perform the actual evaluation. The service component is the one that handles the pool of workers, keeps track of how many workers are available and forks new workers if necessary. The web app does not communicate with workers without the permission of the service.</p>
<p>All the communication between the components is performed with the help of UNIX sockets.</p>
<h2 id=\"request-example\">Request example</h2>
<p>Here’s an example workflow in the system:</p>
<ol style=\"\">
<li>User connects to the web server, sends the request to evaluate a certain bit of code.</li>
<li>Web server talks to the service, requesting a worker.</li>
<li>Server reuses an existing worker if an idle one exists. Otherwise it forks a new one or blocks if the limit is reached.</li>
<li>Worker, upon starting, loads the necessary libraries and applies security restrictions.</li>
<li>The web server receives a worker and sends it a request for evaluation.</li>
<li>The server waits, if there is no reply from the worker after a certain amount of time, it sends a message to the service saying that the worker timed out. If the web service receives the reply, it stores the result in the database and continues with the user request.</li>
<li>When the service receives message about one if its workers it decides whether to kill/restart it or not. If the worker’s process has timed out or results in an error (eg: out of memory exception) then the service restarts it.</li>
</ol>
<h2 id=\"component-permissions\">Component permissions</h2>
<p>Setting up the right permissions for the components is a crucial part in creating a secure environment. Depending on what security restrictions you have enabled you might want to choose different permissions for the processes. On <a href=\"http://paste.hskll.org\">http://paste.hskll.org</a> we use the full set of security restrictions and limits (see the next section) and it requires us to give the components certain permissions.</p>
<ul>
<li><code>scotty-pastebin</code> is run as a user in a multithreaded runtime;</li>
<li><code>eval-service</code> is run as a superuser (required for setting up chrooted jails) in a single-threaded environment (required due to forking/SELinux restrictions, see the SELinux section for details), listens on the ‘control’ socket;</li>
<li>workers are forked from <code>eval-service</code> as root, but they change their processes’ uid as soon as possible, listens on the ‘workerN’ socket (opened prior to chroot’ing);</li>
</ul>
<p>Additionally the whole thing runs in a <a href=\"http://parenz.wordpress.com/2013/06/29/vado/\">VM</a>.</p>
<p><em>See also <a href=\"https://github.com/co-dan/interactive-diagrams/wiki/Design\">this wiki page</a> written by luite</em></p>
<h1 id=\"security-limitations-and-restrictions\">Security limitations and restrictions</h1>
<p>Interactive-digrams applies a whole lot of limitations to the worker processes, which can be configured using the following datatype:</p>
<pre><code><span style=\"color: blue; font-weight: bold;\">data</span> LimitSettings <span style=\"color: red;\">=</span> LimitSettings
<span style=\"color: red;\">{</span> <span style=\"color: green;\">-- | Maximum time for which the code is allowed to run</span>
<span style=\"color: green;\">-- (in seconds)</span>
timeout     <span style=\"color: red;\">::</span> Int
<span style=\"color: green;\">-- | Process priority for the 'nice' syscall.</span>
<span style=\"color: green;\">-- -20 is the highest, 20 is the lowest</span>
<span style=\"color: red;\">,</span> niceness    <span style=\"color: red;\">::</span> Int
<span style=\"color: green;\">-- | Resource limits for the 'setrlimit' syscall</span>
<span style=\"color: red;\">,</span> rlimits     <span style=\"color: red;\">::</span> Maybe RLimits
<span style=\"color: green;\">-- | The directory that the evaluator process will be 'chroot'ed</span>
<span style=\"color: green;\">-- into. Please note that if chroot is applied, all the pathes</span>
<span style=\"color: green;\">-- in 'EvalSettings' will be calculated relatively to this</span>
<span style=\"color: green;\">-- value.</span>
<span style=\"color: red;\">,</span> chrootPath  <span style=\"color: red;\">::</span> Maybe FilePath
<span style=\"color: green;\">-- | The UID that will be set after the call to chroot.</span>
<span style=\"color: red;\">,</span> processUid  <span style=\"color: red;\">::</span> Maybe UserID
<span style=\"color: green;\">-- | SELinux security context under which the worker </span>
<span style=\"color: green;\">-- process will be running.</span>
<span style=\"color: red;\">,</span> secontext   <span style=\"color: red;\">::</span> Maybe SecurityContext
<span style=\"color: green;\">-- | A filepath to the 'tasks' file for the desired cgroup.</span>
<span style=\"color: green;\">-- </span>
<span style=\"color: green;\">-- For example, if I have mounted the @cpu@ controller at</span>
<span style=\"color: green;\">-- @/cgroups/cpu/@ and I want the evaluator to be running in the</span>
<span style=\"color: green;\">-- cgroup 'idiaworkers' then the 'cgroupPath' would be</span>
<span style=\"color: green;\">-- @/cgroups/cpu/idiaworkers@</span>
<span style=\"color: red;\">,</span> cgroupPath  <span style=\"color: red;\">::</span> Maybe FilePath
<span style=\"color: red;\">}</span> <span style=\"color: blue; font-weight: bold;\">deriving</span> <span style=\"color: red;\">(</span>Eq<span style=\"color: red;\">,</span> Show<span style=\"color: red;\">,</span> Generic<span style=\"color: red;\">)</span></code></pre>
<p>There is also a <a href=\"http://hackage.haskell.org/packages/archive/data-default/latest/doc/html/Data-Default.html\">Default</a> instance for <code>LimitSettings</code> and <code>RLimits</code> with most of the restrictions turned off:</p>
<pre><code>defaultLimits <span style=\"color: red;\">::</span> LimitSettings
defaultLimits <span style=\"color: red;\">=</span> LimitSettings
<span style=\"color: red;\">{</span> timeout    <span style=\"color: red;\">=</span> <span class=\"hs-num\">3</span>
<span style=\"color: red;\">,</span> niceness   <span style=\"color: red;\">=</span> <span class=\"hs-num\">10</span>
<span style=\"color: red;\">,</span> rlimits    <span style=\"color: red;\">=</span> Nothing
<span style=\"color: red;\">,</span> chrootPath <span style=\"color: red;\">=</span> Nothing
<span style=\"color: red;\">,</span> processUid <span style=\"color: red;\">=</span> Nothing
<span style=\"color: red;\">,</span> secontext  <span style=\"color: red;\">=</span> Nothing
<span style=\"color: red;\">,</span> cgroupPath <span style=\"color: red;\">=</span> Nothing
<span style=\"color: red;\">}</span></code></pre>
<p>Below I’ll briefly describe each limitation/restriction with some details.</p>
<h2 id=\"timeout-niceness\">Timeout & niceness</h2>
<p>The <code>timeout</code> field specifies how much time (in seconds) the server waits for the worker. (<em>Note: this is the only limitation that is controlled on the side of the web server. The corresponding procedure is <code>processTimeout</code>. We really want this to be run in the multithreaded environment</em>)</p>
<p>Niceness is merely the value passed to the <code>nice()</code> syscall, nothing special.</p>
<h2 id=\"rlimits\">rlimits</h2>
<p>The resource limits are controlled by syscalls to <code>setrlimit</code>. The limits itself are defined in the <code>RLimits</code> datatype:</p>
<pre><code><span style=\"color: blue; font-weight: bold;\">data</span> RLimits <span style=\"color: red;\">=</span> RLimits
<span style=\"color: red;\">{</span> coreFileSizeLimit <span style=\"color: red;\">::</span> ResourceLimits
<span style=\"color: red;\">,</span> cpuTimeLimit      <span style=\"color: red;\">::</span> ResourceLimits
<span style=\"color: red;\">,</span> dataSizeLimit     <span style=\"color: red;\">::</span> ResourceLimits
<span style=\"color: red;\">,</span> fileSizeLimit     <span style=\"color: red;\">::</span> ResourceLimits
<span style=\"color: red;\">,</span> openFilesLimit    <span style=\"color: red;\">::</span> ResourceLimits
<span style=\"color: red;\">,</span> stackSizeLimit    <span style=\"color: red;\">::</span> ResourceLimits
<span style=\"color: red;\">,</span> totalMemoryLimit  <span style=\"color: red;\">::</span> ResourceLimits
<span style=\"color: red;\">}</span> <span style=\"color: blue; font-weight: bold;\">deriving</span> <span style=\"color: red;\">(</span>Eq<span style=\"color: red;\">,</span> Show<span style=\"color: red;\">,</span> Generic<span style=\"color: red;\">)</span></code></pre>
<p><code>ResourceLimits</code> itself is defined in <a href=\"http://hackage.haskell.org/packages/archive/unix/latest/doc/html/System-Posix-Resource.html\">System.Posix.Resource</a>. For more information on resource limits see <a href=\"http://linux.die.net/man/3/setrlimit\">setrlimit(3)</a>.</p>
<h2 id=\"chrooted-jail\">Chrooted jail</h2>
<p>In order to restrict the worker process we run it inside the chroot jail. The easiest way to create a fully working jail is to use <code>debootstrap</code>. It’s also necessary to install gcc and GHC libraries inside the jail.</p>
<pre><code>mkdir
sudo debootstrap wheezy /idia/run/workers/worker1
sudo chmod  /idia/run/workers/worker1
cd /idia/run/workers/worker1
sudo mkdir -p ./home/
sudo chown  ./home/
cd ./home/
mkdir .ghc && sudo mount --bind ~/.ghc .ghc
mkdir .cabal && sudo mount --bind ~/.cabal .cabal
mkdir ghc && sudo mount --bind ~/ghc ghc # ghc libs
cd ../..
cp ~/interactive-diagrams/common/Helper.hs .
sudo chroot .
apt-get install gcc # inside the chroot</code></pre>
<p>I tried installing <a href=\"http://emdebian.org/\">Emdebian</a> using <a href=\"http://wiki.debian.org/Multistrap\">multistrap</a> to reduce the size of the jail, but GHC won’t run properly in that environment, complaining about librt.so (which was present in the system), so I decided to stick with debootstrap. If anyone knows how to avoid this problem with multistrap please mail me or leave a comment.</p>
<h3 id=\"useful-links\">Useful links</h3>
<ul>
<li><a href=\"http://wiki.debian.org/chroot\">http://wiki.debian.org/chroot</a></li>
<li><a href=\"http://wiki.debian.org/Debootstrap\">http://wiki.debian.org/Debootstrap</a></li>
</ul>
<h2 id=\"process-uid\">Process uid</h2>
<p>This is the uid the worker process will run under. The socket file will also be created by the user with this uid.</p>
<h2 id=\"selinux\">SELinux</h2>
<p>SELinux (Security-enhanced Linux) is a Linux kernel module providing mechanisms for enforcing fine-grained <a href=\"http://en.wikipedia.org/wiki/Mandatory_access_control\">mandatory access control</a>, brought to you by the creators of infamous PRISM!</p>
<p>SELinux allows the system administrator to control the security of the system by specifying in (modular) policy files the AVC (access vector cache) rules. The SELinux kernel module sits there and monitors all the syscalls and, if it finds something that is not explicitly allowed in the policy, it blocks it. (<em>Well, actually something a <a href=\"http://danwalsh.livejournal.com/43816.html\">little bit different</a> is going on, but for the sake of simplicity I am leaving it out</em>)</p>
<p>Everything on your system – files, network sockets, file handles, processes, directories – is labelled with a SELinux <em>security context</em>, which consists of a role, a user name (not related to the regular system user name) and a domain (also called <em>type</em> in some literature). In the policy file you specific which domains are allowed to perform various actions on other domains. A typical piece of the policy file will look like this:</p>
<pre><code>allow myprocess_t self:udp_socket { create connect };
allow myprocess_t bin_t:file { execute };</code></pre>
<p>The first line states that the process from the domain <code>myprocess_t</code> is allowed to create and connect to the UDP sockets of the same domain. The second line allows a process in that domain to execute files of type <code>bin_t</code> (usually files in <code>/bin/</code> and <code>/usr/bin</code>).</p>
<p>Note: the <code>secontext</code> field actually contains only the<br />
security domain. When the worker process is changing the security<br />
context it uses the same user/resource as it originally had.</p>
<p>In our <a href=\"https://github.com/co-dan/interactive-diagrams/blob/master/selinux/interactive-diagrams.te\">SELinux policy</a> we have several domains:</p>
<ul>
<li>idia_web_t – the domain under which the <code>scotty-pastebin</code> run</li>
<li>idia_web_exec_t – the domain of the <code>scotty-pastebin</code> executable and other files associated with that binary</li>
<li>idia_service_t – the domain under which the <code>eval-service</code> run</li>
<li>idia_service_exec_t – the domain of the <code>eval-service</code> executable and other files associated with that binary</li>
<li>idia_service_sock_t – UNIX socket files used for communication</li>
<li>idia_db_t, idia_pkg_t, idia_web_common_t – database files, packages, html files, templates and other stuff</li>
<li>idia_worker_env_t – chroot’ed environment in which the worker operates</li>
<li>idia_restricted_t – the most restricted domain in which the workers run and evaluate code</li>
</ul>
<p>The reason we made the service program run in a single-threaded environment is the following: if we run it in the multi-threaded environment (like we wanted) the worker processes want to have access to <a href=\"http://selinuxproject.org/page/ObjectClassesPerms#fd\">file descriptors, inherited</a> from the idia_service_t, which, of course, is dangerous and should not be allowed.</p>
<p>I personally don’t enjoy using SELinux very much. It’s very hard to configure it and among its shortcomings I can list the fact that there is no distinction between file types and process types; there is no proper separation, even when using the modular policy, as the duplicated types are checked when you load the module and there is no way (that I know of) to easily introduce a fresh unused type. And there is this thing that puzzled me for quite a while: home directories are treated specially. Even if you configure a subdirectory in your home dir to have a specific security context, <code>restorecon</code> won’t correctly install the context specified in the policy. You actually have to set he context yourself, using <code>chcon</code>.</p>
<h3 id=\"useful-links-1\">Useful links</h3>
<ul>
<li><a href=\"https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Security-Enhanced_Linux/chap-Security-Enhanced_Linux-SELinux_Contexts.html\">Redhat SELinux docs</a></li>
<li><a href=\"http://wiki.gentoo.org/wiki/SELinux/Tutorials\">Gentoo Wiki SELinux tutorial</a></li>
<li>/usr/share/selinux/default/include/support/ on your system</li>
<li><a href=\"https://wiki.ubuntu.com/AppArmor\">AppArmor</a> – a simpler alternative to SELinux, that deals with file paths rather than with security contexts</li>
</ul>
<h2 id=\"cgroups\">Cgroups</h2>
<p>Cgroups is the system that can be used to aid the way Linux schedules CPU time/shares, distributes memory to the processes. It does so by organizing processes into hierarchical groups with configured behaviour.</p>
<p>Installing cgroups on debian is somewhat tricky, because the package is a little bit weird.</p>
<pre><code>sudo apt-get install cgroup-bin libcgroup1
sudo cgconfigparser -l ~/interactive-diagrams/cgconfig.conf</code></pre>
<p>For our purposes we have a cgroup called <code>idiaworkers</code>. We also mount the cpu controller on <code>/cgroups/cpu</code>:</p>
<pre><code>$> ls -l /cgroups/cpu/
total 0
-rw-r--r--. 1 root root 0 Jul 12 16:22 cgroup.clone_children
--w--w--w-. 1 root root 0 Jul 12 16:22 cgroup.event_control
-rw-r--r--. 1 root root 0 Jul 12 16:22 cgroup.procs
-rw-r--r--. 1 root root 0 Jul 12 16:22 cpu.shares
drwxr-xr-x. 2 root root 0 Jul 12 16:22 idiaworkers
-rw-r--r--. 1 root root 0 Jul 12 16:22 notify_on_release
-rw-r--r--. 1 root root 0 Jul 12 16:22 release_agent
-rw-r--r--. 1 root root 0 Jul 12 16:22 tasks
$> ls -l /cgroups/cpu/idiaworkers
total 0
-rw-r--r--. 1 root    root 0 Jul 12 16:22 cgroup.clone_children
--w--w--w-. 1 root    root 0 Jul 12 16:22 cgroup.event_control
-rw-r--r--. 1 root    root 0 Jul 12 16:22 cgroup.procs
-rw-r--r--. 1 root    root 0 Jul 12 16:22 cpu.shares
-rw-r--r--. 1 root    root 0 Jul 12 16:22 notify_on_release
-rw-r--r--. 1 vagrant root 0 Jul 14 06:21 tasks</code></pre>
<p>In order to modify how much CPU time our group gets, we write to the <code>cpu.shares</code> file: <code>sudo echo 100 > /cgroups/cpu/idiaworkers/cpu.shares</code>. If we want to add the task/process to the group we simply append the <code>tasks</code> file: <code>echo $PID >> /cgroups/cpu/idiaworkers/tasks</code>. The workers append themselves to the task file automatically (if the cgroup restrictions are enabled in the <code>LimitSettings</code>).</p>
<h2 id=\"useful-links-2\">Useful links</h2>
<ul>
<li><a href=\"https://www.kernel.org/doc/Documentation/cgroups/cgroups.txt\">kernel.org docs</a></li>
<li><a href=\"http://en.wikipedia.org/wiki/Cgroups\">Wikipedia</a></li>
</ul>
<h1 id=\"open-problemsrequests\">Open problems/requests</h1>
<p>I am still not sure how do I write tests for this project. Do I write tests for my GHC API wrappers? Do I write tests for my workers pool? I probably should take a look how similar projects handles those.</p>
<h1 id=\"outro\">Outro</h1>
<p>So, as you can see, we have something working here and now that we manage to take the initial steps it will be much easier for us to push changes and make them available for public to use and comment on. There is still a long way to come. The code needs some serious cleanup (we’ve switched the design model a couple of weeks ago, which affected the internal structure seriously), the documentation needs to be written. And of course new features are waiting to be implemented :) We will be supporting multiple UIDs for workers and looking into using LXC for simplifying the setup process too.</p>
<p>I would like to thank augur and luite for their editorial feedback.</p>
<p>Stay tuned for the next posts about configuring the program for evaluation settings and reusing the components from the library.</p>
<br /> Tagged: <a href=\"http://parenz.wordpress.com/tag/diagrams/\">diagrams</a>, <a href=\"http://parenz.wordpress.com/tag/haskell-2/\">haskell</a>, <a href=\"http://parenz.wordpress.com/tag/interactive-diagrams/\">interactive-diagrams</a>, <a href=\"http://parenz.wordpress.com/tag/soc/\">soc</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/parenz.wordpress.com/80/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/parenz.wordpress.com/80/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=parenz.wordpress.com&blog=26722965&post=80&subd=parenz&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "4ab6bda6bb48869eb8fab653650aecc2") (266 (20964 8117 893300) "http://parenz.wordpress.com/2013/07/15/interactive-diagrams-gsoc-progress-report/" "Daniil Frumin: Interactive-diagrams GSoC progress report" nil "Mon, 15 Jul 2013 14:29:03 +0000" "<h1 id=\"intro\">Intro</h1>
<p>As some of you may already know, I’ve published the first demo version of the <a href=\"http://github.com/co-dan/interactive-diagrams\">interactive-diagrams</a> online, it can be found at <a href=\"http://paste.hskll.org\">http://paste.hskll.org</a> (thanks to my mentor <a href=\"http://weblog.luite.com/wordpress/\">Luite Stegeman</a> for hosting). It’s not very interactive yet, but it’s a good start. At the same time it took me a while to get everything up and running so in this blog post I would like to describe and discuss the overall structure and design of the project along with some details about the vast number of security restrictions that are being used.</p>
<p>Please note that <a href=\"http://paste.hskll.org\">http://paste.hskll.org</a> is just a demo version and I can guarantee neither the safety of your pastes nor the uptime of the app. The ‘release notes’ can be found <a href=\"https://github.com/co-dan/interactive-diagrams/releases/tag/first-demo\">here</a>.</p>
<p>If you have any suggestions or bug reports don’t hesitate to mail me (difrumin аt gmail dоt com) or use the <a href=\"https://github.com/co-dan/interactive-diagrams/issues\">bugtracker</a>.</p>
<h2 id=\"system-requirements\">System requirements</h2>
<p>GNU/Linux operating system, GHC 7.7 (I think it’s possible to make the whole thing work with GHC 7.6 but I don’t have time to support it and test everything), lots of RAM. In order to use some security restrictions you will also need SELinux and cgroup.</p>
<h1 id=\"high-level-structure\">High-level structure</h1>
<p>The whole program consists of three main components (it would be better to say <em>three main types of components</em> since there are usually multiple workers in the system):</p>
<ul>
<li>The web app (sources can be found in <code>scotty-pastebin</code>), powered by WAI, Scotty and Blaze;</li>
<li>The service app (<code>eval-api/src-service</code>);</li>
<li>Workers (<code>eval-api/src</code>).</li>
</ul>
<p>The web server handles user requests, database logic, and renders the results. Workers are the processes that perform the actual evaluation. The service component is the one that handles the pool of workers, keeps track of how many workers are available and forks new workers if necessary. The web app does not communicate with workers without the permission of the service.</p>
<p>All the communication between the components is performed with the help of UNIX sockets.</p>
<h2 id=\"request-example\">Request example</h2>
<p>Here’s an example workflow in the system:</p>
<ol style=\"\">
<li>User connects to the web server, sends the request to evaluate a certain bit of code.</li>
<li>Web server talks to the service, requesting a worker.</li>
<li>Server reuses an existing worker if an idle one exists. Otherwise it forks a new one or blocks if the limit is reached.</li>
<li>Worker, upon starting, loads the necessary libraries and applies security restrictions.</li>
<li>The web server receives a worker and sends it a request for evaluation.</li>
<li>The server waits, if there is no reply from the worker after a certain amount of time, it sends a message to the service saying that the worker timed out. If the web service receives the reply, it stores the result in the database and continues with the user request.</li>
<li>When the service receives message about one if its workers it decides whether to kill/restart it or not. If the worker’s process has timed out or results in an error (eg: out of memory exception) then the service restarts it.</li>
</ol>
<h2 id=\"component-permissions\">Component permissions</h2>
<p>Setting up the right permissions for the components is a crucial part in creating a secure environment. Depending on what security restrictions you have enabled you might want to choose different permissions for the processes. On <a href=\"http://paste.hskll.org\">http://paste.hskll.org</a> we use the full set of security restrictions and limits (see the next section) and it requires us to give the components certain permissions.</p>
<ul>
<li><code>scotty-pastebin</code> is run as a user in a multithreaded runtime;</li>
<li><code>eval-service</code> is run as a superuser (required for setting up chrooted jails) in a single-threaded environment (required due to forking/SELinux restrictions, see the SELinux section for details), listens on the ‘control’ socket;</li>
<li>workers are forked from <code>eval-service</code> as root, but they change their processes’ uid as soon as possible, listens on the ‘workerN’ socket (opened prior to chroot’ing);</li>
</ul>
<p>Additionally the whole thing runs in a <a href=\"http://parenz.wordpress.com/2013/06/29/vado/\">VM</a>.</p>
<p><em>See also <a href=\"https://github.com/co-dan/interactive-diagrams/wiki/Design\">this wiki page</a> written by luite</em></p>
<h1 id=\"security-limitations-and-restrictions\">Security limitations and restrictions</h1>
<p>Interactive-digrams applies a whole lot of limitations to the worker processes, which can be configured using the following datatype:</p>
<pre><code><span style=\"color: blue; font-weight: bold;\">data</span> LimitSettings <span style=\"color: red;\">=</span> LimitSettings
<span style=\"color: red;\">{</span> <span style=\"color: green;\">-- | Maximum time for which the code is allowed to run</span>
<span style=\"color: green;\">-- (in seconds)</span>
timeout     <span style=\"color: red;\">::</span> Int
<span style=\"color: green;\">-- | Process priority for the 'nice' syscall.</span>
<span style=\"color: green;\">-- -20 is the highest, 20 is the lowest</span>
<span style=\"color: red;\">,</span> niceness    <span style=\"color: red;\">::</span> Int
<span style=\"color: green;\">-- | Resource limits for the 'setrlimit' syscall</span>
<span style=\"color: red;\">,</span> rlimits     <span style=\"color: red;\">::</span> Maybe RLimits
<span style=\"color: green;\">-- | The directory that the evaluator process will be 'chroot'ed</span>
<span style=\"color: green;\">-- into. Please note that if chroot is applied, all the pathes</span>
<span style=\"color: green;\">-- in 'EvalSettings' will be calculated relatively to this</span>
<span style=\"color: green;\">-- value.</span>
<span style=\"color: red;\">,</span> chrootPath  <span style=\"color: red;\">::</span> Maybe FilePath
<span style=\"color: green;\">-- | The UID that will be set after the call to chroot.</span>
<span style=\"color: red;\">,</span> processUid  <span style=\"color: red;\">::</span> Maybe UserID
<span style=\"color: green;\">-- | SELinux security context under which the worker </span>
<span style=\"color: green;\">-- process will be running.</span>
<span style=\"color: red;\">,</span> secontext   <span style=\"color: red;\">::</span> Maybe SecurityContext
<span style=\"color: green;\">-- | A filepath to the 'tasks' file for the desired cgroup.</span>
<span style=\"color: green;\">-- </span>
<span style=\"color: green;\">-- For example, if I have mounted the @cpu@ controller at</span>
<span style=\"color: green;\">-- @/cgroups/cpu/@ and I want the evaluator to be running in the</span>
<span style=\"color: green;\">-- cgroup 'idiaworkers' then the 'cgroupPath' would be</span>
<span style=\"color: green;\">-- @/cgroups/cpu/idiaworkers@</span>
<span style=\"color: red;\">,</span> cgroupPath  <span style=\"color: red;\">::</span> Maybe FilePath
<span style=\"color: red;\">}</span> <span style=\"color: blue; font-weight: bold;\">deriving</span> <span style=\"color: red;\">(</span>Eq<span style=\"color: red;\">,</span> Show<span style=\"color: red;\">,</span> Generic<span style=\"color: red;\">)</span></code></pre>
<p>There is also a <a href=\"http://hackage.haskell.org/packages/archive/data-default/latest/doc/html/Data-Default.html\">Default</a> instance for <code>LimitSettings</code> and <code>RLimits</code> with most of the restrictions turned off:</p>
<pre><code>defaultLimits <span style=\"color: red;\">::</span> LimitSettings
defaultLimits <span style=\"color: red;\">=</span> LimitSettings
<span style=\"color: red;\">{</span> timeout    <span style=\"color: red;\">=</span> <span class=\"hs-num\">3</span>
<span style=\"color: red;\">,</span> niceness   <span style=\"color: red;\">=</span> <span class=\"hs-num\">10</span>
<span style=\"color: red;\">,</span> rlimits    <span style=\"color: red;\">=</span> Nothing
<span style=\"color: red;\">,</span> chrootPath <span style=\"color: red;\">=</span> Nothing
<span style=\"color: red;\">,</span> processUid <span style=\"color: red;\">=</span> Nothing
<span style=\"color: red;\">,</span> secontext  <span style=\"color: red;\">=</span> Nothing
<span style=\"color: red;\">,</span> cgroupPath <span style=\"color: red;\">=</span> Nothing
<span style=\"color: red;\">}</span></code></pre>
<p>Below I’ll briefly describe each limitation/restriction with some details.</p>
<h2 id=\"timeout-niceness\">Timeout & niceness</h2>
<p>The <code>timeout</code> field specifies how much time (in seconds) the server waits for the worker. (<em>Note: this is the only limitation that is controlled on the side of the web server. The corresponding procedure is <code>processTimeout</code>. We really want this to be run in the multithreaded environment</em>)</p>
<p>Niceness is merely the value passed to the <code>nice()</code> syscall, nothing special.</p>
<h2 id=\"rlimits\">rlimits</h2>
<p>The resource limits are controlled by syscalls to <code>setrlimit</code>. The limits itself are defined in the <code>RLimits</code> datatype:</p>
<pre><code><span style=\"color: blue; font-weight: bold;\">data</span> RLimits <span style=\"color: red;\">=</span> RLimits
<span style=\"color: red;\">{</span> coreFileSizeLimit <span style=\"color: red;\">::</span> ResourceLimits
<span style=\"color: red;\">,</span> cpuTimeLimit      <span style=\"color: red;\">::</span> ResourceLimits
<span style=\"color: red;\">,</span> dataSizeLimit     <span style=\"color: red;\">::</span> ResourceLimits
<span style=\"color: red;\">,</span> fileSizeLimit     <span style=\"color: red;\">::</span> ResourceLimits
<span style=\"color: red;\">,</span> openFilesLimit    <span style=\"color: red;\">::</span> ResourceLimits
<span style=\"color: red;\">,</span> stackSizeLimit    <span style=\"color: red;\">::</span> ResourceLimits
<span style=\"color: red;\">,</span> totalMemoryLimit  <span style=\"color: red;\">::</span> ResourceLimits
<span style=\"color: red;\">}</span> <span style=\"color: blue; font-weight: bold;\">deriving</span> <span style=\"color: red;\">(</span>Eq<span style=\"color: red;\">,</span> Show<span style=\"color: red;\">,</span> Generic<span style=\"color: red;\">)</span></code></pre>
<p><code>ResourceLimits</code> itself is defined in <a href=\"http://hackage.haskell.org/packages/archive/unix/latest/doc/html/System-Posix-Resource.html\">System.Posix.Resource</a>. For more information on resource limits see <a href=\"http://linux.die.net/man/3/setrlimit\">setrlimit(3)</a>.</p>
<h2 id=\"chrooted-jail\">Chrooted jail</h2>
<p>In order to restrict the worker process we run it inside the chroot jail. The easiest way to create a fully working jail is to use <code>debootstrap</code>. It’s also necessary to install gcc and GHC libraries inside the jail.</p>
<pre><code>mkdir
sudo debootstrap wheezy /idia/run/workers/worker1
sudo chmod  /idia/run/workers/worker1
cd /idia/run/workers/worker1
sudo mkdir -p ./home/
sudo chown  ./home/
cd ./home/
mkdir .ghc && sudo mount --bind ~/.ghc .ghc
mkdir .cabal && sudo mount --bind ~/.cabal .cabal
mkdir ghc && sudo mount --bind ~/ghc ghc # ghc libs
cd ../..
cp ~/interactive-diagrams/common/Helper.hs .
sudo chroot .
apt-get install gcc # inside the chroot</code></pre>
<p>I tried installing <a href=\"http://emdebian.org/\">Emdebian</a> using <a href=\"http://wiki.debian.org/Multistrap\">multistrap</a> to reduce the size of the jail, but GHC won’t run properly in that environment, complaining about librt.so (which was present in the system), so I decided to stick with debootstrap. If anyone knows how to avoid this problem with multistrap please mail me or leave a comment.</p>
<h3 id=\"useful-links\">Useful links</h3>
<ul>
<li><a href=\"http://wiki.debian.org/chroot\">http://wiki.debian.org/chroot</a></li>
<li><a href=\"http://wiki.debian.org/Debootstrap\">http://wiki.debian.org/Debootstrap</a></li>
</ul>
<h2 id=\"process-uid\">Process uid</h2>
<p>This is the uid the worker process will run under. The socket file will also be created by the user with this uid.</p>
<h2 id=\"selinux\">SELinux</h2>
<p>SELinux (Security-enhanced Linux) is a Linux kernel module providing mechanisms for enforcing fine-grained <a href=\"http://en.wikipedia.org/wiki/Mandatory_access_control\">mandatory access control</a>, brought to you by the creators of infamous PRISM!</p>
<p>SELinux allows the system administrator to control the security of the system by specifying in (modular) policy files the AVC (access vector cache) rules. The SELinux kernel module sits there and monitors all the syscalls and, if it finds something that is not explicitly allowed in the policy, it blocks it. (<em>Well, actually something a <a href=\"http://danwalsh.livejournal.com/43816.html\">little bit different</a> is going on, but for the sake of simplicity I am leaving it out</em>)</p>
<p>Everything on your system – files, network sockets, file handles, processes, directories – is labelled with a SELinux <em>security context</em>, which consists of a role, a user name (not related to the regular system user name) and a domain (also called <em>type</em> in some literature). In the policy file you specific which domains are allowed to perform various actions on other domains. A typical piece of the policy file will look like this:</p>
<pre><code>allow myprocess_t self:udp_socket { create connect };
allow myprocess_t bin_t:file { execute };</code></pre>
<p>The first line states that the process from the domain <code>myprocess_t</code> is allowed to create and connect to the UDP sockets of the same domain. The second line allows a process in that domain to execute files of type <code>bin_t</code> (usually files in <code>/bin/</code> and <code>/usr/bin</code>).</p>
<p>In our <a href=\"https://github.com/co-dan/interactive-diagrams/blob/master/selinux/interactive-diagrams.te\">SELinux policy</a> we have several domains:</p>
<ul>
<li>idia_web_t – the domain under which the <code>scotty-pastebin</code> run</li>
<li>idia_web_exec_t – the domain of the <code>scotty-pastebin</code> executable and other files associated with that binary</li>
<li>idia_service_t – the domain under which the <code>eval-service</code> run</li>
<li>idia_service_exec_t – the domain of the <code>eval-service</code> executable and other files associated with that binary</li>
<li>idia_service_sock_t – UNIX socket files used for communication</li>
<li>idia_db_t, idia_pkg_t, idia_web_common_t – database files, packages, html files, templates and other stuff</li>
<li>idia_worker_env_t – chroot’ed environment in which the worker operates</li>
<li>idia_restricted_t – the most restricted domain in which the workers run and evaluate code</li>
</ul>
<p>The reason we made the service program run in a single-threaded environment is the following: if we run it in the multi-threaded environment (like we wanted) the worker processes want to have access to <a href=\"http://selinuxproject.org/page/ObjectClassesPerms#fd\">file descriptors, inherited</a> from the idia_service_t, which, of course, is dangerous and should not be allowed.</p>
<p>I personally don’t enjoy using SELinux very much. It’s very hard to configure it and among its shortcomings I can list the fact that there is no distinction between file types and process types; there is no proper separation, even when using the modular policy, as the duplicated types are checked when you load the module and there is no way (that I know of) to easily introduce a fresh unused type. And there is this thing that puzzled me for quite a while: home directories are treated specially. Even if you configure a subdirectory in your home dir to have a specific security context, <code>restorecon</code> won’t correctly install the context specified in the policy. You actually have to set he context yourself, using <code>chcon</code>.</p>
<h3 id=\"useful-links-1\">Useful links</h3>
<ul>
<li><a href=\"https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Security-Enhanced_Linux/chap-Security-Enhanced_Linux-SELinux_Contexts.html\">Redhat SELinux docs</a></li>
<li><a href=\"http://wiki.gentoo.org/wiki/SELinux/Tutorials\">Gentoo Wiki SELinux tutorial</a></li>
<li>/usr/share/selinux/default/include/support/ on your system</li>
<li><a href=\"https://wiki.ubuntu.com/AppArmor\">AppArmor</a> – a simpler alternative to SELinux, that deals with file paths rather than with security contexts</li>
</ul>
<h2 id=\"cgroups\">Cgroups</h2>
<p>Cgroups is the system that can be used to aid the way Linux schedules CPU time/shares, distributes memory to the processes. It does so by organizing processes into hierarchical groups with configured behaviour.</p>
<p>Installing cgroups on debian is somewhat tricky, because the package is a little bit weird.</p>
<pre><code>sudo apt-get install cgroup-bin libcgroup1
sudo cgconfigparser -l ~/interactive-diagrams/cgconfig.conf</code></pre>
<p>For our purposes we have a cgroup called <code>idiaworkers</code>. We also mount the cpu controller on <code>/cgroups/cpu</code>:</p>
<pre><code>$> ls -l /cgroups/cpu/
total 0
-rw-r--r--. 1 root root 0 Jul 12 16:22 cgroup.clone_children
--w--w--w-. 1 root root 0 Jul 12 16:22 cgroup.event_control
-rw-r--r--. 1 root root 0 Jul 12 16:22 cgroup.procs
-rw-r--r--. 1 root root 0 Jul 12 16:22 cpu.shares
drwxr-xr-x. 2 root root 0 Jul 12 16:22 idiaworkers
-rw-r--r--. 1 root root 0 Jul 12 16:22 notify_on_release
-rw-r--r--. 1 root root 0 Jul 12 16:22 release_agent
-rw-r--r--. 1 root root 0 Jul 12 16:22 tasks
$> ls -l /cgroups/cpu/idiaworkers
total 0
-rw-r--r--. 1 root    root 0 Jul 12 16:22 cgroup.clone_children
--w--w--w-. 1 root    root 0 Jul 12 16:22 cgroup.event_control
-rw-r--r--. 1 root    root 0 Jul 12 16:22 cgroup.procs
-rw-r--r--. 1 root    root 0 Jul 12 16:22 cpu.shares
-rw-r--r--. 1 root    root 0 Jul 12 16:22 notify_on_release
-rw-r--r--. 1 vagrant root 0 Jul 14 06:21 tasks</code></pre>
<p>In order to modify how much CPU time our group gets, we write to the <code>cpu.shares</code> file: <code>sudo echo 100 > /cgroups/cpu/idiaworkers/cpu.shares</code>. If we want to add the task/process to the group we simply append the <code>tasks</code> file: <code>echo $PID >> /cgroups/cpu/idiaworkers/tasks</code>. The workers append themselves to the task file automatically (if the cgroup restrictions are enabled in the <code>LimitSettings</code>).</p>
<h2 id=\"useful-links-2\">Useful links</h2>
<ul>
<li><a href=\"https://www.kernel.org/doc/Documentation/cgroups/cgroups.txt\">kernel.org docs</a></li>
<li><a href=\"http://en.wikipedia.org/wiki/Cgroups\">Wikipedia</a></li>
</ul>
<h1 id=\"open-problemsrequests\">Open problems/requests</h1>
<p>I am still not sure how do I write tests for this project. Do I write tests for my GHC API wrappers? Do I write tests for my workers pool? I probably should take a look how similar projects handles those.</p>
<h1 id=\"outro\">Outro</h1>
<p>So, as you can see, we have something working here and now that we manage to take the initial steps it will be much easier for us to push changes and make them available for public to use and comment on. There is still a long way to come. The code needs some serious cleanup (we’ve switched the design model a couple of weeks ago, which affected the internal structure seriously), the documentation needs to be written. And of course new features are waiting to be implemented :) We will be supporting multiple UIDs for workers and looking into using LXC for simplifying the setup process too.</p>
<p>I would like to thank augur and luite for their editorial feedback.</p>
<p>Stay tuned for the next posts about configuring the program for evaluation settings and reusing the components from the library.</p>
<br /> Tagged: <a href=\"http://parenz.wordpress.com/tag/diagrams/\">diagrams</a>, <a href=\"http://parenz.wordpress.com/tag/haskell-2/\">haskell</a>, <a href=\"http://parenz.wordpress.com/tag/interactive-diagrams/\">interactive-diagrams</a>, <a href=\"http://parenz.wordpress.com/tag/soc/\">soc</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/parenz.wordpress.com/80/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/parenz.wordpress.com/80/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=parenz.wordpress.com&blog=26722965&post=80&subd=parenz&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "8f824bbdd1171ffef642ee311f40b643") (265 (20963 63997 651737) "http://www.well-typed.com/blog/79" "Well-Typed.Com: Video and slides on (Alternatives to) Lazy I/O" nil "Thu, 11 Jul 2013 17:30:22 +0000" "<p>Edsko is in London this week running our <a href=\"http://www.well-typed.com/services_training\">regular Haskell training courses</a>.
Last night he gave a talk, as part of the Skills Matter \"In The Brain\" series,
on the subject of lazy I/O in Haskell and the various old and new alternatives.</p><blockquote><h4> (Alternatives to) Lazy I/O</h4><p><em>by Edsko de Vries</em></p><ul><li><a href=\"http://skillsmatter.com/podcast/home/lazy-io-and-alternatives-in-haskell/jd-7959\">Video</a></li><li><a href=\"http://www.well-typed.com/blog/aux/files/alternatives-to-lazy-io.pdf\">Slides</a></li><li><a href=\"http://www.well-typed.com/blog/aux/files/alternatives-to-lazy-io.tar.gz\">Code</a></li></ul></blockquote><p>If you are lucky enough to be in or near London, there is now quite a range of
free evening Haskell events to keep an eye out for:</p><ul><li>The <a href=\"http://skillsmatter.com/\">Skills Matter \"In The Brain\" talks</a>. These
are free evening events and there are talks on Haskell or functional
programming fairly regularly. They're generally at the introductory or
intermediate level.</li><li>The <a href=\"http://www.meetup.com/London-Haskell/\">London Haskell User Group</a> is
alive and running talks again. These are now quite well attended.</li><li>The <a href=\"http://www.meetup.com/hoodlums/\">Haskell Hoodlums</a> group does monthly
\"coding dojo\" events where beginners and experts work together on a shared
problem.</li></ul><p>These are all fun, friendly events to learn a bit more and meet up with fellow
Haskellers and get involved with the community.
</p>" nil nil "60d8016266872108be2ef40758d85fb9") (264 (20963 45898 588488) "http://winterkoninkje.dreamwidth.org/84971.html" "wren ng thornton: In search of algebraic theories" nil "Mon, 15 Jul 2013 03:28:20 +0000" "<p>An important notion that shows up in algebra is the idea of a free object. For example, we have the following free objects for their corresponding algebraic theories:</p>
<ul>
<li><code>NonemptyList A</code> — free semigroups</li>
<li><code>List A</code> — free monoids</li>
<li><code>NonemptyBag A</code> — free commutative semigroups</li>
<li><code>Bag A</code> [1] — free commutative monoids</li>
<li><code>NonemptySet A</code> — free commutative bands (band = idempotent semigroup)</li>
<li><code>Set A</code> — free commutative bands with identity</li>
</ul>
<p>Recently I've been coming across things whose quotient structure looks like:</p>
<blockquote><code><pre>Foo A B = List (NonemptyMap A (NonemptyList B))
Bar A B = (Foo A B, NonemptyList (A,B))</pre></code></blockquote>
<p>I'm curious if anyone has encountered either of these as free objects of some algebraic theory?</p>
<p>[1] I.e., a multiset. In order to get the proper quotienting structure, we can implement <code>Bag A</code> by <code>Map A Nat</code> where <code>a `elem` xs = member a xs</code> and <code>multiplicity a xs = maybe 0 (1+) (lookup a xs)</code>.</p><br /><br /><img src=\"http://www.dreamwidth.org/tools/commentcount?user=winterkoninkje&ditemid=84971\" alt=\"comment count unavailable\" height=\"12\" style=\"vertical-align: middle;\" width=\"30\" /> comments" nil nil "32df0cd3442b24720d1de33f7f0a5966") (263 (20963 45898 587638) "http://alessandrovermeulen.me/2013/07/13/the-difference-between-shallow-and-deep-embedding/" "Alessandro Vermeulen: The difference between shallow and deep embedding" nil "Sat, 13 Jul 2013 21:06:00 +0000" "<p>Deep and shallow embedding are terms associated with Domain Specific Languages
(DSL). A DSL is  a language geared toward a specific domain. The <a href=\"http://www.graphviz.org/content/dot-language\" target=\"_blank\">dot language</a> is
an example of such a DSL for describing Graphs. Conceptually, a shallow
embedding captures the semantics of the data of the domain in a data type and
provides a <em>fixed</em> interpretation of the data, whereas a deep embedding goes
beyond this and captures the semantics of the operations on the domain enabling
<em>variable</em> interpretations.</p>
<p>We will illustrate this difference by embedding a simple expression language
with summation, multiplication and constants in
<a href=\"http://www.haskell.org\">Haskell</a>. Haskell is especially well-suited for and
often used as a host language for embedded DSLs.</p>
<p>We express our language with the following interface. A type synonym <code>Exp</code> for
normal <code>Int</code>s and three separate functions representing summation,
multiplication, and constants.</p>
<div class=\"bogus-wrapper\"><notextile><figure class=\"code\"><figcaption><span></span></figcaption><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
<span class=\"line-number\">2</span>
<span class=\"line-number\">3</span>
<span class=\"line-number\">4</span>
<span class=\"line-number\">5</span>
</pre></td><td class=\"code\"><pre><code class=\"haskell\"><span class=\"line\"><span class=\"kr\">type</span> <span class=\"kt\">Exp</span> <span class=\"ow\">=</span> <span class=\"kt\">Int</span>
</span><span class=\"line\">
</span><span class=\"line\"><span class=\"nf\">plus</span>  <span class=\"ow\">::</span> <span class=\"kt\">Exp</span> <span class=\"ow\">-></span> <span class=\"kt\">Exp</span> <span class=\"ow\">-></span> <span class=\"kt\">Exp</span>
</span><span class=\"line\"><span class=\"nf\">times</span> <span class=\"ow\">::</span> <span class=\"kt\">Exp</span> <span class=\"ow\">-></span> <span class=\"kt\">Exp</span> <span class=\"ow\">-></span> <span class=\"kt\">Exp</span>
</span><span class=\"line\"><span class=\"nf\">const</span> <span class=\"ow\">::</span> <span class=\"kt\">Int</span>        <span class=\"ow\">-></span> <span class=\"kt\">Exp</span>
</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>We embedded the <em>data</em> of the domain in Haskell and provided functions for
construction of the  model and we can easily represent the calculation of an
expression as $4 + 6 * 8$ with the following lines of Haskell:</p>
<div class=\"bogus-wrapper\"><notextile><figure class=\"code\"><figcaption><span></span></figcaption><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
</pre></td><td class=\"code\"><pre><code class=\"haskell\"><span class=\"line\"><span class=\"nf\">val</span> <span class=\"ow\">=</span> <span class=\"n\">const</span> <span class=\"mi\">4</span> <span class=\"p\">`</span><span class=\"n\">plus</span><span class=\"p\">`</span> <span class=\"p\">(</span><span class=\"n\">const</span> <span class=\"mi\">6</span> <span class=\"p\">`</span><span class=\"n\">times</span><span class=\"p\">`</span> <span class=\"n\">const</span> <span class=\"mi\">8</span><span class=\"p\">)</span>
</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>The advantage of this embedding that calculating the value of our expression
is very fast. Other than the value we cannot determine anything else regarding
our expression. This becomes more problematic when we add variables to our
language.</p>
<p>We change our type to contain binding information and add two functions to
represent the assignment and usage of variables.</p>
<div class=\"bogus-wrapper\"><notextile><figure class=\"code\"><figcaption><span></span></figcaption><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
<span class=\"line-number\">2</span>
<span class=\"line-number\">3</span>
<span class=\"line-number\">4</span>
</pre></td><td class=\"code\"><pre><code class=\"haskell\"><span class=\"line\"><span class=\"kr\">type</span> <span class=\"kt\">Exp</span> <span class=\"ow\">=</span> <span class=\"p\">([</span><span class=\"kt\">String</span> <span class=\"err\">⊨</span> <span class=\"kt\">Int</span><span class=\"p\">],</span> <span class=\"kt\">Int</span><span class=\"p\">)</span>
</span><span class=\"line\">
</span><span class=\"line\"><span class=\"nf\">assign</span> <span class=\"ow\">::</span> <span class=\"kt\">String</span> <span class=\"ow\">-></span> <span class=\"kt\">Int</span> <span class=\"ow\">-></span> <span class=\"kt\">Exp</span>
</span><span class=\"line\"><span class=\"nf\">var</span>    <span class=\"ow\">::</span> <span class=\"kt\">String</span>        <span class=\"ow\">-></span> <span class=\"kt\">Exp</span>
</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>And in our naivity we can write the expression $x + 6 * 8$ as follows:</p>
<div class=\"bogus-wrapper\"><notextile><figure class=\"code\"><figcaption><span></span></figcaption><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
</pre></td><td class=\"code\"><pre><code class=\"haskell\"><span class=\"line\"><span class=\"nf\">val</span> <span class=\"ow\">=</span> <span class=\"n\">var</span> <span class=\"s\">\"x\"</span> <span class=\"p\">`</span><span class=\"n\">plus</span><span class=\"p\">`</span> <span class=\"p\">(</span><span class=\"n\">const</span> <span class=\"mi\">6</span> <span class=\"p\">`</span><span class=\"n\">times</span><span class=\"p\">`</span> <span class=\"n\">const</span> <span class=\"mi\">8</span><span class=\"p\">)</span>
</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>Obviously, evaluating this creates havoc! What is the value of <code>x</code>? We should,
of course, have introduced it first:</p>
<div class=\"bogus-wrapper\"><notextile><figure class=\"code\"><figcaption><span></span></figcaption><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
</pre></td><td class=\"code\"><pre><code class=\"haskell\"><span class=\"line\"><span class=\"nf\">val</span> <span class=\"ow\">=</span> <span class=\"kr\">let</span> <span class=\"s\">\"x\"</span> <span class=\"mi\">4</span> <span class=\"p\">(</span><span class=\"n\">var</span> <span class=\"s\">\"x\"</span> <span class=\"p\">`</span><span class=\"n\">plus</span><span class=\"p\">`</span> <span class=\"p\">(</span><span class=\"n\">const</span> <span class=\"mi\">6</span> <span class=\"p\">`</span><span class=\"n\">times</span><span class=\"p\">`</span> <span class=\"n\">const</span> <span class=\"mi\">8</span><span class=\"p\">))</span>
</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>Now we have assigned a value to <code>x</code> and we can safely use it in our
expression.</p>
<p>Had we used a deep embedding we could have prevented the cataclysmic error by
first checking whether each variable is assigned before it is used. We create
a deep embedding of our expression by using a Haskell data type.</p>
<div class=\"bogus-wrapper\"><notextile><figure class=\"code\"><figcaption><span></span></figcaption><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
<span class=\"line-number\">2</span>
<span class=\"line-number\">3</span>
<span class=\"line-number\">4</span>
<span class=\"line-number\">5</span>
<span class=\"line-number\">6</span>
</pre></td><td class=\"code\"><pre><code class=\"haskell\"><span class=\"line\"><span class=\"kr\">data</span> <span class=\"kt\">Exp</span> <span class=\"kr\">where</span>
</span><span class=\"line\">  <span class=\"kt\">Plus</span>   <span class=\"ow\">::</span> <span class=\"kt\">Exp</span> <span class=\"ow\">-></span> <span class=\"kt\">Exp</span>    <span class=\"ow\">-></span> <span class=\"kt\">Exp</span> <span class=\"c1\">-- plus</span>
</span><span class=\"line\">  <span class=\"kt\">Times</span>  <span class=\"ow\">::</span> <span class=\"kt\">Exp</span> <span class=\"ow\">-></span> <span class=\"kt\">Exp</span>    <span class=\"ow\">-></span> <span class=\"kt\">Exp</span> <span class=\"c1\">-- times</span>
</span><span class=\"line\">  <span class=\"kt\">Const</span>  <span class=\"ow\">::</span> <span class=\"kt\">Int</span>           <span class=\"ow\">-></span> <span class=\"kt\">Exp</span> <span class=\"c1\">-- const</span>
</span><span class=\"line\">  <span class=\"kt\">Assign</span> <span class=\"ow\">::</span> <span class=\"kt\">String</span> <span class=\"ow\">-></span> <span class=\"kt\">Int</span> <span class=\"ow\">-></span> <span class=\"kt\">Exp</span> <span class=\"c1\">-- assign</span>
</span><span class=\"line\">  <span class=\"kt\">Var</span>    <span class=\"ow\">::</span> <span class=\"kt\">String</span>        <span class=\"ow\">-></span> <span class=\"kt\">Exp</span> <span class=\"c1\">-- var</span>
</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>Note that we do not specify <em>how</em> the bindings should be stored, only that
such a thing exists. We now define a function that checks whether we use a
variable before it is defined.<sup id=\"fnref:folds\"><a href=\"http://alessandrovermeulen.me/atom.xml#fn:folds\" class=\"footnote\">1</a></sup></p>
<div class=\"bogus-wrapper\"><notextile><figure class=\"code\"><figcaption><span></span></figcaption><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
<span class=\"line-number\">2</span>
<span class=\"line-number\">3</span>
<span class=\"line-number\">4</span>
<span class=\"line-number\">5</span>
<span class=\"line-number\">6</span>
<span class=\"line-number\">7</span>
<span class=\"line-number\">8</span>
<span class=\"line-number\">9</span>
</pre></td><td class=\"code\"><pre><code class=\"haskell\"><span class=\"line\"><span class=\"nf\">useBeforeDefine</span> <span class=\"ow\">::</span> <span class=\"kt\">Exp</span> <span class=\"ow\">-></span> <span class=\"kt\">Bool</span>
</span><span class=\"line\"><span class=\"nf\">useBeforeDefine</span> <span class=\"n\">e</span> <span class=\"ow\">=</span> <span class=\"n\">f</span> <span class=\"kt\">[]</span>
</span><span class=\"line\">  <span class=\"kr\">where</span>
</span><span class=\"line\">  <span class=\"n\">f</span> <span class=\"ow\">::</span> <span class=\"p\">[</span><span class=\"kt\">String</span><span class=\"p\">]</span> <span class=\"ow\">-></span> <span class=\"kt\">Exp</span> <span class=\"ow\">-></span> <span class=\"kt\">Bool</span>
</span><span class=\"line\">  <span class=\"n\">f</span> <span class=\"p\">(</span><span class=\"kt\">Plus</span>  <span class=\"n\">l</span> <span class=\"n\">r</span><span class=\"p\">)</span> <span class=\"n\">env</span>      <span class=\"ow\">=</span> <span class=\"n\">useBeforeDefine</span> <span class=\"n\">l</span> <span class=\"n\">env</span> <span class=\"o\">||</span> <span class=\"n\">useBeforeDefine</span> <span class=\"n\">r</span> <span class=\"n\">env</span>
</span><span class=\"line\">  <span class=\"n\">f</span> <span class=\"p\">(</span><span class=\"kt\">Times</span> <span class=\"n\">l</span> <span class=\"n\">r</span><span class=\"p\">)</span> <span class=\"n\">env</span>      <span class=\"ow\">=</span> <span class=\"n\">useBeforeDefine</span> <span class=\"n\">l</span> <span class=\"n\">env</span> <span class=\"o\">||</span> <span class=\"n\">useBeforeDefine</span> <span class=\"n\">r</span> <span class=\"n\">env</span>
</span><span class=\"line\">  <span class=\"n\">f</span> <span class=\"p\">(</span><span class=\"kt\">Const</span> <span class=\"kr\">_</span><span class=\"p\">)</span>   <span class=\"kr\">_</span>        <span class=\"ow\">=</span> <span class=\"kt\">False</span>
</span><span class=\"line\">  <span class=\"n\">f</span> <span class=\"p\">(</span><span class=\"kt\">Assign</span> <span class=\"n\">var</span> <span class=\"kr\">_</span> <span class=\"n\">e</span><span class=\"p\">)</span> <span class=\"n\">env</span> <span class=\"ow\">=</span> <span class=\"n\">useBeforeDefine</span> <span class=\"n\">e</span> <span class=\"p\">(</span><span class=\"n\">var</span> <span class=\"kt\">:</span> <span class=\"n\">env</span><span class=\"p\">)</span>
</span><span class=\"line\">  <span class=\"n\">f</span> <span class=\"p\">(</span><span class=\"kt\">Var</span> <span class=\"n\">var</span><span class=\"p\">)</span>        <span class=\"n\">env</span> <span class=\"ow\">=</span> <span class=\"n\">not</span> <span class=\"p\">(</span><span class=\"n\">var</span> <span class=\"p\">`</span><span class=\"n\">elem</span><span class=\"p\">`</span> <span class=\"n\">env</span><span class=\"p\">)</span>
</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>With the function above we can <em>check</em> whether an expression is well-formed.
With our deep embedding we can even define transformations of our expression;
e.g. differentiate with respect to a variable.</p>
<div class=\"bogus-wrapper\"><notextile><figure class=\"code\"><figcaption><span></span></figcaption><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
<span class=\"line-number\">2</span>
<span class=\"line-number\">3</span>
<span class=\"line-number\">4</span>
<span class=\"line-number\">5</span>
<span class=\"line-number\">6</span>
<span class=\"line-number\">7</span>
</pre></td><td class=\"code\"><pre><code class=\"haskell\"><span class=\"line\"><span class=\"nf\">diff</span> <span class=\"ow\">::</span> <span class=\"kt\">Exp</span> <span class=\"ow\">-></span> <span class=\"kt\">String</span> <span class=\"ow\">-></span> <span class=\"kt\">Exp</span>
</span><span class=\"line\"><span class=\"nf\">diff</span> <span class=\"p\">(</span><span class=\"kt\">Plus</span>  <span class=\"n\">l</span> <span class=\"n\">r</span><span class=\"p\">)</span> <span class=\"n\">dx</span>      <span class=\"ow\">=</span> <span class=\"n\">diff</span> <span class=\"n\">l</span> <span class=\"n\">dx</span> <span class=\"p\">`</span><span class=\"kt\">Plus</span><span class=\"p\">`</span> <span class=\"n\">diff</span> <span class=\"n\">r</span> <span class=\"n\">dx</span>
</span><span class=\"line\"><span class=\"nf\">diff</span> <span class=\"p\">(</span><span class=\"kt\">Times</span> <span class=\"n\">l</span> <span class=\"n\">r</span><span class=\"p\">)</span> <span class=\"n\">dx</span>      <span class=\"ow\">=</span> <span class=\"p\">(</span><span class=\"n\">diff</span> <span class=\"n\">l</span> <span class=\"n\">dx</span> <span class=\"p\">`</span><span class=\"kt\">Times</span><span class=\"p\">`</span> <span class=\"n\">r</span><span class=\"p\">)</span> <span class=\"p\">`</span><span class=\"kt\">Plus</span><span class=\"p\">`</span> <span class=\"p\">(</span><span class=\"n\">l</span> <span class=\"p\">`</span><span class=\"kt\">Times</span><span class=\"p\">`</span> <span class=\"n\">diff</span> <span class=\"n\">r</span> <span class=\"n\">dx</span><span class=\"p\">)</span>
</span><span class=\"line\"><span class=\"nf\">diff</span> <span class=\"p\">(</span><span class=\"kt\">Const</span> <span class=\"kr\">_</span><span class=\"p\">)</span>   <span class=\"kr\">_</span>       <span class=\"ow\">=</span> <span class=\"kt\">Const</span> <span class=\"mi\">0</span>
</span><span class=\"line\"><span class=\"nf\">diff</span> <span class=\"p\">(</span><span class=\"kt\">Assign</span> <span class=\"n\">var</span> <span class=\"n\">x</span> <span class=\"n\">e</span><span class=\"p\">)</span> <span class=\"n\">dx</span> <span class=\"ow\">=</span> <span class=\"kt\">Assign</span> <span class=\"n\">var</span> <span class=\"n\">x</span> <span class=\"p\">(</span><span class=\"n\">diff</span> <span class=\"n\">e</span> <span class=\"n\">dx</span><span class=\"p\">)</span>
</span><span class=\"line\"><span class=\"nf\">diff</span> <span class=\"p\">(</span><span class=\"kt\">Var</span> <span class=\"n\">var</span><span class=\"p\">)</span>        <span class=\"n\">dx</span> <span class=\"o\">|</span> <span class=\"n\">var</span> <span class=\"o\">==</span> <span class=\"n\">dx</span> <span class=\"ow\">=</span> <span class=\"kt\">Const</span> <span class=\"mi\">1</span>
</span><span class=\"line\">                         <span class=\"o\">|</span> <span class=\"n\">otherwise</span> <span class=\"ow\">=</span> <span class=\"kt\">Const</span> <span class=\"mi\">0</span>
</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>Deep embedding allows us to utilize the semantics of our model by defining
multiple interpretations of our DSL. The downside is that just calculating the
value of our expression has become slower due to the added overhead of the
constructors, whereas the shallow embedding can be evaluated by only using
<code>Int</code>s.</p>
<p>In short:</p>
<ul>
<li><strong>Shallow embedding</strong> should be used when you only need a single interpretation or
when you are in a hurry.</li>
<li><strong>Deep embedding</strong> should be used in all other cases.</li>
</ul>
<p>More reading material on this subject:</p>
<ul>
<li>This <a href=\"http://www.cse.chalmers.se/~josefs/DSLTutorial/tutorialSlides.html\">presentation</a> by Josef Svenningsson.</li>
<li><a href=\"http://www.cse.chalmers.se/~josefs/publications/TFP12.pdf\">Combining Deep and Shallow Embedding for EDSL</a> (Josef Svenningsson and Emil Axelsson, 2012)</li>
<li><a href=\"https://www4.in.tum.de/~nipkow/pubs/tphols04.html\">Certifying Machine Code Safety: Shallow versus Deep Embedding</a> (Martin Wildmoser and Tobias Nipkow, 2004)</li>
<li><a href=\"http://cstheory.stackexchange.com/questions/1370/shallow-versus-deep-embeddings\">Deep versus Shallow embeddings in Coq</a></li>
</ul>
<div class=\"footnotes\">
<ol>
<li id=\"fn:folds\">
<p>Most often you should use <a href=\"http://alessandrovermeulen.me/2009/12/17/haskell-datatypes-and-folds/\">folds</a> (<a href=\"http://alessandrovermeulen.me/2010/01/03/haskell-datatypes-and-folds-part-ii/\">2</a>) instead of this direct recursion. <a href=\"http://alessandrovermeulen.me/atom.xml#fnref:folds\" class=\"reversefootnote\">↩</a></p>
</li>
</ol>
</div>" nil nil "8f2b1ca4cca393d8d16bcc9eaa782364") (262 (20963 45898 585333) "http://winterkoninkje.dreamwidth.org/81209.html" "wren ng thornton: Finite sets" nil "Sat, 13 Jul 2013 20:43:01 +0000" "<p>So, I just encountered a <a href=\"http://hackage.haskell.org/packages/archive/countable/0.1/doc/html/Data-Searchable.html#v:assemble\">most delicious type</a> the other day:</p><p>
</p><blockquote><code><pre>class Finite a where
assemble :: Applicative f => (a -> f b) -> f (a -> b)</pre></code></blockquote>
<p>What's so nice about it is that the only way you can implement it is if the type <code>a</code> is in fact finite. (But see the notes.) So the questions are:</p>
<ul>
<li>Can you see why?</li>
<li>Can you figure out how to implement it for some chosen finite type?</li>
<li>Can you figure out how to implement it in general, given a list of all the values? (you may assume <code>Eq a</code> for this one)</li>
<li>Can you figure out how to get a list of all the values, given some arbitrary implementation of <code>assemble</code>?</li>
</ul>
<span class=\"cuttag_container\"><span style=\"display: none;\" id=\"span-cuttag___1\" class=\"cuttag\"></span><b>( <a href=\"http://winterkoninkje.dreamwidth.org/81209.html#cutid1\">A trivial note</a> )</b><div style=\"display: none;\" id=\"div-cuttag___1\"></div></span>
<span class=\"cuttag_container\"><span style=\"display: none;\" id=\"span-cuttag___2\" class=\"cuttag\"></span><b>( <a href=\"http://winterkoninkje.dreamwidth.org/81209.html#cutid2\">A big note, also a hint perhaps</a> )</b><div style=\"display: none;\" id=\"div-cuttag___2\"></div></span><br /><br /><img src=\"http://www.dreamwidth.org/tools/commentcount?user=winterkoninkje&ditemid=81209\" alt=\"comment count unavailable\" height=\"12\" style=\"vertical-align: middle;\" width=\"30\" /> comments" nil nil "503970362eca949f19d504b78403ec6f") (261 (20963 45898 584997) "http://joyful.com/blog/2013-06-18-darcsden-cleanup.html" "Simon Michael: darcsden cleanup" nil "Sat, 13 Jul 2013 00:31:00 +0000" "<div style=\"font-style: italic;\">June 19, 2013</div>
<h2>darcsden cleanup</h2>
<p>
</p><p>Back to the dev diary. <a href=\"http://joyful.com/2013-06-08-zwiki-styling.html\">Last post</a> was 11 days ago, after a two-week opening streak of daily posts. I got blocked on one, then got busy. Press on.</p>
<p>Yesterday I started looking at BSRK Aditya’s <a href=\"http://bsrkaditya.blogspot.com/2013/06/gsoc-2013-enhancing-darcsden-preweek-1.html\">GSOC darcsden enhancements</a>, to review and hopefully deploy on <a href=\"http://hub.darcs.net\">darcs hub</a>. So far he has worked on alternate login methods (github/google), password reminder, and darcs pack support (for faster gets).</p>
<p>This is forcing some darcsden cleanup, my first darcsden work in a while aside from routine ops and support tasks. I’m going to release what’s in trunk as 1.1, and then start assimilating the new work by BSRK, Ganesh Sittampalam and anyone else who feels like chipping in. Started putting together release notes and a hub status update.</p>
<p>The support requests seem to be on the rise - more usage ? I also found a good bug today: viewing a certain 1K troff file causes darcs hub’s memory footprint to <a href=\"http://hub.darcs.net/simon/darcsden/issue/58\">blow up to 1.5G</a> :)</p>
<p>It would be great to have more functionality (like highlighting) broken out into separate, expendable worker processes, erlang style.</p>
<p>
<br />
<em><a href=\"http://joyful.com/tags/darcs.html\">darcs</a>, <a href=\"http://joyful.com/tags/haskell.html\">haskell</a></em></p>" nil nil "13966d1a69c707e04a9fcda8a5e8872f") (260 (20963 45898 584658) "http://joyful.com/blog/2013-06-08-zwiki-styling.html" "Simon Michael: Zwiki styling" nil "Sat, 13 Jul 2013 00:30:00 +0000" "<div style=\"font-style: italic;\">June  8, 2013</div>
<h2>Zwiki styling</h2>
<p>
</p><p><a href=\"http://joyful.com/2013-06-07-git-hooks-for-site-updates.html\">Yesterday</a>.</p>
<p>Next backlog item: <a href=\"https://trello.com/card/5127f6bb0698a36663002981/16\">style the wiki more like hledger.org</a>.</p>
<p>The wiki software is my own <a href=\"http://zwiki.org\">Zwiki</a> engine. I haven’t skinned a zwiki for a few years, but with the docs (<a href=\"http://zwiki.org/CustomizingAppearance\">CustomizingAppearance</a>, <a href=\"http://zwiki.org/QuickReference#skin-templates\">QuickReference -> skin templates</a>, <a href=\"http://zwiki.org/zwikidir/skins/zwiki\">standard templates</a>) plus experience, it went pretty smoothly.</p>
<p>Zwiki config changes at this point:</p>
<ul>
<li>pasted the standard maintemplate.pt into a Page Template with the same name in the wiki folder, with the hledger.org stylesheet and nav buttons added (in the head and body respectively)</li>
<li>added a style override to give the <code>#content</code> div a zero margin</li>
<li>renamed FrontPage to “hledger wiki”, and configured the new name in a <code>default_page</code> property on the wiki folder</li>
<li>disabled the icon in the zwiki page header by adding a <code>site_logo</code> folder property containing an empty html comment</li>
<li>committed a bugfix for a broken image border that was appearing in the rating form</li>
</ul>
<p>What didn’t work: rewording Zwiki’s “home” navigation link. My custom <code>links.pt</code> page template should do the trick, but it’s being ignored. This is unsatisfying, I suppose I will dig in and debug it, after a suitable cooling-off-and-reflection period.</p>
<p>Zope is still very impressive, and pleasing to use.</p>
<p>Here’s the <a href=\"http://hledger.org/wiki\">wiki</a>, now looking like part of hledger.org.</p>
<p>
<br />
<em><a href=\"http://joyful.com/tags/zwiki.html\">zwiki</a>, <a href=\"http://joyful.com/tags/hledger.html\">hledger</a></em></p>" nil nil "9952988207530acd18068c8154906d2f") (259 (20963 45898 584304) "http://feedproxy.google.com/~r/CartesianClosedComic/~3/Pc8C-6IJguk/20.html" "Cartesian Closed Comic: Weird language" nil "Sat, 13 Jul 2013 00:00:00 +0000" "<a href=\"http://ro-che.info/ccc/20.html\"><img src=\"http://ro-che.info/ccc/thumbs/language.png\" /></a><br />
<img src=\"http://feeds.feedburner.com/~r/CartesianClosedComic/~4/Pc8C-6IJguk\" height=\"1\" width=\"1\" />" nil nil "d88dd808cb713b499aaa46c1c805b8ab") (258 (20963 45898 583915) "http://praisecurseandrecurse.blogspot.com/2013/07/the-polar-game-in-haskell-day-5-34-more.html" "Paul Potts: The Polar Game in Haskell, Day 5 3/4: a Bug Fix and liftM" "noreply@blogger.com (Paul Potts)" "Fri, 12 Jul 2013 22:17:00 +0000" "<p>Jeff Licquia has been playing further with the code and so have I. He discovered a bug in the version I posted in yesterday's installment (my bad). In slide' I neglected to call slide' in the recursive version of slide' but called the existing non-monadic slide. In other words, I had:</p> <pre>slide' ( t : Empty : ts ) = noscore ( Empty : ( slide ( t : ts ) ) )</pre> <p>The problem here is that we'll add nothing to the accumulated score, and proceed into a chain of function invocations that handle ordinary lists. So the score increase that should happen at that point never happens:</p> <pre>*Main> runWriter $ collide' [Heart, House]<br />([Empty,House],Sum {getSum = 1})<br />*Main> runWriter $ collide' [Heart, Empty, House]<br />([Empty,Empty,House],Sum {getSum = 0})</pre> <p>Oops. Yeah, that's a bug. Note that the compiler can't catch this because it's doing what I've asked; there are not actually any type conflicts. The monadic slide' returns the type it is supposed to return, but in building up the \"payload, the <b>[ Tile ]</b> part of <b>ScoreTracker [ Tile ]</b>, the code fails to continue to build up the state. Let this be a lesson to me -- leaving around the previous version of a function, when I'm testing a new one can be hazardous!</p> <p>So, we can just fix that by calling slide', right?</p> <pre>slide' ( t : Empty : ts ) = noscore ( Empty : ( slide' ( t : ts ) ) )</pre> <p>Um, not so much:</p> <pre>arctic-slide.hs:52:49:<br />    Couldn't match expected type `[Tile]'<br />                with actual type `ScoreTracker [Tile]'<br />    In the return type of a call of slide'<br />    In the second argument of `(:)', namely `(slide' (t : ts))'<br />    In the first argument of `noscore', namely<br />      `(Empty : (slide' (t : ts)))'</pre> <p>Oh... yeah. There's that. We want to continue building up the monadic version of the list, but the <b>(:)</b> just takes a regular list. Now it's all complicated! But really there's a simple solution. I'll quote Jeff for a while, since he explained it so well to me. I have not quoted his code <i>exactly</i>, but the ideas are the same:</p> <blockquote>...the straightforward fix fails, because <b>slide'</b> returns a <b>ScoreTracker</b>, not a <b>[ Tile ]</b>.  So the fix is a little more complicated. Since <b>slide'</b> returns pretty much exactly what we need, we can start with just that:</blockquote> <pre>slide' ( t : Empty : ts ) = slide' ( t : ts )</pre> <blockquote>That's not quite right; we just dropped a tile. To get it back, remember that everything is a function, including the : operator [and so it is easily composed with other functions -- PRP]. That means we can create a function that prepends an Empty element to a list...</blockquote> <pre>prefix_empty :: [ Tile ] -> [ Tile ] <br />prefix_empty ts = Empty : ts</pre> <blockquote>So why would we do this? Because we need to take ScoreTracker into account. Here Haskell provides a function called \"liftM\", which takes a normal function and \"lifts\" it into a monad. So:</blockquote> <pre>prefix_empty_st :: ScoreTracker [ Tile ] -> ScoreTracker [ Tile ]<br />prefix_empty_st = liftM prefix_empty</pre> <blockquote>will give us a function with the type <b>ScoreTracker [ Tile ] -> ScoreTracker [ Tile ]</b>, which is what we want. (Technically, that's not true; it gives us <b>Monad m => m [ Tile ] -> m [ Tile ]</b>.  But that's just a generic version of what we want, which works with <b>ScoreTracker</b>, <b>Maybe</b>, or lots of other monads).</blockquote> <p>So now we have this:</p> <pre>slide' ( t : Empty : ts ) = prefix_empty_st $ slide' ( t : ts )</pre> <p>Which doesn't use <b>score</b> or <b>noscore</b> -- it just builds up the list, still in a monadic context, preserving whatever score changes might be applied by the function invocations it makes. And actually since we're not going to use the prefix functions elsewhere, they don't really earn their keep, and we can just write:</p> <pre>slide' ( t : Empty : ts ) = liftM ( Empty : ) $ slide' ( t : ts )</pre> <p>Note the partial application of <b>(:)</b> by binding it to only one parameter before we pass it to <b>liftM</b> -- we're creating a new version of <b>(:)</b> that only takes one argument instead of two.</p> <p>Jeff went on to identify a second bug, basically caused by the same problem in a collide' function also calling slide instead of slide'. A quick fix is to make that collide' function look like the slide' function we just fixed. But then, why not define one in terms of the other?</p> <pre>collide' ( t : Empty : ts ) | movable t = slide' ( t : Empty : ts )</pre> <p>Let's go back a bit and reconsider -- when I was using a special value for Edge, the logic for slide and collide was considerably simpler (although it did not work right). Here it is today:</p> <pre>slide' :: [ Tile ] -> ScoreTracker [ Tile ]<br />slide' ( Ice_Block : ts ) | ( null ts ) || ( blocking $ head ts ) =<br />    noscore ( Ice_Block : ts )<br />slide' ( t : Empty : ts ) = liftM ( Empty : ) $ slide' ( t : ts )<br />slide' ( t : ts ) | ( null ts ) || ( blocking $ head ts ) =<br />    collide' ( t : ts )<br /><br />collide' :: [ Tile ] -> ScoreTracker [ Tile ]<br />collide' [] = noscore []<br />collide' ( t : ts ) | fixed t = noscore ( t : ts )<br />collide' ( Bomb : Mountain : ts) = noscore ( [ Empty, Empty ] ++ ts )<br />collide' ( Heart : House : ts ) = score ( [ Empty, House ] ++ ts )<br />collide' ( Ice_Block : ts ) | ( null ts ) || ( blocking $ head ts ) =<br />    noscore ( Empty : ts )<br />collide' ( t : ts ) | ( movable t ) && ( ( null ts ) ||<br />    ( blocking $ head ts ) ) = noscore ( t : ts )<br />collide' ( t : Empty : ts ) | movable t =<br />    slide' ( t : Empty : ts )</pre> <p>Erm. I'd no longer call that elegant, beautiful code. For one thing, I have to wrap it brutally to fit into my Blogger text window. That's not just annoying when dealing with Blogger -- it suggests that the lines are too long for easy reading even if they aren't wrapped. And here's what Jeff's version looks like today -- he's implemented his own way to structure the code with guards:</p> <pre>slide :: [ Tile ] -> ScoreTracker [ Tile ]<br />slide [] = noscore []<br />slide ( t1 : t2 : ts )<br />  | t1 == Ice_Block && blocking t2 = noscore ( t1 : t2 : ts )<br />  | blocking t2 = collide ( t1 : t2 : ts )<br />  | otherwise = do<br />                  ts' <- slide ( t1 : ts )<br />                  return ( Empty : ts' )<br />slide ( t : ts )<br />  | t == Ice_Block = noscore ( t : ts )<br />  | otherwise = collide ( t : ts )<br /><br />collide :: [ Tile ] -> ScoreTracker [ Tile ]<br />collide [] = noscore []<br />collide ( t1 : t2 : ts )<br />  | ( t1, t2 ) == ( Bomb, Mountain ) = noscore ( Empty : Empty : ts )<br />  | ( t1, t2 ) == ( Heart, House ) = score ( Empty : House : ts )<br />  | t1 == Ice_Block && blocking t2 = noscore ( Empty : t2 : ts )<br />  | movable t1 && blocking t2 = noscore ( t1 : t2 : ts )<br />  | movable t1 = do<br />                   ts' <- slide ( t1 : ts )<br />                   return ( Empty : ts' )<br />  | otherwise = noscore ( t1 : t2 : ts )<br />collide ( t : ts )<br />  | t == Ice_Block = noscore ( Empty : ts )<br />  | otherwise = noscore ( t : ts )</pre> <p>And I like that -- using the separate functions for both slide and collide only to handle the <b>structurally</b> different versions -- empty list, list with at least two items, list with at least one item -- and the <i>guards</i> to handle when we differ by value. It is, I think, more readable than mine. I was a little freaked out by the use of <b>do</b> and <b><-</b> in the middle of a function outside of main, but I'll think on that some more. I have not quite satisfied myself that it is perfectly correct, but then, I haven't really convinced myself that mine is correct either. So I have more to do on that front!</p>" nil nil "14dc4349babfca42aba2b20ab400ed2f") (257 (20963 45898 582676) "http://existentialtype.wordpress.com/2013/07/10/constructive-mathematics-is-not-meta-mathematics/" "Robert Harper: Constructive Mathematics Is Not Metamathematics" nil "Fri, 12 Jul 2013 17:54:56 +0000" "<p>The publication of the <a href=\"http://www.homotopytypetheory.org/book\">Homotopy Type Theory book</a> has renewed interest in type theory as a foundation for mathematics, and spurred computer scientists to investigate the computational meaning of higher-dimensional types. As I mentioned in a <a href=\"http://existentialtype.wordpress.com/2013/06/22/whats-the-big-deal-with-hott/\" title=\"What’s the big deal with HoTT?\">previous post</a>, what makes HoTT work so well for homotopy theory is that it is <em>constructive</em>, which means, at the very least, that it does not postulate that all types are decidable. By Hedberg’s Theorem any type with decidable equality is a set (homotopy 0-type), so a blanket adoption of the classical law of the excluded middle would immediately rule out any higher-dimensional structure.</p>
<p>To my way of thinking, the denial of the universal validity of the excluded middle is not the <em>defining</em> feature of constructivity, but rather a <em>characteristic</em> feature of constructivity—it is the smoke, not the locomotive. But what, then, is the deeper meaning of constructivity that gives rise to the denial of many classical patterns of reasoning, such as proof by contradiction or reasoning by cases on whether a proposition is true or not? Although the full story is not yet completely clear, a necessary condition is that a constructive theory be <em>proof relevant</em>, meaning that proofs are mathematical objects like any other, and that they play a role in the development of constructive mathematics unlike their role in classical mathematics.</p>
<p>The most obvious manifestation of proof relevance is the defining characteristic of HoTT, that <em>proofs of equality</em> correspond to <em>paths in a space</em>. Paths may be thought of as evidence for the equality of their endpoints. That this is a good notion of equality follows from the homotopy invariance of the constructs of type theory: everything in sight respects paths (that is, respect the groupoid structure of types). More generally, theorems in HoTT tend to characterize the space of proofs of a proposition, rather than simply state that the corresponding type is inhabited. For example, the univalence axiom itself states an equivalence between proofs of equivalence of types in a universe and equivalences between these types. This sort of reasoning may take some getting used to, but its beauty is, to my way of thinking, undeniable. Classical modes of thought may be recovered by explicitly obliterating the structure of proofs using truncation. Sometimes this is the best or only available way to state a theorem, but usually one tends to say more than just that a type is inhabited, or that two types are mutually inhabited. In this respect the constructive viewpoint <em>enriches</em>, rather than <em>diminishes</em>, classical mathematics, a point that even the greatest mathematician of the 20th century, David Hilbert, seems to have missed.</p>
<p>The concept of proof relevance in HoTT seems to have revived a very common misunderstanding about the nature of proofs. Many people have been trained to think that a proof is a derivation in an axiomatic theory, such as set theory, a viewpoint often promoted in textbooks and bolstered by the argument that an informal proof can always be written out in full in this form, even if we don’t do that as a matter of course. It is a short step from there to the conclusion that proofs are therefore mathematical objects, even in classical set theory, because we can treat the derivations as elements of an inductively defined set (famously, the set of natural numbers, but more realistically using more natural representations of abstract syntax such as the s-expression formalism introduced by McCarthy in 1960 for exactly this purpose). From this point of view many people are left confused about the stress on “proofs as mathematical objects” as a defining characteristic of HoTT, and wonder what could be original about that.</p>
<p>The key to recognize that <em>a proof is not a formal proof</em>. To avoid further confusion, I hasten to add that by “formal” I do not mean “rigorous”, but rather “represented in a formal system” such as the axiomatic theory of sets. A <em>formal proof</em> is an element of a computably enumerable set generated by the axioms and rules of the formal theory. A <em>proof</em> is an argument that demonstrates the truth of a proposition. While formal proofs are always proofs (at least, under the assumption of consistency of the underlying formal theory), a proof need not be, or even have a representation as, a formal proof. The principal example of this distinction is Goedel’s Theorem, which proves that the computably enumerable set of formal provable propositions in axiomatic arithmetic is not decidable. The key step is to devise a self-referential proposition that (a) is not formally provable, but (b) has a proof that shows that it is true. The crux of the argument is that <em>once you fix the rules of proof, you automatically miss out true things that are not provable in that fixed system</em>.</p>
<p>Now comes the confusing part. HoTT is defined as a formal system, so why doesn’t the same argument apply? It does, pretty much verbatim! But this has no bearing on “proof relevance” in HoTT, because the proofs that are relevant are not the formal proofs (derivations) defining HoTT as a formal system. Rather proofs are formulated internally as objects of the type theory, and there is no commitment <em>a priori</em> to being the only forms of proof there are. Thus, for example, we may easily see that there are only countably many functions definable in HoTT from the outside (because it is defined by a formal system), but within the theory any function space on an infinite type has uncountably many elements. There is no contradiction, because the proofs of implications, being internal functions, are not identified with codes of formal derivations, and hence are not denumerable.</p>
<p>There is a close analogy, <a href=\"http://existentialtype.wordpress.com/2012/08/09/churchs-law/\" title=\"Church’s Law\">previously noted</a> in this blog, with Church’s Law. Accepting Church’s Law internally amounts to fixing the programming language used to define functions in advance, permitting us to show, for example, that certain programs are not expressible in that language. But HoTT does not commit to Church’s Law, so such arguments amount to showing that, for example, there is no Turing machine to decide halting for Turing machines, but allowing that there could be constructive functions (say, equipped with oracles) that make such decisions.</p>
<p>The theory of formal proofs, often called proof theory, was dubbed <em>metamathematics</em> by Kleene. Until the development of type theory the study of proofs was confined to metamathematics. But now in the brave new world of <em>constructive mathematics</em> as embodied in HoTT, proofs (not just formal proofs) have pride of place in mathematics, and provide opportunities for expressing concepts clearly and cleanly that were hitherto obscured or even hidden from our view.</p>
<p><em>Update</em>: Corrected silly wording mistake.</p>
<br />Filed under: <a href=\"http://existentialtype.wordpress.com/category/research/\">Research</a> Tagged: <a href=\"http://existentialtype.wordpress.com/tag/constructive-mathematics/\">constructive mathematics</a>, <a href=\"http://existentialtype.wordpress.com/tag/homotopy-type-theory/\">homotopy type theory</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/existentialtype.wordpress.com/823/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/existentialtype.wordpress.com/823/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=existentialtype.wordpress.com&blog=2157150&post=823&subd=existentialtype&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "a687fa3dde5bc37edb774547a3e3072d") (256 (20963 45898 581264) "http://www.yesodweb.com/blog/2013/07/catching-all-exceptions" "Yesod Web Framework: Catching all exceptions" nil "Fri, 12 Jul 2013 13:00:00 +0000" "<p>Note: This blog post is also <a href=\"https://www.fpcomplete.com/user/snoyberg/general-haskell/exceptions/catching-all-exceptions\">available on the School of
Haskell</a>.
I'd recommend reading it there, as the active code snippets may greatly enhance
the material.</p><hr /><p>A commonly discussed piece of functionality is \"catching all exceptions.\" The goal usually is to write reliable functions, which can recover from any kind of problem that exists in some library, or perhaps in some callback passed into the function, which the library author has no control over. Thanks to extensible exceptions, writing this kind of \"catch any exception\" is pretty trivial in Haskell:</p><pre><code class=\"haskell active\">import Control.Exception
catchAny :: IO a -> (SomeException -> IO a) -> IO a
catchAny = Control.Exception.catch
dangerous :: IO Int
dangerous = error \"Fool you!\"
main :: IO ()
main = do
result <- catchAny dangerous $ \\e -> do
putStrLn $ \"Got an exception: \" ++ show e
putStrLn \"Returning dummy value of -1\"
return (-1)
print result</code></pre><p>But this <code>catchAny</code> function isn't quite correct, due to asynchronous exceptions. I'd like to explain what the problem is, demonstrate a fix for it (inspired by John Lato using Simon Marlow's <code>async</code> library), and then generalize it even further using <code>monad-control</code>.</p><h2>Async exceptions</h2><p>Let's consider the following theoretical workflow:</p><ul><li>I have a potentially exception-throwing function I want to run, called <code>dangerous</code>.</li><li>This function should be run by a larger function, called <code>worker</code>. It should handle exceptions thrown by <code>dangerous</code> gracefully.</li><li>I want to make sure that <code>worker</code> runs for no more than 5 milliseconds. I'll use the <code>timeout</code> function to ensure this.</li><li>But unbeknownst to me, <code>dangerous</code> tends to take about 10 milliseconds.</li></ul><p>Below is an implementation of the above logic, using the <code>catchAny</code> we defined earlier. Before you run this code, consider what the expected behavior here should be. In particular, should <code>worker</code> run to completion or not?</p><pre><code class=\"haskell active\">import Control.Exception
import System.Timeout
import Control.Concurrent
catchAny :: IO a -> (SomeException -> IO a) -> IO a
catchAny = Control.Exception.catch
dangerous :: IO Int
dangerous = do
putStrLn \"Succeeds this time, but takes some time\"
threadDelay 10000
return 5

worker :: IO ()
worker = do
x <- catchAny dangerous $ \\e -> do
putStrLn $ \"Caught an exception: \" ++ show e
return (-1)
putStrLn $ \"x + 10 == \" ++ show (x + 10)
main :: IO ()
main = do
res <- timeout 5000 worker
case res of
Nothing -> putStrLn \"worker did not run to completion\"
Just () -> putStrLn \"worker ran to completion\"</code></pre><p>In an ideal world, <code>worker</code> would be stopped before it finished, since it takes more than the 10 milliseconds provided to it to completely run. However, if you run the above code, you'll see that <code>worker</code> does in fact complete. What gives? Well, this is what <i>actually</i> happens when you run this code:</p><ul><li>The <code>timeout</code> function forks a new thread to run <code>worker</code> in. If <code>worker</code> does not complete within 5 ms, that new thread is thrown a timeout exception. This kind of throwing is done by the <code>throwTo</code> function, and is an <i>asynchronous exception</i>.</li><li>Meanwhile, <code>worker</code> starts running, and wraps <code>dangerous</code> with <code>catchAny</code>.</li><li>Since <code>dangerous</code> takes 10 ms, the timeout exception is called when the new thread is inside <code>dangerous</code>, which itself is inside <code>catchAny</code>. <code>dangerous</code> has no exception handling, so the exception propagates up to <code>worker</code>.</li><li><code>worker</code>'s <code>catchAny</code> catches all exceptions, and therefore treats the timeout exception as if it was thrown from <code>dangerous</code> itself. It therefore continues processing, completely ignoring the command to timeout.</li></ul><p>This is a little tricky, so make sure you understand the situation properly before continuing.</p><h2>Non-solution: examine the types</h2><p>My first inclination for solving this problem was to look at the types of the exception being caught. If it was a timeout exception, or any other kind of asynchronous exception, <code>catchAny</code> could simply ignore it. This looks something like:</p><pre><code class=\"haskell active\">catchAny :: IO a -> (SomeException -> IO a) -> IO a
catchAny m f =
Control.Exception.catch m onExc
where
onExc e
| shouldCatch e = f e
| otherwise = throwIO e
shouldCatch e
| show e == \"<<timeout>>\" = False
| Just (_ :: AsyncException) <- fromException e = False
| otherwise = True</code></pre><p>As you can see, this does in fact solve our problem. <code>catchAny</code> now ignores the timeout exception, so it is propagated to <code>worker</code>, terminating the computation. However, it has a few problems. I won't profess to understand all of the problems, but here's the most salient in my mind: <b>the types have nothing to do with whether an exception is synchronous or asynchronous</b>. Consider that, for some strange reason, we decided to asynchronously throw an <code>IOException</code> to a worker thread, e.g.:</p><pre><code class=\"haskell active\">main :: IO ()
main = do
threadId <- forkIO worker
eresult <- try $ readFile \"does-not-exist.txt\"
case eresult of
Left e -> throwTo threadId (e :: IOException)
Right _ -> putStrLn \"Funny, that shouldn't have worked\"
-- Give the forked thread time to finish
threadDelay 50000</code></pre><p>Since our <code>catchAny</code> knowns nothing about asynchronously thrown <code>IOException</code>s, our worker thread will continue doing work even after we try to kill the thread. This example is clearly a bit contrived, but consider if we had some kind of user quota system, where we send a custom asynchronous exception whenever a thread uses too much disk space. There's no way a generic <code>catchAny</code> could know about every kind of custom exception type a user defines. And even if we did, it's clear that any exception type could be thrown either synchronously or asynchronously.</p><h2>Real solution: separate worker thread</h2><p>John Lato described a very straight-forward means of doing the right thing, leveraging Simon Marlow's excellent <code>async</code> library. In fact, that library is so excellent that it solved some of my implementation details before I even realized they existed... more on that in a moment.</p><p>The concept is simple: if you have some function you want to catch all exceptions for, fork a new thread and run the function there. Catch all exceptions thrown in that new thread, and return them to the original thread (via usage of software transactional memory). Now, if any async exceptions are thrown to the original thread, they are unaffected by the exception catching code. And the cool part that the <code>async</code> library took care of automatically: if the original thread gets an async exception, automatically propagate it down to the worker thread so that it terminates work immediately.</p><p>The amazing thing is just how simple this code is. We'll switch over to implementing <code>tryAny</code> instead of <code>catchAny</code>, since it's easier with the <code>async</code> library, and then we can build <code>catchAny</code> on top of that.</p><p><b>Note</b>: the <code>async</code> library hasn't yet been deployed to the FP Haskell Center at time of writing, so I'll include the necessary code inline from <code>async</code>.</p><pre><code class=\"haskell active\">tryAny :: IO a -> IO (Either SomeException a)
tryAny action = withAsync action waitCatch
catchAny :: IO a -> (SomeException -> IO a) -> IO a
catchAny action onE = tryAny action >>= either onE return</code></pre><p>Our solution is now very concise, built on top of quality libraries, and it resilient to any changes in the future to the exception hierarchy.</p><p>This is really our complete solution to the problem as described. The next two sections describe two optional enhancements to this solution.</p><h2>Going deeper</h2><p>What we really want is to be completely isolated from any exceptions generated by a piece of code. The solution above is still vulnerable to one issue: exceptions from pure code hiding in an unevaluated thunk. Even the most brute force <code>catchAny</code> is susceptible to this problem.</p><pre><code class=\"haskell active\">import Control.Exception
catchAny :: IO a -> (SomeException -> IO a) -> IO a
catchAny = Control.Exception.catch
dangerous :: IO Int
dangerous = return $ error \"Unevaluated!\"
main :: IO ()
main = do
res <- catchAny dangerous (const $ return (-1))
putStrLn \"About to print the result\"
putStrLn $ \"Result: \" ++ show res
putStrLn \"Hmm... does this ever get printed?\"</code></pre><p>What we want to do is force evaluation of the value, and if forcing throws any exceptions, catch them. With the <code>deepseq</code> package, this is easy. Let's call these new functions <code>tryAnyDeep</code> and <code>catchAnyDeep</code>, and base them on our previously defined <code>tryAny</code>:</p><pre><code class=\"haskell active\">tryAnyDeep :: NFData a => IO a -> IO (Either SomeException a)
tryAnyDeep action = tryAny $ do
res <- action
return $!! res -- here's the magic
catchAnyDeep :: NFData a => IO a -> (SomeException -> IO a) -> IO a
catchAnyDeep action onE = tryAnyDeep action >>= either onE return
dangerous :: IO Int
dangerous = return $ error \"Unevaluated!\"
main :: IO ()
main = do
res <- catchAnyDeep dangerous (const $ return (-1))
putStrLn \"About to print the result\"
putStrLn $ \"Result: \" ++ show res
putStrLn \"Hmm... does this ever get printed?\"</code></pre><p>We can now have complete* confidence in the values returned from <code>catchAny</code>.</p><p>* Complete confidence, assuming we trust the <code>NFData</code> instances, but that's a different problem.</p><h2>Transformers</h2><p>OK, one final twist: can we catch exceptions in a monad transformer stack? Many of you may be aware that I'm a big advocate of Bas van Dijk's <code>monad-control</code> package, and the related <code>lifted-base</code> package. <code>monad-control</code> allows for a consistent manner of lifted control operations within a monad transformer stack. Can we generalize our <code>tryAny</code> and <code>catchAny</code> functions to work with arbitrary transformer stacks? Fortunately, we can:</p><pre><code class=\"haskell active\">tryAnyIO :: IO a -> IO (Either SomeException a)
tryAnyIO action = withAsync action waitCatch
tryAny :: MonadBaseControl IO m => m a -> m (Either SomeException a)
tryAny action =
-- MAGIC!
liftBaseWith (\\runInIO -> tryAnyIO (runInIO action)) >>=
either (return . Left) (liftM Right . restoreM)
catchAny :: MonadBaseControl IO m => m a -> (SomeException -> m a) -> m a
catchAny action onE = tryAny action >>= either onE return
tryAnyDeep :: (MonadBaseControl IO m, NFData a)
=> m a
-> m (Either SomeException a)
tryAnyDeep action = tryAny $ do
res <- action
return $!! res -- here's the magic
catchAnyDeep :: (MonadBaseControl IO m, NFData a)
=> m a
-> (SomeException -> m a)
-> m a
catchAnyDeep action onE = tryAnyDeep action >>= either onE return
dangerous :: Monad m => m Int
dangerous = return $ error \"Unevaluated!\"
main :: IO ()
main = flip runReaderT () $ do
res <- catchAnyDeep dangerous (const $ return (-1))
liftIO $ putStrLn \"About to print the result\"
liftIO $ putStrLn $ \"Result: \" ++ show res
liftIO $ putStrLn \"Hmm... does this ever get printed?\"</code></pre><p>That implementation of <code>tryAny</code> is a little bit hairy, but it essentially means:</p><ul><li>Capture the monadic state when we start running (via <code>liftWithBase</code>).</li><li>Put the state inside the <code>IO</code> monad by modifying the internal value (via <code>runInIO</code>).</li><li>Now that we have an <code>IO</code> action, run <code>tryAnyIO</code> on it.</li><li>Get back the result.<ul><li>If an exception was thrown, then return that exception.</li><li>If a value was returned, unwrap the new monadic state from and extract the actual return value (via <code>restoreM</code>).</li></ul></li></ul><h2>Moving forward</h2><p>I've <a href=\"https://github.com/snoyberg/classy-prelude/blob/ccd19f2c62882c69d5dcdd3da5c0df1031334c5a/classy-prelude/ClassyPrelude.hs#L320\">added these functions</a> to the <code>classy-prelude</code> Github repo, and after a bit more testing will be releasing them. But I think including something like this in a more accessible place makes a lot of sense, as we should be trying to make the correct approach easier to implement.</p><p>I'd be happy to hear ideas on how to improve the code, or where the correct place to put these functions might be.</p>" nil nil "602365edd2b9dd50fa66345471ac486a") (255 (20963 45898 579194) "http://praisecurseandrecurse.blogspot.com/2013/07/the-polar-game-in-haskell-day-5-12.html" "Paul Potts: The Polar Game in Haskell, Day 5 1/2: Refactoring with a Monad" "noreply@blogger.com (Paul Potts)" "Thu, 11 Jul 2013 23:22:00 +0000" "<p>The job search has eaten my brain for the last few days -- have I mentioned yet that I need a job? Oh, yes, I believe I may have -- but I'm taking some time to press on with my Haskell larnin', especially since I've been getting great, helpful feedback.</p> <p>The first thing I did was make some minor fixes to the list implementation, as suggested by Jeff. It's working now and my version looks like this:</p> <pre>next_board_list :: BoardList -> Pos -> Dir -><br />    ( Bool, BoardList )<br />next_board_list board pos dir =<br />    let ( penguin_moved, updated_view_list ) =<br />        step_list $ view_list board pos dir<br />    in ( penguin_moved, update_board_from_view_list <br />         board pos dir updated_view_list )<br /><br />apply_view_list_to_row :: [ Tile ] -> Int -> Bool -> [ Tile ] -> [Tile]<br />apply_view_list_to_row orig pos True update =<br />    take ( pos + 1 ) orig ++ update<br />apply_view_list_to_row orig pos False update =<br />    ( reverse update ) ++ ( drop pos orig )<br /><br />apply_view_list_to_rows :: BoardList -> Int -> Int -> Bool -> [ Tile ]<br />    -> BoardList<br />apply_view_list_to_rows orig row pos is_forward update =<br />    take row orig ++<br />    nest ( apply_view_list_to_row ( orig !! row ) pos<br />           is_forward update ) ++<br />    drop ( row + 1 ) orig<br />    where nest xs = [xs]<br /><br />update_board_from_view_list :: BoardList -> Pos -> Dir -> [ Tile ]<br />    -> BoardList<br />update_board_from_view_list board pos dir updated_view_list<br />    | is_eastwest = apply_view_list_to_rows board<br />                        ( posY pos ) ( posX pos )<br />                        is_forward updated_view_list<br />    | otherwise = transpose ( apply_view_list_to_rows ( transpose board )<br />                         ( posX pos ) ( posY pos ) <br />                         is_forward updated_view_list )<br />    where is_forward = elem dir [ East, South ]<br />          is_eastwest = elem dir [ East, West ]</pre> <p>This code is on <a href=\"https://github.com/paulrpotts/arctic-slide-haskell\">GitHub</a> here.</p> <p>Now, it turns out that Jeff did more than suggest a refactoring -- he actually did something I haven't quite gotten my head around yet, which is to refactor my code to use a monad for managing some of this task. He forked my code in his own GitHub repo <a href=\"https://github.com/licquia/arctic-slide-haskell\">here</a> and sent me some notes to share on my blog. Here's part of what he said:</p> <blockquote>The way I got my head wrapped around monads was to think of them as \"important stuff to do, but not the point\". You need to do some housekeeping that's important, but it's not the reason you're writing this function.  The classic example is division. You're writing a math library, and you need to implement division. Division by zero is something you need to deal with sanely, but it's not the point; you're writing the function because you want to divide by things that aren't zero.  So, to handle the zero case, you return a Maybe instead of a simple number. Only now you can't just add numbers together with division, because you're dealing with Maybes, not numbers. So you end up implementing addition with Maybes, except that makes no sense, as adding never fails, and people using your math library get annoyed because now *they* have to deal with division-by-zero errors even when they're not dividing, and it's a mess.  Except -- Maybe is a monad. So you skip all that mess, implement division with a Maybe, everything else without, and use the cool monad and functor features of the language to bridge the gaps.  The same pattern exists with scorekeeping. A lot of the functions in your code need to keep track of the score and occasionally award points, but scores aren't \"the point\" of, say, collide. And when you start thinking about all the places you need to worry about scores, you start seeing scorekeeping infect all kinds of weird places in your code. I think you even mentioned having to \"uglify\" your code with scorekeeping in your blog post.</blockquote> <p>Yes, yes, yes -- mainly the chain of function invocations that handle generating the next board, down to the <b>collide</b> calls. Because it's only at the point where a heart disappears that we can decrement the heart count. Without state, I can't make this a global state. In a purely function form, I have to \"thread\" the indication that the heart count should be decreased through the whole chain of function signatures, which now all have to return an extra thing.</p> <blockquote>So, minimize the ugly with monads. Just do what you need to do to pass around the score, and deal with it when it's appropriate. (In my implementation, that was in next_world).  The Writer monad is perfect for the job. It uses a monoid, which is a fancy ways of saying \"something that knows how to grow\". Lists are monoids, because you can append to them. Numbers are monoids, because you can add and multiply them. And so on.  What the Writer monad does is take care of the adding part. You just return the thing you're working with, and the monad tacks it on using the monoid. Specifically, with scorekeeping, you just note how many points each individual action takes, and the monad does the adding together. When you finally deal with the score in next_world, you get all the accumulated points in one tidy variable.</blockquote> <p>OK, cool... let's see what he came up with!</p> <pre>import Control.Monad.Writer<br /><br />...<br /><br />-- Keep track of the score with a writer monad<br />type ScoreTracker = Writer ( Sum Int )</pre> <p>OK, let me pause there and see if I can make sense of that. <i>Learn You a Haskell</i> <a href=\"http://learnyouahaskell.com/for-a-few-monads-more\">says</a></p> <blockquote>Whereas Maybe is for values with an added context of failure and the list is for non-deterministic values, the Writer monad is for values that have another value attached that acts as a sort of log value. Writer allows us to do computations while making sure that all the log values are combined into one log value that then gets attached to the result.</blockquote> <p>OK, I think I get that -- in <i>Learn You</i> it is used for implementing logging, not scoring of a game, but it seems like it could be generalizable. The example given does this just kind of thing I was mentioning -- makes a simple function return a tuple to pass both the actual interesting return value and the log string, or in our case I think we want a score. <i>Learn You</i> continues:</p> <blockquote>When we were exploring the Maybe monad, we made a function applyMaybe, which took a Maybe a value and a function of type a -> Maybe b and fed that Maybe a value into the function, even though the function takes a normal a instead of a Maybe a. It did this by minding the context that comes with Maybe a values, which is that they are values with possible failure. But inside the a -> Maybe b function, we were able to treat that value as just a normal value, because applyMaybe (which later became >>=) took care of checking if it was a Nothing or a Just value.  In the same vein, let's make a function that takes a value with an attached log, that is, an (a,String) value and a function of type a -> (b,String) and feeds that value into the function. We'll call it applyLog. But because an (a,String) value doesn't carry with it a context of possible failure, but rather a context of an additional log value, applyLog is going to make sure that the log of the original value isn't lost, but is joined together with the log of the value that results from the function.</blockquote> <p>Oooh, again, that sounds very promising. So I'm convinced that <b>Writer</b> is the right abstraction here. The values that <b>Writer</b> gets are <b>Sum</b> and <b>Int</b> -- <b>Sum</b> is our monoid, <b>Int</b> is a type we're going to use to accumulate the updated score. (To go along with the Polar game logic, I think there really should ultimately be two scores -- one should be the heart count for a given board, which decrements, and gets tested against zero to indicate board completion, and the other should be a level, which increments as the player moves through the levels, but never mind that for now).</p> <p>Jeff then came up with:</p> <pre>noscore :: a -> ScoreTracker a<br />noscore x = writer (x, Sum 0)<br /><br />score :: a -> ScoreTracker a<br />score x = writer (x, Sum 1)</pre> <p>Two functions, <b>noscore</b> and <b>score</b>. I think these are both monadic <b>return</b> -- injecting a value, passing it to the next step while applying the sum operation. So let's see how he uses it. here's my <b>slide</b> function:</p> <pre>slide :: [ Tile ] -> [ Tile ]<br />slide ( Ice_Block : ts ) | ( null ts ) || ( blocking $ head ts ) = <br />    ( Ice_Block : ts )<br />slide ( t : Empty : ts ) =<br />    ( Empty : ( slide ( t : ts ) ) )<br />slide ( t : ts ) | ( null ts ) || ( blocking $ head ts ) =<br />    collide ( t : ts )</pre> <p>I'm not going to take Jeff's current version, because he's restructured it a bit using guards, which obscures just the differences due to the use of the ScoreTracker, but here's a version that does the same thing. We don't have to explictly construct the return tuples:</p> <pre>slide' :: [ Tile ] -> ScoreTracker [ Tile ]<br />slide' ( Ice_Block : ts ) | ( null ts ) || ( blocking $ head ts ) =<br />    noscore ( Ice_Block : ts )<br />slide' ( t : Empty : ts ) =<br />    noscore ( Empty : ( slide ( t : ts ) ) )<br />slide' ( t : ts ) | ( null ts ) || ( blocking $ head ts ) =<br />    collide ( t : ts )</pre> <p>And this doesn't actually compile. Note that collide doesn't handle the monad -- the compiler warns us as Jeff described:</p> <pre>    Couldn't match expected type `ScoreTracker [Tile]'<br />                with actual type `[Tile]'<br />    In the return type of a call of `collide'<br />    In the expression: collide (t : ts)<br />    In an equation for slide':<br />        slide' (t : ts)<br />          | (null ts) || (blocking $ head ts) = collide (t : ts)</pre> <p>That seems pretty clear -- so I have to fix it up the same way:</p> <pre>collide' :: [ Tile ] -> ScoreTracker [ Tile ]<br />collide' [] = noscore []<br />collide' ( t : ts ) | fixed t = <br />    noscore ( t : ts )<br />collide' ( Bomb : Mountain : ts) = <br />    noscore ( [ Empty, Empty ] ++ ts )<br />collide' ( Heart : House : ts ) = score ( [ Empty, House ] ++ ts )<br />collide' ( Ice_Block : ts ) | ( null ts ) || ( blocking $ head ts ) = <br />    noscore ( Empty : ts )<br />collide' ( t : ts ) | ( movable t ) && ( ( null ts ) ||<br />    ( blocking $ head ts ) ) = noscore ( t : ts )<br />collide' ( t : Empty : ts ) | movable t = <br />    noscore ( Empty : ( slide( t : ts ) ) )</pre> <p>And slide' should call <b>collide'</b> instead of <b>collide</b>, of course. So once this is compiled and loaded into GHCI, we can play with it and compare it to the original <b>collide</b>:</p> <pre>*Main> :t collide'<br />collide' :: [Tile] -> ScoreTracker [Tile]<br />*Main> :t collide<br />collide :: [Tile] -> [Tile]<br />*Main> collide [ Bomb, Mountain ]<br />[Empty,Empty]<br />*Main> collide [ Heart, House ]<br />[Empty,House]<br />*Main> collide' [ Heart, House ]<br /><br /><interactive>:23:1:<br />    No instance for (Show (ScoreTracker [Tile]))<br />      arising from a use of `print'<br />    Possible fix:<br />      add an instance declaration for (Show (ScoreTracker [Tile]))<br />    In a stmt of an interactive GHCi command: print it</pre> <p>Er, yeah. The result is not printable, but can we see its type?  </p><pre>*Main> :t ( collide' [ Heart, House ] )<br />( collide' [ Heart, House ] ) :: ScoreTracker [Tile]</pre> <p>In fact, we can. So there might be an easy way to make the monadic type printable -- <b>deriving ( Show )</b> doesn't work -- but first, how do we extract the values? Well, we get back the return value of the whole chain from <b>runWriter</b>:</p> <pre>*Main> runWriter $ collide' [Heart, House]<br />([Empty,House],Sum {getSum = 1})</pre> <p>What's the type? It's just a tuple:</p> <pre>*Main> :t ( runWriter $ collide' [Heart, House] )<br />( runWriter $ collide' [Heart, House] ) :: ([Tile], Sum Int)<br />*Main> fst $ runWriter $ collide' [Heart, House]<br />[Empty,House]<br />*Main> snd $ runWriter $ collide' [Heart, House]<br />Sum {getSum = 1}</pre> <p>Anyway, I think my mind is blown enough for today. I'm going to stop there. Jeff has made some other modifications to my code here and there -- modifications that improve the clarity -- but I'll have to get back to those. I'm off to read the monad tutorials again, and maybe understand them better this time!</p>" nil nil "b3468c41f050955f7d7fb69e8cd834e2") (254 (20963 45898 577404) "http://blog.plover.com/tech/cobblestones.html" "Mark Jason Dominus: Cobblestones" "mjd@plover.com (Mark Dominus)" "Thu, 11 Jul 2013 18:33:00 +0000" "<p>This is a public service announcement.</p>
<p>This is not a picture of a cobbled street:</p>
<p><a href=\"http://pic.blog.plover.com/tech/cobblestones/block.jpg\"><img src=\"http://pic.blog.plover.com/tech/cobblestones/block-sm.jpg\" border=\"0\" /></a></p>
<p>Rather, these stones are \"<a href=\"http://en.wikipedia.org/wiki/Belgian_block\">Belgian block</a>\",
also called <i>setts</i>.</p>
<p><a href=\"http://en.wikipedia.org/wiki/Cobblestone\">Cobblestones</a> look like this:</p>
<p><a href=\"http://pic.blog.plover.com/tech/cobblestones/cobbles.jpg\"><img src=\"http://pic.blog.plover.com/tech/cobblestones/cobbles-sm.jpg\" border=\"0\" /></a></p>
I took these pictures in front of the library of the American
Philosophical Society on South 5th Street in Philadelphia. South 5th
Street is paved with Belgian block, and the lane beside the APS is
cobbled. You can just barely distinguish them in <a href=\"http://goo.gl/maps/fA5Kl\">this
satellite photograph</a>.<p></p>" nil nil "fe61f315f449610b6684c1a00dfdd8b2") (253 (20963 45898 577098) "http://www.well-typed.com/blog/80" "Well-Typed.Com: Well-Typed are hiring: Haskell developer" nil "Thu, 11 Jul 2013 17:50:46 +0000" "<p>We are looking to hire a Haskell expert to work with us at Well-Typed as a
Haskell developer. This is an exciting opportunity for someone who is
passionate about Haskell and who is keen to improve and promote Haskell in a
professional context.</p><p>The role is quite general and could cover any of the projects and activities
that we are involved in as a company. The tasks may involve:</p><ul><li>working on the Haskell compiler, libraries and tools;</li></ul><ul><li>Haskell application development;</li></ul><ul><li>working directly with clients to solve their problems;</li></ul><ul><li>teaching Haskell, and developing training materials.</li></ul><p>At the moment, we are particularly hoping to find someone with an interest in
supporting the development and maintenance of GHC. Therefore, some knowledge or
interest in compiler internals, operating systems, the foreign function
interface (FFI), and/or deployment issues would be welcome.</p><p>Well-Typed has a variety of clients. For some we do proprietary Haskell
development and consulting. For others, much of the work involves open-source
development and cooperating with the rest of the Haskell community: the
commercial, open-source and academic users.</p><p>Our ideal candidate has excellent knowledge of Haskell, whether from industry,
academia, or personal interest. Familiarity with other languages, low-level
programming, and good software engineering practices are also useful. Good
organisation and ability to manage your own time, and reliably meet deadlines,
is important. You should also have good communication skills. Being interested
or having experience in teaching Haskell (or other technical topics) is a bonus.
Experience of consulting, or running a business, is also a bonus. You are
likely to have a bachelor's degree or higher in computer science or a related
field, although this isn't a requirement.</p><p>The offer is initially for a one-year full time contract. We are also happy to
receive applications for part-time work. The annual salary is from GBP 34,800
or pro rata for part-time or flexible work. We also operate a bonus scheme.
We offer flexible hours and work from home. Living in England is not required.
We may be able to offer either employment or sub-contracting, depending on the
jurisdiction in which you live.</p><p>If you are interested, please apply via
<a href=\"mailto:info@well-typed.com\">info@well-typed.com</a>. Tell us why you
are interested and why you would be a good fit for the job, and attach your CV.
Please also indicate how soon you might be able to start. We are more than
happy to answer informal enquiries. Contact
<a href=\"http://www.well-typed.com/who_we_are\">Duncan Coutts, Ian Lynagh or Andres Löh</a>
for further information, either by email or IRC.</p><p>To ensure we can properly consider your application, please get it to us by
July 25th, 2013, though we may be able to consider applications received later.
</p>" nil nil "de201d8fceca501ef7449f1060ededaa") (252 (20963 45898 576525) "http://www.well-typed.com/blog/79" "Well-Typed.Com: Video and slides on (Alternatives to) Lazy I/O" nil "Thu, 11 Jul 2013 17:30:22 +0000" "<p>Edsko is in London this week running our <a href=\"http://www.well-typed.com/services_training\">regular Haskell training courses</a>.
Last night he gave a talk, as part of the Skills Matter \"In The Brain\" series,
on the subject of lazy I/O in Haskell and the various old and new alternatives.</p><blockquote><h4> (Alternatives to) Lazy I/O</h4><p><em>by Edsko de Vries</em></p><ul><li><a href=\"http://skillsmatter.com/podcast/home/lazy-io-and-alternatives-in-haskell/jd-7959\">Slides and video</a> </li></ul></blockquote><p>If you are lucky enough to be in or near London, there is now quite a range of
free evening Haskell events to keep an eye out for:</p><ul><li>The <a href=\"http://skillsmatter.com/\">Skills Matter \"In The Brain\" talks</a>. These
are free evening events and there are talks on Haskell or functional
programming fairly regularly. They're generally at the introductory or
intermediate level.</li><li>The <a href=\"http://www.meetup.com/London-Haskell/\">London Haskell User Group</a> is
alive and running talks again. These are now quite well attended.</li><li>The <a href=\"http://www.meetup.com/hoodlums/\">Haskell Hoodlums</a> group does monthly
\"coding dojo\" events where beginners and experts work together on a shared
problem.</li></ul><p>These are all fun, friendly events to learn a bit more and meet up with fellow
Haskellers and get involved with the community.
</p>" nil nil "9467af5b8b5da4787d009a32e0226843") (251 (20963 45898 576013) "http://www.joachim-breitner.de/blog/archives/602-Running-Circle-Packing-in-the-Browser-using-Haste.html" "Joachim Breitner: Running Circle Packing in the Browser using Haste" "mail@joachim-breitner.de (nomeata)" "Thu, 11 Jul 2013 14:45:51 +0000" "<p><a href=\"http://www.joachim-breitner.de/blog/archives/578-Circle-Packing.html\">Half a year ago</a>, I wrote a small Haskell library called <a href=\"http://hackage.haskell.org/package/circle-packing\">circle-packing</a> to pack circles in a tight arrangement. I used this to experiment with <a href=\"http://fay-lang.org/\">the fay compiler</a>, which compiles Haskell to JavaScript, and <a href=\"http://darcs.nomeata.de/circle-packing/fay/fay-demo.html\">the result</a> was quite nice.</p>
<p>Recently, I was pointed to <a href=\"https://github.com/valderman/haste-compiler\">haste</a>, another Haskell-to-JavaScript-compiler, and gave it a shot. It required no changes to my code, and after a <a href=\"https://github.com/valderman/haste-compiler/issues/62\">bug in the compiler</a> was fixed, I could successfully run <a href=\"http://darcs.nomeata.de/circle-packing/haste/haste-demo.html\">the example compiled with haste.</a> Some observations:</p>
<ul>
<li>Haste provides more features that I consider necessary for it to be used seriously. In particular its support for Cabal (so I could just write <tt>haste-inst install circle-packing</tt>) and its support for a much larger subset of Haskell, including type classes, as it builds on GHC.</li>
<li>Interfacing with JavaScript is not as smooth as in fay. Especially having to write JS code in a <a href=\"http://darcs.nomeata.de/circle-packing/haste/helpers.js\">separate helper file</a> is annoying.</li>
<li>A quick unscientific comparison of the two results indicates that the code produced by haste is a bit faster (although I should maybe compile the fay variant with the latest version).<br /></li>
</ul>" nil nil "676c71bb67ae5f942e4920d82f5db30a") (250 (20963 45898 539106) "http://r6.ca/blog/20130710T012527Z.html" "Russell O'Connor: Key Stretching" nil "Wed, 10 Jul 2013 01:25:27 +0000" "<p>I have been on a bit of a key stretching binge this week.
There is a <a href=\"http://martin.kleppmann.com/2013/05/24/improving-security-of-ssh-private-keys.html\" title=\"Improving the security of your SSH private key files\">wonderful article on how to stretch your ssh keys</a>.
Apparently, by default all that stands between your ssh passphrase and your ssh key is a single round of MD5 with 8 bytes of salt.
However, because ssh relies upon openssl, you can change the password format to use PBKDF2.
It is really easy to do.  I highly recommend doing it.</p><p>Next up, I have been wanting to add key streching to my disk encryption for a while.
The problem is that when dm-crypt operates in plain mode, it simply hashes your passphrase once with a given hash.
I am not a big fan of LUKS because the LUKS headers make it really apparent there is encrypted data on your drive rather than a wiped hard disk.
Since I was going to need to stretch my passphrase by hand, I figured I might as well use <a href=\"http://tools.ietf.org/html/draft-josefsson-scrypt-kdf-01\" title=\"The scrypt Password-Based Key Derivation Function\">scrypt</a>.
The problem was that I could not find any stand-alone implementation of scrypt, so I cobbled together <a href=\"http://r6.ca/crypto_scrypt-0.0/crypto_scrypt.c\">my own stand-alone <kbd>crypto_scrypt</kbd> utilty</a>.
It is not pretty; it is in serious need of some command line parameter love; but it works.
I even make <a href=\"http://r6.ca/crypto_scrypt-0.0/crypto_scrypt.nix\">a little <kbd>crypto_scrypt</kbd> nix expression</a> so I could integrate it into my boot process.
</p>" nil nil "b0095ab712aae8248adeb7d339789748") (249 (20963 45898 538571) "http://alessandrovermeulen.me/2013/07/08/combining-graphviz-dot-and-tikz-with-dot2tex/" "Alessandro Vermeulen: Combining graphviz (dot) and TikZ with dot2tex" nil "Mon, 08 Jul 2013 21:06:00 +0000" "<p>We all want to create good looking documents and good looking documents need
good looking images. Because we want consistency and because we are lazy we
want to do this as automatic as possible. That is why we use <span>L<span style=\"\">a</span>T<span style=\"\">e</span>X</span>,
it creates beautifully typeset documents without much manual effort.</p>
<p>Similarly, we use graphviz to generate our graphs for us. It’s automatic layout is the best in the
field and the (<a href=\"http://alessandrovermeulen.me/2013/05/19/why-you-should-switch-to-declarative-programming/\">declarative</a>) dot language is easy to understand and compact to write. We can either include the PDFs dot generated in our document by using <code>\\includegraphics</code> or we could use the latex <a href=\"https://github.com/mprentice/GraphViz-sty\">graphviz package</a>, remember that we are lazy. We can easily get
the image in <a href=\"http://alessandrovermeulen.me/atom.xml#example1\">our first example</a> in our PDF.</p>
<div class=\"bogus-wrapper\"><notextile><figure id=\"example1\">
<img src=\"http://farm8.staticflickr.com/7313/9243796534_60bb926e44_o.png\" alt=\"Image with graphviz\" height=\"155\" width=\"563\" />
<figcaption><strong>Figure 1.</strong> Example of an image generated by Graphviz/dot</figcaption>
</figure></notextile></div>
<p>There is a shadow side to using Graphviz/dot as well. There are two problems.
Firstly, the image just looks a bit out of place around the nicely smoothed
text in a PDF. Secondly, we lack the ability to use TeX code in our graph.
This means we are limited to the formatting by dot and the graphs could
therefore appear out of style with other figures in our document.</p>
<p>No worries, with TikZ it is possible to create very fancy graphs and images in
general but you have to all the positioning manually! Imagine inserting a node
and having to reorder everything!</p>
<p>Enter <a href=\"http://www.fauskes.net/code/dot2tex/\">dot2tex</a> it brings all the love
of graphviz/dot to TeX/TikZ. Using dot2tex has many advantages:</p>
<ol>
<li>Lets you write your graphs in familiar dot syntax;</li>
<li>Let dot – or whichever layout engine you prefer – determine the placement of
your nodes and arrows;</li>
<li>Style your nodes however you want by using TikZ styles;</li>
<li>Optionally, fine-tune the graph by adding extra tikz drawings.</li>
</ol>
<p>Rather than manually calling dot2tex for every dot file you have please use
the <a href=\"http://www.ctan.org/pkg/dot2texi\">dot2texi package</a>. This is the interface to dot2tex and when used as follows generates the image as displayed in <a href=\"http://alessandrovermeulen.me/atom.xml#example2\">Figure 2</a>.</p>
<div class=\"bogus-wrapper\"><notextile><figure class=\"code\"><figcaption><span></span></figcaption><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
<span class=\"line-number\">2</span>
<span class=\"line-number\">3</span>
<span class=\"line-number\">4</span>
<span class=\"line-number\">5</span>
<span class=\"line-number\">6</span>
<span class=\"line-number\">7</span>
<span class=\"line-number\">8</span>
<span class=\"line-number\">9</span>
<span class=\"line-number\">10</span>
<span class=\"line-number\">11</span>
<span class=\"line-number\">12</span>
<span class=\"line-number\">13</span>
<span class=\"line-number\">14</span>
<span class=\"line-number\">15</span>
<span class=\"line-number\">16</span>
<span class=\"line-number\">17</span>
<span class=\"line-number\">18</span>
<span class=\"line-number\">19</span>
<span class=\"line-number\">20</span>
<span class=\"line-number\">21</span>
</pre></td><td class=\"code\"><pre><code class=\"latex\"><span class=\"line\">  <span class=\"k\">\\begin</span><span class=\"nb\">{</span>tikzpicture<span class=\"nb\">}</span>[>=latex',scale=0.5]
</span><span class=\"line\">    <span class=\"c\">% set node style</span>
</span><span class=\"line\">
</span><span class=\"line\">    <span class=\"k\">\\begin</span><span class=\"nb\">{</span>dot2tex<span class=\"nb\">}</span>[dot,tikz,codeonly,styleonly,options=-s -tmath]
</span><span class=\"line\">        digraph G  <span class=\"nb\">{</span>
</span><span class=\"line\">            node [style=\"n\"];
</span><span class=\"line\">            p [label=\"+\"];
</span><span class=\"line\">            t [texlbl=\"<span class=\"k\">\\LaTeX</span>\"];
</span><span class=\"line\">            6
</span><span class=\"line\">            8
</span><span class=\"line\">            10-> p;
</span><span class=\"line\">            6 -> t;
</span><span class=\"line\">            8 -> t;
</span><span class=\"line\">            t -> p;
</span><span class=\"line\">            <span class=\"nb\">{</span>rank=same; 10;6;8<span class=\"nb\">}</span>
</span><span class=\"line\">        <span class=\"nb\">}</span>
</span><span class=\"line\">    <span class=\"k\">\\end</span><span class=\"nb\">{</span>dot2tex<span class=\"nb\">}</span>.
</span><span class=\"line\">    <span class=\"k\">\\begin</span><span class=\"nb\">{</span>pgfonlayer<span class=\"nb\">}{</span>background<span class=\"nb\">}</span>
</span><span class=\"line\">        <span class=\"k\">\\draw</span><span class=\"na\">[rounded corners,fill=blue!20]</span> (6.north west) -- (8.north east) -- (t.south east)--cycle;
</span><span class=\"line\">    <span class=\"k\">\\end</span><span class=\"nb\">{</span>pgfonlayer<span class=\"nb\">}</span>
</span><span class=\"line\"><span class=\"k\">\\end</span><span class=\"nb\">{</span>tikzpicture<span class=\"nb\">}</span>
</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<div class=\"bogus-wrapper\"><notextile><figure id=\"example2\">
<img src=\"http://farm4.staticflickr.com/3804/9241070475_9d48236aa7_o.png\" alt=\"Example of TeX typesetting + TikZ background\" height=\"410\" width=\"430\" />
<figcaption><strong>Figure 2.</strong> Example of TeX typesetting + TikZ background</figcaption>
</figure></notextile></div>
<p>For more TikZ goodness check out the <a href=\"http://www.texample.net/tikz/examples/\">example site</a>.</p>
<p>Happy writing!</p>" nil nil "c8ca14243baff31724dd70d925a508e0") (248 (20963 45898 537609) "http://feedproxy.google.com/~r/FpComplete/~3/AqtR2WFTzGY/new-product-tab" "FP Complete: FP Complete Product Tab" nil "Mon, 08 Jul 2013 19:51:00 +0000" "<p><b>FP Complete Product Tab</b></p><p>Now that the Beta has been released, we want to be sure our users
have everything they need to be successful. Visit our new <a href=\"https://www.fpcomplete.com/business/haskell-center/overview\">product tab</a>
to access the following features:</p><ul><li><a href=\"https://www.fpcomplete.com/business/haskell-center/overview\">FP Haskell
Center</a> (product overview)</li><li><a href=\"https://www.fpcomplete.com/business/haskell-center/video-walk-through\">Video
Walk Through</a> of FP Haskell Center (Step-by-step overview of our services)</li><li>FP Haskell Center <a href=\"https://www.fpcomplete.com/business/haskell-center/release-notes\">Release
Notes</a> (Beta information)</li><li>FP Haskell Center <a href=\"https://www.fpcomplete.com/business/haskell-center/feature-checklist\">Feature
Check List</a> (Notes to help you get started and features we want you to test)</li><li><a href=\"https://www.fpcomplete.com/school\">School
of Haskell</a> (Tutorials and feature articles)</li></ul><p>Our library continues to grow and is full of valuable information to help you be
successful with your Haskell projects. From design through implementation, we want
to be sure you have access to everything you need. If you think we’re missing
anything let us know. We’d love to hear from you. </p><div class=\"feedflare\">
<a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=AqtR2WFTzGY:mHc2Ux6eEFo:yIl2AUoC8zA\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=yIl2AUoC8zA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=AqtR2WFTzGY:mHc2Ux6eEFo:V_sGLiPBpWU\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=AqtR2WFTzGY:mHc2Ux6eEFo:V_sGLiPBpWU\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=AqtR2WFTzGY:mHc2Ux6eEFo:qj6IDK7rITs\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=qj6IDK7rITs\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=AqtR2WFTzGY:mHc2Ux6eEFo:gIN9vFwOqvQ\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=AqtR2WFTzGY:mHc2Ux6eEFo:gIN9vFwOqvQ\" border=\"0\" /></a>
</div><img src=\"http://feeds.feedburner.com/~r/FpComplete/~4/AqtR2WFTzGY\" height=\"1\" width=\"1\" />" nil nil "044c38c066776e94f436d1be07eb4223") (247 (20963 45898 537203) "http://byorgey.wordpress.com/2013/07/08/farm-2013-call-for-demonstration-proposals/" "Brent Yorgey: FARM 2013: call for demonstration proposals" nil "Mon, 08 Jul 2013 16:57:37 +0000" "<p>Do you enjoy writing beautiful code to produce beautiful artifacts? Have something cool to show off at the intersection of functional programming and visual art, music, sound, modeling, visualization, or design?</p>
<p>The deadline for submitting a paper has passed, but the <a href=\"http://www.cis.upenn.edu/~byorgey/farm13/\">Workshop on Functional Art, Music, Modeling and Design (FARM 2013)</a> is currently seeking proposals for <em>10-20 minute demonstrations</em> to be given during the workshop. For example, a demonstration could consist of a short tutorial, an exhibition of some work, or even a livecoding performance. Slots for demonstrations will be shorter than slots for accepted papers, and will not be published as part of the formal proceedings, but can be a great way to show off interesting work and get feedback from other workshop participants. A demonstration slot could be a particularly good way to get feedback on work-in-progress.</p>
<p>A demo proposal should consist of a 1 page abstract, in PDF format, explaining the proposed content of the demonstration and why it would be of interest to the attendees of FARM. Proposals will be judged on interest and relevance to the stated goals and themes of the workshop.</p>
<p>Submissions can be <a href=\"https://www.easychair.org/conferences/?conf=farm2013\">made via EasyChair</a>.</p>
<br />  <a href=\"http://feeds.wordpress.com/1.0/gocomments/byorgey.wordpress.com/1092/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/byorgey.wordpress.com/1092/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=byorgey.wordpress.com&blog=1152889&post=1092&subd=byorgey&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "d98d343f67dafc08f4aee94050c5cbf8") (246 (20963 45898 536827) "http://parenz.wordpress.com/2013/07/08/the-protocol-problem/" "Daniil Frumin: The Protocol Problem" nil "Mon, 08 Jul 2013 16:21:06 +0000" "<p>In the interactive-diagrams project we have a bunch of components (processes) running independently and even under different UIDs. They however need to communicate with each other, and we’ve decided to go full UNIX-way (since already most of our code depend on POSIX-compatibility) and use IPC/UNIX-sockets for communication.</p>
<p>Originally, I’ve implemented the following protocol for sending the<br />
data around:</p>
<p>When sending data:</p>
<ol class=\"org-ol\">
<li>Encode the data using the functions from the <a href=\"http://hackage.haskell.org/package/cereal\">cereal</a> package.</li>
<li>Take the ‘length’ of the resulting bytestring, send it over the<br />
socket.</li>
<li>Send the encoded data on the next line.</li>
</ol>
<p>Upon receiving data:</p>
<ol class=\"org-ol\">
<li>Read the first line, deserialize it to an <code>x :: Int</code></li>
<li>Read the the next <code>x</code> bytes, deserialize the data.</li>
</ol>
<p>A programmer experienced in the area would have probably already<br />
spotted an error in this approach, but for me it took some time to<br />
find a bug, once I’ve realised that I was getting deserialization<br />
errors from time to time.</p>
<p>The problem of course is that I was relying on reading lines from the<br />
socket, not bytes. For example, the number 2623 on my 64bit system has<br />
serialized to something with the newline character in it</p>
<div class=\"figure\">
<p><img src=\"http://orbt.io/Q6I3.png\" alt=\"Q6I3.png\" /></p>
</div>
<p>The solution to this problem is to read the first ’8′ (or ’4′) bytes<br />
to get the length of the upcoming data. To make sure that the number<br />
of bytes representing the length of the data is constant on all the<br />
platforms I’ve switched to using <code>Word32</code>.</p>
<p>This approach too, of course, is not prone to errors. If you are<br />
sending and receiving a lot of data consider using a streaming<br />
library.</p>
<p>PS: We’ve planned originally to release the first public alpha-version yesterday, but it turned out that it is actually taking more time configuring SELinux, chroots and other security measure than expected. I’ve also changed the general structure of the project, I am using a different design model than I had a week ago. The new changes would make the application more salable and the resulting library can (and most likely will) be reused for other stuff. Stay tuned!</p>
<br /> Tagged: <a href=\"http://parenz.wordpress.com/tag/haskell-2/\">haskell</a>, <a href=\"http://parenz.wordpress.com/tag/interactive-diagrams/\">interactive-diagrams</a>, <a href=\"http://parenz.wordpress.com/tag/networking/\">networking</a>, <a href=\"http://parenz.wordpress.com/tag/soc/\">soc</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/parenz.wordpress.com/74/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/parenz.wordpress.com/74/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=parenz.wordpress.com&blog=26722965&post=74&subd=parenz&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "c60fff7a5f494d0f631ffaccda42cd6c") (245 (20963 45898 536220) "http://joyful.com/blog/2013-07-07-darcsden-db-thoughts.html" "Simon Michael: darcsden db thoughts" nil "Sun, 07 Jul 2013 23:00:00 +0000" "<div style=\"font-style: italic;\">July  7, 2013</div>
<h2>darcsden db thoughts</h2>
<p>
</p><p>Spent about half of yesterday setting up <a href=\"http://hub.darcs.net/Aditya/darcsden-import/changes\">Aditya’s darcsden patches</a> on the dev instance of hub.darcs.net, testing them, and exploring db migration issues.</p>
<p>Following BSRK’s instructions, I got the dev instance authenticating via Google’s OAuth servers. Good progress. The UI flow I saw needs a bit more work - eg logging in with google seemed to want me to register a new account. Or, there may be a problem with my setup at Google (wrong callback urls ?) - will have to review it with BSRK.</p>
<h3 id=\"schema-migrations\">Schema, migrations</h3>
<p>My dev instance has so far been using the same database as the live production instance. This is partly because I don’t yet know how to run a second CouchDB instance, partly to reduce complexity, partly to be able to compare old and new code with the same realistic data set.</p>
<p>This of course can lead to trouble, if old and new code require different schemas. darcsden uses CouchDB, a “schemaless” database, but of course there is an implicit schema required by the application code, even if couch doesn’t enforce one. I got more clarity on this when I noticed my dev instance experiments causing errors on the production app.</p>
<p>New darcsden code may include changes to the (implicit) db schema. In this case, there’s a change to the user’s password field. I need to notice such schema changes, and if I want to exercise them on the dev instance, I should first also install them on the production instance. Or, use a separate couchdb instance. Or, use separate databases in the couchdb instance. Or possibly, use separate views in the couchdb databases ?</p>
<p>Eg, here BSRK made the code nicely read user documents (db records) with the old or new schema. Before testing it on the shared db I should have deployed that patch to production as well as dev.</p>
<p>Looking ahead, is this approach (including code to deal with all old schemas) the best way to handle this ? Maybe. It makes things work and seems convenient, at least for now. But it also reminds me of years working with Zope’s ZODB (a schemaless python object database) and the layers of on-the-fly schema updating that built up, and the uncounted number of runtime bugs hunted down due to schema variations in individual objects.</p>
<h3 id=\"schema-less-or-schema-ful\">Schema-less or schema-ful ?</h3>
<p>While recovering from this, I learned some more about managing couchdb, schema migration, and current couchdb alternatives.</p>
<p>Couch has some really good and unusual qualities, and I feel I’m only scratching the surface of it’s power. Even so, I’m starting to feel a schema-ful, relational database is a better fit for darcsden/darcs hub. Replacing couch has been a topic of discussion on #darcs for some time, for other reasons. Here are some reasons to replace it:</p>
<ul>
<li><p>darcsden (more particularly, the instance running darcs hub, which has a lot of long-lived data) works best when all records have the same shape. It gains nothing from the flexibility of a loose schema, in fact will break, at runtime and unpredictably, unless you have extra code that handles all variations perfectly (a hard thing to test).</p></li>
<li><p>couchdb makes darcsden harder to set up, eg on windows. This makes it less successful in its goal to be an easy single-user ui for local darcs repos. It also reduces the number of darcsden hackers.</p></li>
<li><p>it adds complexity by embedding application code in the db. Instead of all logic being in haskell, the darcsden developer has to also deal with design documents and javascript map/reduce functions, and manage the state of those within the db.</p></li>
<li><p>it adds complexity by being less familiar to most people than rdbms system, and by having less mature tools.</p></li>
<li><p>persistent, the likely alternative, would more easily support both large installations (eg postgres for darcs hub) and single-user ones (sqlite) with less code.</p></li>
</ul>
<p>Some reasons not to:</p>
<ul>
<li><p>Don’t replace working code!</p></li>
<li><p>Replacing it could be wasted effort, better spent fixing end-user bugs on darcs hub.</p></li>
<li><p>The migration issue can easily be worked around. It’s not that big a deal for this instance.</p></li>
<li><p>Don’t disrupt the GSOC in progress!</p></li>
</ul>
<p>
<br />
<em><a href=\"http://joyful.com/tags/darcs.html\">darcs</a>, <a href=\"http://joyful.com/tags/haskell.html\">haskell</a>, <a href=\"http://joyful.com/tags/ops.html\">ops</a></em></p>" nil nil "26c67d30939643392091339486a2e260") (244 (20963 45898 534203) "http://feedproxy.google.com/~r/RomanCheplyaka/~3/RVdo6DFKhbc/2013-07-04.html" "Roman Cheplyaka: Quotation, fixed points, and quines" nil "Thu, 04 Jul 2013 00:00:00 +0000" "<h2 id=\"quotation\">Quotation</h2>
<p>Consider an untyped functional language, such as lambda calculus, Scheme, or JavaScript. There are many ways we can represent the terms of the language in the language itself:</p>
<ul>
<li><p>In Scheme, we can represent Scheme expressions by S-expressions: <code class=\"sourceCode scheme\">(<span class=\"kw\">+</span> <span class=\"dv\">1</span> <span class=\"dv\">2</span>)</code> is represented by <code class=\"sourceCode scheme\">'(<span class=\"kw\">+</span> <span class=\"dv\">1</span> <span class=\"dv\">2</span>)</code></p></li>
<li><p>In any language with strings (such as JavaScript) we could use textual representation of expressions: <code class=\"sourceCode javascript\"><span class=\"dv\">1+2</span></code> is represented by <code class=\"sourceCode javascript\"><span class=\"st\">\"1+2\"</span></code></p></li>
<li><p>In lambda calculus with natural numbers, Gödel numbers could be used: <span class=\"math\">\\(\\lambda x.y\\)</span> would be represented by, say, the term <span class=\"math\">\\(3\\)</span>.</p></li>
<li><p>In pure lambda calculus (without numbers), we can use Church encoding instead, so that <span class=\"math\">\\(\\lambda x.y\\)</span> becomes <span class=\"math\">\\(\\lambda f.\\lambda x. f(f(f(x)))\\)</span>.</p></li>
</ul>
<p>In each of these cases, we have a bijection between the set <span class=\"math\">\\(T\\)</span> of all terms and the set <span class=\"math\">\\(Q \\subset T\\)</span> of quotations. This bijection is realized by the functions <span class=\"math\">\\(q \\colon T \\to Q\\)</span> (for quote) and <span class=\"math\">\\(u \\colon Q \\to T\\)</span> (for unquote).</p>
<p>Note that <span class=\"math\">\\(q\\)</span> and <span class=\"math\">\\(u\\)</span> are set functions, not functions in our language. Still, we require them to be computable, that is, there should exist functions <span class=\"math\">\\(q_L, u_L\\in T\\)</span> such that</p>
<ul>
<li><span class=\"math\">\\(\\forall x\\in T\\; q_L(q(x))\\)</span> evaluates to <span class=\"math\">\\(q(q(x))\\)</span></li>
<li><span class=\"math\">\\(\\forall x\\in T\\; u_L(q(x))\\)</span> evaluates to <span class=\"math\">\\(q(u_L(x))\\)</span></li>
</ul><img src=\"http://feeds.feedburner.com/~r/RomanCheplyaka/~4/RVdo6DFKhbc\" height=\"1\" width=\"1\" />" nil nil "094c12496008fec4fea27b602d8ad665") (243 (20963 45898 530715) "http://joyful.com/blog/2013-07-01-june-review.html" "Simon Michael: June review" nil "Mon, 01 Jul 2013 23:00:00 +0000" "<div style=\"font-style: italic;\">July  1, 2013</div>
<h2>June review</h2>
<p>
</p><p>The beginning of a new month. Here’s a quick update.</p>
<p>No hledger release today as there isn’t much new to ship, following a month with several <a href=\"http://hledger.org/NEWS.html\">bugfix releases</a> and otherwise mostly infrastructural work (build and dev tool fixes, wiki styling, site update hook). 8/1 is the likely next release date. Oh, <a href=\"http://newartisans.com/\">John</a> and I also had a nice voice chat - nice to escape the IRC window isn’t it - reviewing our glorious *ledger plans, and I happily accepted his <a href=\"https://github.com/simonmichael/hledger/commit/a05e7a5a671af25b220eb4f152ad935687faef1a\">first hledger patch</a> - thanks John! :)</p>
<p>My free hacking time in recent weeks went more towards <a href=\"http://darcs.net\">darcs</a>:</p>
<ul>
<li><p>Unix shell helpers to get one-line-per-patch output from darcs (awesome!)</p>
<pre class=\"sourceCode bash\"><code class=\"sourceCode bash\"><span class=\"co\"># show darcs changes, push, pull etc. output with one patch per line</span>
<span class=\"co\"># Eg:</span>
<span class=\"co\"># dch --last 3</span>
<span class=\"co\"># darcs pull --dry | d1</span>
<span class=\"kw\">alias</span> darcsoneline=<span class=\"st\">\"egrep '^\\w' -A1 | egrep -v '^(--|The remote repository has|Would pu)' | sed '</span><span class=\"ot\">$!</span><span class=\"st\">N;s/\\n/ /'\"</span>
<span class=\"kw\">alias</span> d1=darcsoneline
<span class=\"kw\">function</span><span class=\"fu\"> dch()</span> <span class=\"kw\">{</span>
<span class=\"kw\">darcs</span> changes <span class=\"ot\">$*</span> <span class=\"kw\">|</span> <span class=\"kw\">darcsoneline</span>
<span class=\"kw\">}</span></code></pre></li>
<li><p>Support for BSRK Aditya’s <a href=\"http://hub.darcs.net/Aditya/darcsden-gsoc/changes\">GSOC work</a>. Together with Ganesh Sittampalam we did several rounds of code review and BSRK’s nice enhancements should be appearing on darcs hub soon.</p></li>
<li><p>Also driven by the above, updated <a href=\"http://hub.darcs.net/simon/darcsden/changes\">darcsden</a> and HSP for current GHC and libraries, and made it easy for me to build and deploy again. Also merged <a href=\"http://hub.darcs.net/ganesh/darcsden-service/changes\">Ganesh’s improvements</a> for MS Windows compatibility. This will be released as darcsden 1.1 shortly.</p></li>
<li><p>Ongoing <a href=\"http://hub.darcs.net\">darcs hub</a> ops/maintenance, including a fix for <a href=\"http://hub.darcs.net/simon/darcsden/issue/59\">this interesting segfault</a>, and a server upgrade from ubuntu 12.04 to 13.04. This last caused about <s>45m</s><a href=\"http://stats.pingdom.com/olo874j6ixzj/632910/2013/06\">1h20m of downtime >:(</a> late last night as I wrestled with the unfamiliar couchdb migration process and erlang stack traces. (For reference: just copy /var/lib/couchdb/1.0.1/* to 1.2.0/, but <em>don’t forget to preserve file ownership</em>.) At least it got resolved it before month-end at pingdom, so there’s a chance to get uptime back up where it should be - 3 or 4 nines - in July!</p></li>
</ul>
<p>
<br />
<em><a href=\"http://joyful.com/tags/hledger.html\">hledger</a>, <a href=\"http://joyful.com/tags/darcs.html\">darcs</a>, <a href=\"http://joyful.com/tags/haskell.html\">haskell</a>, <a href=\"http://joyful.com/tags/ops.html\">ops</a></em></p>" nil nil "043c0e412a7bb6602acf1332888c0df0") (242 (20963 45898 530001) "http://feedproxy.google.com/~r/ezyang/~3/tSmwYHznwqQ/" "Edward Z. Yang: HoTT exercises in Coq (in progress)" nil "Mon, 01 Jul 2013 20:21:18 +0000" "<div class=\"document\">
<p>I spent some of my plane ride yesterday working on Coq versions of the exercises in <a href=\"http://homotopytypetheory.org/book/\" class=\"reference external\">The HoTT book</a>. I got as far as 1.6 (yeah, not very far, perhaps I should make a GitHub repo if other folks are interested in contributing skeletons. Don't know what to do about the solutions though).  All of these have been test solved.</p>
<p>You will need HoTT/coq in order to run this development; instructions on <a href=\"https://github.com/HoTT/HoTT/blob/master/INSTALL.txt\" class=\"reference external\">how to install it are here.</a></p>
<p><strong>Update.</strong> Solutions and more exercises can be found at the <a href=\"https://github.com/ezyang/HoTT-coqex\" class=\"reference external\">HoTT-coqex</a> repository. I’ve done all of the nontrivial homotopy-specific exercises, and left out some of the more standard type theory exercises (which aren’t really homotopy specific). Some of the solutions are really terrible and could use some sprucing up.</p>
<pre class=\"literal-block\">Require Import HoTT.
Definition admit {T: Type} : T. Admitted.
(* Exercise 1.1 *)
Definition mycompose {A B C : Type} (g : B -> C) (f : A -> B) : A -> C := admit.
Goal forall (A B C D : Type) (f : A -> B) (g : B -> C) (h : C -> D),
mycompose h (mycompose g f) = mycompose (mycompose h g) f.
Admitted.
(* Exercise 1.2 *)
Section ex_1_2_prod.
Variable A B : Type.
Check @fst.
Check @snd.
Definition my_prod_rec (C : Type) (g : A -> B -> C) (p : A * B) : C := admit.
Goal fst = my_prod_rec A (fun a => fun b => a). Admitted.
Goal snd = my_prod_rec B (fun a => fun b => b). Admitted.
End ex_1_2_prod.
Section ex_1_2_sig.
Variable A : Type.
Variable B : A -> Type.
Check @projT1.
Check @projT2.
Definition my_sig_rec (C : Type) (g : forall (x : A), B x -> C) (p : exists (x : A), B x) : C := admit.
Goal @projT1 A B = my_sig_rec A (fun a => fun b => a). Admitted.
(* What goes wrong when you try to prove this for projT2? *)
End ex_1_2_sig.
(* Exercise 1.3 *)
Definition refl {A : Type} (x : A) : x = x := 1%path.
Section ex_1_3_prod.
Variable A B : Type.
(* Given by the book *)
Definition uppt : forall (x : A * B), ((fst x, snd x) = x) :=
fun p => match p with (a,b) => refl (a,b) end.
Definition my_prod_ind (C : A * B -> Type) (g : forall (x : A) (y : B), C (x, y)) (x : A * B) : C x := admit.
Goal forall C g a b, my_prod_ind C g (a, b) = g a b. Admitted.
End ex_1_3_prod.
Section ex_1_3_sig.
Variable A : Type.
Variable B : A -> Type.
Definition sig_uppt : forall (x : exists (a : A), B a), ((projT1 x; projT2 x) = x) := admit.
Definition mysig_ind (C : (exists (a : A), B a) -> Type) (g : forall (a : A) (b : B a), C (a; b)) (x : exists (a : A), B a) : C x := admit.
Goal forall C g a b, mysig_ind C g (a; b) = g a b. Admitted.
End ex_1_3_sig.
(* Exercise 1.4 *)
Fixpoint iter (C : Type) (c0 : C) (cs : C -> C) (n : nat) : C :=
match n with
| 0 => c0
| S n' => cs (iter C c0 cs n')
end.
Definition mynat_rec (C : Type) : C -> (nat -> C -> C) -> nat -> C := admit.
Eval compute in mynat_rec (list nat) nil (@cons nat) 2.
Eval compute in nat_rect (fun _ => list nat) nil (@cons nat) 2.
(* Exercise 1.5 *)
Definition mycoprod (A B : Type) := exists (x : Bool), Bool_rect (fun _ => Type) A B x.
Section ex_1_5.
Variable A B : Type.
Definition inl := existT (Bool_rect (fun _ => Type) A B) true.
Definition inr := existT (Bool_rect (fun _ => Type) A B) false.
Definition mycoprod_ind (C : mycoprod A B -> Type)
(l : forall (a : A), C (inl a))
(r : forall (b : B), C (inr b))
(x : mycoprod A B) : C x := admit.
Goal forall C l r x, mycoprod_ind C l r (inl x) = l x. Admitted.
Goal forall C l r x, mycoprod_ind C l r (inr x) = r x. Admitted.
End ex_1_5.
(* Exercise 1.6 *)
Definition myprod (A B : Type) := forall (x : Bool), Bool_rect (fun _ => Type) A B x.
Section ex_1_6.
Context `{Funext}.
Variable A B : Type.
Definition mypr1 (p : myprod A B) := p true.
Definition mypr2 (p : myprod A B) := p false.
Definition mymkprod (a : A) (b : B) : myprod A B := Bool_rect (Bool_rect (fun _ => Type) A B) a b.
Definition myprod_ind (C : myprod A B -> Type)
(g : forall (x : A) (y : B), C (mymkprod x y)) (x : myprod A B) : C x := admit.
Goal forall C g a b, myprod_ind C g (mymkprod a b) = g a b. Admitted.
End ex_1_6.
</pre>
<p>Actually, I lied. I haven't proved the last goal in exercise 1.6; my trouble is I don't know how to get function extensionality to compute, but I’m sure it’s something simple...</p>
</div>
<img src=\"http://feeds.feedburner.com/~r/ezyang/~4/tSmwYHznwqQ\" height=\"1\" width=\"1\" />" nil nil "479728d7345eb9cf061b38cfe172a6b2") (241 (20963 44460 481630) "http://winterkoninkje.dreamwidth.org/84971.html" "wren ng thornton: In search of algebraic theories" nil "Mon, 15 Jul 2013 03:28:20 +0000" "<p>An important notion that shows up in algebra is the idea of a free object. For example, we have the following free objects for their corresponding algebraic theories:</p>
<ul>
<li><code>NonemptyList A</code> — free semigroups</li>
<li><code>List A</code> — free monoids</li>
<li><code>NonemptyBag A</code> — free commutative semigroups</li>
<li><code>Bag A</code> [1] — free commutative monoids</li>
<li><code>NonemptySet A</code> — free commutative bands (band = idempotent semigroup)</li>
<li><code>Set A</code> — free commutative bands with identity</li>
</ul>
<p>Recently I've been coming across things whose quotient structure looks like:</p>
<blockquote><code><pre>Foo A B = List (NonemptyMap A (NonemptyList B))
Bar A B = (Foo A B, NonemptyList (A,B))</pre></code></blockquote>
<p>I'm curious if anyone has encountered either of these as free objects of some algebraic theory?</p>
<p>[1] I.e., a multiset. In order to get the proper quotienting structure, we can implement <code>Bag A</code> by <code>Map A Nat</code> where <code>a `elem` xs = member a xs</code> and <code>multiplicity a xs = maybe 0 (1+) (lookup a xs)</code>.</p><br /><br /><img src=\"http://www.dreamwidth.org/tools/commentcount?user=winterkoninkje&ditemid=84971\" alt=\"comment count unavailable\" height=\"12\" style=\"vertical-align: middle;\" width=\"30\" /> comments" nil nil "e7b47e2dc26e0bf16c0334adf040f79b") (240 (20963 44460 480646) "http://alessandrovermeulen.me/2013/07/13/the-difference-between-shallow-and-deep-embedding/" "Alessandro Vermeulen: The difference between shallow and deep embedding" nil "Sat, 13 Jul 2013 21:06:00 +0000" "<p>Deep and shallow embedding are terms associated with Domain Specific Languages
(DSL). A DSL is  a language geared toward a specific domain. The <a href=\"http://www.graphviz.org/content/dot-language\" target=\"_blank\">dot language</a> is
an example of such a DSL for describing Graphs. Conceptually, a shallow
embedding captures the semantics of the data of the domain in a data type and
provides a <em>fixed</em> interpretation of the data, whereas a deep embedding goes
beyond this and captures the semantics of the operations on the domain enabling
<em>variable</em> interpretations.</p>
<p>We will illustrate this difference by embedding a simple expression language
with summation, multiplication and constants in
<a href=\"http://www.haskell.org\">Haskell</a>. Haskell is especially well-suited for and
often used as a host language for embedded DSLs.</p>
<p>We express our language with the following interface. A type synonym <code>Exp</code> for
normal <code>Int</code>s and three separate functions representing summation,
multiplication, and constants.</p>
<div class=\"bogus-wrapper\"><notextile><figure class=\"code\"><figcaption><span></span></figcaption><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
<span class=\"line-number\">2</span>
<span class=\"line-number\">3</span>
<span class=\"line-number\">4</span>
<span class=\"line-number\">5</span>
</pre></td><td class=\"code\"><pre><code class=\"haskell\"><span class=\"line\"><span class=\"kr\">type</span> <span class=\"kt\">Exp</span> <span class=\"ow\">=</span> <span class=\"kt\">Int</span>
</span><span class=\"line\">
</span><span class=\"line\"><span class=\"nf\">plus</span>  <span class=\"ow\">::</span> <span class=\"kt\">Exp</span> <span class=\"ow\">-></span> <span class=\"kt\">Exp</span> <span class=\"ow\">-></span> <span class=\"kt\">Exp</span>
</span><span class=\"line\"><span class=\"nf\">times</span> <span class=\"ow\">::</span> <span class=\"kt\">Exp</span> <span class=\"ow\">-></span> <span class=\"kt\">Exp</span> <span class=\"ow\">-></span> <span class=\"kt\">Exp</span>
</span><span class=\"line\"><span class=\"nf\">const</span> <span class=\"ow\">::</span> <span class=\"kt\">Int</span>        <span class=\"ow\">-></span> <span class=\"kt\">Exp</span>
</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>We embedded the <em>data</em> of the domain in Haskell and provided functions for
construction of the  model and we can easily represent the calculation of an
expression as $4 + 6 * 8$ with the following lines of Haskell:</p>
<div class=\"bogus-wrapper\"><notextile><figure class=\"code\"><figcaption><span></span></figcaption><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
</pre></td><td class=\"code\"><pre><code class=\"haskell\"><span class=\"line\"><span class=\"nf\">val</span> <span class=\"ow\">=</span> <span class=\"n\">const</span> <span class=\"mi\">4</span> <span class=\"p\">`</span><span class=\"n\">plus</span><span class=\"p\">`</span> <span class=\"p\">(</span><span class=\"n\">const</span> <span class=\"mi\">6</span> <span class=\"p\">`</span><span class=\"n\">times</span><span class=\"p\">`</span> <span class=\"n\">const</span> <span class=\"mi\">8</span><span class=\"p\">)</span>
</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>The advantage of this embedding that calculating the value of our expression
is very fast. Other than the value we cannot determine anything else regarding
our expression. This becomes more problematic when we add variables to our
language.</p>
<p>We change our type to contain binding information and add two functions to
represent the assignment and usage of variables.</p>
<div class=\"bogus-wrapper\"><notextile><figure class=\"code\"><figcaption><span></span></figcaption><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
<span class=\"line-number\">2</span>
<span class=\"line-number\">3</span>
<span class=\"line-number\">4</span>
</pre></td><td class=\"code\"><pre><code class=\"haskell\"><span class=\"line\"><span class=\"kr\">type</span> <span class=\"kt\">Exp</span> <span class=\"ow\">=</span> <span class=\"p\">([</span><span class=\"kt\">String</span> <span class=\"err\">⊨</span> <span class=\"kt\">Int</span><span class=\"p\">],</span> <span class=\"kt\">Int</span><span class=\"p\">)</span>
</span><span class=\"line\">
</span><span class=\"line\"><span class=\"nf\">assign</span> <span class=\"ow\">::</span> <span class=\"kt\">String</span> <span class=\"ow\">-></span> <span class=\"kt\">Int</span> <span class=\"ow\">-></span> <span class=\"kt\">Exp</span>
</span><span class=\"line\"><span class=\"nf\">var</span>    <span class=\"ow\">::</span> <span class=\"kt\">String</span>        <span class=\"ow\">-></span> <span class=\"kt\">Exp</span>
</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>And in our naivity we can write the expression $x + 6 * 8$ as follows:</p>
<div class=\"bogus-wrapper\"><notextile><figure class=\"code\"><figcaption><span></span></figcaption><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
</pre></td><td class=\"code\"><pre><code class=\"haskell\"><span class=\"line\"><span class=\"nf\">val</span> <span class=\"ow\">=</span> <span class=\"n\">var</span> <span class=\"s\">\"x\"</span> <span class=\"p\">`</span><span class=\"n\">plus</span><span class=\"p\">`</span> <span class=\"p\">(</span><span class=\"n\">const</span> <span class=\"mi\">6</span> <span class=\"p\">`</span><span class=\"n\">times</span><span class=\"p\">`</span> <span class=\"n\">const</span> <span class=\"mi\">8</span><span class=\"p\">)</span>
</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>Obviously, evaluating this creates havoc! What is the value of <code>x</code>? We should,
of course, have introduced it first:</p>
<div class=\"bogus-wrapper\"><notextile><figure class=\"code\"><figcaption><span></span></figcaption><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
</pre></td><td class=\"code\"><pre><code class=\"haskell\"><span class=\"line\"><span class=\"nf\">val</span> <span class=\"ow\">=</span> <span class=\"kr\">let</span> <span class=\"s\">\"x\"</span> <span class=\"mi\">4</span> <span class=\"p\">(</span><span class=\"n\">var</span> <span class=\"s\">\"x\"</span> <span class=\"p\">`</span><span class=\"n\">plus</span><span class=\"p\">`</span> <span class=\"p\">(</span><span class=\"n\">const</span> <span class=\"mi\">6</span> <span class=\"p\">`</span><span class=\"n\">times</span><span class=\"p\">`</span> <span class=\"n\">const</span> <span class=\"mi\">8</span><span class=\"p\">))</span>
</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>Now we have assigned a value to <code>x</code> and we can safely use it in our
expression.</p>
<p>Had we used a deep embedding we could have prevented the cataclysmic error by
first checking whether each variable is assigned before it is used. We create
a deep embedding of our expression by using a Haskell data type.</p>
<div class=\"bogus-wrapper\"><notextile><figure class=\"code\"><figcaption><span></span></figcaption><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
<span class=\"line-number\">2</span>
<span class=\"line-number\">3</span>
<span class=\"line-number\">4</span>
<span class=\"line-number\">5</span>
<span class=\"line-number\">6</span>
</pre></td><td class=\"code\"><pre><code class=\"haskell\"><span class=\"line\"><span class=\"kr\">data</span> <span class=\"kt\">Exp</span> <span class=\"kr\">where</span>
</span><span class=\"line\">  <span class=\"kt\">Plus</span>   <span class=\"ow\">::</span> <span class=\"kt\">Exp</span> <span class=\"ow\">-></span> <span class=\"kt\">Exp</span>    <span class=\"ow\">-></span> <span class=\"kt\">Exp</span> <span class=\"c1\">-- plus</span>
</span><span class=\"line\">  <span class=\"kt\">Times</span>  <span class=\"ow\">::</span> <span class=\"kt\">Exp</span> <span class=\"ow\">-></span> <span class=\"kt\">Exp</span>    <span class=\"ow\">-></span> <span class=\"kt\">Exp</span> <span class=\"c1\">-- times</span>
</span><span class=\"line\">  <span class=\"kt\">Const</span>  <span class=\"ow\">::</span> <span class=\"kt\">Int</span>           <span class=\"ow\">-></span> <span class=\"kt\">Exp</span> <span class=\"c1\">-- const</span>
</span><span class=\"line\">  <span class=\"kt\">Assign</span> <span class=\"ow\">::</span> <span class=\"kt\">String</span> <span class=\"ow\">-></span> <span class=\"kt\">Int</span> <span class=\"ow\">-></span> <span class=\"kt\">Exp</span> <span class=\"c1\">-- assign</span>
</span><span class=\"line\">  <span class=\"kt\">Var</span>    <span class=\"ow\">::</span> <span class=\"kt\">String</span>        <span class=\"ow\">-></span> <span class=\"kt\">Exp</span> <span class=\"c1\">-- var</span>
</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>Note that we do not specify <em>how</em> the bindings should be stored, only that
such a thing exists. We now define a function that checks whether we use a
variable before it is defined.<sup id=\"fnref:folds\"><a href=\"http://alessandrovermeulen.me/atom.xml#fn:folds\" class=\"footnote\">1</a></sup></p>
<div class=\"bogus-wrapper\"><notextile><figure class=\"code\"><figcaption><span></span></figcaption><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
<span class=\"line-number\">2</span>
<span class=\"line-number\">3</span>
<span class=\"line-number\">4</span>
<span class=\"line-number\">5</span>
<span class=\"line-number\">6</span>
<span class=\"line-number\">7</span>
<span class=\"line-number\">8</span>
<span class=\"line-number\">9</span>
</pre></td><td class=\"code\"><pre><code class=\"haskell\"><span class=\"line\"><span class=\"nf\">useBeforeDefine</span> <span class=\"ow\">::</span> <span class=\"kt\">Exp</span> <span class=\"ow\">-></span> <span class=\"kt\">Bool</span>
</span><span class=\"line\"><span class=\"nf\">useBeforeDefine</span> <span class=\"n\">e</span> <span class=\"ow\">=</span> <span class=\"n\">f</span> <span class=\"kt\">[]</span>
</span><span class=\"line\">  <span class=\"kr\">where</span>
</span><span class=\"line\">  <span class=\"n\">f</span> <span class=\"ow\">::</span> <span class=\"p\">[</span><span class=\"kt\">String</span><span class=\"p\">]</span> <span class=\"ow\">-></span> <span class=\"kt\">Exp</span> <span class=\"ow\">-></span> <span class=\"kt\">Bool</span>
</span><span class=\"line\">  <span class=\"n\">f</span> <span class=\"p\">(</span><span class=\"kt\">Plus</span>  <span class=\"n\">l</span> <span class=\"n\">r</span><span class=\"p\">)</span> <span class=\"n\">env</span>      <span class=\"ow\">=</span> <span class=\"n\">useBeforeDefine</span> <span class=\"n\">l</span> <span class=\"n\">env</span> <span class=\"o\">||</span> <span class=\"n\">useBeforeDefine</span> <span class=\"n\">r</span> <span class=\"n\">env</span>
</span><span class=\"line\">  <span class=\"n\">f</span> <span class=\"p\">(</span><span class=\"kt\">Times</span> <span class=\"n\">l</span> <span class=\"n\">r</span><span class=\"p\">)</span> <span class=\"n\">env</span>      <span class=\"ow\">=</span> <span class=\"n\">useBeforeDefine</span> <span class=\"n\">l</span> <span class=\"n\">env</span> <span class=\"o\">||</span> <span class=\"n\">useBeforeDefine</span> <span class=\"n\">r</span> <span class=\"n\">env</span>
</span><span class=\"line\">  <span class=\"n\">f</span> <span class=\"p\">(</span><span class=\"kt\">Const</span> <span class=\"kr\">_</span><span class=\"p\">)</span>   <span class=\"kr\">_</span>        <span class=\"ow\">=</span> <span class=\"kt\">False</span>
</span><span class=\"line\">  <span class=\"n\">f</span> <span class=\"p\">(</span><span class=\"kt\">Assign</span> <span class=\"n\">var</span> <span class=\"kr\">_</span> <span class=\"n\">e</span><span class=\"p\">)</span> <span class=\"n\">env</span> <span class=\"ow\">=</span> <span class=\"n\">useBeforeDefine</span> <span class=\"n\">e</span> <span class=\"p\">(</span><span class=\"n\">var</span> <span class=\"kt\">:</span> <span class=\"n\">env</span><span class=\"p\">)</span>
</span><span class=\"line\">  <span class=\"n\">f</span> <span class=\"p\">(</span><span class=\"kt\">Var</span> <span class=\"n\">var</span><span class=\"p\">)</span>        <span class=\"n\">env</span> <span class=\"ow\">=</span> <span class=\"n\">not</span> <span class=\"p\">(</span><span class=\"n\">var</span> <span class=\"p\">`</span><span class=\"n\">elem</span><span class=\"p\">`</span> <span class=\"n\">env</span><span class=\"p\">)</span>
</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>With the function above we can <em>check</em> whether an expression is well-formed.
With our deep embedding we can even define transformations of our expression;
e.g. differentiate with respect to a variable.</p>
<div class=\"bogus-wrapper\"><notextile><figure class=\"code\"><figcaption><span></span></figcaption><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
<span class=\"line-number\">2</span>
<span class=\"line-number\">3</span>
<span class=\"line-number\">4</span>
<span class=\"line-number\">5</span>
<span class=\"line-number\">6</span>
<span class=\"line-number\">7</span>
</pre></td><td class=\"code\"><pre><code class=\"haskell\"><span class=\"line\"><span class=\"nf\">diff</span> <span class=\"ow\">::</span> <span class=\"kt\">Exp</span> <span class=\"ow\">-></span> <span class=\"kt\">String</span> <span class=\"ow\">-></span> <span class=\"kt\">Exp</span>
</span><span class=\"line\"><span class=\"nf\">diff</span> <span class=\"p\">(</span><span class=\"kt\">Plus</span>  <span class=\"n\">l</span> <span class=\"n\">r</span><span class=\"p\">)</span> <span class=\"n\">dx</span>      <span class=\"ow\">=</span> <span class=\"n\">diff</span> <span class=\"n\">l</span> <span class=\"n\">dx</span> <span class=\"p\">`</span><span class=\"kt\">Plus</span><span class=\"p\">`</span> <span class=\"n\">diff</span> <span class=\"n\">r</span> <span class=\"n\">dx</span>
</span><span class=\"line\"><span class=\"nf\">diff</span> <span class=\"p\">(</span><span class=\"kt\">Times</span> <span class=\"n\">l</span> <span class=\"n\">r</span><span class=\"p\">)</span> <span class=\"n\">dx</span>      <span class=\"ow\">=</span> <span class=\"p\">(</span><span class=\"n\">diff</span> <span class=\"n\">l</span> <span class=\"n\">dx</span> <span class=\"p\">`</span><span class=\"kt\">Times</span><span class=\"p\">`</span> <span class=\"n\">r</span><span class=\"p\">)</span> <span class=\"p\">`</span><span class=\"kt\">Plus</span><span class=\"p\">`</span> <span class=\"p\">(</span><span class=\"n\">l</span> <span class=\"p\">`</span><span class=\"kt\">Times</span><span class=\"p\">`</span> <span class=\"n\">diff</span> <span class=\"n\">r</span> <span class=\"n\">dx</span><span class=\"p\">)</span>
</span><span class=\"line\"><span class=\"nf\">diff</span> <span class=\"p\">(</span><span class=\"kt\">Const</span> <span class=\"kr\">_</span><span class=\"p\">)</span>   <span class=\"kr\">_</span>       <span class=\"ow\">=</span> <span class=\"kt\">Const</span> <span class=\"mi\">0</span>
</span><span class=\"line\"><span class=\"nf\">diff</span> <span class=\"p\">(</span><span class=\"kt\">Assign</span> <span class=\"n\">var</span> <span class=\"n\">x</span> <span class=\"n\">e</span><span class=\"p\">)</span> <span class=\"n\">dx</span> <span class=\"ow\">=</span> <span class=\"kt\">Assign</span> <span class=\"n\">var</span> <span class=\"n\">x</span> <span class=\"p\">(</span><span class=\"n\">diff</span> <span class=\"n\">e</span> <span class=\"n\">dx</span><span class=\"p\">)</span>
</span><span class=\"line\"><span class=\"nf\">diff</span> <span class=\"p\">(</span><span class=\"kt\">Var</span> <span class=\"n\">var</span><span class=\"p\">)</span>        <span class=\"n\">dx</span> <span class=\"o\">|</span> <span class=\"n\">var</span> <span class=\"o\">==</span> <span class=\"n\">dx</span> <span class=\"ow\">=</span> <span class=\"kt\">Const</span> <span class=\"mi\">1</span>
</span><span class=\"line\">                         <span class=\"o\">|</span> <span class=\"n\">otherwise</span> <span class=\"ow\">=</span> <span class=\"kt\">Const</span> <span class=\"mi\">0</span>
</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>Deep embedding allows us to utilize the semantics of our model by defining
multiple interpretations of our DSL. The downside is that just calculating the
value of our expression has become slower due to the added overhead of the
constructors, whereas the shallow embedding can be evaluated by only using
<code>Int</code>s.</p>
<p>In short:</p>
<ul>
<li><strong>Shallow embedding</strong> should be used when you only need a single interpretation or
when you are in a hurry.</li>
<li><strong>Deep embedding</strong> should be used in all other cases.</li>
</ul>
<p>More reading material on this subject:</p>
<ul>
<li>This <a href=\"http://www.cse.chalmers.se/~josefs/DSLTutorial/tutorialSlides.html\">presentation</a> by Josef Svenningsson.</li>
<li><a href=\"http://www.cse.chalmers.se/~josefs/publications/TFP12.pdf\">Combining Deep and Shallow Embedding for EDSL</a> (Josef Svenningsson and Emil Axelsson, 2012)</li>
<li><a href=\"https://www4.in.tum.de/~nipkow/pubs/tphols04.html\">Certifying Machine Code Safety: Shallow versus Deep Embedding</a> (Martin Wildmoser and Tobias Nipkow, 2004)</li>
<li><a href=\"http://cstheory.stackexchange.com/questions/1370/shallow-versus-deep-embeddings\">Deep versus Shallow embeddings in Coq</a></li>
</ul>
<div class=\"footnotes\">
<ol>
<li id=\"fn:folds\">
<p>Most often you should use <a href=\"http://alessandrovermeulen.me/2009/12/17/haskell-datatypes-and-folds/\">folds</a> (<a href=\"http://alessandrovermeulen.me/2010/01/03/haskell-datatypes-and-folds-part-ii/\">2</a>) instead of this direct recursion. <a href=\"http://alessandrovermeulen.me/atom.xml#fnref:folds\" class=\"reversefootnote\">↩</a></p>
</li>
</ol>
</div>" nil nil "a825ac5f85a74ff5f3bca67ca0d1be60") (239 (20963 44460 478171) "http://winterkoninkje.dreamwidth.org/81209.html" "wren ng thornton: Finite sets" nil "Sat, 13 Jul 2013 20:43:01 +0000" "<p>So, I just encountered a <a href=\"http://hackage.haskell.org/packages/archive/countable/0.1/doc/html/Data-Searchable.html#v:assemble\">most delicious type</a> the other day:</p><p>
</p><blockquote><code><pre>class Finite a where
assemble :: Applicative f => (a -> f b) -> f (a -> b)</pre></code></blockquote>
<p>What's so nice about it is that the only way you can implement it is if the type <code>a</code> is in fact finite. (But see the notes.) So the questions are:</p>
<ul>
<li>Can you see why?</li>
<li>Can you figure out how to implement it for some chosen finite type?</li>
<li>Can you figure out how to implement it in general, given a list of all the values? (you may assume <code>Eq a</code> for this one)</li>
<li>Can you figure out how to get a list of all the values, given some arbitrary implementation of <code>assemble</code>?</li>
</ul>
<span class=\"cuttag_container\"><span style=\"display: none;\" id=\"span-cuttag___1\" class=\"cuttag\"></span><b>( <a href=\"http://winterkoninkje.dreamwidth.org/81209.html#cutid1\">A trivial note</a> )</b><div style=\"display: none;\" id=\"div-cuttag___1\"></div></span>
<span class=\"cuttag_container\"><span style=\"display: none;\" id=\"span-cuttag___2\" class=\"cuttag\"></span><b>( <a href=\"http://winterkoninkje.dreamwidth.org/81209.html#cutid2\">A big note, also a hint perhaps</a> )</b><div style=\"display: none;\" id=\"div-cuttag___2\"></div></span><br /><br /><img src=\"http://www.dreamwidth.org/tools/commentcount?user=winterkoninkje&ditemid=81209\" alt=\"comment count unavailable\" height=\"12\" style=\"vertical-align: middle;\" width=\"30\" /> comments" nil nil "89690de96f5b6ad79c848d3adce23d38") (238 (20963 44460 477741) "http://joyful.com/blog/2013-06-18-darcsden-cleanup.html" "Simon Michael: darcsden cleanup" nil "Sat, 13 Jul 2013 00:31:00 +0000" "<div style=\"font-style: italic;\">June 19, 2013</div>
<h2>darcsden cleanup</h2>
<p>
</p><p>Back to the dev diary. <a href=\"http://joyful.com/2013-06-08-zwiki-styling.html\">Last post</a> was 11 days ago, after a two-week opening streak of daily posts. I got blocked on one, then got busy. Press on.</p>
<p>Yesterday I started looking at BSRK Aditya’s <a href=\"http://bsrkaditya.blogspot.com/2013/06/gsoc-2013-enhancing-darcsden-preweek-1.html\">GSOC darcsden enhancements</a>, to review and hopefully deploy on <a href=\"http://hub.darcs.net\">darcs hub</a>. So far he has worked on alternate login methods (github/google), password reminder, and darcs pack support (for faster gets).</p>
<p>This is forcing some darcsden cleanup, my first darcsden work in a while aside from routine ops and support tasks. I’m going to release what’s in trunk as 1.1, and then start assimilating the new work by BSRK, Ganesh Sittampalam and anyone else who feels like chipping in. Started putting together release notes and a hub status update.</p>
<p>The support requests seem to be on the rise - more usage ? I also found a good bug today: viewing a certain 1K troff file causes darcs hub’s memory footprint to <a href=\"http://hub.darcs.net/simon/darcsden/issue/58\">blow up to 1.5G</a> :)</p>
<p>It would be great to have more functionality (like highlighting) broken out into separate, expendable worker processes, erlang style.</p>
<p>
<br />
<em><a href=\"http://joyful.com/tags/darcs.html\">darcs</a>, <a href=\"http://joyful.com/tags/haskell.html\">haskell</a></em></p>" nil nil "181dd76112929ea8c77cb2f04f4fffc7") (237 (20963 44460 477310) "http://joyful.com/blog/2013-06-08-zwiki-styling.html" "Simon Michael: Zwiki styling" nil "Sat, 13 Jul 2013 00:30:00 +0000" "<div style=\"font-style: italic;\">June  8, 2013</div>
<h2>Zwiki styling</h2>
<p>
</p><p><a href=\"http://joyful.com/2013-06-07-git-hooks-for-site-updates.html\">Yesterday</a>.</p>
<p>Next backlog item: <a href=\"https://trello.com/card/5127f6bb0698a36663002981/16\">style the wiki more like hledger.org</a>.</p>
<p>The wiki software is my own <a href=\"http://zwiki.org\">Zwiki</a> engine. I haven’t skinned a zwiki for a few years, but with the docs (<a href=\"http://zwiki.org/CustomizingAppearance\">CustomizingAppearance</a>, <a href=\"http://zwiki.org/QuickReference#skin-templates\">QuickReference -> skin templates</a>, <a href=\"http://zwiki.org/zwikidir/skins/zwiki\">standard templates</a>) plus experience, it went pretty smoothly.</p>
<p>Zwiki config changes at this point:</p>
<ul>
<li>pasted the standard maintemplate.pt into a Page Template with the same name in the wiki folder, with the hledger.org stylesheet and nav buttons added (in the head and body respectively)</li>
<li>added a style override to give the <code>#content</code> div a zero margin</li>
<li>renamed FrontPage to “hledger wiki”, and configured the new name in a <code>default_page</code> property on the wiki folder</li>
<li>disabled the icon in the zwiki page header by adding a <code>site_logo</code> folder property containing an empty html comment</li>
<li>committed a bugfix for a broken image border that was appearing in the rating form</li>
</ul>
<p>What didn’t work: rewording Zwiki’s “home” navigation link. My custom <code>links.pt</code> page template should do the trick, but it’s being ignored. This is unsatisfying, I suppose I will dig in and debug it, after a suitable cooling-off-and-reflection period.</p>
<p>Zope is still very impressive, and pleasing to use.</p>
<p>Here’s the <a href=\"http://hledger.org/wiki\">wiki</a>, now looking like part of hledger.org.</p>
<p>
<br />
<em><a href=\"http://joyful.com/tags/zwiki.html\">zwiki</a>, <a href=\"http://joyful.com/tags/hledger.html\">hledger</a></em></p>" nil nil "877a6a57cba8cf89e95268defc7d20b5") (236 (20963 44460 476861) "http://feedproxy.google.com/~r/CartesianClosedComic/~3/Pc8C-6IJguk/20.html" "Cartesian Closed Comic: Weird language" nil "Sat, 13 Jul 2013 00:00:00 +0000" "<a href=\"http://ro-che.info/ccc/20.html\"><img src=\"http://ro-che.info/ccc/thumbs/language.png\" /></a><br />
<img src=\"http://feeds.feedburner.com/~r/CartesianClosedComic/~4/Pc8C-6IJguk\" height=\"1\" width=\"1\" />" nil nil "e5f380e4a0fb6d3b139c3f0d42baa931") (235 (20963 44460 476342) "http://praisecurseandrecurse.blogspot.com/2013/07/the-polar-game-in-haskell-day-5-34-more.html" "Paul Potts: The Polar Game in Haskell, Day 5 3/4: a Bug Fix and liftM" "noreply@blogger.com (Paul Potts)" "Fri, 12 Jul 2013 22:17:00 +0000" "<p>Jeff Licquia has been playing further with the code and so have I. He discovered a bug in the version I posted in yesterday's installment (my bad). In slide' I neglected to call slide' in the recursive version of slide' but called the existing non-monadic slide. In other words, I had:</p> <pre>slide' ( t : Empty : ts ) = noscore ( Empty : ( slide ( t : ts ) ) )</pre> <p>The problem here is that we'll add nothing to the accumulated score, and proceed into a chain of function invocations that handle ordinary lists. So the score increase that should happen at that point never happens:</p> <pre>*Main> runWriter $ collide' [Heart, House]<br />([Empty,House],Sum {getSum = 1})<br />*Main> runWriter $ collide' [Heart, Empty, House]<br />([Empty,Empty,House],Sum {getSum = 0})</pre> <p>Oops. Yeah, that's a bug. Note that the compiler can't catch this because it's doing what I've asked; there are not actually any type conflicts. The monadic slide' returns the type it is supposed to return, but in building up the \"payload, the <b>[ Tile ]</b> part of <b>ScoreTracker [ Tile ]</b>, the code fails to continue to build up the state. Let this be a lesson to me -- leaving around the previous version of a function, when I'm testing a new one can be hazardous!</p> <p>So, we can just fix that by calling slide', right?</p> <pre>slide' ( t : Empty : ts ) = noscore ( Empty : ( slide' ( t : ts ) ) )</pre> <p>Um, not so much:</p> <pre>arctic-slide.hs:52:49:<br />    Couldn't match expected type `[Tile]'<br />                with actual type `ScoreTracker [Tile]'<br />    In the return type of a call of slide'<br />    In the second argument of `(:)', namely `(slide' (t : ts))'<br />    In the first argument of `noscore', namely<br />      `(Empty : (slide' (t : ts)))'</pre> <p>Oh... yeah. There's that. We want to continue building up the monadic version of the list, but the <b>(:)</b> just takes a regular list. Now it's all complicated! But really there's a simple solution. I'll quote Jeff for a while, since he explained it so well to me. I have not quoted his code <i>exactly</i>, but the ideas are the same:</p> <blockquote>...the straightforward fix fails, because <b>slide'</b> returns a <b>ScoreTracker</b>, not a <b>[ Tile ]</b>.  So the fix is a little more complicated. Since <b>slide'</b> returns pretty much exactly what we need, we can start with just that:</blockquote> <pre>slide' ( t : Empty : ts ) = slide' ( t : ts )</pre> <blockquote>That's not quite right; we just dropped a tile. To get it back, remember that everything is a function, including the : operator [and so it is easily composed with other functions -- PRP]. That means we can create a function that prepends an Empty element to a list...</blockquote> <pre>prefix_empty :: [ Tile ] -> [ Tile ] <br />prefix_empty ts = Empty : ts</pre> <blockquote>So why would we do this? Because we need to take ScoreTracker into account. Here Haskell provides a function called \"liftM\", which takes a normal function and \"lifts\" it into a monad. So:</blockquote> <pre>prefix_empty_st :: ScoreTracker [ Tile ] -> ScoreTracker [ Tile ]<br />prefix_empty_st = liftM prefix_empty</pre> <blockquote>will give us a function with the type <b>ScoreTracker [ Tile ] -> ScoreTracker [ Tile ]</b>, which is what we want. (Technically, that's not true; it gives us <b>Monad m => m [ Tile ] -> m [ Tile ]</b>.  But that's just a generic version of what we want, which works with <b>ScoreTracker</b>, <b>Maybe</b>, or lots of other monads).</blockquote> <p>So now we have this:</p> <pre>slide' ( t : Empty : ts ) = prefix_empty_st $ slide' ( t : ts )</pre> <p>Which doesn't use <b>score</b> or <b>noscore</b> -- it just builds up the list, still in a monadic context, preserving whatever score changes might be applied by the function invocations it makes. And actually since we're not going to use the prefix functions elsewhere, they don't really earn their keep, and we can just write:</p> <pre>slide' ( t : Empty : ts ) = liftM ( Empty : ) $ slide' ( t : ts )</pre> <p>Note the partial application of <b>(:)</b> by binding it to only one parameter before we pass it to <b>liftM</b> -- we're creating a new version of <b>(:)</b> that only takes one argument instead of two.</p> <p>Jeff went on to identify a second bug, basically caused by the same problem in a collide' function also calling slide instead of slide'. A quick fix is to make that collide' function look like the slide' function we just fixed. But then, why not define one in terms of the other?</p> <pre>collide' ( t : Empty : ts ) | movable t = slide' ( t : Empty : ts )</pre> <p>Let's go back a bit and reconsider -- when I was using a special value for Edge, the logic for slide and collide was considerably simpler (although it did not work right). Here it is today:</p> <pre>slide' :: [ Tile ] -> ScoreTracker [ Tile ]<br />slide' ( Ice_Block : ts ) | ( null ts ) || ( blocking $ head ts ) =<br />    noscore ( Ice_Block : ts )<br />slide' ( t : Empty : ts ) = liftM ( Empty : ) $ slide' ( t : ts )<br />slide' ( t : ts ) | ( null ts ) || ( blocking $ head ts ) =<br />    collide' ( t : ts )<br /><br />collide' :: [ Tile ] -> ScoreTracker [ Tile ]<br />collide' [] = noscore []<br />collide' ( t : ts ) | fixed t = noscore ( t : ts )<br />collide' ( Bomb : Mountain : ts) = noscore ( [ Empty, Empty ] ++ ts )<br />collide' ( Heart : House : ts ) = score ( [ Empty, House ] ++ ts )<br />collide' ( Ice_Block : ts ) | ( null ts ) || ( blocking $ head ts ) =<br />    noscore ( Empty : ts )<br />collide' ( t : ts ) | ( movable t ) && ( ( null ts ) ||<br />    ( blocking $ head ts ) ) = noscore ( t : ts )<br />collide' ( t : Empty : ts ) | movable t =<br />    slide' ( t : Empty : ts )</pre> <p>Erm. I'd no longer call that elegant, beautiful code. For one thing, I have to wrap it brutally to fit into my Blogger text window. That's not just annoying when dealing with Blogger -- it suggests that the lines are too long for easy reading even if they aren't wrapped. And here's what Jeff's version looks like today -- he's implemented his own way to structure the code with guards:</p> <pre>slide :: [ Tile ] -> ScoreTracker [ Tile ]<br />slide [] = noscore []<br />slide ( t1 : t2 : ts )<br />  | t1 == Ice_Block && blocking t2 = noscore ( t1 : t2 : ts )<br />  | blocking t2 = collide ( t1 : t2 : ts )<br />  | otherwise = do<br />                  ts' <- slide ( t1 : ts )<br />                  return ( Empty : ts' )<br />slide ( t : ts )<br />  | t == Ice_Block = noscore ( t : ts )<br />  | otherwise = collide ( t : ts )<br /><br />collide :: [ Tile ] -> ScoreTracker [ Tile ]<br />collide [] = noscore []<br />collide ( t1 : t2 : ts )<br />  | ( t1, t2 ) == ( Bomb, Mountain ) = noscore ( Empty : Empty : ts )<br />  | ( t1, t2 ) == ( Heart, House ) = score ( Empty : House : ts )<br />  | t1 == Ice_Block && blocking t2 = noscore ( Empty : t2 : ts )<br />  | movable t1 && blocking t2 = noscore ( t1 : t2 : ts )<br />  | movable t1 = do<br />                   ts' <- slide ( t1 : ts )<br />                   return ( Empty : ts' )<br />  | otherwise = noscore ( t1 : t2 : ts )<br />collide ( t : ts )<br />  | t == Ice_Block = noscore ( Empty : ts )<br />  | otherwise = noscore ( t : ts )</pre> <p>And I like that -- using the separate functions for both slide and collide only to handle the <b>structurally</b> different versions -- empty list, list with at least two items, list with at least one item -- and the <i>guards</i> to handle when we differ by value. It is, I think, more readable than mine. I was a little freaked out by the use of <b>do</b> and <b><-</b> in the middle of a function outside of main, but I'll think on that some more. I have not quite satisfied myself that it is perfectly correct, but then, I haven't really convinced myself that mine is correct either. So I have more to do on that front!</p>" nil nil "0c4cf249a7b2c74b631234a8ae1715c4") (234 (20963 44460 474966) "http://existentialtype.wordpress.com/2013/07/10/constructive-mathematics-is-not-meta-mathematics/" "Robert Harper: Constructive Mathematics Is Not Metamathematics" nil "Fri, 12 Jul 2013 17:54:56 +0000" "<p>The publication of the <a href=\"http://www.homotopytypetheory.org/book\">Homotopy Type Theory book</a> has renewed interest in type theory as a foundation for mathematics, and spurred computer scientists to investigate the computational meaning of higher-dimensional types. As I mentioned in a <a href=\"http://existentialtype.wordpress.com/2013/06/22/whats-the-big-deal-with-hott/\" title=\"What’s the big deal with HoTT?\">previous post</a>, what makes HoTT work so well for homotopy theory is that it is <em>constructive</em>, which means, at the very least, that it does not postulate that all types are decidable. By Hedberg’s Theorem any type with decidable equality is a set (homotopy 0-type), so a blanket adoption of the classical law of the excluded middle would immediately rule out any higher-dimensional structure.</p>
<p>To my way of thinking, the denial of the universal validity of the excluded middle is not the <em>defining</em> feature of constructivity, but rather a <em>characteristic</em> feature of constructivity—it is the smoke, not the locomotive. But what, then, is the deeper meaning of constructivity that gives rise to the denial of many classical patterns of reasoning, such as proof by contradiction or reasoning by cases on whether a proposition is true or not? Although the full story is not yet completely clear, a necessary condition is that a constructive theory be <em>proof relevant</em>, meaning that proofs are mathematical objects like any other, and that they play a role in the development of constructive mathematics unlike their role in classical mathematics.</p>
<p>The most obvious manifestation of proof relevance is the defining characteristic of HoTT, that <em>proofs of equality</em> correspond to <em>paths in a space</em>. Paths may be thought of as evidence for the equality of their endpoints. That this is a good notion of equality follows from the homotopy invariance of the constructs of type theory: everything in sight respects paths (that is, respect the groupoid structure of types). More generally, theorems in HoTT tend to characterize the space of proofs of a proposition, rather than simply state that the corresponding type is inhabited. For example, the univalence axiom itself states an equivalence between proofs of equivalence of types in a universe and equivalences between these types. This sort of reasoning may take some getting used to, but its beauty is, to my way of thinking, undeniable. Classical modes of thought may be recovered by explicitly obliterating the structure of proofs using truncation. Sometimes this is the best or only available way to state a theorem, but usually one tends to say more than just that a type is inhabited, or that two types are mutually inhabited. In this respect the constructive viewpoint <em>enriches</em>, rather than <em>diminishes</em>, classical mathematics, a point that even the greatest mathematician of the 20th century, David Hilbert, seems to have missed.</p>
<p>The concept of proof relevance in HoTT seems to have revived a very common misunderstanding about the nature of proofs. Many people have been trained to think that a proof is a derivation in an axiomatic theory, such as set theory, a viewpoint often promoted in textbooks and bolstered by the argument that an informal proof can always be written out in full in this form, even if we don’t do that as a matter of course. It is a short step from there to the conclusion that proofs are therefore mathematical objects, even in classical set theory, because we can treat the derivations as elements of an inductively defined set (famously, the set of natural numbers, but more realistically using more natural representations of abstract syntax such as the s-expression formalism introduced by McCarthy in 1960 for exactly this purpose). From this point of view many people are left confused about the stress on “proofs as mathematical objects” as a defining characteristic of HoTT, and wonder what could be original about that.</p>
<p>The key to recognize that <em>a proof is not a formal proof</em>. To avoid further confusion, I hasten to add that by “formal” I do not mean “rigorous”, but rather “represented in a formal system” such as the axiomatic theory of sets. A <em>formal proof</em> is an element of a computably enumerable set generated by the axioms and rules of the formal theory. A <em>proof</em> is an argument that demonstrates the truth of a proposition. While formal proofs are always proofs (at least, under the assumption of consistency of the underlying formal theory), a proof need not be, or even have a representation as, a formal proof. The principal example of this distinction is Goedel’s Theorem, which proves that the computably enumerable set of formal provable propositions in axiomatic arithmetic is not decidable. The key step is to devise a self-referential proposition that (a) is not formally provable, but (b) has a proof that shows that it is true. The crux of the argument is that <em>once you fix the rules of proof, you automatically miss out true things that are not provable in that fixed system</em>.</p>
<p>Now comes the confusing part. HoTT is defined as a formal system, so why doesn’t the same argument apply? It does, pretty much verbatim! But this has no bearing on “proof relevance” in HoTT, because the proofs that are relevant are not the formal proofs (derivations) defining HoTT as a formal system. Rather proofs are formulated internally as objects of the type theory, and there is no commitment <em>a priori</em> to being the only forms of proof there are. Thus, for example, we may easily see that there are only countably many functions definable in HoTT from the outside (because it is defined by a formal system), but within the theory any function space on an infinite type has uncountably many elements. There is no contradiction, because the proofs of implications, being internal functions, are not identified with codes of formal derivations, and hence are not denumerable.</p>
<p>There is a close analogy, <a href=\"http://existentialtype.wordpress.com/2012/08/09/churchs-law/\" title=\"Church’s Law\">previously noted</a> in this blog, with Church’s Law. Accepting Church’s Law internally amounts to fixing the programming language used to define functions in advance, permitting us to show, for example, that certain programs are not expressible in that language. But HoTT does not commit to Church’s Law, so such arguments amount to showing that, for example, there is no Turing machine to decide halting for Turing machines, but allowing that there could be constructive functions (say, equipped with oracles) that make such decisions.</p>
<p>The theory of formal proofs, often called proof theory, was dubbed <em>metamathematics</em> by Kleene. Until the development of type theory the study of proofs was confined to metamathematics. But now in the brave new world of <em>constructive mathematics</em> as embodied in HoTT, proofs (not just formal proofs) have pride of place in mathematics, and provide opportunities for expressing concepts clearly and cleanly that were hitherto obscured or even hidden from our view.</p>
<p><em>Update</em>: Corrected silly wording mistake.</p>
<br />Filed under: <a href=\"http://existentialtype.wordpress.com/category/research/\">Research</a> Tagged: <a href=\"http://existentialtype.wordpress.com/tag/constructive-mathematics/\">constructive mathematics</a>, <a href=\"http://existentialtype.wordpress.com/tag/homotopy-type-theory/\">homotopy type theory</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/existentialtype.wordpress.com/823/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/existentialtype.wordpress.com/823/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=existentialtype.wordpress.com&blog=2157150&post=823&subd=existentialtype&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "17e383cb8d481f6368e1f229aff448d3") (233 (20963 44460 472281) "http://praisecurseandrecurse.blogspot.com/2013/07/the-polar-game-in-haskell-day-5-12.html" "Paul Potts: The Polar Game in Haskell, Day 5 1/2: Refactoring with a Monad" "noreply@blogger.com (Paul Potts)" "Thu, 11 Jul 2013 23:22:00 +0000" "<p>The job search has eaten my brain for the last few days -- have I mentioned yet that I need a job? Oh, yes, I believe I may have -- but I'm taking some time to press on with my Haskell larnin', especially since I've been getting great, helpful feedback.</p> <p>The first thing I did was make some minor fixes to the list implementation, as suggested by Jeff. It's working now and my version looks like this:</p> <pre>next_board_list :: BoardList -> Pos -> Dir -><br />    ( Bool, BoardList )<br />next_board_list board pos dir =<br />    let ( penguin_moved, updated_view_list ) =<br />        step_list $ view_list board pos dir<br />    in ( penguin_moved, update_board_from_view_list <br />         board pos dir updated_view_list )<br /><br />apply_view_list_to_row :: [ Tile ] -> Int -> Bool -> [ Tile ] -> [Tile]<br />apply_view_list_to_row orig pos True update =<br />    take ( pos + 1 ) orig ++ update<br />apply_view_list_to_row orig pos False update =<br />    ( reverse update ) ++ ( drop pos orig )<br /><br />apply_view_list_to_rows :: BoardList -> Int -> Int -> Bool -> [ Tile ]<br />    -> BoardList<br />apply_view_list_to_rows orig row pos is_forward update =<br />    take row orig ++<br />    nest ( apply_view_list_to_row ( orig !! row ) pos<br />           is_forward update ) ++<br />    drop ( row + 1 ) orig<br />    where nest xs = [xs]<br /><br />update_board_from_view_list :: BoardList -> Pos -> Dir -> [ Tile ]<br />    -> BoardList<br />update_board_from_view_list board pos dir updated_view_list<br />    | is_eastwest = apply_view_list_to_rows board<br />                        ( posY pos ) ( posX pos )<br />                        is_forward updated_view_list<br />    | otherwise = transpose ( apply_view_list_to_rows ( transpose board )<br />                         ( posX pos ) ( posY pos ) <br />                         is_forward updated_view_list )<br />    where is_forward = elem dir [ East, South ]<br />          is_eastwest = elem dir [ East, West ]</pre> <p>This code is on <a href=\"https://github.com/paulrpotts/arctic-slide-haskell\">GitHub</a> here.</p> <p>Now, it turns out that Jeff did more than suggest a refactoring -- he actually did something I haven't quite gotten my head around yet, which is to refactor my code to use a monad for managing some of this task. He forked my code in his own GitHub repo <a href=\"https://github.com/licquia/arctic-slide-haskell\">here</a> and sent me some notes to share on my blog. Here's part of what he said:</p> <blockquote>The way I got my head wrapped around monads was to think of them as \"important stuff to do, but not the point\". You need to do some housekeeping that's important, but it's not the reason you're writing this function.  The classic example is division. You're writing a math library, and you need to implement division. Division by zero is something you need to deal with sanely, but it's not the point; you're writing the function because you want to divide by things that aren't zero.  So, to handle the zero case, you return a Maybe instead of a simple number. Only now you can't just add numbers together with division, because you're dealing with Maybes, not numbers. So you end up implementing addition with Maybes, except that makes no sense, as adding never fails, and people using your math library get annoyed because now *they* have to deal with division-by-zero errors even when they're not dividing, and it's a mess.  Except -- Maybe is a monad. So you skip all that mess, implement division with a Maybe, everything else without, and use the cool monad and functor features of the language to bridge the gaps.  The same pattern exists with scorekeeping. A lot of the functions in your code need to keep track of the score and occasionally award points, but scores aren't \"the point\" of, say, collide. And when you start thinking about all the places you need to worry about scores, you start seeing scorekeeping infect all kinds of weird places in your code. I think you even mentioned having to \"uglify\" your code with scorekeeping in your blog post.</blockquote> <p>Yes, yes, yes -- mainly the chain of function invocations that handle generating the next board, down to the <b>collide</b> calls. Because it's only at the point where a heart disappears that we can decrement the heart count. Without state, I can't make this a global state. In a purely function form, I have to \"thread\" the indication that the heart count should be decreased through the whole chain of function signatures, which now all have to return an extra thing.</p> <blockquote>So, minimize the ugly with monads. Just do what you need to do to pass around the score, and deal with it when it's appropriate. (In my implementation, that was in next_world).  The Writer monad is perfect for the job. It uses a monoid, which is a fancy ways of saying \"something that knows how to grow\". Lists are monoids, because you can append to them. Numbers are monoids, because you can add and multiply them. And so on.  What the Writer monad does is take care of the adding part. You just return the thing you're working with, and the monad tacks it on using the monoid. Specifically, with scorekeeping, you just note how many points each individual action takes, and the monad does the adding together. When you finally deal with the score in next_world, you get all the accumulated points in one tidy variable.</blockquote> <p>OK, cool... let's see what he came up with!</p> <pre>import Control.Monad.Writer<br /><br />...<br /><br />-- Keep track of the score with a writer monad<br />type ScoreTracker = Writer ( Sum Int )</pre> <p>OK, let me pause there and see if I can make sense of that. <i>Learn You a Haskell</i> <a href=\"http://learnyouahaskell.com/for-a-few-monads-more\">says</a></p> <blockquote>Whereas Maybe is for values with an added context of failure and the list is for non-deterministic values, the Writer monad is for values that have another value attached that acts as a sort of log value. Writer allows us to do computations while making sure that all the log values are combined into one log value that then gets attached to the result.</blockquote> <p>OK, I think I get that -- in <i>Learn You</i> it is used for implementing logging, not scoring of a game, but it seems like it could be generalizable. The example given does this just kind of thing I was mentioning -- makes a simple function return a tuple to pass both the actual interesting return value and the log string, or in our case I think we want a score. <i>Learn You</i> continues:</p> <blockquote>When we were exploring the Maybe monad, we made a function applyMaybe, which took a Maybe a value and a function of type a -> Maybe b and fed that Maybe a value into the function, even though the function takes a normal a instead of a Maybe a. It did this by minding the context that comes with Maybe a values, which is that they are values with possible failure. But inside the a -> Maybe b function, we were able to treat that value as just a normal value, because applyMaybe (which later became >>=) took care of checking if it was a Nothing or a Just value.  In the same vein, let's make a function that takes a value with an attached log, that is, an (a,String) value and a function of type a -> (b,String) and feeds that value into the function. We'll call it applyLog. But because an (a,String) value doesn't carry with it a context of possible failure, but rather a context of an additional log value, applyLog is going to make sure that the log of the original value isn't lost, but is joined together with the log of the value that results from the function.</blockquote> <p>Oooh, again, that sounds very promising. So I'm convinced that <b>Writer</b> is the right abstraction here. The values that <b>Writer</b> gets are <b>Sum</b> and <b>Int</b> -- <b>Sum</b> is our monoid, <b>Int</b> is a type we're going to use to accumulate the updated score. (To go along with the Polar game logic, I think there really should ultimately be two scores -- one should be the heart count for a given board, which decrements, and gets tested against zero to indicate board completion, and the other should be a level, which increments as the player moves through the levels, but never mind that for now).</p> <p>Jeff then came up with:</p> <pre>noscore :: a -> ScoreTracker a<br />noscore x = writer (x, Sum 0)<br /><br />score :: a -> ScoreTracker a<br />score x = writer (x, Sum 1)</pre> <p>Two functions, <b>noscore</b> and <b>score</b>. I think these are both monadic <b>return</b> -- injecting a value, passing it to the next step while applying the sum operation. So let's see how he uses it. here's my <b>slide</b> function:</p> <pre>slide :: [ Tile ] -> [ Tile ]<br />slide ( Ice_Block : ts ) | ( null ts ) || ( blocking $ head ts ) = <br />    ( Ice_Block : ts )<br />slide ( t : Empty : ts ) =<br />    ( Empty : ( slide ( t : ts ) ) )<br />slide ( t : ts ) | ( null ts ) || ( blocking $ head ts ) =<br />    collide ( t : ts )</pre> <p>I'm not going to take Jeff's current version, because he's restructured it a bit using guards, which obscures just the differences due to the use of the ScoreTracker, but here's a version that does the same thing. We don't have to explictly construct the return tuples:</p> <pre>slide' :: [ Tile ] -> ScoreTracker [ Tile ]<br />slide' ( Ice_Block : ts ) | ( null ts ) || ( blocking $ head ts ) =<br />    noscore ( Ice_Block : ts )<br />slide' ( t : Empty : ts ) =<br />    noscore ( Empty : ( slide ( t : ts ) ) )<br />slide' ( t : ts ) | ( null ts ) || ( blocking $ head ts ) =<br />    collide ( t : ts )</pre> <p>And this doesn't actually compile. Note that collide doesn't handle the monad -- the compiler warns us as Jeff described:</p> <pre>    Couldn't match expected type `ScoreTracker [Tile]'<br />                with actual type `[Tile]'<br />    In the return type of a call of `collide'<br />    In the expression: collide (t : ts)<br />    In an equation for slide':<br />        slide' (t : ts)<br />          | (null ts) || (blocking $ head ts) = collide (t : ts)</pre> <p>That seems pretty clear -- so I have to fix it up the same way:</p> <pre>collide' :: [ Tile ] -> ScoreTracker [ Tile ]<br />collide' [] = noscore []<br />collide' ( t : ts ) | fixed t = <br />    noscore ( t : ts )<br />collide' ( Bomb : Mountain : ts) = <br />    noscore ( [ Empty, Empty ] ++ ts )<br />collide' ( Heart : House : ts ) = score ( [ Empty, House ] ++ ts )<br />collide' ( Ice_Block : ts ) | ( null ts ) || ( blocking $ head ts ) = <br />    noscore ( Empty : ts )<br />collide' ( t : ts ) | ( movable t ) && ( ( null ts ) ||<br />    ( blocking $ head ts ) ) = noscore ( t : ts )<br />collide' ( t : Empty : ts ) | movable t = <br />    noscore ( Empty : ( slide( t : ts ) ) )</pre> <p>And slide' should call <b>collide'</b> instead of <b>collide</b>, of course. So once this is compiled and loaded into GHCI, we can play with it and compare it to the original <b>collide</b>:</p> <pre>*Main> :t collide'<br />collide' :: [Tile] -> ScoreTracker [Tile]<br />*Main> :t collide<br />collide :: [Tile] -> [Tile]<br />*Main> collide [ Bomb, Mountain ]<br />[Empty,Empty]<br />*Main> collide [ Heart, House ]<br />[Empty,House]<br />*Main> collide' [ Heart, House ]<br /><br /><interactive>:23:1:<br />    No instance for (Show (ScoreTracker [Tile]))<br />      arising from a use of `print'<br />    Possible fix:<br />      add an instance declaration for (Show (ScoreTracker [Tile]))<br />    In a stmt of an interactive GHCi command: print it</pre> <p>Er, yeah. The result is not printable, but can we see its type?  </p><pre>*Main> :t ( collide' [ Heart, House ] )<br />( collide' [ Heart, House ] ) :: ScoreTracker [Tile]</pre> <p>In fact, we can. So there might be an easy way to make the monadic type printable -- <b>deriving ( Show )</b> doesn't work -- but first, how do we extract the values? Well, we get back the return value of the whole chain from <b>runWriter</b>:</p> <pre>*Main> runWriter $ collide' [Heart, House]<br />([Empty,House],Sum {getSum = 1})</pre> <p>What's the type? It's just a tuple:</p> <pre>*Main> :t ( runWriter $ collide' [Heart, House] )<br />( runWriter $ collide' [Heart, House] ) :: ([Tile], Sum Int)<br />*Main> fst $ runWriter $ collide' [Heart, House]<br />[Empty,House]<br />*Main> snd $ runWriter $ collide' [Heart, House]<br />Sum {getSum = 1}</pre> <p>Anyway, I think my mind is blown enough for today. I'm going to stop there. Jeff has made some other modifications to my code here and there -- modifications that improve the clarity -- but I'll have to get back to those. I'm off to read the monad tutorials again, and maybe understand them better this time!</p>" nil nil "7e6a3ebb1922b48dda307ef5c1bf85a7") (232 (20963 44460 382729) "http://twanvl.nl/blog/agda/cong-from-refl" "Twan van Laarhoven: cong from refl in univalent OTT" nil "Thu, 04 Jul 2013 16:00:00 +0000" "<p>This is a follow up on <a href=\"http://www.twanvl.nl/blog/agda/subst-from-cong\">last week's post</a>.
There I showed that in a univalent Observational Type Theory, you can derive <tt><span class=\"varid\">subst</span></tt> from <tt><span class=\"varid\">cong</span></tt>.
Now I am going to go one step further.
</p><p>Suppose we change the definition of paths for functions from
</p><pre class=\"agda\"><span class=\"conid\">Path</span> (<span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>) <span class=\"varid\">f</span> <span class=\"varid\">g</span> <span class=\"varop\">≡</span> <span class=\"keyglyph\">∀</span> <span class=\"varid\">x</span> <span class=\"keyglyph\">→</span> <span class=\"varid\">f</span> <span class=\"varid\">x</span> <span class=\"varop\">≡</span> <span class=\"varid\">g</span> <span class=\"varid\">x</span>
</pre><p>to
</p><pre class=\"agda\"><span class=\"conid\">Path</span> (<span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>) <span class=\"varid\">f</span> <span class=\"varid\">g</span> <span class=\"varop\">≡</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">x</span> <span class=\"varid\">y</span>} <span class=\"keyglyph\">→</span> <span class=\"varid\">x</span> <span class=\"varop\">≡</span> <span class=\"varid\">y</span> <span class=\"keyglyph\">→</span> <span class=\"varid\">f</span> <span class=\"varid\">x</span> <span class=\"varop\">≡</span> <span class=\"varid\">g</span> <span class=\"varid\">y</span>
</pre><p>Then for a function <tt><span class=\"varid\">f</span></tt>, <tt class=\"complex\"><span class=\"varid\">refl</span> <span class=\"varid\">f</span></tt> is actually the same thing as <tt class=\"complex\"><span class=\"varid\">cong</span> <span class=\"varid\">f</span></tt>!.
So that's one less primitive to worry about. In fact the only two path related primitives that remain are <tt><span class=\"conid\">Path</span></tt> and <tt><span class=\"varid\">refl</span></tt>. The rest is just in the computation rules.
</p><p>Here are the changes in the agda code compared to last week:
</p><pre class=\"agda\"><span class=\"keyword\">postulate</span> <span class=\"conid\">Path-→</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>} (<span class=\"varid\">f</span> <span class=\"varid\">g</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>)
<span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>) <span class=\"varid\">f</span> <span class=\"varid\">g</span>
<span class=\"varop\">≡</span> ((<span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">B</span> (<span class=\"varid\">f</span> <span class=\"varid\">x</span>) (<span class=\"varid\">g</span> <span class=\"varid\">y</span>))
<div class=\"empty-line\"></div>
<span class=\"comment\">-- cong = refl</span>
<span class=\"varid\">cong</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>}
<span class=\"keyglyph\">→</span> (<span class=\"varid\">f</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>) <span class=\"keyglyph\">→</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">x</span> <span class=\"varid\">y</span>} <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">B</span> (<span class=\"varid\">f</span> <span class=\"varid\">x</span>) (<span class=\"varid\">f</span> <span class=\"varid\">y</span>)
<span class=\"varid\">cong</span> <span class=\"varid\">f</span> <span class=\"varid\">x=y</span> <span class=\"keyglyph\">=</span> <span class=\"varid\">Meta.subst</span> <span class=\"varid\">id</span> (<span class=\"conid\">Path-→</span> <span class=\"varid\">f</span> <span class=\"varid\">f</span>) (<span class=\"varid\">refl</span> <span class=\"keyglyph\">_</span> <span class=\"varid\">f</span>) <span class=\"keyglyph\">_</span> <span class=\"keyglyph\">_</span> <span class=\"varid\">x=y</span>
<div class=\"empty-line\"></div>
<span class=\"comment\">-- subst is the same as last time</span>
<span class=\"varid\">subst</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} (<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>)
<span class=\"keyglyph\">→</span> {<span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>} <span class=\"keyglyph\">→</span> (<span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span> <span class=\"varid\">x</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span> <span class=\"varid\">y</span>
<span class=\"varid\">subst</span> <span class=\"conid\">B</span> {<span class=\"varid\">x</span>} {<span class=\"varid\">y</span>} <span class=\"varid\">p</span> <span class=\"varid\">with</span> <span class=\"varid\">Meta.subst</span> <span class=\"varid\">id</span> (<span class=\"conid\">Path-Type</span> (<span class=\"conid\">B</span> <span class=\"varid\">x</span>) (<span class=\"conid\">B</span> <span class=\"varid\">y</span>)) (<span class=\"varid\">cong</span> <span class=\"conid\">B</span> <span class=\"varid\">p</span>)
<span class=\"varop\">...</span> <span class=\"keyglyph\">|</span> <span class=\"varid\">lift</span> (<span class=\"varid\">fw</span> , <span class=\"varid\">bw</span> , <span class=\"keyglyph\">_</span> , <span class=\"keyglyph\">_</span>) <span class=\"keyglyph\">=</span> <span class=\"varid\">fw</span>
<div class=\"empty-line\"></div>
<span class=\"comment\">-- and paths for dependent functions</span>
<span class=\"keyword\">postulate</span> <span class=\"conid\">Path-Π</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>} (<span class=\"varid\">f</span> <span class=\"varid\">g</span> <span class=\"varop\">:</span> <span class=\"conid\">Π</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>)
<span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">Π</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>) <span class=\"varid\">f</span> <span class=\"varid\">g</span>
<span class=\"varop\">≡</span> ((<span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>) <span class=\"keyglyph\">→</span> (<span class=\"varid\">pa</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span>)
<span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">B</span> <span class=\"varid\">y</span>) (<span class=\"varid\">subst</span> <span class=\"conid\">B</span> <span class=\"varid\">pa</span> (<span class=\"varid\">f</span> <span class=\"varid\">x</span>)) (<span class=\"varid\">g</span> <span class=\"varid\">y</span>))
</pre><p>Of course this doesn't really change anything, since defining <tt><span class=\"varid\">refl</span></tt> for function types is no easier than defining <tt><span class=\"varid\">cong</span></tt>.
</p><h2><a name=\"representation\"></a>Representation </h2>
<p>You might also notice that for all types <tt><span class=\"conid\">A</span></tt> (except <tt><span class=\"conid\">Set</span></tt>), the structure of <tt class=\"complex\"><span class=\"conid\">Path</span> <span class=\"conid\">A</span></tt> is essentially the same as that of <tt><span class=\"conid\">A</span></tt>. In fact, for a (non-indexed) data type
</p><pre class=\"agda\"><span class=\"keyword\">data</span> <span class=\"conid\">Foo</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"keyword\">where</span>
<span class=\"varid\">foo₀</span> <span class=\"varop\">:</span> <span class=\"conid\">Foo</span>
<span class=\"varid\">foo₁</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Foo</span>
<span class=\"varid\">foo₂</span> <span class=\"varop\">:</span> <span class=\"conid\">Foo</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Foo</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Foo</span>
</pre><p>you can mechanically derive its path type to be
</p><pre class=\"agda\"><span class=\"keyword\">data</span> <span class=\"conid\">Path</span> <span class=\"conid\">Foo</span> <span class=\"varop\">:</span> <span class=\"conid\">Foo</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Foo</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"keyword\">where</span>
<span class=\"varid\">refl-foo₀</span>  <span class=\"varop\">:</span> <span class=\"conid\">Path</span> (<span class=\"varid\">foo₀</span> <span class=\"varid\">x</span>) (<span class=\"varid\">foo₀</span> <span class=\"varid\">x</span>)
<span class=\"varid\">cong₁-foo₁</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">x</span> <span class=\"varid\">x'</span>} <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">x'</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">Foo</span> (<span class=\"varid\">foo₁</span> <span class=\"varid\">x</span>) (<span class=\"varid\">foo₁</span> <span class=\"varid\">x'</span>)
<span class=\"varid\">cong₂-foo₂</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">x</span> <span class=\"varid\">x'</span> <span class=\"varid\">y</span> <span class=\"varid\">y'</span>} <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">Foo</span> <span class=\"varid\">x</span> <span class=\"varid\">x'</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">Foo</span> <span class=\"varid\">y</span> <span class=\"varid\">y'</span>
<span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">Foo</span> (<span class=\"varid\">foo₂</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span>) (<span class=\"varid\">foo₂</span> <span class=\"varid\">x'</span> <span class=\"varid\">y'</span>)
</pre><p>In theory this allows for a nice implementation trick: we can take the representation of <tt><span class=\"varid\">x</span></tt> and <tt class=\"complex\"><span class=\"varid\">refl</span> <span class=\"varid\">x</span></tt> to be the same. So for example <tt class=\"complex\"><span class=\"num\">5</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">Int</span> <span class=\"num\">5</span> <span class=\"num\">5</span></tt> is a path that asserts that 5 = 5, and it is the only such path.
</p><p>Originally I thought that an implementation would have to pass <tt class=\"complex\"><span class=\"varid\">cong</span> <span class=\"varid\">f</span></tt> along with every parameter <tt><span class=\"varid\">f</span></tt> of a function type (which would suck). But in this way we don't have to, since <tt><span class=\"varid\">f</span></tt> and <tt class=\"complex\"><span class=\"varid\">cong</span> <span class=\"varid\">f</span></tt> are the same function.
</p><p>This also corresponds nicely to the idea that extra path constructors can be added in Higher Inductive Types. But I am not quite sure yet how that works out.
</p><h2><a name=\"food-for-thought\"></a>Food for thought </h2>
<ul><li> What is <tt class=\"complex\"><span class=\"varid\">refl</span> <span class=\"keyglyph\">_</span><span class=\"keyglyph\">→</span><span class=\"keyglyph\">_</span></tt>?</li>
<li> What is <tt class=\"complex\"><span class=\"varid\">refl</span> <span class=\"varid\">refl</span></tt>? Does this even make sense?</li>
<li> For the representation of <tt class=\"complex\"><span class=\"varid\">x</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span></tt> and <tt class=\"complex\"><span class=\"varid\">refl</span> <span class=\"varid\">x</span></tt> to be the same, <tt><span class=\"conid\">A</span></tt> and <tt class=\"complex\"><span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">x</span></tt> also need to have the same representation. That seems works for functions and inductive types, but what about <tt><span class=\"conid\">Set</span></tt>?</li>
<li> Is <tt><span class=\"conid\">Path</span></tt> an applicative functor in some sense? With <tt><span class=\"varid\">refl</span></tt> as return and <tt><span class=\"varid\">cong</span></tt> as ap?</li>
</ul>" nil nil "5a1a9f5af3bc72f4f23c028e66fe0a39") (231 (20963 44460 380731) "http://feedproxy.google.com/~r/RomanCheplyaka/~3/RVdo6DFKhbc/2013-07-04.html" "Roman Cheplyaka: Quotation, fixed points, and quines" nil "Thu, 04 Jul 2013 00:00:00 +0000" "<h2 id=\"quotation\">Quotation</h2>
<p>Consider an untyped functional language, such as lambda calculus, Scheme, or JavaScript. There are many ways we can represent the terms of the language in the language itself:</p>
<ul>
<li><p>In Scheme, we can represent Scheme expressions by S-expressions: <code class=\"sourceCode scheme\">(<span class=\"kw\">+</span> <span class=\"dv\">1</span> <span class=\"dv\">2</span>)</code> is represented by <code class=\"sourceCode scheme\">'(<span class=\"kw\">+</span> <span class=\"dv\">1</span> <span class=\"dv\">2</span>)</code></p></li>
<li><p>In any language with strings (such as JavaScript) we could use textual representation of expressions: <code class=\"sourceCode javascript\"><span class=\"dv\">1+2</span></code> is represented by <code class=\"sourceCode javascript\"><span class=\"st\">\"1+2\"</span></code></p></li>
<li><p>In lambda calculus with natural numbers, Gödel numbers could be used: <span class=\"math\">\\(\\lambda x.y\\)</span> would be represented by, say, the term <span class=\"math\">\\(3\\)</span>.</p></li>
<li><p>In pure lambda calculus (without numbers), we can use Church encoding instead, so that <span class=\"math\">\\(\\lambda x.y\\)</span> becomes <span class=\"math\">\\(\\lambda f.\\lambda x. f(f(f(x)))\\)</span>.</p></li>
</ul>
<p>In each of these cases, we have a bijection between the set <span class=\"math\">\\(T\\)</span> of all terms and the set <span class=\"math\">\\(Q \\subset T\\)</span> of quotations. This bijection is realized by the functions <span class=\"math\">\\(q \\colon T \\to Q\\)</span> (for quote) and <span class=\"math\">\\(u \\colon Q \\to T\\)</span> (for unquote).</p>
<p>Note that <span class=\"math\">\\(q\\)</span> and <span class=\"math\">\\(u\\)</span> are set functions, not functions in our language. Still, we require them to be computable, that is, there should exist functions <span class=\"math\">\\(q_L, u_L\\in T\\)</span> such that</p>
<ul>
<li><span class=\"math\">\\(\\forall x\\in T\\; q_L(q(x))\\)</span> evaluates to <span class=\"math\">\\(q(q(x))\\)</span></li>
<li><span class=\"math\">\\(\\forall x\\in T\\; u_L(q(x))\\)</span> evaluates to <span class=\"math\">\\(q(u_L(x))\\)</span></li>
</ul><img src=\"http://feeds.feedburner.com/~r/RomanCheplyaka/~4/RVdo6DFKhbc\" height=\"1\" width=\"1\" />" nil nil "0c81edeeddc20ccdf07e6f155f88d8f3") (230 (20963 44460 376491) "http://feedproxy.google.com/~r/ezyang/~3/tSmwYHznwqQ/" "Edward Z. Yang: HoTT exercises in Coq (in progress)" nil "Mon, 01 Jul 2013 20:21:18 +0000" "<div class=\"document\">
<p>I spent some of my plane ride yesterday working on Coq versions of the exercises in <a href=\"http://homotopytypetheory.org/book/\" class=\"reference external\">The HoTT book</a>. I got as far as 1.6 (yeah, not very far, perhaps I should make a GitHub repo if other folks are interested in contributing skeletons. Don't know what to do about the solutions though).  All of these have been test solved.</p>
<p>You will need HoTT/coq in order to run this development; instructions on <a href=\"https://github.com/HoTT/HoTT/blob/master/INSTALL.txt\" class=\"reference external\">how to install it are here.</a></p>
<p><strong>Update.</strong> Solutions and more exercises can be found at the <a href=\"https://github.com/ezyang/HoTT-coqex\" class=\"reference external\">HoTT-coqex</a> repository. I’ve done all of the nontrivial homotopy-specific exercises, and left out some of the more standard type theory exercises (which aren’t really homotopy specific). Some of the solutions are really terrible and could use some sprucing up.</p>
<pre class=\"literal-block\">Require Import HoTT.
Definition admit {T: Type} : T. Admitted.
(* Exercise 1.1 *)
Definition mycompose {A B C : Type} (g : B -> C) (f : A -> B) : A -> C := admit.
Goal forall (A B C D : Type) (f : A -> B) (g : B -> C) (h : C -> D),
mycompose h (mycompose g f) = mycompose (mycompose h g) f.
Admitted.
(* Exercise 1.2 *)
Section ex_1_2_prod.
Variable A B : Type.
Check @fst.
Check @snd.
Definition my_prod_rec (C : Type) (g : A -> B -> C) (p : A * B) : C := admit.
Goal fst = my_prod_rec A (fun a => fun b => a). Admitted.
Goal snd = my_prod_rec B (fun a => fun b => b). Admitted.
End ex_1_2_prod.
Section ex_1_2_sig.
Variable A : Type.
Variable B : A -> Type.
Check @projT1.
Check @projT2.
Definition my_sig_rec (C : Type) (g : forall (x : A), B x -> C) (p : exists (x : A), B x) : C := admit.
Goal @projT1 A B = my_sig_rec A (fun a => fun b => a). Admitted.
(* What goes wrong when you try to prove this for projT2? *)
End ex_1_2_sig.
(* Exercise 1.3 *)
Definition refl {A : Type} (x : A) : x = x := 1%path.
Section ex_1_3_prod.
Variable A B : Type.
(* Given by the book *)
Definition uppt : forall (x : A * B), ((fst x, snd x) = x) :=
fun p => match p with (a,b) => refl (a,b) end.
Definition my_prod_ind (C : A * B -> Type) (g : forall (x : A) (y : B), C (x, y)) (x : A * B) : C x := admit.
Goal forall C g a b, my_prod_ind C g (a, b) = g a b. Admitted.
End ex_1_3_prod.
Section ex_1_3_sig.
Variable A : Type.
Variable B : A -> Type.
Definition sig_uppt : forall (x : exists (a : A), B a), ((projT1 x; projT2 x) = x) := admit.
Definition mysig_ind (C : (exists (a : A), B a) -> Type) (g : forall (a : A) (b : B a), C (a; b)) (x : exists (a : A), B a) : C x := admit.
Goal forall C g a b, mysig_ind C g (a; b) = g a b. Admitted.
End ex_1_3_sig.
(* Exercise 1.4 *)
Fixpoint iter (C : Type) (c0 : C) (cs : C -> C) (n : nat) : C :=
match n with
| 0 => c0
| S n' => cs (iter C c0 cs n')
end.
Definition mynat_rec (C : Type) : C -> (nat -> C -> C) -> nat -> C := admit.
Eval compute in mynat_rec (list nat) nil (@cons nat) 2.
Eval compute in nat_rect (fun _ => list nat) nil (@cons nat) 2.
(* Exercise 1.5 *)
Definition mycoprod (A B : Type) := exists (x : Bool), Bool_rect (fun _ => Type) A B x.
Section ex_1_5.
Variable A B : Type.
Definition inl := existT (Bool_rect (fun _ => Type) A B) true.
Definition inr := existT (Bool_rect (fun _ => Type) A B) false.
Definition mycoprod_ind (C : mycoprod A B -> Type)
(l : forall (a : A), C (inl a))
(r : forall (b : B), C (inr b))
(x : mycoprod A B) : C x := admit.
Goal forall C l r x, mycoprod_ind C l r (inl x) = l x. Admitted.
Goal forall C l r x, mycoprod_ind C l r (inr x) = r x. Admitted.
End ex_1_5.
(* Exercise 1.6 *)
Definition myprod (A B : Type) := forall (x : Bool), Bool_rect (fun _ => Type) A B x.
Section ex_1_6.
Context `{Funext}.
Variable A B : Type.
Definition mypr1 (p : myprod A B) := p true.
Definition mypr2 (p : myprod A B) := p false.
Definition mymkprod (a : A) (b : B) : myprod A B := Bool_rect (Bool_rect (fun _ => Type) A B) a b.
Definition myprod_ind (C : myprod A B -> Type)
(g : forall (x : A) (y : B), C (mymkprod x y)) (x : myprod A B) : C x := admit.
Goal forall C g a b, myprod_ind C g (mymkprod a b) = g a b. Admitted.
End ex_1_6.
</pre>
<p>Actually, I lied. I haven't proved the last goal in exercise 1.6; my trouble is I don't know how to get function extensionality to compute, but I’m sure it’s something simple...</p>
</div>
<img src=\"http://feeds.feedburner.com/~r/ezyang/~4/tSmwYHznwqQ\" height=\"1\" width=\"1\" />" nil nil "822a44a3adf9f9fde5134a2a101b2c58") (229 (20959 58611 135967) "http://www.yesodweb.com/blog/2013/07/catching-all-exceptions" "Yesod Web Framework: Catching all exceptions" nil "Fri, 12 Jul 2013 13:00:00 +0000" "<p>Note: This blog post is also <a href=\"https://www.fpcomplete.com/user/snoyberg/general-haskell/exceptions/catching-all-exceptions\">available on the School of
Haskell</a>.
I'd recommend reading it there, as the active code snippets may greatly enhance
the material.</p><hr /><p>A commonly discussed piece of functionality is \"catching all exceptions.\" The goal usually is to write reliable functions, which can recover from any kind of problem that exists in some library, or perhaps in some callback passed into the function, which the library author has no control over. Thanks to extensible exceptions, writing this kind of \"catch any exception\" is pretty trivial in Haskell:</p><pre><code class=\"haskell active\">import Control.Exception
catchAny :: IO a -> (SomeException -> IO a) -> IO a
catchAny = Control.Exception.catch
dangerous :: IO Int
dangerous = error \"Fool you!\"
main :: IO ()
main = do
result <- catchAny dangerous $ \\e -> do
putStrLn $ \"Got an exception: \" ++ show e
putStrLn \"Returning dummy value of -1\"
return (-1)
print result</code></pre><p>But this <code>catchAny</code> function isn't quite correct, due to asynchronous exceptions. I'd like to explain what the problem is, demonstrate a fix for it (inspired by John Lato using Simon Marlow's <code>async</code> library), and then generalize it even further using <code>monad-control</code>.</p><h2>Async exceptions</h2><p>Let's consider the following theoretical workflow:</p><ul><li>I have a potentially exception-throwing function I want to run, called <code>dangerous</code>.</li><li>This function should be run by a larger function, called <code>worker</code>. It should handle exceptions thrown by <code>dangerous</code> gracefully.</li><li>I want to make sure that <code>worker</code> runs for no more than 5 milliseconds. I'll use the <code>timeout</code> function to ensure this.</li><li>But unbeknownst to me, <code>dangerous</code> tends to take about 10 milliseconds.</li></ul><p>Below is an implementation of the above logic, using the <code>catchAny</code> we defined earlier. Before you run this code, consider what the expected behavior here should be. In particular, should <code>worker</code> run to completion or not?</p><pre><code class=\"haskell active\">import Control.Exception
import System.Timeout
import Control.Concurrent
catchAny :: IO a -> (SomeException -> IO a) -> IO a
catchAny = Control.Exception.catch
dangerous :: IO Int
dangerous = do
putStrLn \"Succeeds this time, but takes some time\"
threadDelay 10000
return 5

worker :: IO ()
worker = do
x <- catchAny dangerous $ \\e -> do
putStrLn $ \"Caught an exception: \" ++ show e
return (-1)
putStrLn $ \"x + 10 == \" ++ show (x + 10)
main :: IO ()
main = do
res <- timeout 5000 worker
case res of
Nothing -> putStrLn \"worker did not run to completion\"
Just () -> putStrLn \"worker ran to completion\"</code></pre><p>In an ideal world, <code>worker</code> would be stopped before it finished, since it takes more than the 10 milliseconds provided to it to completely run. However, if you run the above code, you'll see that <code>worker</code> does in fact complete. What gives? Well, this is what <i>actually</i> happens when you run this code:</p><ul><li>The <code>timeout</code> function forks a new thread to run <code>worker</code> in. If <code>worker</code> does not complete within 5 ms, that new thread is thrown a timeout exception. This kind of throwing is done by the <code>throwTo</code> function, and is an <i>asynchronous exception</i>.</li><li>Meanwhile, <code>worker</code> starts running, and wraps <code>dangerous</code> with <code>catchAny</code>.</li><li>Since <code>dangerous</code> takes 10 ms, the timeout exception is called when the new thread is inside <code>dangerous</code>, which itself is inside <code>catchAny</code>. <code>dangerous</code> has no exception handling, so the exception propagates up to <code>worker</code>.</li><li><code>worker</code>'s <code>catchAny</code> catches all exceptions, and therefore treats the timeout exception as if it was thrown from <code>dangerous</code> itself. It therefore continues processing, completely ignoring the command to timeout.</li></ul><p>This is a little tricky, so make sure you understand the situation properly before continuing.</p><h2>Non-solution: examine the types</h2><p>My first inclination for solving this problem was to look at the types of the exception being caught. If it was a timeout exception, or any other kind of asynchronous exception, <code>catchAny</code> could simply ignore it. This looks something like:</p><pre><code class=\"haskell active\">catchAny :: IO a -> (SomeException -> IO a) -> IO a
catchAny m f =
Control.Exception.catch m onExc
where
onExc e
| shouldCatch e = f e
| otherwise = throwIO e
shouldCatch e
| show e == \"<<timeout>>\" = False
| Just (_ :: AsyncException) <- fromException e = False
| otherwise = True</code></pre><p>As you can see, this does in fact solve our problem. <code>catchAny</code> now ignores the timeout exception, so it is propagated to <code>worker</code>, terminating the computation. However, it has a few problems. I won't profess to understand all of the problems, but here's the most salient in my mind: <b>the types have nothing to do with whether an exception is synchronous or asynchronous</b>. Consider that, for some strange reason, we decided to asynchronously throw an <code>IOException</code> to a worker thread, e.g.:</p><pre><code class=\"haskell active\">main :: IO ()
main = do
threadId <- forkIO worker
eresult <- try $ readFile \"does-not-exist.txt\"
case eresult of
Left e -> throwTo threadId (e :: IOException)
Right _ -> putStrLn \"Funny, that shouldn't have worked\"
-- Give the forked thread time to finish
threadDelay 50000</code></pre><p>Since our <code>catchAny</code> knowns nothing about asynchronously thrown <code>IOException</code>s, our worker thread will continue doing work even after we try to kill the thread. This example is clearly a bit contrived, but consider if we had some kind of user quota system, where we send a custom asynchronous exception whenever a thread uses too much disk space. There's no way a generic <code>catchAny</code> could know about every kind of custom exception type a user defines. And even if we did, it's clear that any exception type could be thrown either synchronously or asynchronously.</p><h2>Real solution: separate worker thread</h2><p>John Lato described a very straight-forward means of doing the right thing, leveraging Simon Marlow's excellent <code>async</code> library. In fact, that library is so excellent that it solved some of my implementation details before I even realized they existed... more on that in a moment.</p><p>The concept is simple: if you have some function you want to catch all exceptions for, fork a new thread and run the function there. Catch all exceptions thrown in that new thread, and return them to the original thread (via usage of software transactional memory). Now, if any async exceptions are thrown to the original thread, they are unaffected by the exception catching code. And the cool part that the <code>async</code> library took care of automatically: if the original thread gets an async exception, automatically propagate it down to the worker thread so that it terminates work immediately.</p><p>The amazing thing is just how simple this code is. We'll switch over to implementing <code>tryAny</code> instead of <code>catchAny</code>, since it's easier with the <code>async</code> library, and then we can build <code>catchAny</code> on top of that.</p><p><b>Note</b>: the <code>async</code> library hasn't yet been deployed to the FP Haskell Center at time of writing, so I'll include the necessary code inline from <code>async</code>.</p><pre><code class=\"haskell active\">tryAny :: IO a -> IO (Either SomeException a)
tryAny action = withAsync action waitCatch
catchAny :: IO a -> (SomeException -> IO a) -> IO a
catchAny action onE = tryAny action >>= either onE return</code></pre><p>Our solution is now very concise, built on top of quality libraries, and it resilient to any changes in the future to the exception hierarchy.</p><p>This is really our complete solution to the problem as described. The next two sections describe two optional enhancements to this solution.</p><h2>Going deeper</h2><p>What we really want is to be completely isolated from any exceptions generated by a piece of code. The solution above is still vulnerable to one issue: exceptions from pure code hiding in an unevaluated thunk. Even the most brute force <code>catchAny</code> is susceptible to this problem.</p><pre><code class=\"haskell active\">import Control.Exception
catchAny :: IO a -> (SomeException -> IO a) -> IO a
catchAny = Control.Exception.catch
dangerous :: IO Int
dangerous = return $ error \"Unevaluated!\"
main :: IO ()
main = do
res <- catchAny dangerous (const $ return (-1))
putStrLn \"About to print the result\"
putStrLn $ \"Result: \" ++ show res
putStrLn \"Hmm... does this ever get printed?\"</code></pre><p>What we want to do is force evaluation of the value, and if forcing throws any exceptions, catch them. With the <code>deepseq</code> package, this is easy. Let's call these new functions <code>tryAnyDeep</code> and <code>catchAnyDeep</code>, and base them on our previously defined <code>tryAny</code>:</p><pre><code class=\"haskell active\">tryAnyDeep :: NFData a => IO a -> IO (Either SomeException a)
tryAnyDeep action = tryAny $ do
res <- action
return $!! res -- here's the magic
catchAnyDeep :: NFData a => IO a -> (SomeException -> IO a) -> IO a
catchAnyDeep action onE = tryAnyDeep action >>= either onE return
dangerous :: IO Int
dangerous = return $ error \"Unevaluated!\"
main :: IO ()
main = do
res <- catchAnyDeep dangerous (const $ return (-1))
putStrLn \"About to print the result\"
putStrLn $ \"Result: \" ++ show res
putStrLn \"Hmm... does this ever get printed?\"</code></pre><p>We can now have complete* confidence in the values returned from <code>catchAny</code>.</p><p>* Complete confidence, assuming we trust the <code>NFData</code> instances, but that's a different problem.</p><h2>Transformers</h2><p>OK, one final twist: can we catch exceptions in a monad transformer stack? Many of you may be aware that I'm a big advocate of Bas van Dijk's <code>monad-control</code> package, and the related <code>lifted-base</code> package. <code>monad-control</code> allows for a consistent manner of lifted control operations within a monad transformer stack. Can we generalize our <code>tryAny</code> and <code>catchAny</code> functions to work with arbitrary transformer stacks? Fortunately, we can:</p><pre><code class=\"haskell active\">tryAnyIO :: IO a -> IO (Either SomeException a)
tryAnyIO action = withAsync action waitCatch
tryAny :: MonadBaseControl IO m => m a -> m (Either SomeException a)
tryAny action =
-- MAGIC!
liftBaseWith (\\runInIO -> tryAnyIO (runInIO action)) >>=
either (return . Left) (liftM Right . restoreM)
catchAny :: MonadBaseControl IO m => m a -> (SomeException -> m a) -> m a
catchAny action onE = tryAny action >>= either onE return
tryAnyDeep :: (MonadBaseControl IO m, NFData a)
=> m a
-> m (Either SomeException a)
tryAnyDeep action = tryAny $ do
res <- action
return $!! res -- here's the magic
catchAnyDeep :: (MonadBaseControl IO m, NFData a)
=> m a
-> (SomeException -> m a)
-> m a
catchAnyDeep action onE = tryAnyDeep action >>= either onE return
dangerous :: Monad m => m Int
dangerous = return $ error \"Unevaluated!\"
main :: IO ()
main = flip runReaderT () $ do
res <- catchAnyDeep dangerous (const $ return (-1))
liftIO $ putStrLn \"About to print the result\"
liftIO $ putStrLn $ \"Result: \" ++ show res
liftIO $ putStrLn \"Hmm... does this ever get printed?\"</code></pre><p>That implementation of <code>tryAny</code> is a little bit hairy, but it essentially means:</p><ul><li>Capture the monadic state when we start running (via <code>liftWithBase</code>).</li><li>Put the state inside the <code>IO</code> monad by modifying the internal value (via <code>runInIO</code>).</li><li>Now that we have an <code>IO</code> action, run <code>tryAnyIO</code> on it.</li><li>Get back the result.<ul><li>If an exception was thrown, then return that exception.</li><li>If a value was returned, unwrap the new monadic state from and extract the actual return value (via <code>restoreM</code>).</li></ul></li></ul><h2>Moving forward</h2><p>I've <a href=\"https://github.com/snoyberg/classy-prelude/blob/ccd19f2c62882c69d5dcdd3da5c0df1031334c5a/classy-prelude/ClassyPrelude.hs#L320\">added these functions</a> to the <code>classy-prelude</code> Github repo, and after a bit more testing will be releasing them. But I think including something like this in a more accessible place makes a lot of sense, as we should be trying to make the correct approach easier to implement.</p><p>I'd be happy to hear ideas on how to improve the code, or where the correct place to put these functions might be.</p>" nil nil "33b0bdd769589a8fe691d388158b91ff") (228 (20959 47464 311677) "http://praisecurseandrecurse.blogspot.com/2013/07/the-polar-game-in-haskell-day-5-12.html" "Paul Potts: The Polar Game in Haskell, Day 5 1/2: Refactoring with a Monad" "noreply@blogger.com (Paul Potts)" "Thu, 11 Jul 2013 23:22:00 +0000" "<p>The job search has eaten my brain for the last few days -- have I mentioned yet that I need a job? Oh, yes, I believe I may have -- but I'm taking some time to press on with my Haskell larnin', especially since I've been getting great, helpful feedback.</p> <p>The first thing I did was make some minor fixes to the list implementation, as suggested by Jeff. It's working now and my version looks like this:</p> <pre>next_board_list :: BoardList -> Pos -> Dir -><br />    ( Bool, BoardList )<br />next_board_list board pos dir =<br />    let ( penguin_moved, updated_view_list ) =<br />        step_list $ view_list board pos dir<br />    in ( penguin_moved, update_board_from_view_list <br />         board pos dir updated_view_list )<br /><br />apply_view_list_to_row :: [ Tile ] -> Int -> Bool -> [ Tile ] -> [Tile]<br />apply_view_list_to_row orig pos True update =<br />    take ( pos + 1 ) orig ++ update<br />apply_view_list_to_row orig pos False update =<br />    ( reverse update ) ++ ( drop pos orig )<br /><br />apply_view_list_to_rows :: BoardList -> Int -> Int -> Bool -> [ Tile ]<br />    -> BoardList<br />apply_view_list_to_rows orig row pos is_forward update =<br />    take row orig ++<br />    nest ( apply_view_list_to_row ( orig !! row ) pos<br />           is_forward update ) ++<br />    drop ( row + 1 ) orig<br />    where nest xs = [xs]<br /><br />update_board_from_view_list :: BoardList -> Pos -> Dir -> [ Tile ]<br />    -> BoardList<br />update_board_from_view_list board pos dir updated_view_list<br />    | is_eastwest = apply_view_list_to_rows board<br />                        ( posY pos ) ( posX pos )<br />                        is_forward updated_view_list<br />    | otherwise = transpose ( apply_view_list_to_rows ( transpose board )<br />                         ( posX pos ) ( posY pos ) <br />                         is_forward updated_view_list )<br />    where is_forward = elem dir [ East, South ]<br />          is_eastwest = elem dir [ East, West ]</pre> <p>This code is on <a href=\"https://github.com/paulrpotts/arctic-slide-haskell\">GitHub</a> here.</p> <p>Now, it turns out that Jeff did more than suggest a refactoring -- he actually did something I haven't quite gotten my head around yet, which is to refactor my code to use a monad for managing some of this task. He forked my code in his own GitHub repo <a href=\"https://github.com/licquia/arctic-slide-haskell\">here</a> and sent me some notes to share on my blog. Here's part of what he said:</p> <blockquote>The way I got my head wrapped around monads was to think of them as \"important stuff to do, but not the point\". You need to do some housekeeping that's important, but it's not the reason you're writing this function.  The classic example is division. You're writing a math library, and you need to implement division. Division by zero is something you need to deal with sanely, but it's not the point; you're writing the function because you want to divide by things that aren't zero.  So, to handle the zero case, you return a Maybe instead of a simple number. Only now you can't just add numbers together with division, because you're dealing with Maybes, not numbers. So you end up implementing addition with Maybes, except that makes no sense, as adding never fails, and people using your math library get annoyed because now *they* have to deal with division-by-zero errors even when they're not dividing, and it's a mess.  Except -- Maybe is a monad. So you skip all that mess, implement division with a Maybe, everything else without, and use the cool monad and functor features of the language to bridge the gaps.  The same pattern exists with scorekeeping. A lot of the functions in your code need to keep track of the score and occasionally award points, but scores aren't \"the point\" of, say, collide. And when you start thinking about all the places you need to worry about scores, you start seeing scorekeeping infect all kinds of weird places in your code. I think you even mentioned having to \"uglify\" your code with scorekeeping in your blog post.</blockquote> <p>Yes, yes, yes -- mainly the chain of function invocations that handle generating the next board, down to the <b>collide</b> calls. Because it's only at the point where a heart disappears that we can decrement the heart count. Without state, I can't make this a global state. In a purely function form, I have to \"thread\" the indication that the heart count should be decreased through the whole chain of function signatures, which now all have to return an extra thing.</p> <blockquote>So, minimize the ugly with monads. Just do what you need to do to pass around the score, and deal with it when it's appropriate. (In my implementation, that was in next_world).  The Writer monad is perfect for the job. It uses a monoid, which is a fancy ways of saying \"something that knows how to grow\". Lists are monoids, because you can append to them. Numbers are monoids, because you can add and multiply them. And so on.  What the Writer monad does is take care of the adding part. You just return the thing you're working with, and the monad tacks it on using the monoid. Specifically, with scorekeeping, you just note how many points each individual action takes, and the monad does the adding together. When you finally deal with the score in next_world, you get all the accumulated points in one tidy variable.</blockquote> <p>OK, cool... let's see what he came up with!</p> <pre>import Control.Monad.Writer<br /><br />...<br /><br />-- Keep track of the score with a writer monad<br />type ScoreTracker = Writer ( Sum Int )</pre> <p>OK, let me pause there and see if I can make sense of that. <i>Learn You a Haskell</i> <a href=\"http://learnyouahaskell.com/for-a-few-monads-more\">says</a></p> <blockquote>Whereas Maybe is for values with an added context of failure and the list is for non-deterministic values, the Writer monad is for values that have another value attached that acts as a sort of log value. Writer allows us to do computations while making sure that all the log values are combined into one log value that then gets attached to the result.</blockquote> <p>OK, I think I get that -- in <i>Learn You</i> it is used for implementing logging, not scoring of a game, but it seems like it could be generalizable. The example given does this just kind of thing I was mentioning -- makes a simple function return a tuple to pass both the actual interesting return value and the log string, or in our case I think we want a score. <i>Learn You</i> continues:</p> <blockquote>When we were exploring the Maybe monad, we made a function applyMaybe, which took a Maybe a value and a function of type a -> Maybe b and fed that Maybe a value into the function, even though the function takes a normal a instead of a Maybe a. It did this by minding the context that comes with Maybe a values, which is that they are values with possible failure. But inside the a -> Maybe b function, we were able to treat that value as just a normal value, because applyMaybe (which later became >>=) took care of checking if it was a Nothing or a Just value.  In the same vein, let's make a function that takes a value with an attached log, that is, an (a,String) value and a function of type a -> (b,String) and feeds that value into the function. We'll call it applyLog. But because an (a,String) value doesn't carry with it a context of possible failure, but rather a context of an additional log value, applyLog is going to make sure that the log of the original value isn't lost, but is joined together with the log of the value that results from the function.</blockquote> <p>Oooh, again, that sounds very promising. So I'm convinced that <b>Writer</b> is the right abstraction here. The values that <b>Writer</b> gets are <b>Sum</b> and <b>Int</b> -- <b>Sum</b> is our monoid, <b>Int</b> is a type we're going to use to accumulate the updated score. (To go along with the Polar game logic, I think there really should ultimately be two scores -- one should be the heart count for a given board, which decrements, and gets tested against zero to indicate board completion, and the other should be a level, which increments as the player moves through the levels, but never mind that for now).</p> <p>Jeff then came up with:</p> <pre>noscore :: a -> ScoreTracker a<br />noscore x = writer (x, Sum 0)<br /><br />score :: a -> ScoreTracker a<br />score x = writer (x, Sum 1)</pre> <p>Two functions, <b>noscore</b> and <b>score</b>. I think these are both monadic <b>return</b> -- injecting a value, passing it to the next step while applying the sum operation. So let's see how he uses it. here's my <b>slide</b> function:</p> <pre>slide :: [ Tile ] -> [ Tile ]<br />slide ( Ice_Block : ts ) | ( null ts ) || ( blocking $ head ts ) = <br />    ( Ice_Block : ts )<br />slide ( t : Empty : ts ) =<br />    ( Empty : ( slide ( t : ts ) ) )<br />slide ( t : ts ) | ( null ts ) || ( blocking $ head ts ) =<br />    collide ( t : ts )</pre> <p>I'm not going to take Jeff's current version, because he's restructured it a bit using guards, which obscures just the differences due to the use of the ScoreTracker, but here's a version that does the same thing. We don't have to explictly construct the return tuples:</p> <pre>slide' :: [ Tile ] -> ScoreTracker [ Tile ]<br />slide' ( Ice_Block : ts ) | ( null ts ) || ( blocking $ head ts ) =<br />    noscore ( Ice_Block : ts )<br />slide' ( t : Empty : ts ) =<br />    noscore ( Empty : ( slide ( t : ts ) ) )<br />slide' ( t : ts ) | ( null ts ) || ( blocking $ head ts ) =<br />    collide ( t : ts )</pre> <p>And this doesn't actually compile. Note that collide doesn't handle the monad -- the compiler warns us as Jeff described:</p> <pre>    Couldn't match expected type `ScoreTracker [Tile]'<br />                with actual type `[Tile]'<br />    In the return type of a call of `collide'<br />    In the expression: collide (t : ts)<br />    In an equation for slide':<br />        slide' (t : ts)<br />          | (null ts) || (blocking $ head ts) = collide (t : ts)</pre> <p>That seems pretty clear -- so I have to fix it up the same way:</p> <pre>collide' :: [ Tile ] -> ScoreTracker [ Tile ]<br />collide' [] = noscore []<br />collide' ( t : ts ) | fixed t = <br />    noscore ( t : ts )<br />collide' ( Bomb : Mountain : ts) = <br />    noscore ( [ Empty, Empty ] ++ ts )<br />collide' ( Heart : House : ts ) = score ( [ Empty, House ] ++ ts )<br />collide' ( Ice_Block : ts ) | ( null ts ) || ( blocking $ head ts ) = <br />    noscore ( Empty : ts )<br />collide' ( t : ts ) | ( movable t ) && ( ( null ts ) ||<br />    ( blocking $ head ts ) ) = noscore ( t : ts )<br />collide' ( t : Empty : ts ) | movable t = <br />    noscore ( Empty : ( slide( t : ts ) ) )</pre> <p>And slide' should call <b>collide'</b> instead of <b>collide</b>, of course. So once this is compiled and loaded into GHCI, we can play with it and compare it to the original <b>collide</b>:</p> <pre>*Main> :t collide'<br />collide' :: [Tile] -> ScoreTracker [Tile]<br />*Main> :t collide<br />collide :: [Tile] -> [Tile]<br />*Main> collide [ Bomb, Mountain ]<br />[Empty,Empty]<br />*Main> collide [ Heart, House ]<br />[Empty,House]<br />*Main> collide' [ Heart, House ]<br /><br /><interactive>:23:1:<br />    No instance for (Show (ScoreTracker [Tile]))<br />      arising from a use of `print'<br />    Possible fix:<br />      add an instance declaration for (Show (ScoreTracker [Tile]))<br />    In a stmt of an interactive GHCi command: print it</pre> <p>Er, yeah. The result is not printable, but can we see its type?  </p><pre>*Main> :t ( collide' [ Heart, House ] )<br />( collide' [ Heart, House ] ) :: ScoreTracker [Tile]</pre> <p>In fact, we can. So there might be an easy way to make the monadic type printable -- <b>deriving ( Show )</b> doesn't work -- but first, how do we extract the values? Well, we get back the return value of the whole chain from <b>runWriter</b>:</p> <pre>*Main> runWriter $ collide' [Heart, House]<br />([Empty,House],Sum {getSum = 1})</pre> <p>What's the type? It's just a tuple:</p> <pre>*Main> :t ( runWriter $ collide' [Heart, House] )<br />( runWriter $ collide' [Heart, House] ) :: ([Tile], Sum Int)<br />*Main> fst $ runWriter $ collide' [Heart, House]<br />[Empty,House]<br />*Main> snd $ runWriter $ collide' [Heart, House]<br />Sum {getSum = 1}</pre> <p>If we chain them we can see the accumulation going on as the hearts enter the houses:</p> <pre>*Main> runWriter $ collide' [Bomb,House]<br />([Bomb,House],Sum {getSum = 0})<br />*Main> runWriter $ collide' [Bomb,Empty, Empty, Empty, Mountain]<br />([Empty,Empty,Empty,Empty,Empty],Sum {getSum = 0})<br />*Main> runWriter $ collide' [Heart,Empty, Empty, Empty, House]<br />([Empty,Empty,Empty,Empty,House],Sum {getSum = 0})</pre> <p>Anyway, I think my mind is blown enough for today. I'm going to stop there. Jeff has made some other modifications to my code here and there -- modifications that improve the clarity -- but I'll have to get back to those. I'm off to read the monad tutorials again, and maybe understand them better this time!</p>" nil nil "fb701b43bf54607421f303d45dc57aa6") (227 (20959 47464 309736) "http://blog.plover.com/tech/cobblestones.html" "Mark Jason Dominus: Cobblestones" "mjd@plover.com (Mark Dominus)" "Thu, 11 Jul 2013 18:33:00 +0000" "<p>This is a public service announcement.</p>
<p>This is not a picture of a cobbled street:</p>
<p><a href=\"http://pic.blog.plover.com/tech/cobblestones/block.jpg\"><img src=\"http://pic.blog.plover.com/tech/cobblestones/block-sm.jpg\" border=\"0\" /></a></p>
<p>Rather, these stones are \"<a href=\"http://en.wikipedia.org/wiki/Belgian_block\">Belgian block</a>\",
also called <i>setts</i>.</p>
<p><a href=\"http://en.wikipedia.org/wiki/Cobblestone\">Cobblestones</a> look like this:</p>
<p><a href=\"http://pic.blog.plover.com/tech/cobblestones/cobbles.jpg\"><img src=\"http://pic.blog.plover.com/tech/cobblestones/cobbles-sm.jpg\" border=\"0\" /></a></p>
I took these pictures in front of the library of the American
Philosophical Society on South 5th Street in Philadelphia. South 5th
Street is paved with Belgian block, and the lane beside the APS is
cobbled. You can just barely distinguish them in <a href=\"http://goo.gl/maps/fA5Kl\">this
satellite photograph</a>.<p></p>" nil nil "773b96f74d0a060144fe95fc345f3a40") (226 (20959 47464 309362) "http://www.well-typed.com/blog/80" "Well-Typed.Com: Well-Typed are hiring: Haskell developer" nil "Thu, 11 Jul 2013 17:50:46 +0000" "<p>We are looking to hire a Haskell expert to work with us at Well-Typed as a
Haskell developer. This is an exciting opportunity for someone who is
passionate about Haskell and who is keen to improve and promote Haskell in a
professional context.</p><p>The role is quite general and could cover any of the projects and activities
that we are involved in as a company. The tasks may involve:</p><ul><li>working on the Haskell compiler, libraries and tools;</li></ul><ul><li>Haskell application development;</li></ul><ul><li>working directly with clients to solve their problems;</li></ul><ul><li>teaching Haskell, and developing training materials.</li></ul><p>At the moment, we are particularly hoping to find someone with an interest in
supporting the development and maintenance of GHC. Therefore, some knowledge or
interest in compiler internals, operating systems, the foreign function
interface (FFI), and/or deployment issues would be welcome.</p><p>Well-Typed has a variety of clients. For some we do proprietary Haskell
development and consulting. For others, much of the work involves open-source
development and cooperating with the rest of the Haskell community: the
commercial, open-source and academic users.</p><p>Our ideal candidate has excellent knowledge of Haskell, whether from industry,
academia, or personal interest. Familiarity with other languages, low-level
programming, and good software engineering practices are also useful. Good
organisation and ability to manage your own time, and reliably meet deadlines,
is important. You should also have good communication skills. Being interested
or having experience in teaching Haskell (or other technical topics) is a bonus.
Experience of consulting, or running a business, is also a bonus. You are
likely to have a bachelor's degree or higher in computer science or a related
field, although this isn't a requirement.</p><p>The offer is initially for a one-year full time contract. We are also happy to
receive applications for part-time work. The annual salary is from GBP 34,800
or pro rata for part-time or flexible work. We also operate a bonus scheme.
We offer flexible hours and work from home. Living in England is not required.
We may be able to offer either employment or sub-contracting, depending on the
jurisdiction in which you live.</p><p>If you are interested, please apply via
<a href=\"mailto:info@well-typed.com\">info@well-typed.com</a>. Tell us why you
are interested and why you would be a good fit for the job, and attach your CV.
Please also indicate how soon you might be able to start. We are more than
happy to answer informal enquiries. Contact
<a href=\"http://www.well-typed.com/who_we_are\">Duncan Coutts, Ian Lynagh or Andres Löh</a>
for further information, either by email or IRC.</p><p>To ensure we can properly consider your application, please get it to us by
July 25th, 2013, though we may be able to consider applications received later.
</p>" nil nil "0adf47dc5b644ffc806377cd83fb533f") (225 (20959 47464 308773) "http://www.well-typed.com/blog/79" "Well-Typed.Com: Video and slides on (Alternatives to) Lazy I/O" nil "Thu, 11 Jul 2013 17:30:22 +0000" "<p>Edsko is in London this week running our <a href=\"http://www.well-typed.com/services_training\">regular Haskell training courses</a>.
Last night he gave a talk, as part of the Skills Matter \"In The Brain\" series,
on the subject of lazy I/O in Haskell and the various old and new alternatives.</p><blockquote><h4> (Alternatives to) Lazy I/O</h4><p><em>by Edsko de Vries</em></p><ul><li><a href=\"http://skillsmatter.com/podcast/home/lazy-io-and-alternatives-in-haskell/jd-7959\">Slides and video</a> </li></ul></blockquote><p>If you are lucky enough to be in or near London, there is now quite a range of
free evening Haskell events to keep an eye out for:</p><ul><li>The <a href=\"http://skillsmatter.com/\">Skills Matter \"In The Brain\" talks</a>. These
are free evening events and there are talks on Haskell or functional
programming fairly regularly. They're generally at the introductory or
intermediate level.</li><li>The <a href=\"http://www.meetup.com/London-Haskell/\">London Haskell User Group</a> is
alive and running talks again. These are now quite well attended.</li><li>The <a href=\"http://www.meetup.com/hoodlums/\">Haskell Hoodlums</a> group does monthly
\"coding dojo\" events where beginners and experts work together on a shared
problem.</li></ul><p>These are all fun, friendly events to learn a bit more and meet up with fellow
Haskellers and get involved with the community.
</p>" nil nil "15eb930b8b3a6d64b754a1a22400854b") (224 (20958 53232 569832) "http://www.joachim-breitner.de/blog/archives/602-Running-Circle-Packing-in-the-Browser-using-Haste.html" "Joachim Breitner: Running Circle Packing in the Browser using Haste" "mail@joachim-breitner.de (nomeata)" "Thu, 11 Jul 2013 14:45:51 +0000" "<p><a href=\"http://www.joachim-breitner.de/blog/archives/578-Circle-Packing.html\">Half a year ago</a>, I wrote a small Haskell library called <a href=\"http://hackage.haskell.org/package/circle-packing\">circle-packing</a> to pack circles in a tight arrangement. I used this to experiment with <a href=\"http://fay-lang.org/\">the fay compiler</a>, which compiles Haskell to JavaScript, and <a href=\"http://darcs.nomeata.de/circle-packing/fay/fay-demo.html\">the result</a> was quite nice.</p>
<p>Recently, I was pointed to <a href=\"https://github.com/valderman/haste-compiler\">haste</a>, another Haskell-to-JavaScript-compiler, and gave it a shot. It required no changes to my code, and after a <a href=\"https://github.com/valderman/haste-compiler/issues/62\">bug in the compiler</a> was fixed, I could successfully run <a href=\"http://darcs.nomeata.de/circle-packing/haste/haste-demo.html\">the example compiled with haste.</a> Some observations:</p>
<ul>
<li>Haste provides more features that I consider necessary for it to be used seriously. In particular its support for Cabal (so I could just write <tt>haste-inst install circle-packing</tt>) and its support for a much larger subset of Haskell, including type classes, as it builds on GHC.</li>
<li>Interfacing with JavaScript is not as smooth as in fay. Especially having to write JS code in a <a href=\"http://darcs.nomeata.de/circle-packing/haste/helpers.js\">separate helper file</a> is annoying.</li>
<li>A quick unscientific comparison of the two results indicates that the code produced by haste is a bit faster (although I should maybe compile the fay variant with the latest version).<br /></li>
</ul>" nil nil "48a76fd5e4f70bd9d457e2e37a79b6b5") (223 (20958 26471 211950) "http://existentialtype.wordpress.com/2013/07/10/constructive-mathematics-is-not-meta-mathematics/" "Robert Harper: Constructive Mathematics Is Not Metamathematics" nil "Wed, 10 Jul 2013 21:46:56 +0000" "<p>The publication of the <a href=\"http://www.homotopytypetheory.org/book\">Homotopy Type Theory book</a> has renewed interest in type theory as a foundation for mathematics, and spurred computer scientists to investigate the computational meaning of higher-dimensional types. As I mentioned in a <a href=\"http://existentialtype.wordpress.com/2013/06/22/whats-the-big-deal-with-hott/\" title=\"What’s the big deal with HoTT?\">previous post</a>, what makes HoTT work so well for homotopy theory is that it is <em>constructive</em>, which means, at the very least, that it does not postulate that all types are decidable. By Hedberg’s Theorem any type with decidable equality is a set (homotopy 0-type), so a blanket adoption of the classical law of the excluded middle would immediately rule out any higher-dimensional structure.</p>
<p>To my way of thinking, the denial of the universal validity of the excluded middle is not the <em>defining</em> feature of constructivity, but rather a <em>characteristic</em> feature of constructivity—it is the smoke, not the locomotive. But what, then, is the deeper meaning of constructivity that gives rise to the denial of many classical patterns of reasoning, such as proof by contradiction or reasoning by cases on whether a proposition is true or not? Although the full story is not yet completely clear, a necessary condition is that a constructive theory be <em>proof relevant</em>, meaning that proofs are mathematical objects like any other, and that they play a role in the development of constructive mathematics unlike their role in classical mathematics.</p>
<p>The most obvious manifestation of proof relevance is the defining characteristic of HoTT, that <em>proofs of equality</em> correspond to <em>paths in a space</em>. Paths may be thought of as evidence for the equality of their endpoints. That this is a good notion of equality follows from the homotopy invariance of the constructs of type theory: everything in sight respects paths (that is, respect the groupoid structure of types). More generally, theorems in HoTT tend to characterize the space of proofs of a proposition, rather than simply state that the corresponding type is inhabited. For example, the univalence axiom itself states an equivalence between proofs of equivalence of types in a universe and equivalences between these types. This sort of reasoning may take some getting used to, but its beauty is, to my way of thinking, undeniable. Classical modes of thought may be recovered by explicitly obliterating the structure of proofs using truncation. Sometimes this is the best or only available way to state a theorem, but usually one tends to say more than just that a type is inhabited, or that two types are mutually inhabited. In this respect the constructive viewpoint <em>enriches</em>, rather than <em>diminishes</em>, classical mathematics, a point that even the greatest mathematician of the 20th century, David Hilbert, seems to have missed.</p>
<p>The concept of proof relevance in HoTT seems to have revived a very common misunderstanding about the nature of proofs. Many people have been trained to think that a proof is a derivation in an axiomatic theory, such as set theory, a viewpoint often promoted in textbooks and bolstered by the argument that an informal proof can always be written out in full in this form, even if we don’t do that as a matter of course. It is a short step from there to the conclusion that proofs are therefore mathematical objects, even in classical set theory, because we can treat the derivations as elements of an inductively defined set (famously, the set of natural numbers, but more realistically using more natural representations of abstract syntax such as the s-expression formalism introduced by McCarthy in 1960 for exactly this purpose). From this point of view many people are left confused about the stress on “proofs as mathematical objects” as a defining characteristic of HoTT, and wonder what could be original about that.</p>
<p>The key to recognize that <em>a proof is not a formal proof</em>. To avoid further confusion, I hasten to add that by “formal” I do not mean “rigorous”, but rather “represented in a formal system” such as the axiomatic theory of sets. A <em>formal proof</em> is an element of a computably enumerable set generated by the axioms and rules of the formal theory. A <em>proof</em> is an argument that demonstrates the truth of a proposition. While formal proofs are always proofs (at least, under the assumption of consistency of the underlying formal theory), a proof need not be, or even have a representation as, a formal proof. The principal example of this distinction is Goedel’s Theorem, which proves that the computably enumerable set of formal proofs in axiomatic arithmetic is not decidable. The key step is to devise a self-referential proposition that (a) is not formally provable, but (b) has a proof that shows that it is true. The crux of the argument is that <em>once you fix the rules of proof, you automatically miss out true things that are not provable in that fixed system</em>.</p>
<p>Now comes the confusing part. HoTT is defined as a formal system, so why doesn’t the same argument apply? It does, pretty much verbatim! But this has no bearing on “proof relevance” in HoTT, because the proofs that are relevant are not the formal proofs (derivations) defining HoTT as a formal system. Rather proofs are formulated internally as objects of the type theory, and there is no commitment <em>a priori</em> to being the only forms of proof there are. Thus, for example, we may easily see that there are only countably many functions definable in HoTT from the outside (because it is defined by a formal system), but within the theory any function space on an infinite type has uncountably many elements. There is no contradiction, because the proofs of implications, being internal functions, are not identified with codes of formal derivations, and hence are not denumerable.</p>
<p>There is a close analogy, <a href=\"http://existentialtype.wordpress.com/2012/08/09/churchs-law/\" title=\"Church’s Law\">previously noted</a> in this blog, with Church’s Law. Accepting Church’s Law internally amounts to fixing the programming language used to define functions in advance, permitting us to show, for example, that certain programs are not expressible in that language. But HoTT does not commit to Church’s Law, so such arguments amount to showing that, for example, there is no Turing machine to decide halting for Turing machines, but allowing that there could be constructive functions (say, equipped with oracles) that make such decisions.</p>
<p>The theory of formal proofs, often called proof theory, was dubbed <em>metamathematics</em> by Kleene. Until the development of type theory the study of proofs was confined to metamathematics. But now in the brave new world of <em>constructive mathematics</em> as embodied in HoTT, proofs (not just formal proofs) have pride of place in mathematics, and provide opportunities for expressing concepts clearly and cleanly that were hitherto obscured or even hidden from our view.</p>
<br />Filed under: <a href=\"http://existentialtype.wordpress.com/category/research/\">Research</a> Tagged: <a href=\"http://existentialtype.wordpress.com/tag/constructive-mathematics/\">constructive mathematics</a>, <a href=\"http://existentialtype.wordpress.com/tag/homotopy-type-theory/\">homotopy type theory</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/existentialtype.wordpress.com/823/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/existentialtype.wordpress.com/823/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=existentialtype.wordpress.com&blog=2157150&post=823&subd=existentialtype&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "07ff3bd98cf222c87a26a7e0d86dbcae") (222 (20957 28673 885471) "http://joyful.com/blog/2013-07-07-darcsden-db-thoughts.html" "Simon Michael: darcsden db thoughts" nil "Sun, 07 Jul 2013 23:00:00 +0000" "<div style=\"font-style: italic;\">July  7, 2013</div>
<h2>darcsden db thoughts</h2>
<p>
</p><p>Spent about half of yesterday setting up <a href=\"http://hub.darcs.net/Aditya/darcsden-import/changes\">Aditya’s darcsden patches</a> on the dev instance of hub.darcs.net, testing them, and exploring db migration issues.</p>
<p>Following BSRK’s instructions, I got the dev instance authenticating via Google’s OAuth servers. Good progress. The UI flow I saw needs a bit more work - eg logging in with google seemed to want me to register a new account. Or, there may be a problem with my setup at Google (wrong callback urls ?) - will have to review it with BSRK.</p>
<h3 id=\"schema-migrations\">Schema, migrations</h3>
<p>My dev instance has so far been using the same database as the live production instance. This is partly because I don’t yet know how to run a second CouchDB instance, partly to reduce complexity, partly to be able to compare old and new code with the same realistic data set.</p>
<p>This of course can lead to trouble, if old and new code require different schemas. darcsden uses CouchDB, a “schemaless” database, but of course there is an implicit schema required by the application code, even if couch doesn’t enforce one. I got more clarity on this when I noticed my dev instance experiments causing errors on the production app.</p>
<p>New darcsden code may include changes to the (implicit) db schema. In this case, there’s a change to the user’s password field. I need to notice such schema changes, and if I want to exercise them on the dev instance, I should first also install them on the production instance. Or, use a separate couchdb instance. Or, use separate databases in the couchdb instance. Or possibly, use separate views in the couchdb databases ?</p>
<p>Eg, here BSRK made the code nicely read user documents (db records) with the old or new schema. Before testing it on the shared db I should have deployed that patch to production as well as dev.</p>
<p>Looking ahead, is this approach (including code to deal with all old schemas) the best way to handle this ? Maybe. It makes things work and seems convenient, at least for now. But it also reminds me of years working with Zope’s ZODB (a schemaless python object database) and the layers of on-the-fly schema updating that built up, and the uncounted number of runtime bugs hunted down due to schema variations in individual objects.</p>
<h3 id=\"schema-less-or-schema-ful\">Schema-less or schema-ful ?</h3>
<p>While recovering from this, I learned some more about managing couchdb, schema migration, and current couchdb alternatives.</p>
<p>Couch has some really good and unusual qualities, and I feel I’m only scratching the surface of it’s power. Even so, I’m starting to feel a schema-ful, relational database is a better fit for darcsden/darcs hub. Replacing couch has been a topic of discussion on #darcs for some time, for other reasons. Here are some reasons to replace it:</p>
<ul>
<li><p>darcsden (more particularly, the instance running darcs hub, which has a lot of long-lived data) works best when all records have the same shape. It gains nothing from the flexibility of a loose schema, in fact will break, at runtime and unpredictably, unless you have extra code that handles all variations perfectly (a hard thing to test).</p></li>
<li><p>couchdb makes darcsden harder to set up, eg on windows. This makes it less successful in its goal to be an easy single-user ui for local darcs repos. It also reduces the number of darcsden hackers.</p></li>
<li><p>it adds complexity by embedding application code in the db. Instead of all logic being in haskell, the darcsden developer has to also deal with design documents and javascript map/reduce functions, and manage the state of those within the db.</p></li>
<li><p>it adds complexity by being less familiar to most people than rdbms system, and by having less mature tools.</p></li>
<li><p>persistent, the likely alternative, would more easily support both large installations (eg postgres for darcs hub) and single-user ones (sqlite) with less code.</p></li>
</ul>
<p>Some reasons not to:</p>
<ul>
<li><p>Don’t replace working code!</p></li>
<li><p>Replacing it could be wasted effort, better spent fixing end-user bugs on darcs hub.</p></li>
<li><p>The migration issue can easily be worked around. It’s not that big a deal for this instance.</p></li>
<li><p>Don’t disrupt the GSOC in progress!</p></li>
</ul>
<p>
<br />
<em><a href=\"http://joyful.com/tags/darcs.html\">darcs</a>, <a href=\"http://joyful.com/tags/haskell.html\">haskell</a>, <a href=\"http://joyful.com/tags/ops.html\">ops</a></em></p>" nil nil "f09fa546fecb2b614566213349ba3265") (221 (20957 28673 880036) "http://joyful.com/blog/2013-07-01-june-review.html" "Simon Michael: June review" nil "Mon, 01 Jul 2013 23:00:00 +0000" "<div style=\"font-style: italic;\">July  1, 2013</div>
<h2>June review</h2>
<p>
</p><p>The beginning of a new month. Here’s a quick update.</p>
<p>No hledger release today as there isn’t much new to ship, following a month with several <a href=\"http://hledger.org/NEWS.html\">bugfix releases</a> and otherwise mostly infrastructural work (build and dev tool fixes, wiki styling, site update hook). 8/1 is the likely next release date. Oh, <a href=\"http://newartisans.com/\">John</a> and I also had a nice voice chat - nice to escape the IRC window isn’t it - reviewing our glorious *ledger plans, and I happily accepted his <a href=\"https://github.com/simonmichael/hledger/commit/a05e7a5a671af25b220eb4f152ad935687faef1a\">first hledger patch</a> - thanks John! :)</p>
<p>My free hacking time in recent weeks went more towards <a href=\"http://darcs.net\">darcs</a>:</p>
<ul>
<li><p>Unix shell helpers to get one-line-per-patch output from darcs (awesome!)</p>
<pre class=\"sourceCode bash\"><code class=\"sourceCode bash\"><span class=\"co\"># show darcs changes, push, pull etc. output with one patch per line</span>
<span class=\"co\"># Eg:</span>
<span class=\"co\"># dch --last 3</span>
<span class=\"co\"># darcs pull --dry | d1</span>
<span class=\"kw\">alias</span> darcsoneline=<span class=\"st\">\"egrep '^\\w' -A1 | egrep -v '^(--|The remote repository has|Would pu)' | sed '</span><span class=\"ot\">$!</span><span class=\"st\">N;s/\\n/ /'\"</span>
<span class=\"kw\">alias</span> d1=darcsoneline
<span class=\"kw\">function</span><span class=\"fu\"> dch()</span> <span class=\"kw\">{</span>
<span class=\"kw\">darcs</span> changes <span class=\"ot\">$*</span> <span class=\"kw\">|</span> <span class=\"kw\">darcsoneline</span>
<span class=\"kw\">}</span></code></pre></li>
<li><p>Support for BSRK Aditya’s <a href=\"http://hub.darcs.net/Aditya/darcsden-gsoc/changes\">GSOC work</a>. Together with Ganesh Sittampalam we did several rounds of code review and BSRK’s nice enhancements should be appearing on darcs hub soon.</p></li>
<li><p>Also driven by the above, updated <a href=\"http://hub.darcs.net/simon/darcsden/changes\">darcsden</a> and HSP for current GHC and libraries, and made it easy for me to build and deploy again. Also merged <a href=\"http://hub.darcs.net/ganesh/darcsden-service/changes\">Ganesh’s improvements</a> for MS Windows compatibility. This will be released as darcsden 1.1 shortly.</p></li>
<li><p>Ongoing <a href=\"http://hub.darcs.net\">darcs hub</a> ops/maintenance, including a fix for <a href=\"http://hub.darcs.net/simon/darcsden/issue/59\">this interesting segfault</a>, and a server upgrade from ubuntu 12.04 to 13.04. This last caused about <s>45m</s><a href=\"http://stats.pingdom.com/olo874j6ixzj/632910/2013/06\">1h20m of downtime >:(</a> late last night as I wrestled with the unfamiliar couchdb migration process and erlang stack traces. (For reference: just copy /var/lib/couchdb/1.0.1/* to 1.2.0/, but <em>don’t forget to preserve file ownership</em>.) At least it got resolved it before month-end at pingdom, so there’s a chance to get uptime back up where it should be - 3 or 4 nines - in July!</p></li>
</ul>
<p>
<br />
<em><a href=\"http://joyful.com/tags/hledger.html\">hledger</a>, <a href=\"http://joyful.com/tags/darcs.html\">darcs</a>, <a href=\"http://joyful.com/tags/haskell.html\">haskell</a>, <a href=\"http://joyful.com/tags/ops.html\">ops</a></em></p>" nil nil "41c148c575d6bbe2b1f8f59a7ff76d02") (220 (20957 28673 776213) "http://joyful.com/blog/2013-06-18-darcsden-cleanup.html" "Simon Michael: darcsden cleanup" nil "Wed, 19 Jun 2013 01:15:00 +0000" "<div style=\"font-style: italic;\">June 19, 2013</div>
<h2>darcsden cleanup</h2>
<p>
</p><p>Back to the dev diary. <a href=\"http://joyful.com/2013-06-07-git-hooks-for-site-updates.html\">Last post</a> was 11 days ago, after a two-week opening streak of daily posts. I got blocked on one, then got busy. Press on.</p>
<p>Yesterday I started looking at BSRK Aditya’s <a href=\"http://bsrkaditya.blogspot.com/2013/06/gsoc-2013-enhancing-darcsden-preweek-1.html\">GSOC darcsden enhancements</a>, to review and hopefully deploy on <a href=\"http://hub.darcs.net\">darcs hub</a>. So far he has worked on alternate login methods (github/google), password reminder, and darcs pack support (for faster gets).</p>
<p>This is forcing some darcsden cleanup, my first darcsden work in a while aside from routine ops and support tasks. I’m going to release what’s in trunk as 1.1, and then start assimilating the new work by BSRK, Ganesh Sittampalam and anyone else who feels like chipping in. Started putting together release notes and a hub status update.</p>
<p>The support requests seem to be on the rise - more usage ? I also found a good bug today: viewing a certain 1K troff file causes darcs hub’s memory footprint to <a href=\"http://hub.darcs.net/simon/darcsden/issue/58\">blow up to 1.5G</a> :)</p>
<p>It would be great to have more functionality (like highlighting) broken out into separate, expendable worker processes, erlang style.</p>
<p>
<br />
<em><a href=\"http://joyful.com/tags/darcs.html\">darcs</a>, <a href=\"http://joyful.com/tags/haskell.html\">haskell</a></em></p>" nil nil "626c072f03bd0cde5daf3f91f02596b1") (219 (20957 6059 317912) "http://r6.ca/blog/20130710T012527Z.html" "Russell O'Connor: Key Stretching" nil "Wed, 10 Jul 2013 01:25:27 +0000" "<p>I have been on a bit of a key stretching binge this week.
There is a <a href=\"http://martin.kleppmann.com/2013/05/24/improving-security-of-ssh-private-keys.html\" title=\"Improving the security of your SSH private key files\">wonderful article on how to stretch your ssh keys</a>.
Apparently, by default all that stands between your ssh passphrase and your ssh key is a single round of MD5 with 8 bytes of salt.
However, because ssh relies upon openssl, you can change the password format to use PBKDF2.
It is really easy to do.  I highly recommend doing it.</p><p>Next up, I have been wanting to add key streching to my disk encryption for a while.
The problem is that when dm-crypt operates in plain mode, it simply hashes your passphrase once with a given hash.
I am not a big fan of LUKS because the LUKS headers make it really apparent there is encrypted data on your drive rather than a wiped hard disk.
Since I was going to need to stretch my passphrase by hand, I figured I might as well use <a href=\"http://tools.ietf.org/html/draft-josefsson-scrypt-kdf-01\" title=\"The scrypt Password-Based Key Derivation Function\">scrypt</a>.
The problem was that I could not find any stand-alone implementation of scrypt, so I cobbled together <a href=\"http://r6.ca/crypto_scrypt-0.0/crypto_scrypt.c\">my own stand-alone <kbd>crypto_scrypt</kbd> utilty</a>.
It is not pretty; it is in serious need of some command line parameter love; but it works.
I even make <a href=\"http://r6.ca/crypto_scrypt-0.0/crypto_scrypt.nix\">a little <kbd>crypto_scrypt</kbd> nix expression</a> so I could integrate it into my boot process.
</p>" nil nil "b5966e615bc6dbea257308039001f72b") (218 (20956 14885 748324) "http://alessandrovermeulen.me/2013/07/08/combining-graphviz-dot-and-tikz-with-dot2tex/" "Alessandro Vermeulen: Combining graphviz (dot) and TikZ with dot2tex" nil "Mon, 08 Jul 2013 21:06:00 +0000" "<p>We all want to create good looking documents and good looking documents need
good looking images. Because we want consistency and because we are lazy we
want to do this as automatic as possible. That is why we use <span>L<span style=\"\">a</span>T<span style=\"\">e</span>X</span>,
it creates beautifully typeset documents without much manual effort.</p>
<p>Similarly, we use graphviz to generate our graphs for us. It’s automatic layout is the best in the
field and the (<a href=\"http://alessandrovermeulen.me/2013/05/19/why-you-should-switch-to-declarative-programming/\">declarative</a>) dot language is easy to understand and compact to write. We can either include the PDFs dot generated in our document by using <code>\\includegraphics</code> or we could use the latex <a href=\"https://github.com/mprentice/GraphViz-sty\">graphviz package</a>, remember that we are lazy. We can easily get
the image in <a href=\"http://alessandrovermeulen.me/atom.xml#example1\">our first example</a> in our PDF.</p>
<div class=\"bogus-wrapper\"><notextile><figure id=\"example1\">
<img src=\"http://farm8.staticflickr.com/7313/9243796534_60bb926e44_o.png\" alt=\"Image with graphviz\" height=\"155\" width=\"563\" />
<figcaption><strong>Figure 1.</strong> Example of an image generated by Graphviz/dot</figcaption>
</figure></notextile></div>
<p>There is a shadow side to using Graphviz/dot as well. There are two problems.
Firstly, the image just looks a bit out of place around the nicely smoothed
text in a PDF. Secondly, we lack the ability to use TeX code in our graph.
This means we are limited to the formatting by dot and the graphs could
therefore appear out of style with other figures in our document.</p>
<p>No worries, with TikZ it is possible to create very fancy graphs and images in
general but you have to all the positioning manually! Imagine inserting a node
and having to reorder everything!</p>
<p>Enter <a href=\"http://www.fauskes.net/code/dot2tex/\">dot2tex</a> it brings all the love
of graphviz/dot to TeX/TikZ. Using dot2tex has many advantages:</p>
<ol>
<li>Lets you write your graphs in familiar dot syntax;</li>
<li>Let dot – or whichever layout engine you prefer – determine the placement of
your nodes and arrows;</li>
<li>Style your nodes however you want by using TikZ styles;</li>
<li>Optionally, fine-tune the graph by adding extra tikz drawings.</li>
</ol>
<p>Rather than manually calling dot2tex for every dot file you have please use
the <a href=\"http://www.ctan.org/pkg/dot2texi\">dot2texi package</a>. This is the interface to dot2tex and when used as follows generates the image as displayed in <a href=\"http://alessandrovermeulen.me/atom.xml#example2\">Figure 2</a>.</p>
<div class=\"bogus-wrapper\"><notextile><figure class=\"code\"><figcaption><span></span></figcaption><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
<span class=\"line-number\">2</span>
<span class=\"line-number\">3</span>
<span class=\"line-number\">4</span>
<span class=\"line-number\">5</span>
<span class=\"line-number\">6</span>
<span class=\"line-number\">7</span>
<span class=\"line-number\">8</span>
<span class=\"line-number\">9</span>
<span class=\"line-number\">10</span>
<span class=\"line-number\">11</span>
<span class=\"line-number\">12</span>
<span class=\"line-number\">13</span>
<span class=\"line-number\">14</span>
<span class=\"line-number\">15</span>
<span class=\"line-number\">16</span>
<span class=\"line-number\">17</span>
<span class=\"line-number\">18</span>
<span class=\"line-number\">19</span>
<span class=\"line-number\">20</span>
<span class=\"line-number\">21</span>
</pre></td><td class=\"code\"><pre><code class=\"latex\"><span class=\"line\">  <span class=\"k\">\\begin</span><span class=\"nb\">{</span>tikzpicture<span class=\"nb\">}</span>[>=latex',scale=0.5]
</span><span class=\"line\">    <span class=\"c\">% set node style</span>
</span><span class=\"line\">
</span><span class=\"line\">    <span class=\"k\">\\begin</span><span class=\"nb\">{</span>dot2tex<span class=\"nb\">}</span>[dot,tikz,codeonly,styleonly,options=-s -tmath]
</span><span class=\"line\">        digraph G  <span class=\"nb\">{</span>
</span><span class=\"line\">            node [style=\"n\"];
</span><span class=\"line\">            p [label=\"+\"];
</span><span class=\"line\">            t [texlbl=\"<span class=\"k\">\\LaTeX</span>\"];
</span><span class=\"line\">            6
</span><span class=\"line\">            8
</span><span class=\"line\">            10-> p;
</span><span class=\"line\">            6 -> t;
</span><span class=\"line\">            8 -> t;
</span><span class=\"line\">            t -> p;
</span><span class=\"line\">            <span class=\"nb\">{</span>rank=same; 10;6;8<span class=\"nb\">}</span>
</span><span class=\"line\">        <span class=\"nb\">}</span>
</span><span class=\"line\">    <span class=\"k\">\\end</span><span class=\"nb\">{</span>dot2tex<span class=\"nb\">}</span>.
</span><span class=\"line\">    <span class=\"k\">\\begin</span><span class=\"nb\">{</span>pgfonlayer<span class=\"nb\">}{</span>background<span class=\"nb\">}</span>
</span><span class=\"line\">        <span class=\"k\">\\draw</span><span class=\"na\">[rounded corners,fill=blue!20]</span> (6.north west) -- (8.north east) -- (t.south east)--cycle;
</span><span class=\"line\">    <span class=\"k\">\\end</span><span class=\"nb\">{</span>pgfonlayer<span class=\"nb\">}</span>
</span><span class=\"line\"><span class=\"k\">\\end</span><span class=\"nb\">{</span>tikzpicture<span class=\"nb\">}</span>
</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<div class=\"bogus-wrapper\"><notextile><figure id=\"example2\">
<img src=\"http://farm4.staticflickr.com/3804/9241070475_9d48236aa7_o.png\" alt=\"Example of TeX typesetting + TikZ background\" height=\"410\" width=\"430\" />
<figcaption><strong>Figure 2.</strong> Example of TeX typesetting + TikZ background</figcaption>
</figure></notextile></div>
<p>For more TikZ goodness check out the <a href=\"http://www.texample.net/tikz/examples/\">example site</a>.</p>
<p>Happy writing!</p>" nil nil "ac9183134ea604ec160de19c7d043d34") (217 (20955 50167 29692) "http://alessandrovermeulen.me/2013/07/08/combining-graphviz-dot-and-tikz-with-dot2tex/" "Alessandro Vermeulen: Combining graphviz (dot) and TikZ with dot2tex" nil "Mon, 08 Jul 2013 21:06:00 +0000" "<p>We all want to create good looking documents and good looking documents need
good looking images. Because we want consistency and because we are lazy we
want to do this as automatic as possible. That is why we use <span>L<span style=\"\">a</span>T<span style=\"\">e</span>X</span>,
it creates beautifully typeset documents without much manual effort.</p>
<p>Similarly, we use graphviz to generate our graphs for us. It’s automatic layout is the best in the
field and the (<a href=\"http://alessandrovermeulen.me/2013/05/19/why-you-should-switch-to-declarative-programming/\">declarative</a>) dot language is easy to understand and compact to write. We can either include the PDFs dot generated in our document by using <code>\\includegraphics</code> or we could use the latex <a href=\"https://github.com/mprentice/GraphViz-sty\">graphviz package</a>, remember that we are lazy. We can easily get
the image in <a href=\"http://alessandrovermeulen.me/atom.xml#example1\">our first example</a> in our PDF.</p>
<div class=\"bogus-wrapper\"><notextile><figure id=\"example1\">
<img src=\"http://farm8.staticflickr.com/7313/9243796534_60bb926e44_o.png\" alt=\"Image with graphviz\" height=\"155\" width=\"563\" />
<figcaption><strong>Figure 1.</strong> Example of an image generated by Graphviz/dot</figcaption>
</figure></notextile></div>
<p>There is a shadow side to using Graphviz/dot as well. There are two problems.
Firstly, the image just looks a bit out of place around the nicely smoothed
text in a PDF. Secondly, we lack the ability to use TeX code in our graph.
This means we are limited to the formatting by dot and the graphs could
therefore appear out of style with other figures in our document.</p>
<p>No worries, with TikZ it is possible to create very fancy graphs and images in
general but you have to all the positioning manually! Imagine inserting a node
and having to reorder everything!</p>
<p>Enter <a href=\"http://www.fauskes.net/code/dot2tex/\">dot2tex</a> it brings all the love
of graphviz/dot to TeX/TikZ. Using dot2tex has many advantages:</p>
<ol>
<li>Lets you write your graphs in familiar dot syntax;</li>
<li>Let dot – or whichever layout engine you prefer – determine the placement of
your nodes and arrows;</li>
<li>Style your nodes however you want by using TikZ styles;</li>
<li>Optionally, fine-tune the graph by adding extra tikz drawings.</li>
</ol>
<p>Rather than manually calling dot2tex for every dot file you have please use
the <a href=\"http://www.ctan.org/pkg/dot2texi\">dot2texi package</a>. This is the interface to dot2tex and when used as follows generates the image as displayed in <a href=\"http://alessandrovermeulen.me/atom.xml#example2\">Figure 2</a>.</p>
<div class=\"bogus-wrapper\"><notextile><figure id=\"example2\">
<img src=\"http://farm4.staticflickr.com/3804/9241070475_9d48236aa7_o.png\" alt=\"Example of TeX typesetting + TikZ background\" height=\"410\" width=\"430\" />
<figcaption><strong>Figure 2.</strong> Example of TeX typesetting + TikZ background</figcaption>
</figure></notextile></div>
<p>For more TikZ goodness check out the <a href=\"http://www.texample.net/tikz/examples/\">example site</a>.</p>
<p>Happy writing!</p>" nil nil "2180f6ec0f064fd1397a22c396fffcd3") (216 (20955 50167 29077) "http://feedproxy.google.com/~r/FpComplete/~3/AqtR2WFTzGY/new-product-tab" "FP Complete: FP Complete Product Tab" nil "Mon, 08 Jul 2013 19:51:00 +0000" "<p><b>FP Complete Product Tab</b></p><p>Now that the Beta has been released, we want to be sure our users
have everything they need to be successful. Visit our new <a href=\"https://www.fpcomplete.com/business/haskell-center/overview\">product tab</a>
to access the following features:</p><ul><li><a href=\"https://www.fpcomplete.com/business/haskell-center/overview\">FP Haskell
Center</a> (product overview)</li><li><a href=\"https://www.fpcomplete.com/business/haskell-center/video-walk-through\">Video
Walk Through</a> of FP Haskell Center (Step-by-step overview of our services)</li><li>FP Haskell Center <a href=\"https://www.fpcomplete.com/business/haskell-center/release-notes\">Release
Notes</a> (Beta information)</li><li>FP Haskell Center <a href=\"https://www.fpcomplete.com/business/haskell-center/feature-checklist\">Feature
Check List</a> (Notes to help you get started and features we want you to test)</li><li><a href=\"https://www.fpcomplete.com/school\">School
of Haskell</a> (Tutorials and feature articles)</li></ul><p>Our library continues to grow and is full of valuable information to help you be
successful with your Haskell projects. From design through implementation, we want
to be sure you have access to everything you need. If you think we’re missing
anything let us know. We’d love to hear from you. </p><div class=\"feedflare\">
<a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=AqtR2WFTzGY:mHc2Ux6eEFo:yIl2AUoC8zA\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=yIl2AUoC8zA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=AqtR2WFTzGY:mHc2Ux6eEFo:V_sGLiPBpWU\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=AqtR2WFTzGY:mHc2Ux6eEFo:V_sGLiPBpWU\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=AqtR2WFTzGY:mHc2Ux6eEFo:qj6IDK7rITs\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=qj6IDK7rITs\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=AqtR2WFTzGY:mHc2Ux6eEFo:gIN9vFwOqvQ\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=AqtR2WFTzGY:mHc2Ux6eEFo:gIN9vFwOqvQ\" border=\"0\" /></a>
</div><img src=\"http://feeds.feedburner.com/~r/FpComplete/~4/AqtR2WFTzGY\" height=\"1\" width=\"1\" />" nil nil "3884c3815bc44c6ac75611bc837bf25d") (215 (20955 50167 28557) "http://byorgey.wordpress.com/2013/07/08/farm-2013-call-for-demonstration-proposals/" "Brent Yorgey: FARM 2013: call for demonstration proposals" nil "Mon, 08 Jul 2013 16:57:37 +0000" "<p>Do you enjoy writing beautiful code to produce beautiful artifacts? Have something cool to show off at the intersection of functional programming and visual art, music, sound, modeling, visualization, or design?</p>
<p>The deadline for submitting a paper has passed, but the <a href=\"http://www.cis.upenn.edu/~byorgey/farm13/\">Workshop on Functional Art, Music, Modeling and Design (FARM 2013)</a> is currently seeking proposals for <em>10-20 minute demonstrations</em> to be given during the workshop. For example, a demonstration could consist of a short tutorial, an exhibition of some work, or even a livecoding performance. Slots for demonstrations will be shorter than slots for accepted papers, and will not be published as part of the formal proceedings, but can be a great way to show off interesting work and get feedback from other workshop participants. A demonstration slot could be a particularly good way to get feedback on work-in-progress.</p>
<p>A demo proposal should consist of a 1 page abstract, in PDF format, explaining the proposed content of the demonstration and why it would be of interest to the attendees of FARM. Proposals will be judged on interest and relevance to the stated goals and themes of the workshop.</p>
<p>Submissions can be <a href=\"https://www.easychair.org/conferences/?conf=farm2013\">made via EasyChair</a>.</p>
<br />  <a href=\"http://feeds.wordpress.com/1.0/gocomments/byorgey.wordpress.com/1092/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/byorgey.wordpress.com/1092/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=byorgey.wordpress.com&blog=1152889&post=1092&subd=byorgey&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "316234683876e1749217cc16266ecb00") (214 (20954 60216 748062) "http://parenz.wordpress.com/2013/07/08/the-protocol-problem/" "Daniil Frumin: The Protocol Problem" nil "Mon, 08 Jul 2013 16:21:06 +0000" "<p>In the interactive-diagrams project we have a bunch of components (processes) running independently and even under different UIDs. They however need to communicate with each other, and we’ve decided to go full UNIX-way (since already most of our code depend on POSIX-compatibility) and use IPC/UNIX-sockets for communication.</p>
<p>Originally, I’ve implemented the following protocol for sending the<br />
data around:</p>
<p>When sending data:</p>
<ol class=\"org-ol\">
<li>Encode the data using the functions from the <a href=\"http://hackage.haskell.org/package/cereal\">cereal</a> package.</li>
<li>Take the ‘length’ of the resulting bytestring, send it over the<br />
socket.</li>
<li>Send the encoded data on the next line.</li>
</ol>
<p>Upon receiving data:</p>
<ol class=\"org-ol\">
<li>Read the first line, deserialize it to an <code>x :: Int</code></li>
<li>Read the the next <code>x</code> bytes, deserialize the data.</li>
</ol>
<p>A programmer experienced in the area would have probably already<br />
spotted an error in this approach, but for me it took some time to<br />
find a bug, once I’ve realised that I was getting deserialization<br />
errors from time to time.</p>
<p>The problem of course is that I was relying on reading lines from the<br />
socket, not bytes. For example, the number 2623 on my 64bit system has<br />
serialized to something with the newline character in it</p>
<div class=\"figure\">
<p><img src=\"http://orbt.io/Q6I3.png\" alt=\"Q6I3.png\" /></p>
</div>
<p>The solution to this problem is to read the first ’8′ (or ’4′) bytes<br />
to get the length of the upcoming data. To make sure that the number<br />
of bytes representing the length of the data is constant on all the<br />
platforms I’ve switched to using <code>Word32</code>.</p>
<p>This approach too, of course, is not prone to errors. If you are<br />
sending and receiving a lot of data consider using a streaming<br />
library.</p>
<p>PS: We’ve planned originally to release the first public alpha-version yesterday, but it turned out that it is actually taking more time configuring SELinux, chroots and other security measure than expected. I’ve also changed the general structure of the project, I am using a different design model than I had a week ago. The new changes would make the application more salable and the resulting library can (and most likely will) be reused for other stuff. Stay tuned!</p>
<br /> Tagged: <a href=\"http://parenz.wordpress.com/tag/haskell-2/\">haskell</a>, <a href=\"http://parenz.wordpress.com/tag/interactive-diagrams/\">interactive-diagrams</a>, <a href=\"http://parenz.wordpress.com/tag/networking/\">networking</a>, <a href=\"http://parenz.wordpress.com/tag/soc/\">soc</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/parenz.wordpress.com/74/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/parenz.wordpress.com/74/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=parenz.wordpress.com&blog=26722965&post=74&subd=parenz&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "fa0048c045e4d6ed9eced14a3289e8ca") (213 (20954 30960 949205) "http://kenta.blogspot.com/2013/07/kqfwttaf-random-access-to-random.html" "Ken T Takusagawa: [kqfwttaf] Random access to Random" "noreply@blogger.com (Ken)" "Mon, 08 Jul 2013 04:59:00 +0000" "<p dir=\"ltr\">A pseudorandom number generator implemented using a block cipher in Counter mode has the feature that one can fast-forward to any random number in the stream without having to generate the previous ones.  And rewind.  Can we leverage this feature to do interesting things not possible with a traditional RNG which operates by iterating a function on a state?</p><p dir=\"ltr\">Suppose we are modeling a Markov process.  Can we fast forward this process the same way?</p><p dir=\"ltr\">Probably not in general, but there may be interesting special cases.  An arbitrary Fibonacci number can be computed with the number of operations logarithmic in the index (not linear as the naive way of generating Fibonacci.)</p><p dir=\"ltr\">The oblique inspiration was the Haskell RandomGen \"split\" operation which allows random computations to be parallelized, again not possible for a traditional iterative RNG.</p><p dir=\"ltr\">Are there more interesting computational structures to generate randomness with interesting features?</p>" nil nil "3dbb401c1239919f8b11cafc94666675") (212 (20954 30960 948831) "http://joyful.com/blog/2013-07-07-darcsden-db-thoughts.html" "Simon Michael: darcsden db thoughts" nil "Sun, 07 Jul 2013 23:00:00 +0000" "<div style=\"font-style: italic;\">July  7, 2013</div>
<h2>darcsden db thoughts</h2>
<p>
</p><p>Spent about half of yesterday setting up <a href=\"http://hub.darcs.net/Aditya/darcsden-import/changes\">Aditya’s darcsden patches</a> on the dev instance of hub.darcs.net, testing them, and exploring db migration issues.</p>
<p>Following BSRK’s instructions, I got the dev instance authenticating via Google’s OAuth servers. Good progress. The UI flow I saw needs a bit more work - eg logging in with google seemed to want me to register a new account. Or, there may be a problem with my setup at Google (wrong callback urls ?) - will have to review it with BSRK.</p>
<h2 id=\"schema-migrations\">Schema, migrations</h2>
<p>My dev instance has so far been using the same database as the live production instance. This is partly because I don’t yet know how to run a second CouchDB instance, partly to reduce complexity, partly to be able to compare old and new code with the same realistic data set.</p>
<p>This of course can lead to trouble, if old and new code require different schemas. darcsden uses CouchDB, a “schemaless” database, but of course there is an implicit schema required by the application code, even if couch doesn’t enforce one. I got more clarity on this when I noticed my dev instance experiments causing errors on the production app.</p>
<p>New darcsden code may include changes to the (implicit) db schema. In this case, there’s a change to the user’s password field. I need to notice such schema changes, and if I want to exercise them on the dev instance, I should first also install them on the production instance. Or, use a separate couchdb instance. Or, use separate databases in the couchdb instance. Or possibly, use separate views in the couchdb databases ?</p>
<p>Eg, here BSRK made the code nicely read user documents (db records) with the old or new schema. Before testing it on the shared db I should have deployed that patch to production as well as dev.</p>
<p>Looking ahead, is this approach (including code to deal with all old schemas) the best way to handle this ? Maybe. It makes things work and seems convenient, at least for now. But it also reminds me of years working with Zope’s ZODB (a schemaless python object database) and the layers of on-the-fly schema updating that built up, and the uncounted number of runtime bugs hunted down due to schema variations in individual objects.</p>
<h2 id=\"schema-less-or-schema-ful\">Schema-less or schema-ful ?</h2>
<p>While recovering from this, I learned some more about managing couchdb, schema migration, and current couchdb alternatives.</p>
<p>Couch has some really good and unusual qualities, and I feel I’m only scratching the surface of it’s power. Even so, I’m starting to feel a schema-ful, relational database is a better fit for darcsden/darcs hub. Replacing couch has been a topic of discussion on #darcs for some time, for other reasons. Here are some reasons to replace it:</p>
<ul>
<li><p>darcsden (more particularly, the instance running darcs hub, which has a lot of long-lived data) works best when all records have the same shape. It gains nothing from the flexibility of a loose schema, in fact will break, at runtime and unpredictably, unless you have extra code that handles all variations perfectly (a hard thing to test).</p></li>
<li><p>couchdb makes darcsden harder to set up, eg on windows. This makes it less successful in its goal to be an easy single-user ui for local darcs repos. It also reduces the number of darcsden hackers.</p></li>
<li><p>it adds complexity by embedding application code in the db. Instead of all logic being in haskell, the darcsden developer has to also deal with design documents and javascript map/reduce functions, and manage the state of those within the db.</p></li>
<li><p>it adds complexity by being less familiar to most people than rdbms system, and by having less mature tools.</p></li>
<li><p>persistent, the likely alternative, would more easily support both large installations (eg postgres for darcs hub) and single-user ones (sqlite) with less code.</p></li>
</ul>
<p>Some reasons not to:</p>
<ul>
<li><p>Don’t replace working code!</p></li>
<li><p>Replacing it could be wasted effort, better spent fixing end-user bugs on darcs hub.</p></li>
<li><p>The migration issue can easily be worked around. It’s not that big a deal for this instance.</p></li>
<li><p>Don’t disrupt the GSOC in progress!</p></li>
</ul>" nil nil "672a1abec3badeb1ee7b14f83e466ab3") (211 (20954 30960 948013) "http://feedproxy.google.com/~r/FpComplete/~3/FaTU0eHhtDI/beta-activation-update" "FP Complete: FP Haskell Center Beta Sign-Up Still Open. Scheduled Activations Ongoing" nil "Fri, 05 Jul 2013 19:51:00 +0000" "<p>﻿<b>FP Haskell Center Beta Sign-Up Still Open.  Scheduled Activations Ongoing.</b></p><p>We got many enthusiastic beta testers asking “I am all ready to test the product.  When can I get activated?”   Here’s the story: we started activating beta sign ups since last Sunday, based on a schedule of increasing numbers each day.  We have over 1,000 sign-ups to-date, so we expect to activate all by July 15.  If you already signed up and haven’t received notice yet to activate, please wait a few more days, we will get to all of you.  There is NO NEED TO SIGN-UP AGAIN.</p><p>If you haven’t signed up yet, by all means do, here: https://www.fpcomplete.com/business/designer-ide. </p><p>All of us at FP Complete are excited and gratified by the mostly positive comments about the product based on the <a href=\"https://www.fpcomplete.com/blog/2013/06/fp-haskell-center-beta-demo\">video walkthrough</a> of the product.  We are eagerly awaiting the feedback from you as you are testing the product.  Thanks in advance!</p><div class=\"feedflare\">
<a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=FaTU0eHhtDI:sIRcM0MY9xM:yIl2AUoC8zA\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=yIl2AUoC8zA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=FaTU0eHhtDI:sIRcM0MY9xM:V_sGLiPBpWU\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=FaTU0eHhtDI:sIRcM0MY9xM:V_sGLiPBpWU\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=FaTU0eHhtDI:sIRcM0MY9xM:qj6IDK7rITs\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=qj6IDK7rITs\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=FaTU0eHhtDI:sIRcM0MY9xM:gIN9vFwOqvQ\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=FaTU0eHhtDI:sIRcM0MY9xM:gIN9vFwOqvQ\" border=\"0\" /></a>
</div><img src=\"http://feeds.feedburner.com/~r/FpComplete/~4/FaTU0eHhtDI\" height=\"1\" width=\"1\" />" nil nil "115d34f590e73d777135a427f63d89d6") (210 (20954 30960 947381) "http://twanvl.nl/blog/agda/cong-from-refl" "Twan van Laarhoven: cong from refl in univalent OTT" nil "Thu, 04 Jul 2013 16:00:00 +0000" "<p>This is a follow up on <a href=\"http://twanvl.nl/blog/agda/subst-from-cong\">last week's post</a>.
There I showed that in a univalent Observational Type Theory, you can derive <tt><span class=\"varid\">subst</span></tt> from <tt><span class=\"varid\">cong</span></tt>.
Now I am going to go one step further.
</p><p>Suppose we change the definition of paths for functions from
</p><pre class=\"agda\"><span class=\"conid\">Path</span> (<span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>) <span class=\"varid\">f</span> <span class=\"varid\">g</span> <span class=\"varop\">≡</span> <span class=\"keyglyph\">∀</span> <span class=\"varid\">x</span> <span class=\"keyglyph\">→</span> <span class=\"varid\">f</span> <span class=\"varid\">x</span> <span class=\"varop\">≡</span> <span class=\"varid\">g</span> <span class=\"varid\">x</span>
</pre><p>to
</p><pre class=\"agda\"><span class=\"conid\">Path</span> (<span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>) <span class=\"varid\">f</span> <span class=\"varid\">g</span> <span class=\"varop\">≡</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">x</span> <span class=\"varid\">y</span>} <span class=\"keyglyph\">→</span> <span class=\"varid\">x</span> <span class=\"varop\">≡</span> <span class=\"varid\">y</span> <span class=\"keyglyph\">→</span> <span class=\"varid\">f</span> <span class=\"varid\">x</span> <span class=\"varop\">≡</span> <span class=\"varid\">g</span> <span class=\"varid\">y</span>
</pre><p>Then for a function <tt><span class=\"varid\">f</span></tt>, <tt class=\"complex\"><span class=\"varid\">refl</span> <span class=\"varid\">f</span></tt> is actually the same thing as <tt class=\"complex\"><span class=\"varid\">cong</span> <span class=\"varid\">f</span></tt>!.
So that's one less primitive to worry about. In fact the only two path related primitives that remain are <tt><span class=\"conid\">Path</span></tt> and <tt><span class=\"varid\">refl</span></tt>. The rest is just in the computation rules.
</p><p>Here are the changes in the agda code compared to last week:
</p><pre class=\"agda\"><span class=\"keyword\">postulate</span> <span class=\"conid\">Path-→</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>} (<span class=\"varid\">f</span> <span class=\"varid\">g</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>)
<span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>) <span class=\"varid\">f</span> <span class=\"varid\">g</span>
<span class=\"varop\">≡</span> ((<span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">B</span> (<span class=\"varid\">f</span> <span class=\"varid\">x</span>) (<span class=\"varid\">g</span> <span class=\"varid\">y</span>))
<div class=\"empty-line\"></div>
<span class=\"comment\">-- cong = refl</span>
<span class=\"varid\">cong</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>}
<span class=\"keyglyph\">→</span> (<span class=\"varid\">f</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>) <span class=\"keyglyph\">→</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">x</span> <span class=\"varid\">y</span>} <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">B</span> (<span class=\"varid\">f</span> <span class=\"varid\">x</span>) (<span class=\"varid\">f</span> <span class=\"varid\">y</span>)
<span class=\"varid\">cong</span> <span class=\"varid\">f</span> <span class=\"varid\">x=y</span> <span class=\"keyglyph\">=</span> <span class=\"varid\">Meta.subst</span> <span class=\"varid\">id</span> (<span class=\"conid\">Path-→</span> <span class=\"varid\">f</span> <span class=\"varid\">f</span>) (<span class=\"varid\">refl</span> <span class=\"keyglyph\">_</span> <span class=\"varid\">f</span>) <span class=\"keyglyph\">_</span> <span class=\"keyglyph\">_</span> <span class=\"varid\">x=y</span>
<div class=\"empty-line\"></div>
<span class=\"comment\">-- subst is the same as last time</span>
<span class=\"varid\">subst</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} (<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>)
<span class=\"keyglyph\">→</span> {<span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>} <span class=\"keyglyph\">→</span> (<span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span> <span class=\"varid\">x</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span> <span class=\"varid\">y</span>
<span class=\"varid\">subst</span> <span class=\"conid\">B</span> {<span class=\"varid\">x</span>} {<span class=\"varid\">y</span>} <span class=\"varid\">p</span> <span class=\"varid\">with</span> <span class=\"varid\">Meta.subst</span> <span class=\"varid\">id</span> (<span class=\"conid\">Path-Type</span> (<span class=\"conid\">B</span> <span class=\"varid\">x</span>) (<span class=\"conid\">B</span> <span class=\"varid\">y</span>)) (<span class=\"varid\">cong</span> <span class=\"conid\">B</span> <span class=\"varid\">p</span>)
<span class=\"varop\">...</span> <span class=\"keyglyph\">|</span> <span class=\"varid\">lift</span> (<span class=\"varid\">fw</span> , <span class=\"varid\">bw</span> , <span class=\"keyglyph\">_</span> , <span class=\"keyglyph\">_</span>) <span class=\"keyglyph\">=</span> <span class=\"varid\">fw</span>
<div class=\"empty-line\"></div>
<span class=\"comment\">-- and paths for dependent functions</span>
<span class=\"keyword\">postulate</span> <span class=\"conid\">Path-Π</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>} (<span class=\"varid\">f</span> <span class=\"varid\">g</span> <span class=\"varop\">:</span> <span class=\"conid\">Π</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>)
<span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">Π</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>) <span class=\"varid\">f</span> <span class=\"varid\">g</span>
<span class=\"varop\">≡</span> ((<span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>) <span class=\"keyglyph\">→</span> (<span class=\"varid\">pa</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span>)
<span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">B</span> <span class=\"varid\">y</span>) (<span class=\"varid\">subst</span> <span class=\"conid\">B</span> <span class=\"varid\">pa</span> (<span class=\"varid\">f</span> <span class=\"varid\">x</span>)) (<span class=\"varid\">g</span> <span class=\"varid\">y</span>))
</pre><p>Of course this doesn't really change anything, since defining <tt><span class=\"varid\">refl</span></tt> for function types is no easier than defining <tt><span class=\"varid\">cong</span></tt>.
</p><h2><a name=\"representation\"></a>Representation </h2>
<p>You might also notice that for all types <tt><span class=\"conid\">A</span></tt> (except <tt><span class=\"conid\">Set</span></tt>), the structure of <tt class=\"complex\"><span class=\"conid\">Path</span> <span class=\"conid\">A</span></tt> is essentially the same as that of <tt><span class=\"conid\">A</span></tt>. In fact, for a (non-indexed) data type
</p><pre class=\"agda\"><span class=\"keyword\">data</span> <span class=\"conid\">Foo</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"keyword\">where</span>
<span class=\"varid\">foo₀</span> <span class=\"varop\">:</span> <span class=\"conid\">Foo</span>
<span class=\"varid\">foo₁</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Foo</span>
<span class=\"varid\">foo₂</span> <span class=\"varop\">:</span> <span class=\"conid\">Foo</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Foo</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Foo</span>
</pre><p>you can mechanically derive its path type to be
</p><pre class=\"agda\"><span class=\"keyword\">data</span> <span class=\"conid\">Path</span> <span class=\"conid\">Foo</span> <span class=\"varop\">:</span> <span class=\"conid\">Foo</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Foo</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"keyword\">where</span>
<span class=\"varid\">refl-foo₀</span>  <span class=\"varop\">:</span> <span class=\"conid\">Path</span> (<span class=\"varid\">foo₀</span> <span class=\"varid\">x</span>) (<span class=\"varid\">foo₀</span> <span class=\"varid\">x</span>)
<span class=\"varid\">cong₁-foo₁</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">x</span> <span class=\"varid\">x'</span>} <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">x'</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">Foo</span> (<span class=\"varid\">foo₁</span> <span class=\"varid\">x</span>) (<span class=\"varid\">foo₁</span> <span class=\"varid\">x'</span>)
<span class=\"varid\">cong₂-foo₂</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">x</span> <span class=\"varid\">x'</span> <span class=\"varid\">y</span> <span class=\"varid\">y'</span>} <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">Foo</span> <span class=\"varid\">x</span> <span class=\"varid\">x'</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">Foo</span> <span class=\"varid\">y</span> <span class=\"varid\">y'</span>
<span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">Foo</span> (<span class=\"varid\">foo₂</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span>) (<span class=\"varid\">foo₂</span> <span class=\"varid\">x'</span> <span class=\"varid\">y'</span>)
</pre><p>In theory this allows for a nice implementation trick: we can take the representation of <tt><span class=\"varid\">x</span></tt> and <tt class=\"complex\"><span class=\"varid\">refl</span> <span class=\"varid\">x</span></tt> to be the same. So for example <tt class=\"complex\"><span class=\"num\">5</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">Int</span> <span class=\"num\">5</span> <span class=\"num\">5</span></tt> is a path that asserts that 5 = 5, and it is the only such path.
</p><p>Originally I thought that an implementation would have to pass <tt class=\"complex\"><span class=\"varid\">cong</span> <span class=\"varid\">f</span></tt> along with every parameter <tt><span class=\"varid\">f</span></tt> of a function type (which would suck). But in this way we don't have to, since <tt><span class=\"varid\">f</span></tt> and <tt class=\"complex\"><span class=\"varid\">cong</span> <span class=\"varid\">f</span></tt> are the same function.
</p><p>This also corresponds nicely to the idea that extra path constructors can be added in Higher Inductive Types. But I am not quite sure yet how that works out.
</p><h2><a name=\"food-for-thought\"></a>Food for thought </h2>
<ul><li> What is <tt class=\"complex\"><span class=\"varid\">refl</span> <span class=\"keyglyph\">_</span><span class=\"keyglyph\">→</span><span class=\"keyglyph\">_</span></tt>?</li>
<li> What is <tt class=\"complex\"><span class=\"varid\">refl</span> <span class=\"varid\">refl</span></tt>? Does this even make sense?</li>
<li> For the representation of <tt class=\"complex\"><span class=\"varid\">x</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span></tt> and <tt class=\"complex\"><span class=\"varid\">refl</span> <span class=\"varid\">x</span></tt> to be the same, <tt><span class=\"conid\">A</span></tt> and <tt class=\"complex\"><span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">x</span></tt> also need to have the same representation. That seems works for functions and inductive types, but what about <tt><span class=\"conid\">Set</span></tt>?</li>
<li> Is <tt><span class=\"conid\">Path</span></tt> an applicative functor in some sense? With <tt><span class=\"varid\">refl</span></tt> as return and <tt><span class=\"varid\">cong</span></tt> as ap?</li>
</ul>" nil nil "f1c38fa920b77fe47ab694ea07524171") (209 (20954 29022 109328) "http://kenta.blogspot.com/2013/07/kqfwttaf-random-access-to-random.html" "Ken T Takusagawa: [kqfwttaf] Random access to Random" "noreply@blogger.com (Ken)" "Mon, 08 Jul 2013 04:59:00 +0000" "<p dir=\"ltr\">A pseudorandom number generator implemented using a block cipher in Counter mode has the feature that one can fast-forward to any random number in the stream without having to generate the previous ones.  And rewind.  Can we leverage this feature to do interesting things not possible with a traditional RNG which operates by iterating a function on a state?</p><p dir=\"ltr\">Suppose we are modeling a Markov process.  Can we fast forward this process the same way?</p><p dir=\"ltr\">Probably not in general, but there may be interesting special cases.  An arbitrary Fibonacci number can be computed with the number of operations logarithmic in the index (not linear as the naive way of generating Fibonacci.)</p><p dir=\"ltr\">The oblique inspiration was the Haskell RandomGen \"split\" operation which allows random computations to be parallelized, again not possible for a traditional iterative RNG.</p><p dir=\"ltr\">Are there more interesting computational structures to generate randomness with interesting features?</p>" nil nil "66182219f0b7b9fedb5456390d592793") (208 (20954 29022 108920) "http://joyful.com/blog/2013-07-07-darcsden-db-thoughts.html" "Simon Michael: darcsden db thoughts" nil "Sun, 07 Jul 2013 23:00:00 +0000" "<div style=\"font-style: italic;\">July  7, 2013</div>
<h2>darcsden db thoughts</h2>
<p>
</p><p>Spent about half of yesterday setting up <a href=\"http://hub.darcs.net/Aditya/darcsden-import/changes\">Aditya’s darcsden patches</a> on the dev instance of hub.darcs.net, testing them, and exploring db migration issues.</p>
<p>Following BSRK’s instructions, I got the dev instance authenticating via Google’s OAuth servers. Good progress. The UI flow I saw needs a bit more work - eg logging in with google seemed to want me to register a new account. Or, there may be a problem with my setup at Google (wrong callback urls ?) - will have to review it with BSRK.</p>
<h2 id=\"schema-migrations\">Schema, migrations</h2>
<p>My dev instance has so far been using the same database as the live production instance. This is partly because I don’t yet know how to run a second CouchDB instance, partly to reduce complexity, partly to be able to compare old and new code with the same realistic data set.</p>
<p>This of course can lead to trouble, if old and new code require different schemas. darcsden uses CouchDB, a “schemaless” database, but of course there is an implicit schema required by the application code, even if couch doesn’t enforce one. I got more clarity on this when I noticed my dev instance experiments causing errors on the production app.</p>
<p>New darcsden code may include changes to the (implicit) db schema. In this case, there’s a change to the user’s password field. I need to notice such schema changes, and if I want to exercise them on the dev instance, I should first also install them on the production instance. Or, use a separate couchdb instance. Or, use separate databases in the couchdb instance. Or possibly, use separate views in the couchdb databases ?</p>
<p>Eg, here BSRK made the code nicely read user documents (db records) with the old or new schema. Before testing it on the shared db I should have deployed that patch to production as well as dev.</p>
<p>Looking ahead, is this approach (including code to deal with all old schemas) the best way to handle this ? Maybe. It makes things work and seems convenient, at least for now. But it also reminds me of years working with Zope’s ZODB (a schemaless python object database) and the layers of on-the-fly schema updating that built up, and the uncounted number of runtime bugs hunted down due to schema variations in individual objects.</p>
<h2 id=\"schema-less-or-schema-ful\">Schema-less or schema-ful ?</h2>
<p>While recovering from this, I learned some more about managing couchdb, schema migration, and current couchdb alternatives.</p>
<p>Couch has some really good and unusual qualities, and I feel I’m only scratching the surface of it’s power. Even so, I’m starting to feel a schema-ful, relational database is a better fit for darcsden/darcs hub. Replacing couch has been a topic of discussion on #darcs for some time, for other reasons. Here are some reasons to replace it:</p>
<ul>
<li><p>darcsden (more particularly, the instance running darcs hub, which has a lot of long-lived data) works best when all records have the same shape. It gains nothing from the flexibility of a loose schema, in fact will break, at runtime and unpredictably, unless you have extra code that handles all variations perfectly (a hard thing to test).</p></li>
<li><p>couchdb makes darcsden harder to set up, eg on windows. This makes it less successful in its goal to be an easy single-user ui for local darcs repos. It also reduces the number of darcsden hackers.</p></li>
<li><p>it adds complexity by embedding application code in the db. Instead of all logic being in haskell, the darcsden developer has to also deal with design documents and javascript map/reduce functions, and manage the state of those within the db.</p></li>
<li><p>it adds complexity by being less familiar to most people than rdbms system, and by having less mature tools.</p></li>
<li><p>persistent, the likely alternative, would more easily support both large installations (eg postgres for darcs hub) and single-user ones (sqlite) with less code.</p></li>
</ul>
<p>Some reasons not to:</p>
<ul>
<li><p>Don’t replace working code!</p></li>
<li><p>Replacing it could be wasted effort, better spent fixing end-user bugs on darcs hub.</p></li>
<li><p>The migration issue can easily be worked around. It’s not that big a deal for this instance.</p></li>
<li><p>Don’t disrupt the GSOC in progress!</p></li>
</ul>" nil nil "2c528a4f608e2f69171a4c2a948d665d") (207 (20954 29022 108053) "http://feedproxy.google.com/~r/FpComplete/~3/FaTU0eHhtDI/beta-activation-update" "FP Complete: FP Haskell Center Beta Sign-Up Still Open. Scheduled Activations Ongoing" nil "Fri, 05 Jul 2013 19:51:00 +0000" "<p>﻿<b>FP Haskell Center Beta Sign-Up Still Open.  Scheduled Activations Ongoing.</b></p><p>We got many enthusiastic beta testers asking “I am all ready to test the product.  When can I get activated?”   Here’s the story: we started activating beta sign ups since last Sunday, based on a schedule of increasing numbers each day.  We have over 1,000 sign-ups to-date, so we expect to activate all by July 15.  If you already signed up and haven’t received notice yet to activate, please wait a few more days, we will get to all of you.  There is NO NEED TO SIGN-UP AGAIN.</p><p>If you haven’t signed up yet, by all means do, here: https://www.fpcomplete.com/business/designer-ide. </p><p>All of us at FP Complete are excited and gratified by the mostly positive comments about the product based on the <a href=\"https://www.fpcomplete.com/blog/2013/06/fp-haskell-center-beta-demo\">video walkthrough</a> of the product.  We are eagerly awaiting the feedback from you as you are testing the product.  Thanks in advance!</p><div class=\"feedflare\">
<a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=FaTU0eHhtDI:sIRcM0MY9xM:yIl2AUoC8zA\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=yIl2AUoC8zA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=FaTU0eHhtDI:sIRcM0MY9xM:V_sGLiPBpWU\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=FaTU0eHhtDI:sIRcM0MY9xM:V_sGLiPBpWU\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=FaTU0eHhtDI:sIRcM0MY9xM:qj6IDK7rITs\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=qj6IDK7rITs\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=FaTU0eHhtDI:sIRcM0MY9xM:gIN9vFwOqvQ\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=FaTU0eHhtDI:sIRcM0MY9xM:gIN9vFwOqvQ\" border=\"0\" /></a>
</div><img src=\"http://feeds.feedburner.com/~r/FpComplete/~4/FaTU0eHhtDI\" height=\"1\" width=\"1\" />" nil nil "2fa5746fe54c4aaf4ead17a44677d79c") (206 (20950 32338 770086) "http://twanvl.nl/blog/agda/cong-from-refl" "Twan van Laarhoven: cong from refl in univalent OTT" nil "Thu, 04 Jul 2013 16:00:00 +0000" "<p>This is a follow up on <a href=\"http://www.twanvl.nl/blog/agda/subst-from-cong\">last week's post</a>.
There I showed that in a univalent Observational Type Theory, you can derive <tt><span class=\"varid\">subst</span></tt> from <tt><span class=\"varid\">cong</span></tt>.
Now I am going to go one step further.
</p><p>Suppose we change the definition of paths for functions from
</p><pre class=\"agda\"><span class=\"conid\">Path</span> (<span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>) <span class=\"varid\">f</span> <span class=\"varid\">g</span> <span class=\"varop\">≡</span> <span class=\"keyglyph\">∀</span> <span class=\"varid\">x</span> <span class=\"keyglyph\">→</span> <span class=\"varid\">f</span> <span class=\"varid\">x</span> <span class=\"varop\">≡</span> <span class=\"varid\">g</span> <span class=\"varid\">x</span>
</pre><p>to
</p><pre class=\"agda\"><span class=\"conid\">Path</span> (<span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>) <span class=\"varid\">f</span> <span class=\"varid\">g</span> <span class=\"varop\">≡</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">x</span> <span class=\"varid\">y</span>} <span class=\"keyglyph\">→</span> <span class=\"varid\">x</span> <span class=\"varop\">≡</span> <span class=\"varid\">y</span> <span class=\"keyglyph\">→</span> <span class=\"varid\">f</span> <span class=\"varid\">x</span> <span class=\"varop\">≡</span> <span class=\"varid\">g</span> <span class=\"varid\">y</span>
</pre><p>Then for a function <tt><span class=\"varid\">f</span></tt>, <tt class=\"complex\"><span class=\"varid\">refl</span> <span class=\"varid\">f</span></tt> is actually the same thing as <tt class=\"complex\"><span class=\"varid\">cong</span> <span class=\"varid\">f</span></tt>!.
So that's one less primitive to worry about. In fact the only two path related primitives that remain are <tt><span class=\"conid\">Path</span></tt> and <tt><span class=\"varid\">refl</span></tt>. The rest is just in the computation rules.
</p><p>Here are the changes in the agda code compared to last week:
</p><pre class=\"agda\"><span class=\"keyword\">postulate</span> <span class=\"conid\">Path-→</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>} (<span class=\"varid\">f</span> <span class=\"varid\">g</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>)
<span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>) <span class=\"varid\">f</span> <span class=\"varid\">g</span>
<span class=\"varop\">≡</span> ((<span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">B</span> (<span class=\"varid\">f</span> <span class=\"varid\">x</span>) (<span class=\"varid\">g</span> <span class=\"varid\">y</span>))
<div class=\"empty-line\"></div>
<span class=\"comment\">-- cong = refl</span>
<span class=\"varid\">cong</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>}
<span class=\"keyglyph\">→</span> (<span class=\"varid\">f</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>) <span class=\"keyglyph\">→</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">x</span> <span class=\"varid\">y</span>} <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">B</span> (<span class=\"varid\">f</span> <span class=\"varid\">x</span>) (<span class=\"varid\">f</span> <span class=\"varid\">y</span>)
<span class=\"varid\">cong</span> <span class=\"varid\">f</span> <span class=\"varid\">x=y</span> <span class=\"keyglyph\">=</span> <span class=\"varid\">Meta.subst</span> <span class=\"varid\">id</span> (<span class=\"conid\">Path-→</span> <span class=\"varid\">f</span> <span class=\"varid\">f</span>) (<span class=\"varid\">refl</span> <span class=\"keyglyph\">_</span> <span class=\"varid\">f</span>) <span class=\"keyglyph\">_</span> <span class=\"keyglyph\">_</span> <span class=\"varid\">x=y</span>
<div class=\"empty-line\"></div>
<span class=\"comment\">-- subst is the same as last time</span>
<span class=\"varid\">subst</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} (<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>)
<span class=\"keyglyph\">→</span> {<span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>} <span class=\"keyglyph\">→</span> (<span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span> <span class=\"varid\">x</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span> <span class=\"varid\">y</span>
<span class=\"varid\">subst</span> <span class=\"conid\">B</span> {<span class=\"varid\">x</span>} {<span class=\"varid\">y</span>} <span class=\"varid\">p</span> <span class=\"varid\">with</span> <span class=\"varid\">Meta.subst</span> <span class=\"varid\">id</span> (<span class=\"conid\">Path-Type</span> (<span class=\"conid\">B</span> <span class=\"varid\">x</span>) (<span class=\"conid\">B</span> <span class=\"varid\">y</span>)) (<span class=\"varid\">cong</span> <span class=\"conid\">B</span> <span class=\"varid\">p</span>)
<span class=\"varop\">...</span> <span class=\"keyglyph\">|</span> <span class=\"varid\">lift</span> (<span class=\"varid\">fw</span> , <span class=\"varid\">bw</span> , <span class=\"keyglyph\">_</span> , <span class=\"keyglyph\">_</span>) <span class=\"keyglyph\">=</span> <span class=\"varid\">fw</span>
<div class=\"empty-line\"></div>
<span class=\"comment\">-- and paths for dependent functions</span>
<span class=\"keyword\">postulate</span> <span class=\"conid\">Path-Π</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>} (<span class=\"varid\">f</span> <span class=\"varid\">g</span> <span class=\"varop\">:</span> <span class=\"conid\">Π</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>)
<span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">Π</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>) <span class=\"varid\">f</span> <span class=\"varid\">g</span>
<span class=\"varop\">≡</span> ((<span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>) <span class=\"keyglyph\">→</span> (<span class=\"varid\">pa</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span>)
<span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">B</span> <span class=\"varid\">y</span>) (<span class=\"varid\">subst</span> <span class=\"conid\">B</span> <span class=\"varid\">pa</span> (<span class=\"varid\">f</span> <span class=\"varid\">x</span>)) (<span class=\"varid\">g</span> <span class=\"varid\">y</span>))
</pre><p>Of course this doesn't really change anything, since defining <tt><span class=\"varid\">refl</span></tt> for function types is no easier than defining <tt><span class=\"varid\">cong</span></tt>.
</p><h2><a name=\"representation\"></a>Representation </h2>
<p>You might also notice that for all types <tt><span class=\"conid\">A</span></tt> (except <tt><span class=\"conid\">Set</span></tt>), the structure of <tt class=\"complex\"><span class=\"conid\">Path</span> <span class=\"conid\">A</span></tt> is essentially the same as that of <tt><span class=\"conid\">A</span></tt>. In fact, for a (non-indexed) data type
</p><pre class=\"agda\"><span class=\"keyword\">data</span> <span class=\"conid\">Foo</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"keyword\">where</span>
<span class=\"varid\">foo₀</span> <span class=\"varop\">:</span> <span class=\"conid\">Foo</span>
<span class=\"varid\">foo₁</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Foo</span>
<span class=\"varid\">foo₂</span> <span class=\"varop\">:</span> <span class=\"conid\">Foo</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Foo</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Foo</span>
</pre><p>you can mechanically derive its path type to be
</p><pre class=\"agda\"><span class=\"keyword\">data</span> <span class=\"conid\">Path</span> <span class=\"conid\">Foo</span> <span class=\"varop\">:</span> <span class=\"conid\">Foo</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Foo</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"keyword\">where</span>
<span class=\"varid\">refl-foo₀</span>  <span class=\"varop\">:</span> <span class=\"conid\">Path</span> (<span class=\"varid\">foo₀</span> <span class=\"varid\">x</span>) (<span class=\"varid\">foo₀</span> <span class=\"varid\">x</span>)
<span class=\"varid\">cong₁-foo₁</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">x</span> <span class=\"varid\">x'</span>} <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">x'</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">Foo</span> (<span class=\"varid\">foo₁</span> <span class=\"varid\">x</span>) (<span class=\"varid\">foo₁</span> <span class=\"varid\">x'</span>)
<span class=\"varid\">cong₂-foo₂</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">x</span> <span class=\"varid\">x'</span> <span class=\"varid\">y</span> <span class=\"varid\">y'</span>} <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">Foo</span> <span class=\"varid\">x</span> <span class=\"varid\">x'</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">Foo</span> <span class=\"varid\">y</span> <span class=\"varid\">y'</span>
<span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">Foo</span> (<span class=\"varid\">foo₂</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span>) (<span class=\"varid\">foo₂</span> <span class=\"varid\">x'</span> <span class=\"varid\">y'</span>)
</pre><p>In theory this allows for a nice implementation trick: we can take the representation of <tt><span class=\"varid\">x</span></tt> and <tt class=\"complex\"><span class=\"varid\">refl</span> <span class=\"varid\">x</span></tt> to be the same. So for example <tt class=\"complex\"><span class=\"num\">5</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">Int</span> <span class=\"num\">5</span> <span class=\"num\">5</span></tt> is a path that asserts that 5 = 5, and it is the only such path.
</p><p>Originally I thought that an implementation would have to pass <tt class=\"complex\"><span class=\"varid\">cong</span> <span class=\"varid\">f</span></tt> along with every parameter <tt><span class=\"varid\">f</span></tt> of a function type (which would suck). But in this way we don't have to, since <tt><span class=\"varid\">f</span></tt> and <tt class=\"complex\"><span class=\"varid\">cong</span> <span class=\"varid\">f</span></tt> are the same function.
</p><p>This also corresponds nicely to the idea that extra path constructors can be added in Higher Inductive Types. But I am not quite sure yet how that works out.
</p><h2><a name=\"food-for-thought\"></a>Food for thought </h2>
<ul><li> What is <tt class=\"complex\"><span class=\"varid\">refl</span> <span class=\"keyglyph\">_</span><span class=\"keyglyph\">→</span><span class=\"keyglyph\">_</span></tt>?</li>
<li> What is <tt class=\"complex\"><span class=\"varid\">refl</span> <span class=\"varid\">refl</span></tt>? Does this even make sense?</li>
<li> For the representation of <tt class=\"complex\"><span class=\"varid\">x</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span></tt> and <tt class=\"complex\"><span class=\"varid\">refl</span> <span class=\"varid\">x</span></tt> to be the same, <tt><span class=\"conid\">A</span></tt> and <tt class=\"complex\"><span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">x</span></tt> also need to have the same representation. That seems works for functions and inductive types, but what about <tt><span class=\"conid\">Set</span></tt>?</li>
<li> Is <tt><span class=\"conid\">Path</span></tt> an applicative functor in some sense? With <tt><span class=\"varid\">refl</span></tt> as return and <tt><span class=\"varid\">cong</span></tt> as ap?</li>
</ul>" nil nil "73f979147a49300c4f6c4ee0e38be394") (205 (20949 42001 578573) "http://twanvl.nl/blog/agda/cong-from-refl" "Twan van Laarhoven: cong from refl in univalent OTT" nil "Thu, 04 Jul 2013 16:00:00 +0000" "<p>This is a follow up on <a href=\"http://twanvl.nl/blog/agda/subst-from-cong\">last week's post</a>.
There I showed that in a univalent Observational Type Theory, you can derive <tt><span class=\"varid\">subst</span></tt> from <tt><span class=\"varid\">cong</span></tt>.
Now I am going to go one step further.
</p><p>Suppose we change the definition of paths for functions from
</p><pre class=\"agda\"><span class=\"conid\">Path</span> (<span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>) <span class=\"varid\">f</span> <span class=\"varid\">g</span> <span class=\"varop\">≡</span> <span class=\"keyglyph\">∀</span> <span class=\"varid\">x</span> <span class=\"keyglyph\">→</span> <span class=\"varid\">f</span> <span class=\"varid\">x</span> <span class=\"varop\">≡</span> <span class=\"varid\">g</span> <span class=\"varid\">x</span>
</pre><p>to
</p><pre class=\"agda\"><span class=\"conid\">Path</span> (<span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>) <span class=\"varid\">f</span> <span class=\"varid\">g</span> <span class=\"varop\">≡</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">x</span> <span class=\"varid\">y</span>} <span class=\"keyglyph\">→</span> <span class=\"varid\">x</span> <span class=\"varop\">≡</span> <span class=\"varid\">y</span> <span class=\"keyglyph\">→</span> <span class=\"varid\">f</span> <span class=\"varid\">x</span> <span class=\"varop\">≡</span> <span class=\"varid\">g</span> <span class=\"varid\">y</span>
</pre><p>Then for a function <tt><span class=\"varid\">f</span></tt>, <tt class=\"complex\"><span class=\"varid\">refl</span> <span class=\"varid\">f</span></tt> is actually the same thing as <tt class=\"complex\"><span class=\"varid\">cong</span> <span class=\"varid\">f</span></tt>!.
So that's one less primitive to worry about. In fact the only two path related primitives that remain are <tt><span class=\"conid\">Path</span></tt> and <tt><span class=\"varid\">refl</span></tt>. The rest is just in the computation rules.
</p><p>Here are the changes in the agda code compared to last week:
</p><pre class=\"agda\"><span class=\"keyword\">postulate</span> <span class=\"conid\">Path-→</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>} (<span class=\"varid\">f</span> <span class=\"varid\">g</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>)
<span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>) <span class=\"varid\">f</span> <span class=\"varid\">g</span>
<span class=\"varop\">≡</span> ((<span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">B</span> (<span class=\"varid\">f</span> <span class=\"varid\">x</span>) (<span class=\"varid\">g</span> <span class=\"varid\">y</span>))
<div class=\"empty-line\"></div>
<span class=\"comment\">-- cong = refl</span>
<span class=\"varid\">cong</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>}
<span class=\"keyglyph\">→</span> (<span class=\"varid\">f</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>) <span class=\"keyglyph\">→</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">x</span> <span class=\"varid\">y</span>} <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">B</span> (<span class=\"varid\">f</span> <span class=\"varid\">x</span>) (<span class=\"varid\">f</span> <span class=\"varid\">y</span>)
<span class=\"varid\">cong</span> <span class=\"varid\">f</span> <span class=\"varid\">x=y</span> <span class=\"keyglyph\">=</span> <span class=\"varid\">Meta.subst</span> <span class=\"varid\">id</span> (<span class=\"conid\">Path-→</span> <span class=\"varid\">f</span> <span class=\"varid\">f</span>) (<span class=\"varid\">refl</span> <span class=\"keyglyph\">_</span> <span class=\"varid\">f</span>) <span class=\"keyglyph\">_</span> <span class=\"keyglyph\">_</span> <span class=\"varid\">x=y</span>
<div class=\"empty-line\"></div>
<span class=\"comment\">-- subst is the same as last time</span>
<span class=\"varid\">subst</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} (<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>)
<span class=\"keyglyph\">→</span> {<span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>} <span class=\"keyglyph\">→</span> (<span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span> <span class=\"varid\">x</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span> <span class=\"varid\">y</span>
<span class=\"varid\">subst</span> <span class=\"conid\">B</span> {<span class=\"varid\">x</span>} {<span class=\"varid\">y</span>} <span class=\"varid\">p</span> <span class=\"varid\">with</span> <span class=\"varid\">Meta.subst</span> <span class=\"varid\">id</span> (<span class=\"conid\">Path-Type</span> (<span class=\"conid\">B</span> <span class=\"varid\">x</span>) (<span class=\"conid\">B</span> <span class=\"varid\">y</span>)) (<span class=\"varid\">cong</span> <span class=\"conid\">B</span> <span class=\"varid\">p</span>)
<span class=\"varop\">...</span> <span class=\"keyglyph\">|</span> <span class=\"varid\">lift</span> (<span class=\"varid\">fw</span> , <span class=\"varid\">bw</span> , <span class=\"keyglyph\">_</span> , <span class=\"keyglyph\">_</span>) <span class=\"keyglyph\">=</span> <span class=\"varid\">fw</span>
<div class=\"empty-line\"></div>
<span class=\"comment\">-- and paths for dependent functions</span>
<span class=\"keyword\">postulate</span> <span class=\"conid\">Path-Π</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>} (<span class=\"varid\">f</span> <span class=\"varid\">g</span> <span class=\"varop\">:</span> <span class=\"conid\">Π</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>)
<span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">Π</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>) <span class=\"varid\">f</span> <span class=\"varid\">g</span>
<span class=\"varop\">≡</span> ((<span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>) <span class=\"keyglyph\">→</span> (<span class=\"varid\">pa</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span>)
<span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">B</span> <span class=\"varid\">y</span>) (<span class=\"varid\">subst</span> <span class=\"conid\">B</span> <span class=\"varid\">pa</span> (<span class=\"varid\">f</span> <span class=\"varid\">x</span>)) (<span class=\"varid\">g</span> <span class=\"varid\">y</span>))
</pre><p>Of course this doesn't really change anything, since defining <tt><span class=\"varid\">refl</span></tt> for function types is no easier than defining <tt><span class=\"varid\">cong</span></tt>.
</p><h2><a name=\"representation\"></a>Representation </h2>
<p>You might also notice that for all types <tt><span class=\"conid\">A</span></tt> (except <tt><span class=\"conid\">Set</span></tt>), the structure of <tt class=\"complex\"><span class=\"conid\">Path</span> <span class=\"conid\">A</span></tt> is essentially the same as that of <tt><span class=\"conid\">A</span></tt>. In fact, for a (non-indexed) data type
</p><pre class=\"agda\"><span class=\"keyword\">data</span> <span class=\"conid\">Foo</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"keyword\">where</span>
<span class=\"varid\">foo₀</span> <span class=\"varop\">:</span> <span class=\"conid\">Foo</span>
<span class=\"varid\">foo₁</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Foo</span>
<span class=\"varid\">foo₂</span> <span class=\"varop\">:</span> <span class=\"conid\">Foo</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Foo</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Foo</span>
</pre><p>you can mechanically derive its path type to be
</p><pre class=\"agda\"><span class=\"keyword\">data</span> <span class=\"conid\">Path</span> <span class=\"conid\">Foo</span> <span class=\"varop\">:</span> <span class=\"conid\">Foo</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Foo</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"keyword\">where</span>
<span class=\"varid\">refl-foo₀</span>  <span class=\"varop\">:</span> <span class=\"conid\">Path</span> (<span class=\"varid\">foo₀</span> <span class=\"varid\">x</span>) (<span class=\"varid\">foo₀</span> <span class=\"varid\">x</span>)
<span class=\"varid\">cong₁-foo₁</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">x</span> <span class=\"varid\">x'</span>} <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">x'</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">Foo</span> (<span class=\"varid\">foo₁</span> <span class=\"varid\">x</span>) (<span class=\"varid\">foo₁</span> <span class=\"varid\">x'</span>)
<span class=\"varid\">cong₂-foo₂</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">x</span> <span class=\"varid\">x'</span> <span class=\"varid\">y</span> <span class=\"varid\">y'</span>} <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">Foo</span> <span class=\"varid\">x</span> <span class=\"varid\">x'</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">Foo</span> <span class=\"varid\">y</span> <span class=\"varid\">y'</span>
<span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">Foo</span> (<span class=\"varid\">foo₂</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span>) (<span class=\"varid\">foo₂</span> <span class=\"varid\">x'</span> <span class=\"varid\">y'</span>)
</pre><p>In theory this allows for a nice implementation trick: we can take the representation of <tt><span class=\"varid\">x</span></tt> and <tt class=\"complex\"><span class=\"varid\">refl</span> <span class=\"varid\">x</span></tt> to be the same. So for example <tt class=\"complex\"><span class=\"num\">5</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">Int</span> <span class=\"num\">5</span> <span class=\"num\">5</span></tt> is a path that asserts that 5 = 5, and it is the only such path.
</p><p>Originally I thought that an implementation would have to pass <tt class=\"complex\"><span class=\"varid\">cong</span> <span class=\"varid\">f</span></tt> along with every parameter <tt><span class=\"varid\">f</span></tt> of a function type (which would suck). But in this way we don't have to, since <tt><span class=\"varid\">f</span></tt> and <tt class=\"complex\"><span class=\"varid\">cong</span> <span class=\"varid\">f</span></tt> are the same function.
</p><p>This also corresponds nicely to the idea that extra path constructors can be added in Higher Inductive Types. But I am not quite sure yet how that works out.
</p><h2><a name=\"food-for-thought\"></a>Food for thought </h2>
<ul><li> What is <tt class=\"complex\"><span class=\"varid\">refl</span> <span class=\"keyglyph\">_</span><span class=\"keyglyph\">→</span><span class=\"keyglyph\">_</span></tt>?</li>
<li> What is <tt class=\"complex\"><span class=\"varid\">refl</span> <span class=\"varid\">refl</span></tt>? Does this even make sense?</li>
<li> For the representation of <tt class=\"complex\"><span class=\"varid\">x</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span></tt> and <tt class=\"complex\"><span class=\"varid\">refl</span> <span class=\"varid\">x</span></tt> to be the same, <tt><span class=\"conid\">A</span></tt> and <tt class=\"complex\"><span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">x</span></tt> also need to have the same representation. That seems works for functions and inductive types, but what about <tt><span class=\"conid\">Set</span></tt>?</li>
<li> Is <tt><span class=\"conid\">Path</span></tt> an applicative functor in some sense? With <tt><span class=\"varid\">refl</span></tt> as return and <tt><span class=\"varid\">cong</span></tt> as ap?</li>
</ul>" nil nil "a9f1581cdc18c9e4646154588be31dc8") (204 (20949 25792 680659) "http://winterkoninkje.dreamwidth.org/84727.html" "wren ng thornton: Bitties" nil "Wed, 03 Jul 2013 03:57:07 +0000" "<p>Just got back from <a href=\"http://www.cs.cornell.edu/Conferences/MFPS29/\">MFPS</a>-<a href=\"http://lii.rwth-aachen.de/lics/lics13/\">LICS</a>-<a href=\"http://csf2013.seas.harvard.edu/index.html\">CSF</a> saturday night. T'was the first LICS I've been to, and my first time in the deep south. I had fun overall. Definitely enjoyed the French Quarter with its narrower streets, delightful architecture, and other non-American features. And I ran into the Pride parade the day after arriving; I seem to have a knack for that ;)  The humidity was killer though.</p>
<p>The slides from my <a href=\"http://www.indiana.edu/~iulg/nlcs.html\">NLCS</a> talk are <a href=\"http://llama.freegeek.org/~wren/pubs/chiastic_nlcs2013.pdf\">available here</a>. I've been having some issues with my bibtex2html script, so they're not linked to on the publications page yet; but they will be once I get that issue fixed.</p>
<p>In less happy news, I got some bloodwork back today. Cholesterol is far far too high, and I'm getting into the pre-diabetic range for bloodsugar levels. So, I'm starting a major diet change in hopes of getting those under control. Apparently lack of protein is a big part of the problem (for me), which is ironic since most americans get far too much. Damn midwestern genes. Went grocery shopping today; it's profoundly difficult to get a 1::1 carbs-to-protein ratio as a vegetarian.</p><br /><br /><img src=\"http://www.dreamwidth.org/tools/commentcount?user=winterkoninkje&ditemid=84727\" alt=\"comment count unavailable\" height=\"12\" style=\"vertical-align: middle;\" width=\"30\" /> comments" nil nil "fa7955fe4b7c2ab25be7ea5b1029f052") (203 (20949 25792 680235) "http://winterkoninkje.dreamwidth.org/83774.html" "wren ng thornton: Upcoming talk" nil "Wed, 03 Jul 2013 03:43:14 +0000" "<p>Next month I'll be giving a talk at the <a href=\"http://www.indiana.edu/~iulg/nlcs.html\">NLCS</a> workshop, on the chiastic lambda-calculi I first presented at NASSLLI 2010 (<a href=\"http://llama.freegeek.org/~wren/pubs/ccgjp_nasslli2010.pdf\">slides</a>[1]). After working out some of the metatheory for one of my quals, I gave more recent talks at our local PL Wonks and CLingDing seminars (<a href=\"http://llama.freegeek.org/~wren/pubs/chiastic_plwonks2013.pdf\">slides</a>). The NASSLLI talk was more about the linguistic motivations and the general idea, whereas the PLWonks/CLingDing talks were more about the formal properties of the calculus itself. For NLCS I hope to combine these threads a bit better— which has always been the challenge with this work.</p>
<p>NLCS is collocated with this year's <a href=\"http://lii.rwth-aachen.de/lics/lics13/\">LICS</a> (and MFPS and CSF). I'll also be around for LICS itself, and in town for MFPS though probably not attending. So if you're around, feel free to stop by and chat.</p>
<p>[1] N.B., the NASSLLI syntax is a bit different than the newer version: square brackets were used instead of angle brackets (the latter were chosen because they typeset better in general); juxtaposition was just juxtaposition rather than being made explicit; and the left- vs right-chiastic distinction was called chi vs ksi (however, it turns out that ksi already has an important meaning in type theory).</p>
<p><i>Edit 2013.07.02:</i> the slides are <a href=\"http://llama.freegeek.org/~wren/pubs/chiastic_nlcs2013.pdf\">available here</a>.</p><br /><br /><img src=\"http://www.dreamwidth.org/tools/commentcount?user=winterkoninkje&ditemid=83774\" alt=\"comment count unavailable\" height=\"12\" style=\"vertical-align: middle;\" width=\"30\" /> comments" nil nil "f90c96a83fe24df84400bfb4f549e8d1") (202 (20949 25792 628873) "http://feedproxy.google.com/~r/ezyang/~3/zSgfaMODNkM/" "Edward Z. Yang: No grammar? No problem!" nil "Wed, 03 Jul 2013 02:17:02 +0000" "<div class=\"document\">
<p>One day, you’re strolling along fields of code, when suddenly you spot a syntax construct that you don’t understand.</p>
<p>Perhaps you’d ask your desk-mate, who’d tell you in an instant what it was.</p>
<p>Perhaps your programming toolchain can tell you. (Perhaps the IDE would you mouse over the construct, or you’re using Coq which let’s you <tt class=\"docutils literal\">Locate</tt> custom notations.)</p>
<p>Perhaps you’d pull up the manual (or, more likely, one of many tutorials) and scan through looking for the syntax construct in question.</p>
<p>But when all this fails, what is one to do?  What if the code in question is written in an internal language for a compiler, whose details have changed since it was last documented, for which the documentation is out of date?</p>
<p><em>No problem.</em> As long as you’re willing to roll up your sleeves and take a look at the source code of the compiler in question, you can frequently resolve your question for less effort than it would have taken to look up the syntax in the manual (and it’s guaranteed to be up-to-date too!)  The key is that  modern compilers all use parser generators, and the input to these are essentially executable specifications.</p>
<hr class=\"docutils\" />
<p>I’ll give two examples from GHC.  The first is from C--, GHC’s high-level assembly language. Consider this function:</p>
<pre class=\"literal-block\">INFO_TABLE_RET(stg_maskUninterruptiblezh_ret, RET_SMALL, W_ info_ptr)
return (P_ ret)
{
StgTSO_flags(CurrentTSO) =
%lobits32(
(TO_W_(StgTSO_flags(CurrentTSO))
| TSO_BLOCKEX)
& ~TSO_INTERRUPTIBLE
);
return (ret);
}
</pre>
<p>Some aspects of this definition are familiar to someone who has written C before, but there are some mysterious bits. For example, what does the <tt class=\"docutils literal\">return (P_ ret)</tt> mean in the preamble?</p>
<p>The first order of business is to find the relevant file.  When the code in question has very distinctive keywords (as this one does), a grep will often do the trick:</p>
<pre class=\"literal-block\">ezyang@javelin:~/Dev/ghc-clean/rts$ grep -R INFO_TABLE_RET ../compiler/
../compiler/cmm/CmmParse.y:INFO_TABLE_RET ( label, FRAME_TYPE, info_ptr, field1, ..., fieldN )
../compiler/cmm/CmmParse.y:        'INFO_TABLE_RET'{ L _ (CmmT_INFO_TABLE_RET) }
../compiler/cmm/CmmParse.y:        | 'INFO_TABLE_RET' '(' NAME ',' INT ')'
../compiler/cmm/CmmParse.y:        | 'INFO_TABLE_RET' '(' NAME ',' INT ',' formals0 ')'
../compiler/cmm/CmmParse.y:-- is.  That is, for an INFO_TABLE_RET we want the return convention,
../compiler/cmm/CmmLex.x:  | CmmT_INFO_TABLE_RET
../compiler/cmm/CmmLex.x:   ( \"INFO_TABLE_RET\",     CmmT_INFO_TABLE_RET ),
</pre>
<p>File extensions can also be dead giveaways; GHC uses a parser generator named Happy, and the file extension of Happy files is <tt class=\"docutils literal\">.y</tt>:</p>
<pre class=\"literal-block\">ezyang@javelin:~/Dev/ghc-clean/rts$ find ../compiler -name *.y
../compiler/cmm/CmmParse.y
../compiler/parser/ParserCore.y
</pre>
<p>From there, we can search the file for keywords or symbols (check for the string token name if a lexer is used; also, make sure to quote alphanumeric literals).  A symbol can show up in multiple places, as it does for return:</p>
<pre class=\"literal-block\">maybe_conv :: { Convention }
: {- empty -}        { NativeNodeCall }
| 'return'           { NativeReturn }
</pre>
<p>and:</p>
<pre class=\"literal-block\">stmt    :: { CmmParse () }
: ';'                                   { return () }
...
| 'goto' NAME ';'
{ do l <- lookupLabel $2; emit (mkBranch l) }
| 'return' '(' exprs0 ')' ';'
{ doReturn $3 }
</pre>
<p>Guessing from the names of the productions and the contexts, it seems more likely that <tt class=\"docutils literal\">maybe_conv</tt> is the relevant production. It is used here:</p>
<pre class=\"literal-block\">cmmproc :: { CmmParse () }
: info maybe_conv maybe_formals maybe_body
{ do ((entry_ret_label, info, stk_formals, formals), agraph) <-
getCodeR $ loopDecls $ do {
(entry_ret_label, info, stk_formals) <- $1;
formals <- sequence (fromMaybe [] $3);
$4;
return (entry_ret_label, info, stk_formals, formals) }
let do_layout = isJust $3
code (emitProcWithStackFrame $2 info
entry_ret_label stk_formals formals agraph
do_layout ) }
</pre>
<p>Now, if you really need to know <em>exactly</em> how it is lade out, you can go and checkout how <tt class=\"docutils literal\">emitProcWithStackFrame</tt> is implemented.  Alternately, you might hope there is a useful comment in the source file which explains what is up:</p>
<pre class=\"literal-block\">A stack frame is written like this:
INFO_TABLE_RET ( label, FRAME_TYPE, info_ptr, field1, ..., fieldN )
return ( arg1, ..., argM )
{
... code ...
}
where field1 ... fieldN are the fields of the stack frame (with types)
arg1...argN are the values returned to the stack frame (with types).
The return values are assumed to be passed according to the
NativeReturn convention.
</pre>
<hr class=\"docutils\" />
<p>The second example is for STG, which you can ask GHC to print out using <tt class=\"docutils literal\"><span class=\"pre\">-ddump-stg</span></tt>. Now, there is no parser for STG, so instead you’ll have to look at the <em>pretty-printer</em>. Not too difficult. Take this simple function:</p>
<pre class=\"literal-block\">Gnam.$WKST =
\\r [tpl_sl4 tpl_sl6]
case tpl_sl4 of tpl_sl8 {
__DEFAULT ->
case tpl_sl6 of tpl_sl9 {
__DEFAULT -> Gnam.KST [tpl_sl8 tpl_sl9];
};
};
</pre>
<p>Some aspects are familiar. But what does the <tt class=\"docutils literal\">\\r</tt> mean?</p>
<p>Once again, we have to find the relevant source file.  Since STG is printed out only when we pass the <tt class=\"docutils literal\"><span class=\"pre\">-ddump-stg</span></tt> flag, a good start is to trace the flag through the source code:</p>
<pre class=\"literal-block\">ezyang@javelin:~/Dev/ghc-clean/compiler$ grep -R ddump-stg .
./main/DynFlags.hs:  , Flag \"ddump-stg\"               (setDumpFlag Opt_D_dump_stg)
ezyang@javelin:~/Dev/ghc-clean/compiler$ grep -R Opt_D_dump_stg .
./main/DynFlags.hs:   | Opt_D_dump_stg
./main/DynFlags.hs:  , Flag \"ddump-stg\"               (setDumpFlag Opt_D_dump_stg)
./simplStg/SimplStg.lhs:        ; dumpIfSet_dyn dflags Opt_D_dump_stg \"STG syntax:\"
</pre>
<p>That’s a good sign! Popping open <tt class=\"docutils literal\">SimpleStg.lhs</tt> gives us:</p>
<pre class=\"literal-block\">; dumpIfSet_dyn dflags Opt_D_dump_stg \"STG syntax:\"
(pprStgBindings un_binds)
</pre>
<p>And the location of <tt class=\"docutils literal\">pprStgBindings</tt> (<tt class=\"docutils literal\">compiler/stgSyn/StgSyn.lhs</tt>) is in fact the ticket.</p>
<p>STG is pretty small, and as it turns out if you just do a quick scan of the file you’re likely to find what you need. But in case you don’t, you can still figure things out deliberately. Suppose we search for a quoted backslash:</p>
<pre class=\"literal-block\">pprStgExpr (StgLam bndrs body)
= sep [ char '\\\\' <+> ppr_list (map (pprBndr LambdaBind) bndrs)
<+> ptext (sLit \"->\"),
pprStgExpr body ]
where ppr_list = brackets . fsep . punctuate comma
...
-- general case
pprStgRhs (StgRhsClosure cc bi free_vars upd_flag srt args body)
= sdocWithDynFlags $ \\dflags ->
hang (hsep [if gopt Opt_SccProfilingOn dflags then ppr cc else empty,
pp_binder_info bi,
ifPprDebug (brackets (interppSP free_vars)),
char '\\\\' <> ppr upd_flag, pprMaybeSRT srt, brackets (interppSP args)])
4 (ppr body)
</pre>
<p>Which is it? As it turns out:</p>
<pre class=\"literal-block\">StgLam is used *only* during CoreToStg's work. Before CoreToStg has
finished it encodes (\\x -> e) as (let f = \\x -> e in f)
</pre>
<p>Since <tt class=\"docutils literal\"><span class=\"pre\">-ddump-stg</span></tt> is post-CoreToSTG, we must be looking at <tt class=\"docutils literal\">StgRhsClosure</tt>, and <tt class=\"docutils literal\">ppr upd_flag</tt> looks like the ticket.  <tt class=\"docutils literal\">r</tt> must be an <tt class=\"docutils literal\">upd_flag</tt>, whatever that is. An <tt class=\"docutils literal\">UpdateFlag</tt>, as it turns out:</p>
<pre class=\"literal-block\">data UpdateFlag = ReEntrant | Updatable | SingleEntry
instance Outputable UpdateFlag where
ppr u = char $ case u of
ReEntrant   -> 'r'
Updatable   -> 'u'
SingleEntry -> 's'
</pre>
<p>The <tt class=\"docutils literal\">r</tt> indicates the function is re-entrant! (Of course, as for what that means, you’ll have to consult other documentation.)</p>
<hr class=\"docutils\" />
<p>Of course, in an ideal world, all of this would be documented. But even if it is not, there is no reason why you can’t help yourself. If your codebase is as nice as GHC’s, there will be plenty of breadcrumbs and comments to help you out. I hope this gives some insight into one possible thought process when you encounter something you don’t know, and don’t know how to learn. (Of course, sometimes it’s just best to ignore it!)</p>
</div>
<img src=\"http://feeds.feedburner.com/~r/ezyang/~4/zSgfaMODNkM\" height=\"1\" width=\"1\" />" nil nil "0081bba4f515deb580f5f66fe805e9b3") (201 (20949 25792 626962) "http://praisecurseandrecurse.blogspot.com/2013/07/the-polar-game-in-haskell-day-5-array-v.html" "Paul Potts: The Polar Game in Haskell, Day 5: Array v. List" "noreply@blogger.com (Paul Potts)" "Tue, 02 Jul 2013 23:25:00 +0000" "<p>So, a little more progress in learning me a Haskell: I've managed to implement the board using an immutable array. There's good news and bad news here. If you're an old hand at functional programming, you probably know all this and more, but I needed to do a little thinking on purely functional data structures. I have not really been satisfied with the amount of code necessary to manage my 2-D board in a list. I spent some time doodling some possible alternative implementation before concluding that purely functional data structures -- in which nodes are never mutated -- are hard. Anything I might be accustomed to doing with double or multiply-linked lists is pretty much a washout, since you can't ever share structure. In fact, I think one data structure I came up with might not be constructible at all without being able to mutate links between nodes. So I'm starting to understand why the tutorials all advise me to stick with lists.</p> <p>Nevertheless, this is a small problem, and efficiency is not my biggest concern, at least not in the learning phase. I wanted to figure out how to use an immutable array. The tutorials have not been very satisfying. They seem to assume that anything this trivial is too trivial to demonstrate. But here's what I did.</p> <p>First, the type of an array in Haskell encodes the number of dimensions and the node type, but not the size. You set that when you call the constructor. Here's a 2-D array type for my board:</p> <pre>type BoardArray = Array ( Int, Int ) Tile</pre> <p>I specified some bounds:</p> <pre>max_row :: Int<br />max_row = 3<br /><br />max_col :: Int<br />max_col = 23</pre> <p>And I should point out one of the fundamental problems with using arrays: it's very easy to kill your program by exceeding the array bounds. There is a similar problem with <b>head</b>, but when writing functions with pattern-matching and guards there are pretty accepted conventions for dealing with empty lists. I suppose one could use guard patterns on all array accesses, but it starts to seem a little silly.</p> <p>The next thing is that a given array works with some auxiliary types. The <b>//</b> operator takes an array and a list of tuples and builds a new array with updated content. The type of that list of tuples is this:</p> <pre>type TileAssocList = [ ( ( Int, Int ), Tile ) ]</pre> <p>For accessing multiple items in an array, the <b>range</b> method builds lists of indexing tuples. The syntax to range requires tuples of tuples, with the parentheses piling up, so I wrapped it up in a function:</p> <pre>make_2d_range :: Int -> Int -> Int -> Int -> [ ( Int, Int ) ]<br />make_2d_range y0 x0 y1 x1 = range ( ( y0, x0 ), ( y1, x1 ) )</pre> <p>So how does that work? It just iterates coordinates, permuting from higher indices to lower, like so:</p> <pre>*Main> make_range 0 0 0 1<br />[(0,0),(0,1)]<br /><br />*Main> make_range 0 0 1 3<br />[(0,0),(0,1),(0,2),(0,3),(1,0),(1,1),(1,2),(1,3)]</pre> <p>For this problem domain, I need to know how reversed ranges work. For example, when the penguin is facing West, I want to build a range and a list of tiles in reverse index order. Can range do that for me?</p> <pre>*Main> make_range 0 23 0 0<br />[]</pre> <p>Ah... no. I guess that would have been too easy. So I'll have to account for those cases specially. Here's a function to get the penguin's view out of a 2-D array of tiles, in the form of a tile association list I can use to create a freshly created \"modified\" array (it's not really modified, but a new one is created with the updates from that list applied):</p> <pre>view_array :: BoardArray -> Pos -> Dir -> TileAssocList<br />view_array board pos dir =<br />    let row = ( posY pos )<br />        col = ( posX pos )<br />        coord_list = case dir of<br />            East  -> if ( col == max_col )<br />                     then []<br />                     else make_2d_range row ( col + 1 ) row max_col<br />            South -> if ( row == max_row )<br />                     then []<br />                     else make_2d_range ( row + 1 ) col max_row col<br />            West ->  if ( col == 0 )<br />                     then []<br />                     else make_2d_range row 0 row ( col - 1 )<br />            North -> if ( row == 0 )<br />                     then []<br />                     else make_2d_range 0 col ( row - 1 ) col<br />        tile_assoc = zip coord_list ( map ( (!) board )<br />                                           coord_list )<br />    in case dir of<br />        East -> tile_assoc<br />        South -> tile_assoc<br />        West -> reverse tile_assoc<br />        North -> reverse tile_assoc</pre> <p>That's not so bad. The key to this function is the <b>!</b> operator -- this gets a tuple and an array and returns an element -- and I zip the elements up with their coordinate tuples. Note that a lot of the bulk of this function is handling the edge cases, because we don't want to apply an out-of-range coordinate tuple to <b>!</b>. There may still be a shorter, clearer implementation possible. By comparison, here's a list-of-lists version factored a bit using currying to make it as self-documenting as I could get it -- note the use of <b>id</b> to let me return a general function as <b>orient</b>. I'm sure it doesn't impress FP whizzes, but I'm kinda proud of it -- I feel like I'm starting to use Haskell a little more idiomatically:</p> <pre>view_list :: BoardList -> Pos -> Dir -> [Tile]<br />view_list board pos dir =<br />    let row = ( posY pos )<br />        col = ( posX pos )<br />        transposed = elem dir [ South, North ]<br />        reversed = elem dir [ West, North ]<br />        orient | reversed = reverse<br />               | otherwise = id<br />        trim = case dir of<br />            East -> drop ( col + 1 )<br />            South -> drop ( row + 1 )<br />            West -> take col<br />            North -> take row<br />        extract | transposed = ( transpose board ) !! col<br />                | otherwise = board !! row  <br />    in orient $ trim $ extract</pre> <p>Testing <b>view_list</b>:</p> <pre>*Main> view_list init_board_list (Pos 0 0) East<br />[Empty,Empty,Empty,Empty,Empty,Empty,Empty,Empty,Empty,Empty,Empty,Empty,<br />Empty,Empty,Tree,Empty,Empty,Empty,Empty,Empty,Ice_Block,Empty,Empty]<br /><br />*Main> view_array init_board_array (Pos 0 0) East<br />[((0,1),Empty),((0,2),Empty),((0,3),Empty),((0,4),Empty),<br />((0,5),Empty),((0,6),Empty),((0,7),Empty),((0,8),Empty),<br />((0,9),Empty),((0,10),Empty),((0,11),Empty),((0,12),Empty),<br />((0,13),Empty),((0,14),Empty),((0,15),Tree),((0,16),Empty),<br />((0,17),Empty),((0,18),Empty),((0,19),Empty),((0,20),Empty),<br />((0,21),Ice_Block),((0,22),Empty),((0,23),Empty)]</pre> <p>Now we can write <b>step</b>. Here's the list version I've presented before:</p> <pre>step_list :: [Tile] -> ( Bool, [Tile] )<br />step_list [] = ( False, [] )<br />step_list ts = if walkable (head ts) then ( True, ts )<br />                                     else ( False, collide ts )</pre> <p>The array version is a little more complicated, because I want to strip the list I pass to <b>collide</b> down to just a list of tiles, in order to retain that clean logic for dealing with just a list of tiles. So I unzip my coordinate tuples from my tiles, get a potentially updated tile list, and zip it back together. That complicates it a bit, like so:</p> <pre>step_array :: TileAssocList -> ( Bool, TileAssocList )<br />step_array [] = ( False, [] )<br />step_array tile_assoc = if ( walkable $ head tile_list )<br />                        then ( True, tile_assoc )<br />                        else ( False, zip coord_list<br />                               ( collide tile_list ) )<br />    where ( coord_list, tile_list ) = unzip tile_assoc</pre> <p>I'm going to have to uglify my nice collide method a bit because I need to return at least one additional value -- indicating whether <b>collide</b> consumed a heart, so that we can keep score of the game.</p> <p>Next up, you can see the array and list solutions start to diverge hugely. It's hard to merge the list-based board back together with the potentially updated tile list to create the next immutable list-based board. My original method was pretty hideous. With Jeff's refactoring it's still a lot of code. (Note: I don't have this completely working yet; I'm getting a run-time error about bad patterns I haven't quite figured out yet):</p> <pre>next_board_list :: BoardList -> Pos -> Dir -> ( Bool, BoardList )<br />next_board_list board pos dir =<br />    let ( penguin_could_move, updated_view_list ) = <br />        step_list $ view_list board pos dir<br />    in ( penguin_could_move, update_board_from_view_list <br />         board pos dir updated_view_list )<br /><br />apply_view_list_to_row :: [Tile] -> Int -> Bool -> [Tile] -> [Tile]<br />apply_view_list_to_row orig pos True update =<br />    take ( pos + 1 ) orig ++ ( init update )<br />apply_view_to_row orig pos False update =<br />    ( reverse ( init update ) ) ++ ( drop pos orig )<br /><br />apply_view_list_to_rows :: BoardList -> Int -> Int -> <br />    Bool -> [Tile] -> BoardList<br />apply_view_list_to_rows orig row pos is_forward update =<br />    take row orig ++<br />    nest ( apply_view_to_row ( orig !! row ) pos is_forward update ) ++<br />    drop ( row + 1 ) orig<br /><br />update_board_from_view_list :: BoardList -> Pos -> Dir -> <br />    [Tile] -> BoardList<br />update_board_from_view_list board pos dir updated_view_list<br />    | is_eastwest = apply_view_list_to_rows board<br />                        ( posY pos ) ( posX pos )<br />                        is_forward updated_view_list<br />    | otherwise = transpose ( apply_view_list_to_rows ( transpose board )<br />                              ( posX pos ) ( posY pos ) <br />                              is_forward updated_view_list )<br />    where is_forward = elem dir [ East, South ]<br />          is_eastwest = elem dir [ East, West ]</pre> <p>By comparison, the array is much more suited to create an updated version of itself, given a list of elements to update. This is handled by the <b>//</b> function, in this simple function to create the next board in array form, called from <b>step_array</b>:</p> <pre>next_board_array :: BoardArray -> Pos -> Dir -> ( Bool, BoardArray )<br />next_board_array board pos dir =<br />    let ( penguin_could_move, updated_view ) =<br />        step_array $ view_array board pos dir<br />    in ( penguin_could_move, board // updated_view )</pre> <p>I like that -- it looks like we're working with the data structure rather than against it, although the overhead to manage the ranges and lists still feels to me more complicated than it should be. That complexity carries over elsewhere: for example, pretty-printing the array requires that range logic again. In fact I wind up just wrapping up and re-using the logic to pretty-print the list, so you can see how much additional code I needed:</p> <pre>pretty_tiles :: [Tile] -> String<br />pretty_tiles [] = \"\\n\"<br />pretty_tiles (t:ts) = case t of<br />                 Empty     -> \"___\"<br />                 Mountain  -> \"mt \"<br />                 House     -> \"ho \"<br />                 Ice_Block -> \"ic \"<br />                 Heart     -> \"he \"<br />                 Bomb      -> \"bo \"<br />                 Tree      -> \"tr \"<br />             ++ pretty_tiles ts<br /><br />pretty_board_list :: BoardList -> String<br />pretty_board_list [] = \"\"<br />pretty_board_list (ts:tss) = pretty_tiles ts ++ pretty_board_list tss<br /><br />split_tile_list :: [ Tile ] -> [ [ Tile ] ]<br />split_tile_list [] = []<br />split_tile_list ts = [ take tiles_in_row ts ] ++<br />                     ( split_tile_list $ ( drop tiles_in_row ) ts )<br />    where tiles_in_row = max_col + 1<br /><br />pretty_board_array :: BoardArray -> String <br />pretty_board_array board = pretty_board_list split_tiles<br />    where full_range = make_2d_range 0 0 max_row max_col<br />          all_tiles = map ( (!) board ) full_range<br />          split_tiles = split_tile_list all_tiles</pre> <p>As an aside, it seems like there ought to be at least one standard list split function, but it looks like folks don't really agree on how it should work</p> <p>So there it is -- the array is kind of a mixed blessing here. I haven't done any large-scale profiling on it, to determine if the need to generate a whole new array each pass is a big loss, compared to the potential structure-sharing in the list implementation. It simplifies some of the code dramatically, while adding a layer of dealing with ranges and lists of tuples everywhere -- as soon as we want to pull items out of the array, or merge them back in to a new array, we're dealing with lists again. Still, given the ugliness of the list merge code, it seems like the more natural choice for this kind of small game board data structure.</p>" nil nil "0bab6d4599888e16712c0067aef1cb5b") (200 (20949 25792 624591) "http://parenz.wordpress.com/2013/06/29/vado/" "Daniil Frumin: Agile development and deployment in the cloud with Haskell and vado" nil "Tue, 02 Jul 2013 13:26:14 +0000" "<p>
In this post I would like to give you an update on vado – a piece of<br />
software for running programs on vagrant VMs (or any other ssh server,<br />
actually), projects I’ve contributed briefly to.
</p>
<div id=\"outline-container-sec-1\" class=\"outline-2\">
<h2 id=\"sec-1\"><span class=\"section-number-2\">1</span> New build system</h2>
<div id=\"text-1\" class=\"outline-text-2\">
<p>
The <a href=\"http://parenz.wordpress.com/2013/06/12/ghcjs-build/\">old</a> <a href=\"http://github.com/ghcjs/ghcjs-build\">build system</a> for ghcjs was a little bit messy. Basically, it was<br />
just one Puppet configuration file that contained a hardcoded shell<br />
script as a resource that is supposed to be written to the home<br />
directory and executed. I decided to clean it up a notch and take more<br />
of a Puppet approach to the whole thing.
</p>
<p>
You can find the new set of build script on the GitHub:<br />
<a href=\"https://github.com/ghcjs/ghcjs-build\">https://github.com/ghcjs/ghcjs-build</a>
</p>
<p>
And since the errors are now printed to the screen it’s<br />
easy to see which stage the build is going through and if anything<br />
goes wrong you see an error trace for the current stage.
</p>
<p>
The <a href=\"https://github.com/ghcjs/ghcjs-build/tree/prebuilt\">prebuilt</a> version has also been updated by<br />
<a href=\"http://weblog.luite.com/wordpress/\">Luite Stegeman</a>.
</p>
</div>
</div>
<div id=\"outline-container-sec-2\" class=\"outline-2\">
<h2 id=\"sec-2\"><span class=\"section-number-2\">2</span> Vado</h2>
<div id=\"text-2\" class=\"outline-text-2\">
</div>
<div id=\"outline-container-sec-2-1\" class=\"outline-3\">
<h3 id=\"sec-2-1\"><span class=\"section-number-3\">2.1</span> Vado intro</h3>
<div id=\"text-2-1\" class=\"outline-text-3\">
<p>
Hamish Mackenzie and I have been working on <a href=\"https://github.com/hamishmack/vado\">vado</a> – a quick way to run<br />
commands on a remote ssh server. Just mount the directory you want to<br />
run the command in using <a href=\"http://fuse.sourceforge.net/sshfs.html\">sshfs</a>, in that directory (or its<br />
subdirectory) run vado like this:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">vado ls -l
</pre>
</div>
<p>
vado will run ‘mount’ to identify the user account, server name and<br />
the remote directory to run the command in. It will then run ssh to<br />
connect to the server and run the command.
</p>
<p>
You can also pass ssh options like this:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">vado -t htop
</pre>
</div>
<p>
This tells vado to pass -t to ssh (forces pseudo-tty allocation and<br />
makes programs like vim and htop work nicely).
</p>
<p>
I will explain below how to set up vado for multiple remote<br />
servers/sshfs mount points and how to develop Haskell projects on a<br />
remote server/VM nicely using Emacs and ghc-mod.
</p>
</div>
</div>
<div id=\"outline-container-sec-2-2\" class=\"outline-3\">
<h3 id=\"sec-2-2\"><span class=\"section-number-3\">2.2</span> .vadosettings</h3>
<div id=\"text-2-2\" class=\"outline-text-3\">
<p>
Vado is not tied to vagrant, but can be used with it and is faster<br />
than <code>vagrant ssh</code>. If the user and host detected in <code>mount</code> are<br />
specified in the <code>~/.vadosettings</code> file, then the specified key and<br />
port will be used.
</p>
<p>
The contents of the <code>~/.vadosettings</code> file is basically a Haskell<br />
list of <code>MountSettings</code> datastructures and we use standard <code>Read</code> and<br />
<code>Show</code> type-classes for serialization.
</p>
<p>
The <code>MountSettings</code> data type is defined as follows:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-haskell\"><span style=\"color: #b5bd68;\">-- | Mount point settings</span>
<span style=\"color: #b294bb;\">data</span> <span style=\"color: #f0c674;\">MountSettings</span> <span style=\"color: #cc6666;\">=</span> <span style=\"color: #f0c674;\">MountSettings</span> {
sshfsUser <span style=\"color: #cc6666;\">::</span> <span style=\"color: #f0c674;\">Text</span>
, sshfsHost <span style=\"color: #cc6666;\">::</span> <span style=\"color: #f0c674;\">Text</span>
, sshfsPort <span style=\"color: #cc6666;\">::</span> <span style=\"color: #f0c674;\">Int</span>
, idFile <span style=\"color: #cc6666;\">::</span> <span style=\"color: #f0c674;\">FilePath</span>
} <span style=\"color: #b294bb;\">deriving</span> (<span style=\"color: #f0c674;\">Show</span>, <span style=\"color: #f0c674;\">Read</span>)
</pre>
</div>
<p>
If the file is not present or incorrectly formatted<br />
then the default settings for vagrant will be used:
</p>
<ul class=\"org-ul\">
<li>User: vagrant
</li>
<li>Host: 127.0.0.1
</li>
<li>Port: 2222
</li>
<li>Key file: <code>~/.vagrant.d/insecure_private_key</code>
</li>
</ul>
</div>
<div id=\"outline-container-sec-2-2-1\" class=\"outline-4\">
<h4 id=\"sec-2-2-1\"><span class=\"section-number-4\">2.2.1</span> Example .vadosettings file</h4>
<div id=\"text-2-2-1\" class=\"outline-text-4\">
<p>
An example settings file might look like this:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-haskell\">[
<span style=\"color: #f0c674;\">MountSettings</span> {
sshfsUser <span style=\"color: #cc6666;\">=</span> <span style=\"color: #b5bd68;\">\"vagrant\"</span>
, sshfsHost <span style=\"color: #cc6666;\">=</span> <span style=\"color: #b5bd68;\">\"localhost\"</span>
, sshfsPort <span style=\"color: #cc6666;\">=</span> 2222
, idFile <span style=\"color: #cc6666;\">=</span> <span style=\"color: #b5bd68;\">\"/Users/dan/.vagrant.d/insecure_private_key\"</span>
},
<span style=\"color: #f0c674;\">MountSettings</span> {
sshfsUser <span style=\"color: #cc6666;\">=</span> <span style=\"color: #b5bd68;\">\"admin\"</span>
, sshfsHost <span style=\"color: #cc6666;\">=</span> <span style=\"color: #b5bd68;\">\"server.local\"</span>
, sshfsPort <span style=\"color: #cc6666;\">=</span> 2233
, idFile <span style=\"color: #cc6666;\">=</span> <span style=\"color: #b5bd68;\">\"/Users/dan/keys/local_server_key\"</span>
}
]
</pre>
</div>
</div>
</div>
</div>
<div id=\"outline-container-sec-2-3\" class=\"outline-3\">
<h3 id=\"sec-2-3\"><span class=\"section-number-3\">2.3</span> Vamount</h3>
<div id=\"text-2-3\" class=\"outline-text-3\">
<p>
Of course, using <code>vado</code> requires mounting the sshfs beforehand. But<br />
it gets tedious typing out
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">sshfs vagrant@localhost:/home/vagrant ../vm/ -p2222
-reconnect,defer_permissions,negative_vncache,<span style=\"color: #cc6666;\">volname</span>=ghcjs,<span style=\"color: #cc6666;\">IdentityFile</span>=~/.vagrant.d/insecure_private_key
</pre>
</div>
<p>
every time. A tool called <code>vamount</code> which is bundled together<br />
with <code>vado</code> can be used for mounting remote filesystems based on<br />
<code>~/.vadosettings</code> file.
</p>
<p>
You can use it like this:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">vamount [ssh options] remote_path [profile <span style=\"color: #969896;\">#</span><span style=\"color: #969896;\">]</span>
</pre>
</div>
<p>
The <code>remote_path</code> from the remote server specified in the<br />
~/.vadosettings file under number [profile #] will be mounted in the<br />
current directory using sshfs.
</p>
<p>
The profile number count starts from 1. If the [profile #] is absent<br />
or is 0 then the default (vagrant) configuration will be used.
</p>
</div>
</div>
<div id=\"outline-container-sec-2-4\" class=\"outline-3\">
<h3 id=\"sec-2-4\"><span class=\"section-number-3\">2.4</span> Vado and ghc-mod</h3>
<div id=\"text-2-4\" class=\"outline-text-3\">
<p>
<a href=\"http://www.mew.org/~kazu/proj/ghc-mod/en/\">ghc-mod</a> is a backend designed command to enrich Haskell programming on<br />
editors like Emacs and Vim and it also features a front-end for Emacs<br />
as a set of elisp scripts. It’s a really cool piece of software and if<br />
you have not tried it yet I highly recommend you to invest into<br />
installing and using it.
</p>
<p>
What we would like, however, is to edit files on the mounted<br />
filesystem using Emacs on the host machine, but run ghc-mod inside the<br />
VM. In order to do that we need to install ghc-mod both on our host<br />
machine and on the VM.
</p>
<p>
While installing ghc-mod on the host machine running the latest<br />
haskell-platform is pretty straightforward it is harder to do so on<br />
the VM running GHC 7.7 due to the fact that many libraries are not<br />
ready for GHC 7.7 and base 4.7 yet. We have to resort to installing<br />
most of the things from source.
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\"><span style=\"color: #969896;\"># </span><span style=\"color: #969896;\">run this on the guest machine</span>
mkdir ghcmod && <span style=\"color: #D0D0FF;\">cd</span> ghcmod
<span style=\"color: #969896;\"># </span><span style=\"color: #969896;\">patching installing convertible</span>
cabal unpack convertible
<span style=\"color: #D0D0FF;\">cd</span> convertible*
wget http://co-dan.github.io/patched/convertible.patch
patch -p1 Data/Convertible/Utils.hs convertible.patch
cabal install
<span style=\"color: #D0D0FF;\">cd</span> ..
<span style=\"color: #969896;\"># </span><span style=\"color: #969896;\">installing ghc-syb-utils</span>
git clone https://github.com/co-dan/ghc-syb.git
<span style=\"color: #D0D0FF;\">cd</span> ghc-syb/utils/
cabal install
<span style=\"color: #D0D0FF;\">cd</span> ../..
<span style=\"color: #969896;\"># </span><span style=\"color: #969896;\">finally getting and installing ghc-mod</span>
git clone https://github.com/co-dan/ghc-mod.git
<span style=\"color: #D0D0FF;\">cd</span> ghc-mod
cabal install
</pre>
</div>
<p>
Ghc-mod itself uses the GHC API extensively so it’s no surprise we<br />
have to change at least some code. Now that we have installed ghc-mod<br />
on the guest VM we need to set up our host’s Emacs configuration to<br />
communicate properly with the VM. First of all put this in your Emacs<br />
config:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-elisp\"><span style=\"color: #7f7f7f;\">(</span>setq load-path <span style=\"color: #7f7f7f;\">(</span>cons <span style=\"color: #b5bd68;\">\"~/Library/Haskell/ghc-7.6.3/lib/ghc-mod-2.0.3/share\"</span> load-path<span style=\"color: #7f7f7f;\">))</span>
<span style=\"color: #7f7f7f;\">(</span>autoload 'ghc-init <span style=\"color: #b5bd68;\">\"ghc\"</span> nil t<span style=\"color: #7f7f7f;\">)</span>
<span style=\"color: #7f7f7f;\">(</span>add-hook 'haskell-mode-hook <span style=\"color: #7f7f7f;\">(</span><span style=\"color: #b294bb;\">lambda</span> <span style=\"color: #7f7f7f;\">()</span> <span style=\"color: #7f7f7f;\">(</span>ghc-init<span style=\"color: #7f7f7f;\">)))</span>
<span style=\"color: #969896;\">;; </span><span style=\"color: #969896;\">(setq ghc-module-command \"ghc-mod\")</span>
<span style=\"color: #7f7f7f;\">(</span>setq ghc-module-command <span style=\"color: #b5bd68;\">\"~/vado-ghc-mod.sh\"</span><span style=\"color: #7f7f7f;\">)</span>
</pre>
</div>
<p>
<code>~/vado-ghc-mod.sh</code> should contain the following:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\"><span style=\"color: #969896;\">#</span><span style=\"color: #969896;\">!/bin/</span><span style=\"color: #b294bb;\">bash</span>
<span style=\"color: #cc6666;\">VADO</span>=/Users/dan/Library/Haskell/bin/vado
<span style=\"color: #cc6666;\">LOCAL_PATH</span>=/Users/dan/projects/ghcjs/mnt/
<span style=\"color: #cc6666;\">REMOTE_PATH</span>=/home/vagrant/
$<span style=\"color: #cc6666;\">VADO</span> -t ghc-mod ${<span style=\"color: #cc6666;\">@</span>//$<span style=\"color: #cc6666;\">LOCAL_PATH</span>/$<span style=\"color: #cc6666;\">REMOTE_PATH</span>} | sed <span style=\"color: #b5bd68;\">\"s,$REMOTE_PATH,$LOCAL_PATH,g\"</span>
</pre>
</div>
<p>
I know that it’s a hack, but it does work and I guess that’s what<br />
shell scripts are for ;)
</p>
<p>
Now go to <code>~/.bashrc</code> on the <i>guest machine</i> and make sure that the<br />
<code>PATH</code> variable is <a href=\"http://stackoverflow.com/questions/820517/bashrc-at-ssh-login\">set correctly</a>:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\"><span style=\"color: #cc6666;\">PATH</span>=/home/vagrant/ghcjs/bin:/home/vagrant/.cabal/bin:/home/vagrant/ghc/bin:/home/vagrant/jsshell:/home/vagrant/node-v0.10.10-linux-x86/bin:$<span style=\"color: #cc6666;\">PATH</span>
<span style=\"color: #969896;\"># </span><span style=\"color: #969896;\">PATH is set *before* this line:</span>
[ -z <span style=\"color: #b5bd68;\">\"$PS1\"</span> ] && <span style=\"color: #b294bb;\">return</span>
<span style=\"color: #969896;\"># </span><span style=\"color: #969896;\"><snip></span>
</pre>
</div>
<p>
And that’s it, you should be done!
</p>
<p>Before (ghc-mod running on the host machine):<br />
<a href=\"http://parenz.files.wordpress.com/2013/06/ghcmod-before.png\"><img src=\"http://parenz.files.wordpress.com/2013/06/ghcmod-before.png?w=600&h=306\" alt=\"ghcmod-before\" height=\"306\" class=\"alignnone size-medium wp-image-66\" width=\"600\" /></a></p>
<p>After (ghc-mod running inside <a href=\"https://github.com/ghcjs/ghcjs-build\">ghcjs-build</a> VM):<br />
<a href=\"http://parenz.files.wordpress.com/2013/06/ghcmod-after.png\"><img src=\"http://parenz.files.wordpress.com/2013/06/ghcmod-after.png?w=600&h=306\" alt=\"ghcmod-after\" height=\"306\" class=\"alignnone size-medium wp-image-65\" width=\"600\" /></a></p>
</div>
</div>
</div>
<div id=\"outline-container-sec-3\" class=\"outline-2\">
<h2 id=\"sec-3\"><span class=\"section-number-2\">3</span> Conclusion and future work</h2>
<div id=\"text-3\" class=\"outline-text-2\">
<p>
We’ve seen how a small but useful tool <code>vado</code> can make our life easier if<br />
we want to develop Haskell projects on a remote server or on a<br />
virtual machine. You can get Vado from GitHub: <a href=\"https://github.com/hamishmack/vado\">https://github.com/hamishmack/vado</a>
</p>
<p>
Next week we are planning on releasing our first version of<br />
interactive-diagrams pastesite (not going to be very interactive<br />
though) and writing out its security model.
</p>
<p>
Meanwhile check Luite’s <a href=\"http://weblog.luite.com/wordpress/?p=127\">post</a> on using Sodium FRP library for creating<br />
Functional Reactive Web interfaces. It’s astonishing how easily you<br />
can just get a FRP library, compile to JavaScript and make nifty web<br />
apps with it.
</p>
</div>
</div>
<br /> Tagged: <a href=\"http://parenz.wordpress.com/tag/ghcjs/\">ghcjs</a>, <a href=\"http://parenz.wordpress.com/tag/haskell-2/\">haskell</a>, <a href=\"http://parenz.wordpress.com/tag/soc/\">soc</a>, <a href=\"http://parenz.wordpress.com/tag/vm/\">vm</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/parenz.wordpress.com/64/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/parenz.wordpress.com/64/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=parenz.wordpress.com&blog=26722965&post=64&subd=parenz&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "e15d9e41f915e9682be23b1611e93c88") (199 (20949 25792 622480) "http://joyful.com/blog/2013-07-01-june-review.html" "Simon Michael: June review" nil "Mon, 01 Jul 2013 23:00:00 +0000" "<div style=\"font-style: italic;\">July  1, 2013</div>
<h2>June review</h2>
<p>
</p><p>The beginning of a new month. Here’s a quick update.</p>
<p>No hledger release today as there isn’t much new to ship, following a month with several <a href=\"http://hledger.org/NEWS.html\">bugfix releases</a> and otherwise mostly infrastructural work (build and dev tool fixes, wiki styling, site update hook). 8/1 is the likely next release date. Oh, <a href=\"http://newartisans.com/\">John</a> and I also had a nice voice chat - nice to escape the IRC window isn’t it - reviewing our glorious *ledger plans, and I happily accepted his <a href=\"https://github.com/simonmichael/hledger/commit/a05e7a5a671af25b220eb4f152ad935687faef1a\">first hledger patch</a> - thanks John! :)</p>
<p>My free hacking time in recent weeks went more towards <a href=\"http://darcs.net\">darcs</a>:</p>
<ul>
<li><p>Unix shell helpers to get one-line-per-patch output from darcs (awesome!)</p>
<pre class=\"sourceCode bash\"><code class=\"sourceCode bash\"><span class=\"co\"># show darcs changes, push, pull etc. output with one patch per line</span>
<span class=\"co\"># Eg:</span>
<span class=\"co\"># dch --last 3</span>
<span class=\"co\"># darcs pull --dry | d1</span>
<span class=\"kw\">alias</span> darcsoneline=<span class=\"st\">\"egrep '^\\w' -A1 | egrep -v '^(--|The remote repository has|Would pu)' | sed '</span><span class=\"ot\">$!</span><span class=\"st\">N;s/\\n/ /'\"</span>
<span class=\"kw\">alias</span> d1=darcsoneline
<span class=\"kw\">function</span><span class=\"fu\"> dch()</span> <span class=\"kw\">{</span>
<span class=\"kw\">darcs</span> changes <span class=\"ot\">$*</span> <span class=\"kw\">|</span> <span class=\"kw\">darcsoneline</span>
<span class=\"kw\">}</span></code></pre></li>
<li><p>Support for BSRK Aditya’s <a href=\"http://hub.darcs.net/Aditya/darcsden-gsoc/changes\">GSOC work</a>. Together with Ganesh Sittampalam we did several rounds of code review and BSRK’s nice enhancements should be appearing on darcs hub soon.</p></li>
<li><p>Also driven by the above, updated <a href=\"http://hub.darcs.net/simon/darcsden/changes\">darcsden</a> and HSP for current GHC and libraries, and made it easy for me to build and deploy again. Also merged <a href=\"http://hub.darcs.net/ganesh/darcsden-service/changes\">Ganesh’s improvements</a> for MS Windows compatibility. This will be released as darcsden 1.1 shortly.</p></li>
<li><p>Ongoing <a href=\"http://hub.darcs.net\">darcs hub</a> ops/maintenance, including a fix for <a href=\"http://hub.darcs.net/simon/darcsden/issue/59\">this interesting segfault</a>, and a server upgrade from ubuntu 12.04 to 13.04. This last caused about <s>45m</s><a href=\"http://stats.pingdom.com/olo874j6ixzj/632910/2013/06\">1h20m of downtime >:(</a> late last night as I wrestled with the unfamiliar couchdb migration process and erlang stack traces. (For reference: just copy /var/lib/couchdb/1.0.1/* to 1.2.0/, but <em>don’t forget to preserve file ownership</em>.) At least it got resolved it before month-end at pingdom, so there’s a chance to get uptime back up where it should be - 3 or 4 nines - in July!</p></li>
</ul>" nil nil "a74a44b51c8e44fffeed4d9cab07fb55") (198 (20949 25792 621750) "http://feedproxy.google.com/~r/ezyang/~3/tSmwYHznwqQ/" "Edward Z. Yang: HoTT exercises in Coq (in progress)" nil "Mon, 01 Jul 2013 20:21:18 +0000" "<div class=\"document\">
<p>I spent some of my plane ride yesterday working on Coq versions of the exercises in <a href=\"http://homotopytypetheory.org/book/\" class=\"reference external\">The HoTT book</a>. I got as far as 1.6 (yeah, not very far, perhaps I should make a GitHub repo if other folks are interested in contributing skeletons. Don't know what to do about the solutions though).  All of these have been test solved.</p>
<p>You will need HoTT/coq in order to run this development; instructions on <a href=\"https://github.com/HoTT/HoTT/blob/master/INSTALL.txt\" class=\"reference external\">how to install it are here.</a></p>
<pre class=\"literal-block\">Require Import HoTT.
Definition admit {T: Type} : T. Admitted.
(* Exercise 1.1 *)
Definition mycompose {A B C : Type} (g : B -> C) (f : A -> B) : A -> C := admit.
Goal forall (A B C D : Type) (f : A -> B) (g : B -> C) (h : C -> D),
mycompose h (mycompose g f) = mycompose (mycompose h g) f.
Admitted.
(* Exercise 1.2 *)
Section ex_1_2_prod.
Variable A B : Type.
Check @fst.
Check @snd.
Definition my_prod_rec (C : Type) (g : A -> B -> C) (p : A * B) : C := admit.
Goal fst = my_prod_rec A (fun a => fun b => a). Admitted.
Goal snd = my_prod_rec B (fun a => fun b => b). Admitted.
End ex_1_2_prod.
Section ex_1_2_sig.
Variable A : Type.
Variable B : A -> Type.
Check @projT1.
Check @projT2.
Definition my_sig_rec (C : Type) (g : forall (x : A), B x -> C) (p : exists (x : A), B x) : C := admit.
Goal @projT1 A B = my_sig_rec A (fun a => fun b => a). Admitted.
(* What goes wrong when you try to prove this for projT2? *)
End ex_1_2_sig.
(* Exercise 1.3 *)
Definition refl {A : Type} (x : A) : x = x := 1%path.
Section ex_1_3_prod.
Variable A B : Type.
(* Given by the book *)
Definition uppt : forall (x : A * B), ((fst x, snd x) = x) :=
fun p => match p with (a,b) => refl (a,b) end.
Definition my_prod_ind (C : A * B -> Type) (g : forall (x : A) (y : B), C (x, y)) (x : A * B) : C x := admit.
Goal forall C g a b, my_prod_ind C g (a, b) = g a b. Admitted.
End ex_1_3_prod.
Section ex_1_3_sig.
Variable A : Type.
Variable B : A -> Type.
Definition sig_uppt : forall (x : exists (a : A), B a), ((projT1 x; projT2 x) = x) := admit.
Definition mysig_ind (C : (exists (a : A), B a) -> Type) (g : forall (a : A) (b : B a), C (a; b)) (x : exists (a : A), B a) : C x := admit.
Goal forall C g a b, mysig_ind C g (a; b) = g a b. Admitted.
End ex_1_3_sig.
(* Exercise 1.4 *)
Fixpoint iter (C : Type) (c0 : C) (cs : C -> C) (n : nat) : C :=
match n with
| 0 => c0
| S n' => cs (iter C c0 cs n')
end.
Definition mynat_rec (C : Type) : C -> (nat -> C -> C) -> nat -> C := admit.
Eval compute in mynat_rec (list nat) nil (@cons nat) 2.
Eval compute in nat_rect (fun _ => list nat) nil (@cons nat) 2.
(* Exercise 1.5 *)
Definition mycoprod (A B : Type) := exists (x : Bool), Bool_rect (fun _ => Type) A B x.
Section ex_1_5.
Variable A B : Type.
Definition inl := existT (Bool_rect (fun _ => Type) A B) true.
Definition inr := existT (Bool_rect (fun _ => Type) A B) false.
Definition mycoprod_ind (C : mycoprod A B -> Type)
(l : forall (a : A), C (inl a))
(r : forall (b : B), C (inr b))
(x : mycoprod A B) : C x := admit.
Goal forall C l r x, mycoprod_ind C l r (inl x) = l x. Admitted.
Goal forall C l r x, mycoprod_ind C l r (inr x) = r x. Admitted.
End ex_1_5.
(* Exercise 1.6 *)
Definition myprod (A B : Type) := forall (x : Bool), Bool_rect (fun _ => Type) A B x.
Section ex_1_6.
Context `{Funext}.
Variable A B : Type.
Definition mypr1 (p : myprod A B) := p true.
Definition mypr2 (p : myprod A B) := p false.
Definition mymkprod (a : A) (b : B) : myprod A B := Bool_rect (Bool_rect (fun _ => Type) A B) a b.
Definition myprod_ind (C : myprod A B -> Type)
(g : forall (x : A) (y : B), C (mymkprod x y)) (x : myprod A B) : C x := admit.
Goal forall C g a b, myprod_ind C g (mymkprod a b) = g a b. Admitted.
End ex_1_6.
</pre>
<p>Actually, I lied. I haven't proved the last goal in exercise 1.6; my trouble is I don't know how to get function extensionality to compute, but I’m sure it’s something simple...</p>
</div>
<img src=\"http://feeds.feedburner.com/~r/ezyang/~4/tSmwYHznwqQ\" height=\"1\" width=\"1\" />" nil nil "3988b25978269ce76c412cb4f230d628") (197 (20949 25792 620840) "http://www.yesodweb.com/blog/2013/07/runtime-lucius-mixins" "Yesod Web Framework: Runtime Lucius: now with mixins!" nil "Mon, 01 Jul 2013 13:00:00 +0000" "<p>About two months ago, <a href=\"http://www.yesodweb.com/blog/2013/04/mixin-support-in-lucius\">I announced that Lucius now had mixin
support</a>.
Unfortunately, it was missing something important: support in runtime Lucius.
Many of you have probably never used runtime Lucius, but it's the component
underlying Lucius's ability to do live code reloading during development. So
without this feature, it's impossible to use mixins when using <code>yesod devel</code>.</p><p>As of <code>shakespeare-css</code> 1.0.6.1, this is no longer a problem: mixins should now
work perfectly with <code>yesod devel</code>. In order to take advantage of this, just add
a minimum bound on your shakespeare-css constraint in your cabal file. (The
next release of yesod-platform will include this change.)</p><p>If anyone finds any problems, let me know.</p>" nil nil "026039983c8de2699655d62bd127a161") (196 (20949 25792 620508) "http://lambda.jstolarek.com/2013/06/msr-internship-and-some-retrospection/" "Jan Stolarek: MSR internship and some retrospection" nil "Sun, 30 Jun 2013 20:00:38 +0000" "<p style=\"text-align: justify;\">I feel I can finally write about: I got accepted for a three-month internship at Microsoft Research Cambridge! This means I will be developing GHC and, hopefully, doing some serious research on the subject of functional programming and compiler implementation. My internship starts tomorrow, on 1st July. I’m not yet 100% certain about the exact topic of my research, so I’ll refrain from going into any kind of technical details for now and I will focus on my personal experience with functional programming. I feel this is really a good moment to summarize the past 1,5 year. I learned about functional programming at the very beginning of 2012 and since then I progressed from knowing completely nothing to being in Cambridge – something I would have not imagined 18 months ago.</p>
<p style=\"text-align: justify;\">Somewhere around July 2011 I finished writing my PhD. I had yet to deal with many formalities – which in the end took 8 months – but the most important part of my work was done and I only continued research on a few minor subjects that I ran into while writing a PhD. Somewhere in October I decided I need a break from all my current research topic – I finally wanted some time to pursue topics that interested me all along and for which I never had time. Compiler construction and theory of automata were two main topics I had in mind. That was the plan, but it wasn’t meant to work out, at least not yet. Somewhere around December 2012 I stumbled upon a book <a href=\"http://lambda.jstolarek.com/2012/04/7-languages-in-7-weeks-book-review/\">“Seven languages in seven weeks”</a>, which was my first contact with functional programming. I didn’t follow the book exactly. I read chapters about Ruby, Io, Prolog (so much fun!), Scala and Erlang, but instead of reading chapter about Clojure I went for Scheme. I read <a href=\"http://www.schemers.org/Documents/Standards/R5RS/\">R5RS</a> language specification and <a href=\"http://lambda.jstolarek.com/2013/01/the-little-schemer-book-review/\">The Little Schemer</a> and when I reached the chapter about Haskell I decided to read <a href=\"http://learnyouahaskell.com/chapters\">Learn You A Haskell</a> instead. At that point I already knew that Haskell is <em>the</em> functional programming language and I think that this was the moment I started having some serious plans about functional programming. But at the same time I was figuring out how to learn about compilers. It was April when <a href=\"http://lambda.jstolarek.com/2012/04/stanford-opens-new-online-courses-about-compilers-and-automata/\">Stanford University announced their two online courses on Compilers and Automata</a> – these were really godsend. The Compilers course ended in late June. This concludes my first six months of contact with FP and I think that these months were extremely intense. I learned theoretical and practical foundations of compilers, a new programming paradigm and some new languages designed in that paradigm. I also started reading research papers on functional programming, with a focus on implementation of GHC. At that point I didn’t even try to work on the source code, but I was trying to understand how the compiler is designed.</p>
<p style=\"text-align: justify;\">The next six months, from July to December, were not as fruitful. I picked up interest in doing data-parallel computations in Haskell, as this seemed to be an active topic of research and also related to my PhD work. I made a failed attempt of an efficient parallel implementation of a wavelet transform. Although I wasn’t successful, my time was not wasted: I learned how to write, test and benchmark libraries in Haskell and also read a lot of papers on FP. I also got in touch with <a href=\"http://www.cse.unsw.edu.au/~benl/\">Ben Lippmeier</a>, who pointed me to one problem with GHC he needed fixed. This was somewhere in January 2013. I already started reading the source code of GHC in December, but now I finally had a particular problem to solve. It was the time to start working on GHC. That is mostly what I did during the last six months, although I also managed to spend some time on theory (more papers and <a href=\"http://lambda.jstolarek.com/2013/02/to-mock-a-mockingbird-or-how-i-learned-to-stop-worrying-and-learned-combinatory-logic/\">a book on combinatory logic</a>).</p>
<p style=\"text-align: justify;\">As for the internship, I decided to apply for it in February. I polished my CV and cover letter (many thanks go to my friend <a href=\"http://www.mareklab.org/\">Marek</a> for his help) and sent my application at the beginning of March. After an interview with Geoffrey Mainland and Simon Peyton Jones I got acceptance notification at the beginning of April. And here I am in Cambridge, over 1300km from home, waiting for my first day at Microsoft Research.</p>" nil nil "f7ce656d3416b1e9d315b4c8784dfc2c") (195 (20949 25792 619668) "http://feedproxy.google.com/~r/FpComplete/~3/WtRkqbxIn5Q/fp-haskell-center-beta-announcement" "FP Complete: FP Haskell Center Beta Released, and Beta Accounts Activated" nil "Sun, 30 Jun 2013 19:51:00 +0000" "<h3>Beta Release Blog</h3><p>It’s here! After months of hard work by our engineers, and only 9 months since we announced our plans in ICFP last September, I am pleased to announce that we’ve released the <a href=\"https://www.fpcomplete.com/business/designer-ide\">beta of FP Haskell Center</a>, the world's first commercial Haskell IDE and deployment platform.  We’ve received great response with nearly 1,000 sign-ups already.  Since we want to have a smooth beta process and a good user experience, we are going to activate beta accounts selectively, in ever increasing numbers, in the next few weeks as we test new features and load factors.  We will notify users via email that their account is ready to be activated; some of you who are reading this may already have received the message.  We expect to have “open enrollment” for all before the end of July.  </p><p><a href=\"https://www.fpcomplete.com/blog/2013/06/fp-haskell-center-beta-demo\">Watch a video</a> walkthrough of the highlighted features.  There’s still time to <a href=\"https://www.fpcomplete.com/business/designer-ide\">sign-up</a>.</p><p>As an appreciation and reward for being in the beta program, we will offer a special discount only to beta customers who buy an annual subscription to the GA product before the official release date in early September.  We are working on our pricing and offering plans, and expect to have them completed by early August, so stay tuned.</p><p>FP Haskell Center has two integrated components that allow you to develop and deploy Haskell applications in the cloud from a single platform.  The FP Haskell Development Environment is an IDE that includes a Haskell compiler and a continually updated set of vetted, tested and supported libraries and code templates. There is no need to run Cabal or other installers. The FP Haskell Application Server is used to deploy and run Haskell applications directly in the cloud with no additional effort. A free shared instance is included with every account. Larger and dedicated instances are available for active project deployments at a reasonable monthly charge.</p><p>For further information and sign up, <a href=\"https://www.fpcomplete.com/business/designer-ide\">please go here</a>.</p><div class=\"feedflare\">
<a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=WtRkqbxIn5Q:EMKkzrydVc4:yIl2AUoC8zA\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=yIl2AUoC8zA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=WtRkqbxIn5Q:EMKkzrydVc4:V_sGLiPBpWU\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=WtRkqbxIn5Q:EMKkzrydVc4:V_sGLiPBpWU\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=WtRkqbxIn5Q:EMKkzrydVc4:qj6IDK7rITs\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=qj6IDK7rITs\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=WtRkqbxIn5Q:EMKkzrydVc4:gIN9vFwOqvQ\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=WtRkqbxIn5Q:EMKkzrydVc4:gIN9vFwOqvQ\" border=\"0\" /></a>
</div><img src=\"http://feeds.feedburner.com/~r/FpComplete/~4/WtRkqbxIn5Q\" height=\"1\" width=\"1\" />" nil nil "9a8e471c1a89046962de5a17e0d8c4fb") (194 (20949 25792 619117) "http://jpmoresmau.blogspot.com/2013/06/eclipsefp-253-released.html" "JP Moresmau: EclipseFP 2.5.3 released" "noreply@blogger.com (JP Moresmau)" "Sun, 30 Jun 2013 18:20:49 +0000" "Hello, I've just released a new version of EclipseFP, 2.5.3. This is a minor release for bug fixes, general stability and hopefully better performance.<br /><br />You can find the release notes here: <a href=\"https://raw.github.com/JPMoresmau/eclipsefp/master/docs/releasenotes/net.sf.eclipsefp.haskell_2.5.3.txt\">https://raw.github.com/JPMoresmau/eclipsefp/master/docs/releasenotes/net.sf.eclipsefp.haskell_2.5.3.txt</a>.<br /><br />I don't have a lot of time for EclipseFP at the moment, being busy on other projects, but I'm well aware that there are a few enhancements that people have asked for in the queue. I'll try to address these later on, and of course I'll happily accept pull request on <a href=\"https://github.com/JPMoresmau/eclipsefp\">https://github.com/JPMoresmau/eclipsefp</a>.<br /><br />As usual install or update by pointing your Eclipse to <span style=\"background-color: white; font-family: monospace; font-size: 12px; line-height: 19px;\">http://eclipsefp.sf.net/updates.</span><br /><span style=\"background-color: white; font-family: monospace; font-size: 12px; line-height: 19px;\"><br /></span>Happy Haskell Hacking!" nil nil "8a281eee8f73b1a48f77c35429a45690") (193 (20949 25792 618721) "http://blog.darcs.net/2013/06/darcs-news-104.html" "Darcs: darcs news #104" "noreply@blogger.com (guillaume)" "Sun, 30 Jun 2013 11:29:10 +0000" "<h3 id=\"news-and-discussions\">News and discussions</h3><ol style=\"\"><li>Google Summer of Code 2013 has begun! BSRK and José will post updates on their blogs:<br /> <ul><li><a href=\"http://bsrkaditya.blogspot.com/search/label/darcs\"><code class=\"url\">http://bsrkaditya.blogspot.com/search/label/darcs</code></a></li><li><a href=\"http://blog.jlneder.com.ar/search/label/darcs\"><code class=\"url\">http://blog.jlneder.com.ar/search/label/darcs</code></a></li></ul></li></ol><h3 id=\"issues-resolved-8\">Issues resolved (8)</h3><dl><dt>issue2163 Radoslav Dorcik</dt><dd><ul><li>new option for amend, select author for patch stealing.</li><li><a href=\"http://bugs.darcs.net/issue2163\"><code class=\"url\">http://bugs.darcs.net/issue2163</code></a></li></ul></dd><dt>issue2227 Ganesh Sittampalam</dt><dd><ul><li>move the rebase patch to the end before an amend-record</li><li><a href=\"http://bugs.darcs.net/issue2227\"><code class=\"url\">http://bugs.darcs.net/issue2227</code></a></li></ul></dd><dt>issue2248 Ganesh Sittampalam</dt><dd><ul><li>always clean up rebase-in-progress state</li><li><a href=\"http://bugs.darcs.net/issue2248\"><code class=\"url\">http://bugs.darcs.net/issue2248</code></a></li></ul></dd><dt>issue2250 BSRK Aditya</dt><dd><ul><li>tabbing in usageHelper - pad by max length of command name</li><li><a href=\"http://bugs.darcs.net/issue2250\"><code class=\"url\">http://bugs.darcs.net/issue2250</code></a></li></ul></dd><dt>issue2311 Sebastian Fischer</dt><dd><ul><li>posthook for 'get' should run in created repo</li><li><a href=\"http://bugs.darcs.net/issue2311\"><code class=\"url\">http://bugs.darcs.net/issue2311</code></a></li></ul></dd><dt>issue2312 Sebastian Fischer</dt><dd><ul><li>posthooks for 'record' and 'amend-record' should receive DARCS_PATCHES</li><li><a href=\"http://bugs.darcs.net/issue2312\"><code class=\"url\">http://bugs.darcs.net/issue2312</code></a></li></ul></dd><dt>issue2320 Jose Luis Neder</dt><dd><ul><li>save prompted author name in ~/.darcs/author instead of ./_darcs/prefs/author</li><li><a href=\"http://bugs.darcs.net/issue2320\"><code class=\"url\">http://bugs.darcs.net/issue2320</code></a></li></ul></dd><dt>issue2321 Jose Luis Neder</dt><dd><ul><li>when no patch name given, directly invoke text editor</li><li><a href=\"http://bugs.darcs.net/issue2321\"><code class=\"url\">http://bugs.darcs.net/issue2321</code></a></li></ul></dd></dl><h3 id=\"patches-applied-20\">Patches applied (20)</h3><dl><dt>2013-06-09 Guillaume Hoffmann</dt><dd><ul><li>make nano the default text editor instead of vi</li></ul></dd><dt>2013-06-20 BSRK Aditya</dt><dd><ul><li>Resolve issue2250: tabbing in usageHelper - pad by max length of command name</li></ul></dd><dt>2013-06-16 Guillaume Hoffmann</dt><dd><ul><li>remove word repetition in fileHelpAuthor string</li></ul></dd><dt>2013-06-16 Jose Luis Neder</dt><dd><ul><li>resolve issue2320: save prompted author name in ~/.darcs/author instead of ./_darcs/prefs/author</li><li>resolve issue2321: when no patch name given, directly invoke text editor</li></ul></dd><dt>2013-04-30 Guillaume Hoffmann</dt><dd><ul><li>remove repository flag DryRun parameter when not used or always NoDryRun</li></ul></dd><dt>2013-04-05 Ganesh Sittampalam</dt><dd><ul><li>fix test for Windows</li></ul></dd><dt>2013-03-10 Sebastian Fischer</dt><dd><ul><li>Follow-up on patch1066 resolving issue2312.</li><li>resolve issue2312: posthooks for 'record' and 'amend-record' should receive DARCS_PATCHES</li><li>Added tests for issue2312: posthooks for 'record' and 'amend-record' should receive DARCS_PATCHES</li></ul></dd><dt>2013-02-16 Ganesh Sittampalam</dt><dd><ul><li>resolve issue2227: move the rebase patch to the end before an amend-record</li><li>tidy command definitions in Darcs.UI.Commands.Rebase</li><li>resolve issue2248: always clean up rebase-in-progress state</li><li>add --ignore-times option to rebase commands that read the working dir</li></ul></dd><dt>2013-03-08 Sebastian Fischer</dt><dd><ul><li>resolve issue2311: posthook for 'get' should run in created repo</li><li>Added tests for Issue 2311.</li></ul></dd><dt>2013-06-03 Guillaume Hoffmann</dt><dd><ul><li>haddocks for functions that look for user e-mail</li></ul></dd><dt>2013-03-02 Radoslav Dorcik</dt><dd><ul><li>Resolve issue2163: new option for amend, select author for patch stealing.</li></ul></dd><dt>2013-05-29 BSRK Aditya</dt><dd><ul><li>Export doOptimizeHTTP from Optimize module</li><li>Increase efficiency of patch index update by more efficient extraction</li></ul></dd></dl>See <a href=\"http://wiki.darcs.net/DarcsWeeklyNews/2013-06-30\">darcs wiki entry</a> for details." nil nil "56ea395ce4cd3bedb7fbf7289242b5bb") (192 (20949 25792 617926) "http://wadler.blogspot.com/2013/06/knowledge-economy.html" "Philip Wadler: Knowledge Economy" "noreply@blogger.com (Philip Wadler)" "Sun, 30 Jun 2013 11:20:54 +0000" "<div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://2.bp.blogspot.com/-5FG3qlbvISc/UdATLL5FduI/AAAAAAAACdk/5DgXlPXknxY/s242/ke-logo.gif\"><img src=\"http://2.bp.blogspot.com/-5FG3qlbvISc/UdATLL5FduI/AAAAAAAACdk/5DgXlPXknxY/s400/ke-logo.gif\" height=\"208\" border=\"0\" width=\"400\" /></a></div><div style=\"clear: both; text-align: justify;\" class=\"separator\">UCU writes:</div><blockquote class=\"tr_bq\"><span style=\"background-color: white; color: #222222; text-align: start;\"><span style=\"font-family: inherit;\">Wednesday’s spending review was bad news for universities, colleges and students. Student visa charges will go up, student grants will be frozen and funding aimed at encouraging the poorest students to apply to university will be axed. On Thursday, Danny Alexander announced plans to sell off student loans. All this in the same week that the OECD research showed the UK falling behind in investment in higher education at a time when demand for highly skilled graduates is still rising faster than supply.</span></span></blockquote>Sign up to the <a href=\"http://www.knowledgeeconomy.org.uk/\">Knowledge Economy campaign</a>.<br /><div style=\"clear: both; text-align: center;\" class=\"separator\"><br /></div><div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://3.bp.blogspot.com/-PWs4Y4eMJZg/UdASqk29BeI/AAAAAAAACdg/6iOJK4FXLTE/s1600/ke1.tiff\"><img src=\"http://3.bp.blogspot.com/-PWs4Y4eMJZg/UdASqk29BeI/AAAAAAAACdg/6iOJK4FXLTE/s640/ke1.tiff\" height=\"188\" border=\"0\" width=\"640\" /></a></div><div style=\"clear: both; text-align: center;\" class=\"separator\"><br /></div><br /><div style=\"clear: both; text-align: center;\" class=\"separator\"></div><br />" nil nil "34884c5760602ac45a7f0cd270449f8d") (191 (20949 25792 617400) "http://praisecurseandrecurse.blogspot.com/2013/06/the-polar-game-in-haskell-day-4-12.html" "Paul Potts: The Polar Game in Haskell, Day 4 1/2: Folding a Penguin" "noreply@blogger.com (Paul Potts)" "Sat, 29 Jun 2013 19:03:00 +0000" "<p>So, just a quick update today. While I was cooking bacon this morning I looked at comments and tried to implement an idea I had last night. Roland suggested I could get rid of <b>Edge</b>. I had already been asking myself this. Using a special flag value for the edge-of-board case came from the Objective-C version where I wanted to avoid reading tiles outside the bounds of the board array. When using lists there is a built-in termination condition, so Edge is gone completely.</p> <p>Roland also suggested a simplified next_ppos, like so:</p> <pre>next_ppos :: Pos -> Dir -> Pos<br />next_ppos pos dir = Pos ( posY pos + fst step ) ( posX pos + snd step )<br />    where step = delta dir<br />          delta East = ( 0, 1 )<br />          delta South = ( 1, 0 )<br />          delta West = ( 0, -1 )<br />          delta North = ( -1, 0 )</pre> <p>So that's in there now. Thanks, Roland!</p> <p>The next thing I wanted to do is get rid of that ugly test code with all the nested calls to next_world. I was re-reading <i>Learn You a Haskell</i> and it occurred to me that this sort of thing -- distilling a list -- is what <i>folds</i> are for. And then, a minute later, that I don't actually want to <i>fold</i> the worlds down to one final world -- I want to capture all the intermediate worlds as we process a list of moves. And that's what a <i>scan</i> is for. So we're conducting surveillance on the penguin as he goes about his business. GHCI tells me that the type of <b>scanl</b> is <b>(a -> b -> a) -> a -> [b] -> [a]</b>. So I'm calling it with a function that takes a <b>World</b> and a <b>Dir</b> and returns a <b>World</b>. That's the <b>(a -> b -> a)</b> part. Then it gets an initial <b>World</b>, that's the <b>a</b>, and a list of elements of type <b>Dir</b>, that's the <b>[b]</b>, and returns a list of elements of type <b>World</b>, that's <b>[a]</b>.</p> <pre>moves_to_dirs :: [(Dir, Int)] -> [Dir]<br />moves_to_dirs [] = []<br />moves_to_dirs (m:ms) = replicate ( snd m ) ( fst m ) ++ moves_to_dirs ms<br /><br />moves_board_1 = [(East,21),(South,2), (East,3),(North,2),(West,2)]<br /><br />move_sequence :: [(Dir,Int)] -> [World]<br />move_sequence repeats = scanl next_world init_world steps<br />    where steps = moves_to_dirs repeats<br /><br />main :: IO ()<br />main = do<br />    mapM_ putStrLn pretty_worlds<br />    where worlds = move_sequence moves_board_1</pre> <p>And that gives me the whole shebang, ending in:</p> <pre>penguin @: Pos {posY = 0, posX = 22}, facing: West, hearts: 3<br />tr __________________________________________tr _______________ic ______<br />tr ___bo ___mt ___he ic he ___________________________tr ______tr ______<br />tr _____________________________________________he _________mt ho ______<br />tr tr ____________tr ___________________________________________________<br /><br />penguin @: Pos {posY = 0, posX = 21}, facing: West, hearts: 3<br />tr __________________________________________tr ic _____________________<br />tr ___bo ___mt ___he ic he ___________________________tr ______tr ______<br />tr _____________________________________________he _________mt ho ______<br />tr tr ____________tr ___________________________________________________</pre> <p>Oh, if you just want to see the final result, foldl will work here. Their types are identical, except that foldl returns a single <b>a</b> (in this case, a <b>World</b>) instead of a list of elements of type <b>World</b>. So a function to make use of that just returns a single <b>World</b>, but everything else is the same. Like so:</p> <pre>move_sequence' :: [(Dir,Int)] -> World<br />move_sequence' repeats = foldl next_world init_world steps<br />    where steps = moves_to_dirs repeats</pre> <p>And then I can display both:</p> <pre>main :: IO ()<br />main = do<br />    mapM_ putStrLn pretty_worlds <br />    putStrLn pretty_final_world<br />    where worlds = move_sequence moves_board_1<br />          final_world = move_sequence' moves_board_1<br />          pretty_worlds = map pretty_world worlds</pre> <p>I like it -- examples of fold and scan that are a little more complex than the usual textbook examples. Personally I'd rather read more of those and less about how we can implement some simple math operation that can be trivially implemented in a dozen other, more readable ways.</p> <p>Oh, and it's not thoroughly tested or finished by any means, but if you'd like to play with this code, it's on github now: <a href=\"https://github.com/paulrpotts/arctic-slide-haskell\">https://github.com/paulrpotts/arctic-slide-haskell</a>. Comments are welcome as always.</p>" nil nil "e644f992ffc62cdd15429eb6c34796e3") (190 (20949 25792 616596) "http://lpuppet.banquise.net/blog/2013/06/28/full-rewrite-in-progress/" "language-puppet: Full rewrite in progress" nil "Fri, 28 Jun 2013 20:24:00 +0000" "<p>In the process of writing the language-puppet library, I learned quite a lot about Haskell and its libraries. The first part of language-puppet that was written was the parser. At that time I did not understand monads, brute-forced the do-notation until it seemed to do what I wanted, and generally made all kind of blunders. The other problem was that I was learning Puppet too, at a time when it was changing a lot and nothing was really documented. This led to unfortunate decisions that I already <a href=\"http://lpuppet.banquise.net/blog/2012/10/08/types-used-in-the-interpretation-stage/\">documented</a>.</p>
<p>I dediced to rewrite everything from scratch, by directly implementing all I could find in the
<a href=\"http://docs.puppetlabs.com/puppet/3/reference/\">reference</a>. I started a new parser during the weekend, encoding as many verifications as possible in
it, and then tried it on real manifests. Boy, was I naïve ! It did not work at all. The specification is good for learning the language or dissipating
some common misconceptions, but is of moderate use for my purpose. I relaxed most of the checks and it seems to work now.</p>
<p><img src=\"http://lpuppet.banquise.net/images/lpuppet-parser-color.png\" alt=\"Alt text\" /></p>
<p>On the technical side, I am now using the <a href=\"http://hackage.haskell.org/package/parsers\">parsers</a> package, which has a very nice interface. I considered
using <a href=\"http://hackage.haskell.org/package/trifecta\">trifecta</a> as the underlying parser. Its error messages are gorgeous, but it turns out it is not trivial to get my own <em>lexeme</em>
system in place with it. I went with <a href=\"http://hackage.haskell.org/package/parsec\">parsec</a>, and, instead of using the
<a href=\"http://hackage.haskell.org/package/parsec-parsers\">parsec-parsers</a> package, wrote my own instances (to be honest I copy-pasted those of the package
and added a non-default definition for <em>token</em>). Edward Kmett was nice enough to give me pointers on how to do this with trifecta, but this did look quite
clumsy. He hinted that he might work on a monad-transformer approach to this problem, so I am just waiting for this to happen. The nice thing about
the parsers approach is that switching now is trivial.</p>
<p>As can be seen on the previous screenshot, I am using a <a href=\"http://hackage.haskell.org/package/ansi-wl-pprint\">nice pretty printing library</a> that let me
(ab)use color.</p>
<p>Another huge difference is that I now use strict type whenever possible. The previous version seemed to be able to support an arbitrary number of worker threads with
300mb of storage for my catalogs, whereas the Puppet version could go up to 800mb for a single thread. I would like to at least halve this figure for
the next version.</p>
<p>The next step is to write the new <em>daemon</em> infrastructure. I already have a generic <a href=\"https://github.com/bartavelle/filecache\">file-cache</a> module that
let you cache things related to files. When a file is modified, the cached value is automagically invalidated (using inotify). I hope this will work
well in practice and will not be blocking all the other threads.</p>" nil nil "5f0d3e3d368b716a5a2100c34568da42") (189 (20949 25792 615804) "http://praisecurseandrecurse.blogspot.com/2013/06/the-polar-game-in-haskell-day-4.html" "Paul Potts: The Polar Game in Haskell, Day 4" "noreply@blogger.com (Paul Potts)" "Fri, 28 Jun 2013 20:07:00 +0000" "<p>OK, things are getting meaty: I've made some minor modifications to <b>World</b>:</p> <pre>data World = World { wBoard :: Board, wPenguinPos :: Pos,<br />                     wPenguinDir :: Dir, wHeartCount :: Int }<br />                     deriving (Show)</pre> <p>This extracts the sequence of tiles in front of the penguin, for various directions, from a nested list representation of the board:</p> <pre>view :: Board -> Pos -> Dir -> [Tile]<br />view board pos East = ( drop ( posX pos + 1 ) $<br />    board !! ( posY pos ) ) ++ [Edge]<br />view board pos South = ( drop ( posY pos + 1 ) $<br />    ( transpose board ) !! ( posX pos ) ) ++ [Edge]<br />view board pos West = ( reverse $ take ( posX pos ) $<br />    board !! ( posY pos ) ) ++ [Edge]<br />view board pos North = ( reverse $ take ( posY pos ) $<br />    ( transpose board ) !! ( posX pos ) ) ++ [Edge]</pre> <p>I have fleshed out slide and collide after some testing; I haven't tested all my known cases yet. Maybe tomorrow. Here is how I create the initial world:</p> <pre>init_world :: World<br />init_world = ( World init_board ( Pos 0 0 ) South 3 )</pre> <p>South because in the south-facing representation, the penguin's face is visible (although of course I don't have a GUI yet).</p> <p>A little utility function for clarity:</p> <pre>nest :: [a] -> [[a]]<br />nest xs = [xs]</pre> <p>And now, deep breath, the logic to build the next board out of the current board combined with a replaced list of tiles that may have been changed due to object interaction. It gets pretty ugly here when we're undoing the appending of Edge with init, and undoing the reversing that view has done when looking North and West, and working with the transposed board for North and South. There are some extra line breaks in there that are not in the working code. I have an issue with my <b>let</b> clauses not compiling correctly if I break the lines. I'm sure there's a prettier workaround, and I will look that up, but after going down a rabbit hole of Haskell syntax, I have timed out for today and right now I'm just happy it runs:</p> <pre>next_board :: Board -> Pos -> Dir -> ( Bool, Board )<br />next_board board pos East =<br />    let ( penguin_could_move, updated_view ) =<br />        step $ view board pos East<br />    in (<br />        penguin_could_move,<br />        take ( posY pos ) board ++<br />        nest (<br />            ( take ( posX pos + 1 )<br />                ( board !! ( posY pos ) ) ) ++<br />            ( init updated_view ) ) ++<br />        drop ( posY pos + 1 ) board )<br />next_board board pos South =<br />    let ( penguin_could_move, updated_view ) =<br />        step $ view board pos South<br />    in (<br />        penguin_could_move,<br />        transpose (<br />            take ( posX pos ) ( transpose board ) ++<br />            nest (<br />                ( take ( posY pos + 1 )<br />                    ( ( transpose board ) !! ( posX pos ) ) ) ++<br />                ( init updated_view ) ) ++<br />        drop ( posX pos + 1 ) ( transpose board ) ) )<br />next_board board pos West =<br />    let ( penguin_could_move, updated_view ) =<br />        step $ view board pos West<br />    in (<br />        penguin_could_move,<br />        take ( posY pos ) board ++<br />        nest (<br />            ( reverse ( init updated_view ) ) ++<br />            ( drop ( posX pos )<br />                ( board !! ( posY pos ) ) ) ) ++<br />        drop ( posY pos + 1 ) board )<br />next_board board pos North =<br />    let ( penguin_could_move, updated_view ) =<br />        step $ view board pos North<br />    in (<br />        penguin_could_move,<br />            transpose (<br />            take ( posX pos ) ( transpose board ) ++<br />            nest (<br />                ( reverse ( init updated_view ) ) ++<br />                ( drop ( posY pos )<br />                    ( ( transpose board ) !! ( posX pos ) ) ) ) ++<br />            drop ( posX pos + 1 ) ( transpose board ) ) )</pre> <p>That... seems like way too much code, and I would like to kill it in favor of using a real array type -- soon. The tutorials were pretty insistent that I try to use lists. I'm pretty sure this is not what they meant. I will say that I was really impressed, writing this, how much of it worked the first time, as soon as I got it past the compiler. But that doesn't necessarily mean this is the best possible design for this code.</p> <p>Anyway, updating penguin pos:</p> <pre>next_ppos :: Pos -> Dir -> Pos<br />next_ppos pos East = ( Pos ( posY pos ) ( posX pos + 1 ) )<br />next_ppos pos South = ( Pos ( posY pos + 1 ) ( posX pos ) )<br />next_ppos pos West = ( Pos ( posY pos ) ( posX pos - 1 ) )<br />next_ppos pos North = ( Pos ( posY pos - 1 ) ( posX pos ) )</pre> <p>And, updating the world. I had a similar problem with the line-broken <b>let</b> clause here:</p> <pre>next_world :: World -> Dir-> World<br />next_world old_world move_dir =<br />    let ( can_move, board ) = next_board ( wBoard old_world )<br />        ( wPenguinPos old_world ) ( wPenguinDir old_world )<br />    in<br />        if ( move_dir /= wPenguinDir old_world )<br />        then ( World ( wBoard old_world ) ( wPenguinPos old_world )<br />                   move_dir ( wHeartCount old_world ) )<br />        else ( World board<br />                   ( next_ppos ( wPenguinPos old_world )<br />                               ( wPenguinDir old_world ) )<br />                   ( wPenguinDir old_world )<br />                   ( wHeartCount old_world ) )</pre> <p>Now, some pretty-printing, since it gets pretty tedious to visualize the board from reading the dumped-out list in GHCI:</p> <pre>pretty_tiles :: [Tile] -> String<br />pretty_tiles [] = \"\\n\"<br />pretty_tiles (t:ts) = case t of<br />                 Empty     -> \"___ \"<br />                 Mountain  -> \"mtn \"<br />                 House     -> \"hou \"<br />                 Ice_Block -> \"ice \"<br />                 Heart     -> \"hea \"<br />                 Bomb      -> \"bom \"<br />                 Tree      -> \"tre \"<br />                 Edge      -> \"### \"<br />             ++ pretty_tiles ts<br /><br />pretty_board :: Board -> String<br />pretty_board [] = \"\"<br />pretty_board (ts:tss) = pretty_tiles ts ++ pretty_board tss<br /><br />pretty_world :: World -> String<br />pretty_world world =<br />    \"penguin @: \" ++ show ( wPenguinPos world ) ++<br />    \", facing: \"  ++ show ( wPenguinDir world ) ++<br />    \", hearts: \"  ++ show ( wHeartCount world ) ++<br />    \"\\n\" ++ pretty_board ( wBoard world )</pre> <p>And here's where the rubber meets the road -- or, rather, fails to. I need state, at least simulated state. I messed with state monads for a while but I'm not quite ready. I will tackle that another day. I messed with trying to capture a list in a closure and append a series of successive worlds to it but while that would work fine in Scheme, Lisp, or Dylan I realized that in Haskell I was just fighting the entire language design. So I gave in and did this stupid thing for now, just so I could see my world updating and start to validate that all the tile interactions on the board work:</p> <pre>main :: IO ()<br />main = do<br />    putStrLn \"ArcticSlide start\"<br />    let world0 = init_world<br />    putStrLn $ pretty_world world0<br /><br />    -- 21 East<br />    let world5  = next_world ( next_world ( next_world ( next_world (<br />        next_world world0  East ) East ) East ) East ) East<br />    let world10 = next_world ( next_world ( next_world ( next_world (<br />        next_world world5  East ) East ) East ) East ) East<br />    let world15 = next_world ( next_world ( next_world ( next_world (<br />        next_world world10 East ) East ) East ) East ) East<br />    let world20 = next_world ( next_world ( next_world ( next_world (<br />        next_world world15 East ) East ) East ) East ) East<br />    let world21 = next_world world20 East<br />    putStrLn $ pretty_world world21<br />    -- 2 South<br />    let world23 = next_world ( next_world world21 South ) South<br />    putStrLn $ pretty_world world23<br />    -- 3 East<br />    let world26 = next_world ( next_world (<br />        next_world world23 East ) East ) East<br />    putStrLn $ pretty_world world26<br />    -- 2 North<br />    let world28 = next_world ( next_world world26 North ) North<br />    putStrLn $ pretty_world world28<br />    -- 2 West<br />    let world30 = next_world ( next_world world28 West ) West<br />    putStrLn $ pretty_world world30</pre> <p>That is far from what I'd like to be doing eventually with managing game moves, and I still haven't put in any handling for the heart count, but it works:</p> <pre>ArcticSlide start<br />penguin @: Pos {posY = 0, posX = 0}, facing: South, hearts: 3<br />tr __________________________________________tr _______________ic ______<br />tr ___bo ___mt ___he ic he ___________________________tr ______tr ______<br />tr _____________________________________________he _________mt ho ______<br />tr tr ____________tr ___________________________________________________<br /><br />...<br /><br />penguin @: Pos {posY = 0, posX = 22}, facing: North, hearts: 3<br />tr __________________________________________tr _______________ic ______<br />tr ___bo ___mt ___he ic he ___________________________tr ______tr ______<br />tr _____________________________________________he _________mt ho ______<br />tr tr ____________tr ___________________________________________________<br /><br />penguin @: Pos {posY = 0, posX = 21}, facing: West, hearts: 3<br />tr __________________________________________tr ic _____________________<br />tr ___bo ___mt ___he ic he ___________________________tr ______tr ______<br />tr _____________________________________________he _________mt ho ______<br />tr tr ____________tr ___________________________________________________<br /></pre> <p>Aaaand... the penguin has pushed the ice block in the upper right to the west, and it has slid west and become blocked by the tree. That's... good, right? My brain is a little fried. All that to update a game board. I need a break, and maybe a stiff drink. I'm going to have to fortify myself before I successfully tackle the state monad. But I am determined!</p>" nil nil "73a798ed492ba1b9458e4eef40bcfa9e") (188 (20949 25792 614068) "http://wadler.blogspot.com/2013/06/parallel-prefix-scan-and-mapreduce.html" "Philip Wadler: Parallel prefix scan and MapReduce" "noreply@blogger.com (Philip Wadler)" "Fri, 28 Jun 2013 12:25:45 +0000" "<div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://2.bp.blogspot.com/-xZnXzPFujn8/Uc1_cVu63CI/AAAAAAAACdA/zp4IE1PRG54/s445/MapReduce.png\"><img src=\"http://2.bp.blogspot.com/-xZnXzPFujn8/Uc1_cVu63CI/AAAAAAAACdA/zp4IE1PRG54/s400/MapReduce.png\" height=\"341\" border=\"0\" width=\"400\" /></a></div>The <a href=\"http://dl.acm.org/citation.cfm?id=1327492\">MapReduce</a> paper begins its discussion of related work as follows:<br /><blockquote class=\"tr_bq\">Many systems have provided restricted programming<br />models and used the restrictions to parallelize the computation<br />automatically. For example, an associative function<br />can be computed over all prefixes of an <i>N</i> element<br />array in log <i>N</i> time on <i>N</i> processors using parallel prefix<br />computations.</blockquote>Has anyone implemented parallel prefix scan as an extension to MapReduce or a similar framework such as Hadoop, and did it prove useful?" nil nil "d5f695d9be3979005be79c7d456a701f") (187 (20949 25792 613643) "http://praisecurseandrecurse.blogspot.com/2013/06/the-polar-game-in-haskell-day-3.html" "Paul Potts: The Polar Game in Haskell, Day 3" "noreply@blogger.com (Paul Potts)" "Fri, 28 Jun 2013 01:12:00 +0000" "<p>More phone interviews, more coding. On my laptop, amidst a gaggle of fighting children, during a thunderstorm, with our basement flooding, with the kind assistance of some friendly commentors, a little more progress. Let's change <b>Pos</b></p> <pre>data Pos = Pos { posY :: Int, posX :: Int }<br />    deriving (Show, Eq)</pre> <p>And define a game world:</p> <pre>data World = World { board :: Board, penguinPos :: Pos,<br />                          penguinDir :: Dir,<br />                          heartCount :: Int } deriving (Show)</pre> <p>It was painful, took an embarrassingly long time, and this can't possibly be how I want to keep it indefinitely, but I finished <b>slice</b> which treats a list of lists of tiles like a 2-dimensional array and gives us what the penguin sees before him, looking in a given direction:</p> <pre>slice :: Board -> Pos -> Dir -> [Tile]<br />slice board pos East = ( drop ( posX pos ) $ <br />    board !! ( posY pos ) ) ++ [Edge]<br />slice board pos South = ( drop ( posY pos ) $ <br />    ( transpose board ) !! ( posX pos ) ) ++ [Edge]<br />slice board pos West = ( reverse $ take ( posX pos + 1 ) $ <br />    board !! ( posY pos ) ) ++ [Edge]<br />slice board pos North = ( reverse $ take ( posY pos + 1 ) $ <br />    ( transpose board ) !! ( posX pos ) ) ++ [Edge]</pre> <p>Let's just leave that as it is for now and use it, with the intent of replacing it with a real array of some sort later on. I still have to figure out how to merge a modified penguin track with an unmodified board to create the next state of the entire board... that's not going to be pretty, but it's doable.</p> <p>So, one of the things I really love about Haskell is that once you get these pieces, they really do start come together nicely. Let's go ahead and define the first board. I could make it from the strings or a run-length encoding or something, but for now let's just bite the bullet and build the list the hard way:</p> <pre>get_initial_board :: [[Tile]]<br />get_initial_board = [[Tree,Empty,Empty,Empty,Empty,Empty,<br />                      Empty,Empty,Empty,Empty,Empty,Empty,<br />                      Empty,Empty,Empty,Tree,Empty,Empty,<br />                      Empty,Empty,Empty,Ice_Block,Empty,Empty],<br />                     [Tree,Empty,Bomb,Empty,Mountain,Empty,<br />                      Heart,Ice_Block,Heart,Empty,Empty,Empty,<br />                      Empty,Empty,Empty,Empty,Empty,Empty,<br />                      Tree,Empty,Empty,Tree,Empty,Empty],<br />                     [Tree,Empty,Empty,Empty,Empty,Empty,<br />                      Empty,Empty,Empty,Empty,Empty,Empty,<br />                      Empty,Empty,Empty,Empty,Heart,Empty,<br />                      Empty,Empty,Mountain,House,Empty,Empty],<br />                     [Tree,Tree,Empty,Empty,Empty,Empty,<br />                      Tree,Empty,Empty,Empty,Empty,Empty,<br />                      Empty,Empty,Empty,Empty,Empty,Empty,<br />                      Empty,Empty,Empty,Empty,Empty,Empty]]<br /><br />penguin_view :: Board -> Pos -> Dir -> [Tile]<br />penguin_view board pos dir = drop 1 $ slice board pos dir</pre> <p>So now we can actually start doing stuff with this. Here's what's in front of the penguin when he looks at the board from different points, in different directions:</p> <a href=\"http://4.bp.blogspot.com/-7lLSOnNaHd8/Ua4uWuQMFmI/AAAAAAAADBs/8ByFzRW9Ccs/s1600/level_1_blown_up.tiff\"><img src=\"http://4.bp.blogspot.com/-7lLSOnNaHd8/Ua4uWuQMFmI/AAAAAAAADBs/8ByFzRW9Ccs/s640/level_1_blown_up.tiff\" height=\"120\" border=\"0\" width=\"512\" /></a> <pre>*Main> penguin_view get_initial_board (Pos 0 0) East<br />[Empty,Empty,Empty,Empty,Empty,Empty,Empty,Empty,Empty,<br />Empty,Empty,Empty,Empty,Empty,Tree,Empty,Empty,Empty,Empty,<br />Empty,Ice_Block,Empty,Empty,Edge]<br /><br />*Main> penguin_view get_initial_board (Pos 0 0) South<br />[Tree,Tree,Tree,Edge]<br /><br />*Main> penguin_view get_initial_board (Pos 0 0) West<br />[Edge]<br /><br />*Main> penguin_view get_initial_board (Pos 0 0) North<br />[Edge]<br /><br />*Main> penguin_view get_initial_board (Pos 3 21) North<br />[House,Tree,Ice_Block,Edge]</pre> <p>Fun! Tomorrow, if I can manage it... an updated world.</p>" nil nil "d534ae397d50fec22f33bf8801abbb99") (186 (20949 25792 612797) "http://feedproxy.google.com/~r/FpComplete/~3/LJ7ZmluBNOk/fp-haskell-center-beta-demo" "FP Complete: FP Haskell Center Beta Demo" nil "Thu, 27 Jun 2013 19:51:00 +0000" "<p>Thanks to the roughly 1000 people who have already
<a href=\"https://www.fpcomplete.com/business/haskell-center\">requested beta accounts</a> to try FP Haskell Center.
We are about to start admitting beta users in small groups,
and in the meantime I thought you all might enjoy a detailed demo. Enjoy!</p><p><a href=\"http://www.youtube.com/watch?v=cyyDmQKcHMs\">FP Haskell Center Beta Demo</a> on YouTube.</p><div class=\"feedflare\">
<a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=LJ7ZmluBNOk:MzhjMDnd8lU:yIl2AUoC8zA\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=yIl2AUoC8zA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=LJ7ZmluBNOk:MzhjMDnd8lU:V_sGLiPBpWU\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=LJ7ZmluBNOk:MzhjMDnd8lU:V_sGLiPBpWU\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=LJ7ZmluBNOk:MzhjMDnd8lU:qj6IDK7rITs\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=qj6IDK7rITs\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=LJ7ZmluBNOk:MzhjMDnd8lU:gIN9vFwOqvQ\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=LJ7ZmluBNOk:MzhjMDnd8lU:gIN9vFwOqvQ\" border=\"0\" /></a>
</div><img src=\"http://feeds.feedburner.com/~r/FpComplete/~4/LJ7ZmluBNOk\" height=\"1\" width=\"1\" />" nil nil "561d6a0962b18a3fbdc4b80a616e2bbf") (185 (20949 25792 612418) "http://theorylunch.wordpress.com/2013/06/27/having-lunch-in-a-garden-of-eden/" "Theory Lunch (Institute of Cybernetics, Tallinn): Having lunch in a Garden of Eden" nil "Thu, 27 Jun 2013 13:30:53 +0000" "<p>Today I talked about the Garden-of-Eden theorem, the first rigorous result in cellular automata theory.</p>
<p>I wrote a post about it in my new blog, dedicated to cellular automata, which I launched this week. The post contains extended proofs and examples, and most important, fixes several errors I had made during the talk. I might update it later, by adding figures—which are well known to take their time.</p>
<p>Link: <a href=\"http://anotherblogonca.wordpress.com/2013/06/27/in-a-garden-of-eden/\" target=\"_blank\">http://anotherblogonca.wordpress.com/2013/06/27/in-a-garden-of-eden/</a></p>
<br />  <a href=\"http://feeds.wordpress.com/1.0/gocomments/theorylunch.wordpress.com/1017/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/theorylunch.wordpress.com/1017/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=theorylunch.wordpress.com&blog=43735749&post=1017&subd=theorylunch&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "6f5680cd76bebaa814eb07f5b0e21d98") (184 (20949 25792 611900) "http://praisecurseandrecurse.blogspot.com/2013/06/the-polar-game-in-haskell-day-2.html" "Paul Potts: The Polar Game in Haskell, Day 2" "noreply@blogger.com (Paul Potts)" "Wed, 26 Jun 2013 20:59:00 +0000" "<p>Another short day since I had several phone interviews. Thanks to the folks who left comments!</p> <p>I got a little further today; I feel like I'm starting to understand Haskell's data handling a little bit better. It's a cliché but I think the hard part is un-learning, and understanding what something like this <i>doesn't</i> do. So here's where it stands now -- not finished by any means, but coming along, with painful slowness as I continue to learn:</p> <pre>data Dir = North | East | South | West<br />    deriving (Show, Eq)<br /><br />data Pos y x = Pos Int Int<br />    deriving (Show, Eq)<br /><br />-- N.B.: capitalization of initial letters in posY, posX is<br />-- semantically important!<br />posY ( Pos y x ) = y<br />posX ( Pos y x ) = x<br /><br />data Tile = Empty | Tree | Mountain | House | Ice_Block |<br />    Bomb | Heart | Edge deriving (Show, Eq)<br /><br />-- Different types of tiles have different properties in<br />-- different interaction contexts: <br /><br />-- The penguin can walk through empty tiles or trees (forest)<br />walkable :: Tile -> Bool<br />walkable t = ( t == Empty ) || ( t == Tree )<br /><br />-- But everything except empty tiles will block sliding objects<br />blocking :: Tile -> Bool<br />blocking t = ( t /= Empty )<br /><br />-- A subset of tiles are movable (and will slide until blocked)<br />movable :: Tile -> Bool<br />movable t = ( t == Bomb ) || ( t == Heart ) || ( t == Ice_Block )<br /><br />-- A subset of tiles aren't movable; note that this set<br />-- overlaps blocking and that Tree is both walkable and fixed<br />fixed :: Tile -> Bool<br />fixed t = ( t == House ) || ( t == Mountain ) || ( t == Edge )</pre> <p>That all should be fairly non-controversial, I think. The predicate approach to classifying tiles in different contexts may actually make more sense in Haskell, given that I can then use these predicates as guards. The replacement for a simple struct, <b>Pos</b>, still feels awkward -- I haven't really dug into whether it could be improved with record syntax, or some other technique. For now it's there because it works.</p> <p>All the beginner tutorials say \"don't use arrays, don't use arrays, don't use arrays!\" At least not until I reach the stage where I need to optimize the implementation. So I'll try that. Let's try a list, and I'll extract \"slices\" from it, lists starting at a given <b>Pos</b> going in one of four different directions. Eventually I want the slice function to terminate the slices with <b>Edge</b> tiles that aren't actually stored in the list. So... I have to think about this some more, but here's a single case, sort of taken care of:</p> <pre>type Board = [[Tile]]<br /><br />slice :: Board -> Pos y x -> Dir -> [Tile]<br />slice board pos East = drop ( posX pos )<br />    $ head $ drop ( posY pos ) board<br />slice _ _ _ = error \"slice: not handled yet!\"</pre> <p>I don't have <b>slide</b> finished, but here's a version of collide that works, at least a little:</p> <pre>collide :: [Tile] -> [Tile]<br />collide (t:(Empty:ts)) | movable t =<br />    [Empty] ++ collide (t:ts)<br />collide (Bomb:(Mountain:ts)) = [Empty, Empty] ++ ts<br />collide (Heart:House:ts) = [Empty, House] ++ ts<br />collide (_) = error \"collide: unexpected case!\"</pre> <p>The nested pattern <b>(Bomb:(Mountain:ts))</b> was sort of a flash of inspiration -- but it appears that maybe both this version and the <b>(Heart:House:ts)</b> version work the same -- I think -- so perhaps it's kind of pointless. It seemed to go along with the \"destructure it the way you would structure it\" idea, although I would normally not build a list out of cons cells unless it was irregular in some way.</p> <p>Here's the penguin step function, returning True if the penguin can move onto the tile at the head of the list:</p> <pre>step :: [Tile] -> ( Bool, [Tile] )<br />step [] = error \"step: empty list!\"<br />step ts = if walkable (head ts) then ( True, ts )<br />                                else ( False, collide ts )</pre> <p>And there's a move, which \"absorbs\" the case where the penguin is turned to face a different direction. It's not really done; the idea is that it will give back the board, basically generating a new world. For now we kind of punt on the question of how to rebuild the board out of the existing board and the modified \"slice\" -- and so the I just return a list as the first element of the tuple. In the first case where the penguin hasn't moved, that doesn't actually make sense, but it satisfies GHC for now (wow, she's kind of a harsh mistress, but you've got to love those thigh-high black leather boots!)</p> <pre>move :: Board -> Pos y x -> Dir -> Dir -><br />    ( [Tile], Pos y x, Dir, Dir )<br />move board pos move_dir penguin_dir =<br />    if move_dir /= penguin_dir<br />    then ( head board, pos, move_dir, move_dir )<br />    else ( collide $ slice board (Pos 1 0) penguin_dir,<br />        pos, penguin_dir, penguin_dir )<br /></pre> <p>Boy, that's tuple-icious... not sure I like it, but it's a start. So:</p> <pre>*Main> walkable Tree<br />True<br />*Main> :t Pos<br />Pos :: Int -> Int -> Pos y x<br />*Main> let slice = [Heart, House]<br />*Main> collide slice<br />[Empty,House]<br />*Main> let slice = [Bomb, Empty, Mountain]<br />*Main> collide slice<br />[Empty,House]<br />*Main> let board = [[Empty, Tree, Empty, Edge],<br />    [Bomb, Empty, Mountain, Edge]]<br />*Main> move board (Pos 1 0) West East<br />([Empty,Tree,Empty,Edge],Pos 1 0,West,West)<br />*Main> move board (Pos 1 0) East East<br />([Empty,Empty,Empty,Edge],Pos 1 0,East,East)</pre> <p>More tomorrow if I can manage it! Oh, and it's here, such as it is: <a href=\"https://github.com/paulrpotts/arctic-slide-haskell\">https://github.com/paulrpotts/arctic-slide-haskell</a></p>" nil nil "fb64711f3be5863556b3e0ccf567a2c9") (183 (20949 25792 610843) "http://blog.plover.com/prog/git-vacillation.html" "Mark Jason Dominus: Rewriting published history in Git" "mjd@plover.com (Mark Dominus)" "Wed, 26 Jun 2013 18:19:00 +0000" "<a href=\"http://blog.plover.com/prog/git-habits.html\">My earlier article about my
habits using Git</a> attracted some comment, most of which was
favorable. But one recurring comment was puzzlement about my seeming
willingness to rewrite published history.  In practice, this was not
at all a problem, I think for three reasons:<p>
</p><ol>
<li>Rewriting published history is not nearly as confusing as
people seem to think it will be.
</li><li>I worked in a very small shop with very talented developers, so
the necessary communication was easy.
</li><li>Our repository setup and workflow were very well-designed and
unusually effective, and made a lot of things easier, including this one.
</li></ol>
This article is about item 3.  Here's what they do at my previous
workplace to avoid most of the annoyances of people rewriting
published history.<p>
If there are <i>N</i> developers, there are <i>N</i>+1 repositories.</p><p>
There is a master repository to which only a few very responsible
persons can push. It is understood that history in this repository
should almost never be rewritten, only in the most exceptional
circumstances.  We usually call this master repository
<tt>gitbox</tt>.  It has only a couple of branches, typically
<tt>master</tt> and <tt>deployed</tt>.
You had better not push incomplete work to <tt>master</tt>, because
if you do someone is likely to deploy it.
When you deploy a new version
from <tt>master</tt>, you advance <tt>deployed</tt> up to
<tt>master</tt> to match.</p><p>
In addition, each developer has their own semi-public repository,
named after them, which everyone can read, but which nobody but them
can write.  Mine is <tt>mjd</tt>, and that's what we call it when
discussing it, but my personal git configuration calls it
<tt>origin</tt>. When I <tt>git push origin master</tt> I am pushing
to this semi-public repo.</p><p>
It is understood that this semi-public repository is my sandbox and I
am free to rewrite whatever history I want in it.  People building
atop my branches in this repo, therefore, know that they should be
prepared for me to rewrite the history they see there, or to contact
me if they want me to desist for some reason.</p><p></p><p>
When I get the changes in my own semi-public repository the way I want
them, <i>then</i> I push the changes up to gitbox.  Nothing is
considered truly \"published\" until it is on the master repo.</p><p>
When a junior programmer is ready to deploy to the master repository,
they can't do it themselves, because they only have read access on the
master.  Instead, they publish to their own semi-private repository,
and then notify a senior programmer to review the changes.  The senior
programmer will then push those changes to the master repository and
deploy them.</p><p>
</p><p align=\"center\"><img src=\"http://pic.blog.plover.com/prog/git-vacillation/git%20repos.png\" /></p>
The semi-public <tt>mjd</tt> repo has lots of benefits.  I can rewrite
my branches 53 times a day (and I do!) but nobody will
care. Conversely, I don't need to know or care how much my co-workers
vacillate.<p>
If I do work from three or four different machines, I can use the
<tt>mjd</tt> repo to exchange commits between them.  At the end of the
day I will push my work-in-progress up to the <tt>mjd</tt> repo, and
then if I want to look at it later that evening, I can fetch the
work-in-progress to my laptop or another home computer.</p><p></p><p>
I can create and abandon many topic branches without cluttering up the
master repository's history.  If I want to send a change or a new test
file to a co-worker, I can push it to <tt>mjd</tt> and then point them
at the branch there.</p><p>
A related note: There is a lot of FUD around the rewriting of
published history.  For example, the \"gitinfo\" robot on the #git IRC
channel has a canned message:</p><p>
</p><blockquote>
Rewriting public history is a very bad idea.  Anyone else who
may have pulled the old history will have to <tt>git pull
--rebase</tt> and even worse things if they have tagged or
branched, so you must publish your humiliation so they know
what to do.  You will need to <tt>git push -f</tt> to force the push.
The server may not allow this.  <tt>See receive.denyNonFastForwards</tt>
(git-config)<p>
</p></blockquote>
I think this grossly exaggerates the problems.  Very bad!
Humiliation!  The server may deny you!  But dealing with a rebased
upstream branch is not very hard. It is at worst annoying: you have to
rebase your subsequent work onto the rewritten branch and move any
refs that pointed to that branch.  If you don't have any subsequent
work, you might still have to move refs, if you have any that point to
it, but you might not have any.<p>
[ Thanks to Rik Signes for helping me put this together. ]</p><p></p>" nil nil "1cf5f93b5240d1f03072f2aca64f4664") (182 (20949 25792 609704) "http://blog.plover.com/prog/git-habits.html" "Mark Jason Dominus: My Git Habits" "mjd@plover.com (Mark Dominus)" "Wed, 26 Jun 2013 18:19:00 +0000" "Miles Gould asked his Twitter followers whether they used <tt>git-add
-p</tt> or <tt>git-commit -a</tt> and how often.  My reply was too
long for Twitter, so here it is.<p>
First the short version: I use <tt>git-add -p</tt> frequently, and
<tt>git-commit -a</tt> almost never. The exception is when I'm working
on the repo that holds my blog, where I rarely commit changes to more
than one or two files at a time.  Then I'll usually just
<tt>git-commit -a -m ...</tt>.</p><p>
But I use <tt>git-add -p</tt> all the time. Typically what will happen
is that I will be developing some fairly complicated feature.  It will
necessitate a bunch of changes and reshuffling elsewhere in the
system.  I'll make commits on the topic branch as I go along without
worrying too much about whether the commits are neatly packaged.</p><p>
Often I'll be in the middle of something, with a dirty work tree, when
it's time to leave for the day.  Then I'll just commit everything with
the subject <tt>WIP</tt> (\"work-in-progress\").  First thing the next
morning I'll <tt>git-reset HEAD^</tt> and continue where I left
off.</p><p>
So the model is that the current head is usually a terrible mess,
accumulating changes as it moves forward in time.  When I'm done, I
will merge the topic into master and run the tests. </p><p>
If they pass, I am not finished.  The merge I just created is only a
draft merge.  The topic branch is often full of all sorts of garbage,
commits where I tried one approach, found it didn't work later on, and
then tried a different approach, places where I committed debugging
code, and so on. So it is now time to clean up the topic branch.  Only
the cleaned-up topic branch gets published.</p><p>
</p><h3>Cleaning up messy topic branches</h3>
The core of the cleanup procedure is to reset the head back to the
last place that look good, possibly all the way back to the merge-base
if that is not too long ago.  This brings all the topic changes into
the working directory. Then:<p>
</p><ol>
<li>Compose the commits: Repeat until the working tree is clean:<br />
<ol>
<li>Eyeball the output of <tt>git-diff</tt>
</li><li>Think of an idea for an intelligible commit
</li><li>Use <tt>git-add -p</tt> to stage the planned commit
</li><li>Use <tt>git diff --cached</tt> to make sure it makes sense
</li><li>Commit it
</li></ol>
</li><li>Order the commits: Use <tt>git-rebase --interactive</tt>
</li></ol>
Notice that this separates the work of composing the commits from the
work of ordering them.  This is more important than it might appear.
It would be extremely difficult to try to do these at the same time.
I can't know the sensible order for the commits until I know what the
commits are!  But it's very hard to know what the commits are without
actually making them.<p>
By separating these tasks, I can proceed something like this: I
eyeball the diff, and the first thing I see is something about the
penguin feature.  I can immediately say \"Great, I'll make up a commit
of all the stuff related to the penguin feature\", and proceed to the
<tt>git-add -p</tt> step without worrying that there might be other
stuff that should precede the penguin feature in the commit sequence.
I can focus on just getting the penguin commit right without needing
to think about any of the other changes.</p><p>
When the time comes to put the commits in order, I can do it well
because by then I have abstracted away all the details, and reduced
each group of changes to a single atomic unit with a one-line
description.</p><p>
For the most complicated cases, I will print out the diffs, read them
over, and mark them up in six colors of highlighter: code to throw
away gets marked in orange; code that I suspect is erroneous is pink.
I make many notes in pen to remind me how I want to divide up the
changes into commits.  When a commit occurs to me I'll jot a numbered
commit message, and then mark all the related parts of the diff with
that number.  Once I have the commits planned, I'll reset the topic
ref and then run through the procedure above, using <tt>git-add
-p</tt> repeatedly to construct the commits I planned on paper. Since
I know ahead of time what they are I might do them in the right order,
but more likely I'll just do them in the order I thought of them and
then reorder them at the end, as usual.</p><p>
For simple cases I'll just do a series of <tt>git-rebase
--interactive</tt> passes, pausing at any leftover <tt>WIP</tt>
commits to run the loop above, reordering the commits to squash
related commits together, and so on.</p><p>
The very simplest cases of all require no cleanup, of course.</p><p>
For example, here's my current topic branch, called <tt>c-domain</tt>,
with the oldest commits at the top:</p><p>
</p><pre>        055a2f7 correction to bulk consumer template
d9630bd DomainActivator half of Pobox Domain consumer
ebebb4a Add HasDomain role to provide ->domain reader for domain consumers
ade6ac6 stubbed domain test
e170e77 start templates for Pobox domain consumers
067ca81 stubbed Domain::ThumbTwiddler
685a3ee cost calculations for DomainActivator
ec8b1cc test fixes; trivial domain test passes now
845b1f2 rename InvoiceCharge::CreateDomain to ..::RegisterDomain
(e)     6083a97 add durations to Domain consumers and charges
c64fda0 tests for Domain::Activator consumer
41e4292 repeat activator tests for 1-year and 3-year durations
7d68065 tests for activator's replacement
(d)     87f3b09 move days_in_year to Moonpig::Util
3cd9f3b WIP
e5063d4 add test for sent invoice in domain.t
c8dbf41 WIP
9e6ffa4 add missing MakesReplacement stuff
fc13059 bring in Net::OpenSRS module
(c)     52c18fb OpenSRS interface
893f16f notes about why domain queries might fail
(b)     f64361f rename \"croak\" method to \"fail\" to avoid conflicts
4e500ec Domain::Activator initial_invoice_charge_pairs
(a)     3c5cdd4 WIP
</pre>
3c5cdd4 (a) was the end-of-day state for yesterday; I made it and
pushed it just before I dashed out the door to go home.  Such commits
rarely survive beyond the following morning, but if I didn't make them,
I wouldn't be able to continue work from home if the mood took me to
do that.<p>
f64361f (b) is a prime candidate for later squashing.  5c218fb (c)
introduced a module with a \"croak\" method.  This turned out to be a
stupid idea, because this conflicted with the <tt>croak</tt> function
from Perl's <tt>Carp</tt> module, which we use everywhere.  I needed
to rename it.  By then, the intervening commit already existed.  I
probably should have squashed these right away, but I didn't think of
it at the time.  No problem!  Git means never having to say \"If only
I'd realized sooner.\"</p><p>
Similarly, 6083a97 (e) added a days_in_year function that I later
decided at 87f3b09 (d) should be in a utility module  in a
different repository.  87f3b09 will eventually be squashed into
6083a97 so that days_in_year never appears in this code at all.</p><p>
I don't know what is in the WIP commits c8dbf41 or 3cd9f3b, for which
I didn't invent commit messages. I don't know why those are left in
the tree, but I can figure it out later.</p><p>
</p><h3>An example cleanup</h3>
Now I'm going to clean up this branch.  First I <tt>git-checkout -b
cleanup c-domain</tt> so that if something goes awry I can start over
completely fresh by doing <tt>git-reset --hard c-domain</tt>.  That's
probably superfluous in this case because <tt>origin/c-domain</tt> is
also pointing to the same place, and <tt>origin</tt> is my private
repo, but hey, branches are cheap.<p>
The first order of business is to get rid of those <tt>WIP</tt>
commits.  I'll <tt>git-reset HEAD^</tt> to bring 3c5cdd4 into the
working directory, then use <tt>git-status</tt> to see how many
changes there are:</p><p>
</p><pre>         M lib/Pobox/Moonpig/Consumer/Domain/Activator.pm
M lib/Pobox/Moonpig/Role/HasDomain.pm
M lib/Pobox/Moonpig/TemplateSet.pm
?? bin/register_domains
M t/consumer/domain.t
?? t/lib/MockOpenSRS.pm
</pre>
(This is the output from <tt>git-status --short</tt>, for which I have
an alias, <tt>git s</tt>.  I use this probably 99 times as often as
plain <tt>git-status</tt>.)<p>
Not too bad, probably no need for a printout.  The new
<tt>bin/register-domains</tt> program can go in right away by itself:</p><p>
</p><pre>        % <b>git add bin</b>
% <b>git commit -m 'new register_domains utility program'</b>
</pre>
Next I'll deal with that new mock object class in
<tt>t/lib/MockOpenSRS.pm</tt>.  I'll add that, then use <tt>git-add
-p</tt> to add the related changes from the other files:<p>
</p><pre>        % <b>git add t/lib</b>
% <b>git add -p</b>
...
% <b>git s</b>
MM lib/Pobox/Moonpig/Consumer/Domain/Activator.pm
M lib/Pobox/Moonpig/Role/HasDomain.pm
M lib/Pobox/Moonpig/TemplateSet.pm
A  t/lib/MockOpenSRS.pm
MM t/consumer/domain.t
% <b>git ix</b>
...
</pre>
The <tt>git ix</tt> command at the end there is an alias for <tt>git diff
--cached</tt>: it displays what's staged in the index.  The output
looks good, so I'll commit it:<p>
</p><pre>        % <b>git commit -m 'mock OpenSRS object; add tests'</b>
</pre>
Now I want to see if those tests actually pass.  Maybe I forgot
something!
<pre>        % <b>git stash</b>
% <b>make test</b>
...
OK
% <b>git stash pop</b>
</pre>
The <tt>git-stash</tt> command hides the unrelated changes from the
test suite so that I can see if the tests I just put into
<tt>t/consumer/domain.t</tt> work properly.  They do, so I bring back
the stashed changes and continue.  If they didn't, I'd probably amend
the last commit with <tt>git commit --amend</tt> and try again.<p>
Continuing:</p><p>
</p><pre>        % <b>git diff</b>
...
% <b>git add -p lib/Pobox/Moonpig/Role/HasDomain.pm</b>
...
% <b>git commit -m 'Domains do not have explicit start dates'</b>
% <b>git diff</b>
...
% <b>git add -p</b>
...
% <b>git commit --fixup :/mock</b>
</pre>
That last bit should have been part of the \"mock OpenSRS object\"
commit, but I forgot it. So I make a fixup commit, which I'll merge
into the main commit later on.  A fixup commit is one whose subject
begins with <tt>fixup!</tt>. Did you know that you can name a commit
by writing <tt>:/<i>text</i></tt>, and it names the most recent commit
whose message contains that text?<p>
It goes on like that for a while:</p><p>
</p><pre>        % <b>git diff</b>
...
% <b>git add -p ...</b>
...
% <b>git commit -m 'Activator consumer can generate special charges'</b>
% <b>git diff</b>
...
% <b>git checkout lib/Pobox/Moonpig/Role/HasDomain.pm</b>
</pre>
The only uncommitted change left in <tt>HasDomain.pm</tt> was a
superfluous line, so I just threw it away.<p>
</p><pre>        % <b>git diff</b>
...
% <b>git add -u</b>
% <b>git commit -m 'separate templates for domain-registering and domain-renewing consumers'</b>
</pre>
By this time all the remaining changes belong in the same commit, so I
use <tt>git-add -u</tt> to add them all at once.  The working tree is
now clean.  The history is as I showed above, except that in place of
the final <tt>WIP</tt> commit, I have:<p>
</p><pre>        a3c0b92 new register_domains utility program
53d704d mock OpenSRS object; add tests
a24acd8 Domains do not have explicit start dates
17a915d fixup! mock OpenSRS object; add tests
86e472b Activator consumer can generate special charges
5b2ad2b separate templates for domain-registering and domain-renewing consumers
</pre>
(Again the oldest commit is first.)  Now I'll get rid of that
<tt>fixup!</tt>:<p>
</p><pre>        % <b>git rebase -i --autosquash HEAD~6</b>
</pre>
Because of <tt>--autosquash</tt>, the <tt>git-rebase</tt> menu is
reordered so that the fixup commit is put just after
the commit it fixes up, and its default action is 'fixup' instead of
'pick'.  So I don't need to edit the rebase instructions at all.  But
I might as well take the opportunity to put the commits in the right
order.  The result is:<p>
</p><pre>        a3c0b92 new register_domains utility program
ea8dacd Domains do not have explicit start dates
297366a separate templates for domain-registering and domain-renewing consumers
4ef0e28 mock OpenSRS object; add tests
c3ab1eb Activator consumer can generate special charges
</pre>
I have two tools for dealing with cleaned-up
branches like this one.  One is <a href=\"https://github.com/mjdominus/git-util/blob/master/git-vee\"><tt>git-vee</tt></a>, which compares two branches. It's
just a wrapper around the command <tt>git log --decorate --cherry-mark
--oneline --graph --boundary <i>A</i>\"...\"<i>B</i></tt>.  <p>
Here's a
comparison the original <tt>c-domain</tt> branch and my new
<tt>cleanup</tt> version:</p><p>
</p><pre>        % <b>git vee c-domain</b>
* c3ab1eb (HEAD, cleanup) Activator consumer can generate special charges
* 4ef0e28 mock OpenSRS object; add tests
* 297366a separate templates for domain-registering and domain-renewing consumer
* ea8dacd Domains do not have explicit start dates
* a3c0b92 new register_domains utility program
| * 3c5cdd4 (origin/c-domain, c-domain) WIP
|/
o 4e500ec Domain::Activator initial_invoice_charge_pairs
</pre>
This clearly shows where the original and cleaned up branches diverge,
and what the differences are.  I also use <tt>git-vee</tt> to compare
pre- and post-rebase versions of branches (with <tt>git-vee
ORIG_HEAD</tt>) and local branches with their remote tracking branches
after fetching (with <tt>git-vee remote</tt> or just plain
<tt>git-vee</tt>).<p>
A cleaned-up branch should usually have the same final tree as the
tree at the end of the original branch.  I have another tool, <a href=\"https://github.com/mjdominus/git-util/blob/master/git-treehash\"><tt>git-treehash</tt></a>,
which compares trees.  By default it compares <tt>HEAD</tt> with
<tt>ORIG_HEAD</tt>, so after I use git-rebase to squash or to split
commits, I sometimes run \"git treehash\" to make sure that the tree
hasn't changed.  In this example, I do:</p><p>
</p><pre>        % <b>git treehash c-domain HEAD</b>
d360408d1afa90e0176aaa73bf8d3cae641a0850 HEAD
f0fd6ea0de7dbe60520e2a69fbec210260370d78 c-domain
</pre>
which tells me that they are <i>not</i> the same.  Most often this
happens because I threw away all the debugging code that I put in
earlier, but this time it was because of that line of superfluous code
I eliminated from <tt>HasDomain.pm</tt>.  When the treehashes differ, I'll use
<tt>git-diff</tt> to make sure that the difference is innocuous:<p>
</p><pre>        % <b>git diff c-domain</b>
diff --git a/lib/Pobox/Moonpig/Role/HasDomain.pm b/lib/Pobox/Moonpig/Role/HasDomain.pm
index 3d8bb8c..21cb752 100644
--- a/lib/Pobox/Moonpig/Role/HasDomain.pm
+++ b/lib/Pobox/Moonpig/Role/HasDomain.pm
@@ -5,7 +5,6 @@ use Carp qw(croak confess);
use ICG::Handy qw(is_domain);
use Moonpig::Types qw(Factory Time);
use Moose::Util::TypeConstraints qw(duck_type enum subtype);
-use MooseX::SetOnce;
with (
'Moonpig::Role::StubBuild',
</pre>
Okay then.<p>
The next task is probably to deal with the older WIP commits.  This
time I'll omit all the details.  But the enclosing procedure looks
like this:</p><p>
</p><pre>        % <b>git checkout -b wip-cleanup c8dbf41</b>
% <b>git reset HEAD^</b>
% ... (a lot of git-add -p as above) ...
...
% <b>git vee c8dbf41</b>
* 4c6ff45 (wip-cleanup) get rid of unused twiddler test
* b328de5 test full payment cycle
* 201a4f2 abstract out pay_invoice operation
* 55ae45e add upper limit (default 30d) to wait_until utility
| * c8dbf41 WIP
|/
o e5063d4 add test for sent invoice in domain.t
% <b>git treehash c8dbf41 HEAD</b>
7f52ba68923e2ede8fda407ffa9c06c5c48338ae
% <b>git checkout cleanup</b>
% <b>git rebase wip-cleanup</b>
</pre>
The output of <tt>git-treehash</tt> says that the tree at the end of
the <tt>wip-cleanup</tt> branch is identical to the one in the WIP
commit it is supposed to replace, so it's perfectly safe to rebase the
rest of the <tt>cleanup</tt> branch onto it, replacing the one WIP
commit with the four new commits in <tt>wip-cleanup</tt>.  Now the
cleaned up branch looks like this:<p>
</p><pre>        % <b>git vee c-domain</b>
* a425aa1 (HEAD, cleanup) Activator consumer can generate special charges
* 2bb0932 mock OpenSRS object; add tests
* a77bfcb separate templates for domain-registering and domain-renewing consumer
* 4c44db2 Domains do not have explicit start dates
* fab500f new register_domains utility program
= 38018b6 Domain::Activator initial_invoice_charge_pairs
= aebbae6 rename \"croak\" method to \"fail\" to avoid conflicts
= 45a224d notes about why domain queries might fail
= 80e4a90 OpenSRS interface
= 27f4562 bring in Net::OpenSRS module
= f5cb624 add missing MakesReplacement stuff
* 4c6ff45 (wip-cleanup) get rid of unused twiddler test
* b328de5 test full payment cycle
* 201a4f2 abstract out pay_invoice operation
* 55ae45e add upper limit (default 30d) to wait_until utility
| * 3c5cdd4 (origin/c-domain, c-domain) WIP
| = 4e500ec Domain::Activator initial_invoice_charge_pairs
| = f64361f rename \"croak\" method to \"fail\" to avoid conflicts
| = 893f16f notes about why domain queries might fail
| = 52c18fb OpenSRS interface
| = fc13059 bring in Net::OpenSRS module
| = 9e6ffa4 add missing MakesReplacement stuff
| * c8dbf41 WIP
|/
o e5063d4 add test for sent invoice in domain.t
</pre>
<tt>git-vee</tt> marks a commit with an equal sign instead of a star
if it's equivalent to a commit in the other branch.  The commits in
the middle marked with equals signs are the ones that weren't changed.
The upper WIP was replaced with five commits, and the lower one with
four.<p>
I've been planning for a long time to write a tool to help me with
breaking up WIP commits like this, and with branch cleanup in general:
It will write each changed hunk into a file, and then let me separate
the hunk files into several subdirectories, each of which represents
one commit, and then it will create the commits automatically from the
directory contents.  This is still only partly finished, but I think
when it's done it will eliminate the six-color diff printouts.</p><p>
[ Addendum 20120404: Further observation has revealed that I almost
never use <tt>git-commit -a</tt>, even when it would be quicker to do
so.  Instead, I almost always use <tt>git-add -u</tt> and then
<tt>git-commit</tt> the resulting index. This is just an observation,
and not a claim that my practice is either better or worse than using
<tt>git-commit -a</tt>. ]</p><p>
[ Addendum 20120825: There is now <a href=\"http://blog.plover.com/prog/git-vacillation.html\">a followup article about how
to manage rewriting of published history</a>. ]</p><p></p>" nil nil "b937508520079d61312314cb40b9c241") (181 (20949 25792 606284) "http://blog.plover.com/prog/git-commit-hook.html" "Mark Jason Dominus: How I got four errors into a one-line program" "mjd@plover.com (Mark Dominus)" "Wed, 26 Jun 2013 18:19:00 +0000" "At my current job, each task is assigned a ticket number of the form
<tt>e12345</tt>. The git history is extremely convoluted, and it's
been observed that it's easier to find things if you include the
ticket number at the front of the commit message.  I got tired of
inserting it manually, and thought I would write a <tt>prepare-commit-message</tt> hook to insert
it automatically.<p>
A <tt>prepare-commit-message</tt> hook is a program that you stick in the file
<tt>.git/hooks/prepare-commit-hook</tt>. When you run <tt>git-commit</tt>, git first
writes the commit message to a file, then invokes the <tt>prepare-commit-message</tt> program on
file; the program can modify the contents of the message, or abort the
commit if it wants to. Then git runs the editor on the message, if it
was going to do that, and creates the commit with the edited
message.</p><p>
The hook I wrote was basically a one-liner, and the reason I am
posting this note is because I found three significant programming
errors in it in the first day of use. </p><p>
Here's the first cut:</p><p>
</p><pre>case $2 in
message)
perl -i -lpe \"s/^(e\\d+:\\s+)?/$(cs -): /\" $1
;;
esac
</pre>
This is a shell script, but the main purpose is to run the perl
one-liner. The shell script gets two arguments: <tt>$1</tt> is the
path to the file that contains the proposed commit message.
The <tt>$2</tt> argument is a tag which describes the commit's
context; it's <tt>merge</tt> if the commit is a merge commit, for
example; it's <tt>template</tt> if the commit message is supplied from
a template via <tt>-t</tt> on the command line or the
<tt>commit.template</tt> configuration option.  The default is the
empty string, and <tt>message</tt>, which I have here, means that the
message was supplied with the <tt>-m</tt> command-line option.<p>
The Perl script edits the commit message file, named in <tt>$1</tt>,
in-place, looking for something like <tt>e12345: </tt> at the
beginning of a line, and replacing it with the output of the
<tt>cs -</tt> command, which is a little program I wrote to print
the current ticket number.</p><p> (<tt>cs</tt> is run by the shell, and
its output is inserted into the Perl script before <tt>perl</tt> is
run, so that the program that Perl sees is something like
<tt>s/^(e\\d+:\\s+)?/e12345: /</tt>.)  Simple enough.</p><p>
There is already an error here, although it's a design error, not an
implementation error: the Perl one-liner is only invoked when
<tt>$2</tt> is <tt>message</tt>.  For some reason I decided that I
would want it only when I supplied <tt>git-commit</tt> with the
<tt>-m message</tt> option. This belief lasted exactly until the
first time I ran <tt>git-commit</tt> in default mode it popped up the editor to
edit the commit message, and I had to insert the ticket number
manually.</p><p>
So the first change was to let the hook run in the default case as well
as the <tt>message</tt> case:</p><p>
</p><pre>case $2 in
<span class=\"emph\">\"\"|</span>message)
perl -i -lpe \"s/^(e\\d+:\\s+)?/$(cs -): /\" $1
;;
esac
</pre>
This was wrong because it inserts the ticket number at the start of
each line; I wanted it only at the start of the first line. So that
was programming error number 1:<p>
</p><pre>case $2 in
\"\"|message)
perl -i -lpe \"<span class=\"emph\">$. == 1 && </span>s/^(e\\d+:\\s+)?/$(cs -): /\" $1
;;
esac
</pre>
So far, so good.<p>
Bug #2 appeared the first time I tried a rebase. The <tt>cs</tt>
command infers the ticket number from the name of the current branch.
If it fails, it issues a warning and emits the string <tt>eXXXXX</tt>
instead.  During a rebase, the head is detached and there is no
current branch.  So the four commits I rebased all had their
formerly-correct ticket numbers replaced with the string
<tt>eXXXXX</tt>.</p><p>
There are several ways to fix this. The best way would be to make sure
that the current ticket number was stashed somewhere that <tt>cs</tt>
could always get it.  Instead, I changed the Perl script to recognize
when the commit message already began with a ticket number, and to
leave it alone if so:</p><p>
</p><pre>case $2 in
\"\"|message)
perl -i -lpe \"\\$. == 1 &&<span class=\"emph\"> !/^e\\d+:\\s+/ && s/^/</span>$(cs -): /\" $1
;;
esac
</pre>
It probably would have been a good idea to leave an escape hatch, and
have <tt>cs</tt> emit the value of <tt>$ENV{TICKET_NUMBER}</tt> if
that is set, to allow invocations like <tt>TICKER_NUMBER=e71828 git
commit -m …</tt>, but I didn't do it, yet.<p>
The third bug appeared when I did <tt>git commit --fixup</tt> for the
first time.  With <tt>--fixup</tt> you tell it which commit you are
trying to fix up, and it writes the commit message in a special form
that tells a subsequent <tt>git-rebase --interactive</tt> that this
new commit should be handled specially. (It should be applied
immediately after that other one, and should be marked as a \"fixup\",
which means that it is squashed into the other one and that its log
message is discarded in favor of the other one.)  If you are fixing up
a commit whose message was <tt>Frobulate the veeblefetzers</tt>, the
fixup commit's message is automatically generated as
<tt>fixup! Frobulate the veeblefetzers</tt>. Or it would have
been, if you were not using my <tt>prepare-commit-message</tt> hook, which would rewrite it to
<tt>e12345: fixup! Frobulate the veeblefetzers</tt>. This is not
in the right form, so it's not recognized by <tt>git-rebase
--interactive</tt> for special handling.</p><p>
So the hook became:</p><p>
</p><pre>case $2 in
\"\"|message)
perl -i -lpe \"\\$. == 1 && <span class=\"emph\">!/^(squash|fixup)! / &&</span> !/^e\\d+:\\s+/ && s/^/$(cs -): /\" $1
;;
esac
</pre>
(The exception for <tt>squash</tt> is similar to the one for
<tt>fixup</tt>. I never use <tt>squash</tt>, but it seemed foolish not
to put it in while I was thinking of it.)<p>
This is starting to look a little gross, but in a program this small I
can tolerate a little grossness.</p><p>
I thought it was remarkable that such a small program broke in so many
different ways.  Much of that is because it must interact with git,
which is very large and complicated, and partly it is that it must
interact with <tt>git</tt>, which is in many places not very well
designed.
The first bug, where the ticket number was appended to each line
instead of just the first, is not git's fault.  It was fallout from my
initial bad design decision to apply the script only to messages
supplied with <tt>-m</tt>, which are typically one-liners, so that's
what I was thinking of when I wrote the Perl script.</p><p>
But the other two errors would have been avoided had the interface to
the hook been more uniform. There seems to be no reason that rebasing
(or cherry-picking) and <tt>git-commit --fixup</tt> contexts couldn't
have been communicated to the hook via the same <tt>$2</tt> argument
that communicates other contexts.  Had this been done in a more
uniform way, my program would have worked more correctly.  But it
wasn't done, and it's probably too late to change it now, since such a
change risks breaking many existing <tt>prepare-commit-message</tt> hooks. (\"The enemy of software
is software.)  A well-written hook will of course have a catchall:</p><p>
</p><pre>case $2 in
\"\"|message)
perl -i -lpe \"\\$. == 1 && !/^(squash|fixup)! / && !/^e\\d+:\\s+/ && s/^/$(cs -): /\" $1
;;
<span class=\"emph\">
merge|template|squash|commit)
# do nothing
;;
*)      # wat
echo \"prepare-message-hook: unknown context '$2'\" 1>&2
exit 1;
;;
</span>
esac
</pre>
But mine doesn't and I bet a lot of others don't either.<p></p>" nil nil "f86e28ea50fab7f0bc4ec652badda3ef") (180 (20949 25792 604862) "http://edwinb.wordpress.com/2013/06/25/sequential-decision-problems-dependently-typed-solutions/" "Edwin Brady: Sequential decision problems, dependently typed solutions" nil "Tue, 25 Jun 2013 19:44:01 +0000" "<p>We’ve just shipped the camera ready version of the following paper to <a href=\"http://www.cicm-conference.org/2013/cicm.php?event=plmms\">PLMMS 2013</a>:</p>
<p>
<a href=\"http://eb.host.cs.st-andrews.ac.uk/writings/plmms13.pdf\">Sequential decision problems, dependently typed solutions</a><br />
<a href=\"http://www.pik-potsdam.de/members/botta\">Nicola Botta</a>, <a href=\"http://www.pik-potsdam.de/members/ionescu\">Cezar Ionescu</a>, <a href=\"http://edwinb.wordpress.com/2013/06/25/sequential-decision-problems-dependently-typed-solutions/edwinb.wordpress.com\">Edwin Brady</a>
</p>
<blockquote><p>
We propose a dependently typed formalization for a simple class of sequential decision problems. For this class of problems, we implement a generic version of Bellman’s backwards induction algorithm and a machine checkable proof that the proposed implementation is correct. The formalization is generic. It is presented in Idris, but it can be easily translated to other dependently-typed programming languages. We conclude with an informal discussion of the problems we have faced in extending the formalization to generic monadic sequential decision problems.
</p></blockquote>
<p>You can find the <a href=\"http://eb.host.cs.st-andrews.ac.uk/writings/plmms13.pdf\">full paper here</a>.</p>
<br />  <a href=\"http://feeds.wordpress.com/1.0/gocomments/edwinb.wordpress.com/237/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/edwinb.wordpress.com/237/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=edwinb.wordpress.com&blog=666773&post=237&subd=edwinb&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "2a021f6c5fac19dfe6401c57ea40c752") (179 (20949 25792 604355) "http://wadler.blogspot.com/2013/06/come-for-performance-stay-for.html" "Philip Wadler: Come for the performance, stay for the correctness" "noreply@blogger.com (Philip Wadler)" "Tue, 25 Jun 2013 18:34:34 +0000" "<div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://1.bp.blogspot.com/-68rTy8Dc4fM/UcnhdnNkd9I/AAAAAAAACcc/Yj25dAU8tnc/s1600/haskell.jpeg\"><img src=\"http://1.bp.blogspot.com/-68rTy8Dc4fM/UcnhdnNkd9I/AAAAAAAACcc/Yj25dAU8tnc/s400/haskell.jpeg\" height=\"299\" border=\"0\" width=\"400\" /></a></div>An <a href=\"http://www.hpcwire.com/hpcwire/2013-06-24/lustre_founder_spots_haskell_on_hpc_horizon.html?featured=top\">article in HPC Wire</a> lists industrial uses of Haskell, several of which I hadn't heard before. The article profiles Peter Braam, founder of Parallel Scientific. Spotted by Hans Wolfgang Loidl.<br /><br /><blockquote class=\"tr_bq\">Arguably, Google and Facebook have brought more attention to Haskell  in recent years, but there are a number of other notable uses that  highlight Braam’s confidence in the functional language. For instance,  Chicago-based Allston Trading, a high frequency trading company, uses  Haskell in their trading infrastructure. AT&T is using it in their  Network Security group to automate internet abuse complaint processing.  Bank of American is using it in their backend data transformation and  loading system and Credit Suisse’s Global Modeling and Analytics Group  has been using it since 2006 to improve modeler productivity and open  access to those models across the organization.<br /><br />Biotech giant Amgen also uses Haskell for math-heavy models and to  “break developers out of their development rut by giving them a new way  to think about software. According to the company’s David Balaban, “Our  experience is that using functional programming reduces the critical  conceptual distance between thought/algorithms design and code.” But the  real value says Balaban is the level of correctness they’ve been able  to achieve.<br /><br />As Amgen’s Balaban says “we  have been able to develop code quickly and verify--to an applied  mathematician’s satisfaction--the correctness of Haskell code  straightforwardly; we have yet to achieve this with more traditional  mainstream languages.” </blockquote>" nil nil "4e496387ddac165fb0bd11c36cf246d5") (178 (20949 25792 603418) "http://parenz.wordpress.com/2013/06/12/ghcjs-build/" "Daniil Frumin: Building GHCJS" nil "Tue, 25 Jun 2013 15:45:34 +0000" "<div id=\"outline-container-sec-1\" class=\"outline-2\">
<h2 id=\"sec-1\"><span class=\"section-number-2\">1</span> Intro</h2>
<div id=\"text-1\" class=\"outline-text-2\">
<p>
In this post I would like to talk about my experience with<br />
bootstrapping <a href=\"http://weblog.luite.com/wordpress/?p=14\">GHCJS</a> using the provided facilities <a href=\"https://github.com/ghcjs/ghcjs-build\">ghcjs-build</a>. I<br />
never used tools like Vagrant or Puppet before so all of this was<br />
kinda new to me.
</p>
</div>
</div>
<div id=\"outline-container-sec-2\" class=\"outline-2\">
<h2 id=\"sec-2\"><span class=\"section-number-2\">2</span> Initial installation</h2>
<div id=\"text-2\" class=\"outline-text-2\">
<p>
GHCJS can’t actually work with vanilla GHC 7.* as it requires to<br />
apply some patches (in order to get JS ffi to work, it adds<br />
<code>JavaScriptFFI</code> language extension among other modifications).
</p>
<p>
<a href=\"https://github.com/ghcjs/ghcjs-build\">ghcjs-build</a> uses <a href=\"http://vagrantup.com\">Vagrant</a> (a tool for automatically building and<br />
running work environments) to mange the work environment, so prior to<br />
running GHCJS you need to install vagrant and <a href=\"http://virtualbox.org\">VirtualBox</a>. It’s actually<br />
a sensible way to tackle a project like that: everyone has similar<br />
work environments, you don’t have to mess with your local GHC<br />
installation. It also make use of <a href=\"http://puppetlabs.com\">Puppet</a> deployment system in<br />
<code>puppetlabs-vcsrepo</code> module for cloning Git repositories.
</p>
<p>
Currently, there are two ways to start up GHCJS using <code>ghcjs-build</code>
</p>
</div>
<div id=\"outline-container-sec-2-1\" class=\"outline-3\">
<h3 id=\"sec-2-1\"><span class=\"section-number-3\">2.1</span> Using the prebuilt version</h3>
<div id=\"text-2-1\" class=\"outline-text-3\">
<div class=\"org-src-container\">
<pre class=\"src src-sh\">git clone https://github.com/ghcjs/ghcjs-build.git
<span style=\"color: #D0D0FF;\">cd</span> ghcjs-build
git checkout prebuilt
vagrant up
</pre>
</div>
<p>
Using this configuration the following procedures are performed:
</p>
<ol class=\"org-ol\">
<li>Vagrant sets up a 32-bit Ubuntu Precise system (/Note: if this is<br />
your first time running Vagrant it downloads the 280Mb<br />
precise32.box file from the Vagrant site/)
</li>
<li>Vagrants does some provisioning using Puppet (downloads and<br />
installs necessary packages)
</li>
<li>A 1.4GB archive with ghcjs and other prebuilt tools are downloaded<br />
and extracted.
</li>
</ol>
</div>
</div>
<div id=\"outline-container-sec-2-2\" class=\"outline-3\">
<h3 id=\"sec-2-2\"><span class=\"section-number-3\">2.2</span> Compiling from source</h3>
<div id=\"text-2-2\" class=\"outline-text-3\">
<div class=\"org-src-container\">
<pre class=\"src src-sh\">git clone https://github.com/ghcjs/ghcjs-build.git
<span style=\"color: #D0D0FF;\">cd</span> ghcjs-build
vagrant up
</pre>
</div>
<p>
Apart from setting up the box this will
</p>
<ol class=\"org-ol\">
<li>Get the GHC sources from Git HEAD and applies the GHCJS <a href=\"http://ghcjs.github.io/patches/ghc-ghcjs.patch\">patch</a>.
</li>
<li>Get all the necessary packages for ghcjs
</li>
<li>Get the latest Cabal from Git HEAD, applies the GHCJS <a href=\"http://ghcjs.github.io/patches/cabal-ghcjs.patch\">patch</a> and<br />
build it.
</li>
<li>Compile the necessary libraries using ghcjs
</li>
<li>Compile <code>ghcjs-examples</code> and its dependencies (it appears that it<br />
can take a lot of time to compile gtk2hs and gtk2hs’s tools)
</li>
</ol>
<p>
Please note, that depending on your computer, you might want to go for<br />
a long walk, enjoy a small book or get a night sleep (assuming you are<br />
not scared by the sound of computer fans).
</p>
<p>
Apart from being slow, the process of compiling everything from<br />
source is error prone. To give you a taste, last night I was not able<br />
to reproduce a working environment myself, because of some recent<br />
changes in GHC HEAD. The prebuilt version on the other hand is<br />
guaranteed to install correctly.
</p>
<p>
Hopefully, the GHCJS patches will be merged upstream before the GHC<br />
7.8 is out. That way you won’t need to partake in building GHC from<br />
the source in order to use GHCJS.
</p>
</div>
</div>
<div id=\"outline-container-sec-2-3\" class=\"outline-3\">
<h3 id=\"sec-2-3\"><span class=\"section-number-3\">2.3</span> Communicating with the VM</h3>
<div id=\"text-2-3\" class=\"outline-text-3\">
<p>
After you’ve finished with the initial setup you should be able just<br />
to
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">vagrant ssh
</pre>
</div>
<p>
in your new vm and start messing around.
</p>
<p>
<code>ghcjs</code> command is available to you and Vagrant kindly forwards the<br />
3000 port on the VM to the local 3030 port, allowing you to run web<br />
servers like <code>warp</code> on the VM and accessing them locally.
</p>
<p>
You can access your local project directory under <code>/vagrant</code> in VM:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">$ ls /vagrant
keys  manifests  modules  outputs  README.rst  Vagrantfile
</pre>
</div>
<p>
However, copying file back-and-forth is not a perfect solution. I<br />
recommend setting up a sshfs filesystem (<i>Note: if you are on OSX,<br />
don’t forget to install fuse4x kernel extension</i>):
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">$ vagrant ssh-config
Host default
HostName 127.0.0.1
User vagrant
Port 2222
UserKnownHostsFile /dev/null
StrictHostKeyChecking no
PasswordAuthentication no
IdentityFile <span style=\"color: #b5bd68;\">\"/Users/dan/.vagrant.d/insecure_private_key\"</span>
IdentitiesOnly yes
LogLevel FATAL
$ sshfs vagrant@localhost:/home/vagrant ../vm -p2222 -oreconnect,defer_permissions,negative_vncache,<span style=\"color: #cc6666;\">volname</span>=ghcjs,<span style=\"color: #cc6666;\">IdentityFile</span>=~/.vagrant.d/insecure_private_key
$ ls ../vm
</pre>
</div>
<p>
When you are done you can just <code>umount ../vm</code>
</p>
</div>
</div>
</div>
<div id=\"outline-container-sec-3\" class=\"outline-2\">
<h2 id=\"sec-3\"><span class=\"section-number-2\">3</span> Compiling other packages</h2>
<div id=\"text-3\" class=\"outline-text-2\">
<p>
Since the <code>diagrams</code> package on Hackage depends on the older version<br />
of base we are going to use the latest version from Git:
</p>
<pre class=\"example\">mkdir dia; cd dia
git clone git://github.com/diagrams/diagrams-core.git
cd diagrams-core && cabal install && cd ..
cabal unpack active
cd active-0.1*
cat >version.patch <<EOF
--- active.cabal        2013-06-12 12:58:40.082914214 +0000
+++ active.cabal.new    2013-06-12 12:58:31.029465815 +0000
@@ -19,7 +19,7 @@
library
exposed-modules:     Data.Active
-  build-depends:       base >= 4.0 && < 4.7,
+  build-depends:       base >= 4.0 && < 4.8,
array >= 0.3 && < 0.5,
semigroups >= 0.1 && < 0.10,
semigroupoids >= 1.2 && < 3.1,
@@ -31,7 +31,7 @@
test-suite active-tests
type:              exitcode-stdio-1.0
main-is:           active-tests.hs
-    build-depends:     base >= 4.0 && < 4.7,
+    build-depends:     base >= 4.0 && < 4.8,
array >= 0.3 && < 0.5,
semigroups >= 0.1 && < 0.10,
semigroupoids >= 1.2 && < 3.1,
EOF
patch active.cabal < version.patch
cabal install
cd ..
git clone git://github.com/diagrams/diagrams-lib.git
cd diagrams-lib && cabal install && cd ..
git clone git://github.com/diagrams/diagrams-svg.git
cd diagrams-svg && cabal install && cd ..
</pre>
<p>
Other packages I had to install already had their Hackage versions<br />
updated.
</p>
<p>
Now you can try to build a test diagram to see that everything works
</p>
<div class=\"org-src-container\">
<pre class=\"src src-haskell\"><span style=\"color: #b294bb;\">module</span> <span style=\"color: #f0c674;\">Main</span> <span style=\"color: #b294bb;\">where</span>
<span style=\"color: #b294bb;\">import</span> <span style=\"color: #f0c674;\">Diagrams.Prelude</span>
<span style=\"color: #b294bb;\">import</span> <span style=\"color: #f0c674;\">Diagrams.Backend.SVG.CmdLine</span>
<span style=\"color: #81a2be;\">d</span> <span style=\"color: #cc6666;\">::</span> <span style=\"color: #f0c674;\">Diagram</span> <span style=\"color: #f0c674;\">SVG</span> <span style=\"color: #f0c674;\">R2</span>
<span style=\"color: #81a2be;\">d</span> <span style=\"color: #cc6666;\">=</span> square 20 <span style=\"color: #cc6666;\">#</span> lw 0<span style=\"color: #cc6666;\">.</span>5
<span style=\"color: #cc6666;\">#</span> fc black
<span style=\"color: #cc6666;\">#</span> lc green
<span style=\"color: #cc6666;\">#</span> dashing [0<span style=\"color: #cc6666;\">.</span>2,0<span style=\"color: #cc6666;\">.</span>2] 0
<span style=\"color: #81a2be;\">main</span> <span style=\"color: #cc6666;\">=</span> defaultMain (pad 1<span style=\"color: #cc6666;\">.</span>1 d)
</pre>
</div>
<p>
then you can compile and run it
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">ghc --make Test.hs
./Test -w 400 -o /vagrant/test.svg
</pre>
</div>
<p><a href=\"http://parenz.files.wordpress.com/2013/06/screen-shot-2013-06-12-at-5-19-03-pm.png\"><img src=\"http://parenz.files.wordpress.com/2013/06/screen-shot-2013-06-12-at-5-19-03-pm.png?w=300&h=289\" alt=\"Screen Shot 2013-06-12 at 5.19.03 PM\" height=\"289\" class=\"alignnone size-medium wp-image-47\" width=\"300\" /></a></p>
<p>
And that’s it!
</p>
</div>
</div>
<div id=\"outline-container-sec-4\" class=\"outline-2\">
<h2 id=\"sec-4\"><span class=\"section-number-2\">4</span> Outro</h2>
<div id=\"text-4\" class=\"outline-text-2\">
<p>
I would also like to note that we are currently polishing the GHCJS<br />
build process. Luite, especially is working on making ghcjs work (and<br />
run tests) with <a href=\"https://travis-ci.org/\">Travis CI</a> (it take quite a bit of time to build ghcjs<br />
and sometimes travis is timeouting) and I am working on tidying up<br />
the build config.
</p>
<p>
Stay tuned for more updates.
</p>
</div>
</div>
<br /> Tagged: <a href=\"http://parenz.wordpress.com/tag/diagrams/\">diagrams</a>, <a href=\"http://parenz.wordpress.com/tag/ghcjs/\">ghcjs</a>, <a href=\"http://parenz.wordpress.com/tag/haskell-2/\">haskell</a>, <a href=\"http://parenz.wordpress.com/tag/soc/\">soc</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/parenz.wordpress.com/49/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/parenz.wordpress.com/49/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=parenz.wordpress.com&blog=26722965&post=49&subd=parenz&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "e9bd00837f7d9ff75ce6adf08299e35e") (177 (20949 25792 600623) "http://feedproxy.google.com/~r/ezyang/~3/qvy2VqDp6Is/" "Edward Z. Yang: (Homotopy) Type Theory: Chapter One" nil "Mon, 24 Jun 2013 22:56:27 +0000" "<div class=\"document\">
<p>In what is old news by now, the folks at the Institute for Advanced Study have released <a href=\"http://homotopytypetheory.org/book/\" class=\"reference external\">Homotopy Type Theory:
Univalent Foundations of Mathematics</a>.  There has been some (meta)commentary (<a href=\"https://plus.google.com/107913314994758123748/posts/VzWAsojiifE\" class=\"reference external\">Dan Piponi</a>, <a href=\"http://existentialtype.wordpress.com/2013/06/22/whats-the-big-deal-with-hott/\" class=\"reference external\">Bob Harper</a>, <a href=\"http://math.andrej.com/2013/06/20/the-hott-book/\" class=\"reference external\">Andrej Bauer</a>, <a href=\"http://dorais.org/archives/1425\" class=\"reference external\">François G. Dorais</a>, <a href=\"http://homotopytypetheory.org/2013/06/20/the-hott-book/\" class=\"reference external\">Steve Awodey</a>, <a href=\"http://www.carloangiuli.com/blog/homotopy-type-theory-univalent-foundations-of-mathematics/\" class=\"reference external\">Carlo Angiuli</a>, <a href=\"http://golem.ph.utexas.edu/category/2013/06/the_hott_book.html\" class=\"reference external\">Mike Shulman</a>, <a href=\"https://plus.google.com/117663015413546257905/posts/cm1sKge8qxX\" class=\"reference external\">John Baez</a>) on the Internet, though, of course, it takes time to read a math textbook, so don’t expect detailed technical commentary from non-authors for a while.</p>
<p>Of course, being a puny grad student, I was, of course, most interested in the book’s contribution of <em>yet another Martin-Löf intuitionistic type theory introduction</em>, e.g. chapter one.  The classic introduction is, of course, the papers that Martin Löf wrote (nota bene: there were many iterations of this paper, so it’s a little hard to find the right one, though it seems Giovanni Sambin’s notes are the easiest to find), but an introduction of type theory for <em>homotopy type theory</em> has to make certain adjustments, and this makes for some novel presentation.  In particular, the chapter’s discussion of <em>identity types</em> is considerably more detailed than I have seen elsewhere (this is not surprising, since identity is of central importance to homotopy type theory). There is also a considerable bit of pedantry/structure in the discussion of the types that make up the theory, reminiscent of the <a href=\"http://existentialtype.wordpress.com/2012/12/03/pfpl-is-out/\" class=\"reference external\">PFPL</a> (though I believe that this particular chapter  was mostly written by others). And, of course, there are many little variations in how the theory is actually put together, expounded upon in some detail in the chapter notes.</p>
<p>In more detail:</p>
<p><strong>Definitional and propositional equality.</strong> The chapter spends a little bit of time carefully distinguishing between definitional equality (a purely syntactic notion up to computation) and propositional equality (which involves evidence), which I appreciated. The difference between connectives which show up inside and outside the deductive system was a major point of confusion for me when I was originally learning logic.</p>
<p><strong>The general pattern of the introduction of a new kind of type.</strong> The modern style for introducing logical connectives is to classify the rules into various kinds, such as introduction rules and elimination rules, and then hew to this regularity in the presentation.  Often, readers are expected to “see it”, but this book makes a helpful remark laying out the style. I found a useful exercise was to take the rules and reorganize them so that, for example, all of the elimination rules are together and compare them.</p>
<p><strong>Recursion and induction.</strong> <a href=\"http://blog.ezyang.com/2013/04/the-difference-between-recursion-induction/\" class=\"reference external\">I’ve written about this subject before</a>, arguing that recursion and induction aren’t the same thing, since induction needs to work over indexed types.  This is true, but there is an important point I did not make: <em>induction is generalized recursion</em>. This is because when you specify your type family <em>P</em> to be the <em>constant type family</em> which ignores its index, the dependence is erased and you have an ordinary recursor.  In fact, this is a <a href=\"http://adam.chlipala.net/cpdt/html/InductiveTypes.html\" class=\"reference external\">CPDT exercise</a>; I think it clarifies things to see this in both Coq and informal mathematics, as the informal presentation makes the dimension of generalization clearer.</p>
<p><strong>Identity types.</strong> I won’t lie: I had a difficult time with this section, and I don’t think I fully understand why path induction works, even after a very long remark at the end of the section.  (Additionally, while the notes point to some prior literature about the subject, I took a look at the papers and I did not see anything that resembled their presentation of path induction.) By default, Coq thinks the inductive principle for equality types should be what is referred to in this book as the indiscernability of identicals:</p>
<pre class=\"literal-block\">> Check eq_rect.
eq_rect
: forall (A : Type) (x : A) (P : A -> Type),
P x -> forall y : A, x = y -> P y
</pre>
<p>(As a tangent, the use of family <em>C</em> is confusingly overloaded; when discussing the generalization of the previous principlem the reader is required to imagine <tt class=\"docutils literal\">C(x) <span class=\"pre\">-></span> C(y)  ===  C(x, y)</tt>—the C’s of course being distinct.) Path induction asks for more:</p>
<pre class=\"literal-block\">eq_ind
: forall (A : Type), forall (C : forall (x y : A), x = y -> Type),
(forall (x : A), C x x (eq_refl x)) -> forall (x y : A), forall (p : x = y), C x y p
</pre>
<p>This is perhaps not too surprising, since this machinery is principally motivated by homotopy type theory. Additionally, the inductive principle follows the same pattern as the other inductive principles defined for the other types. The trouble is a frustrating discussion of why this inductive principle valid, even when you might expect, in a HoTT setting, that not all equality was proven using reflexivity. My understanding of the matter is that is has to do with the placement of the <tt class=\"docutils literal\">forall (x : A)</tt> quantifier. It is permissible to move one of the x's to the top level (based path induction), but not <em>both</em>. (This is somewhat obscured by the reuse of variable names.) There is also a geometric intuition, which is that when both or one endpoints of the path are free (inner-quantification), then I can contract the path into nothingness. But I have a difficult time mapping this onto any sort of rigorous argument. Perhaps you can help me out.</p>
<blockquote>
As an aside, I have some general remarks about learning type theory from a functional programming background.  I have noticed that it is not too hard to use Coq without knowing much type theory, and even easier to miss the point of why the type theory might be helpful.  But in the end, it is really useful to understand what is going on, and so it’s well worth studying <em>why</em> dependent products and sums generalize the way they do.  It also seems that people find the pi and sigma notation confusing: it helps if you realize that they are algebraic puns. Don’t skip the definition of the inductive principles.</blockquote>
<p>I apologize if any of this post has been inaccurate or misleadingly skewed. My overall impression is that this first chapter is a very crisp introduction to type theory, but that the segments on identity types may be a little difficult to understand. Now, onwards to chapter two!</p>
</div>
<img src=\"http://feeds.feedburner.com/~r/ezyang/~4/qvy2VqDp6Is\" height=\"1\" width=\"1\" />" nil nil "ded0efee52c8409d7a27de5ea9b16a57") (176 (20949 25792 597903) "http://feedproxy.google.com/~r/FpComplete/~3/F6zWN-sWxgw/fp-haskell-center-video-blog" "FP Complete: FP Haskell Center Video Blog" nil "Mon, 24 Jun 2013 14:42:00 +0000" "<p>FP Haskell Center is approaching its beta release date for an on-time delivery, and I wanted to share with you some of the details of our product in a short video blog. You can find a link to the video below:</p><p><a href=\"http://youtu.be/3lPFg-tQaLY\">FP Haskell Center Video Blog</a></p><p>Remember, there is still plenty of time to sign-up for the <a href=\"https://www.fpcomplete.com/business/haskell-center\">FP Haskell Center beta.</a></p><div class=\"feedflare\">
<a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=F6zWN-sWxgw:3yiTnUAVPzw:yIl2AUoC8zA\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=yIl2AUoC8zA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=F6zWN-sWxgw:3yiTnUAVPzw:V_sGLiPBpWU\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=F6zWN-sWxgw:3yiTnUAVPzw:V_sGLiPBpWU\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=F6zWN-sWxgw:3yiTnUAVPzw:qj6IDK7rITs\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=qj6IDK7rITs\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=F6zWN-sWxgw:3yiTnUAVPzw:gIN9vFwOqvQ\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=F6zWN-sWxgw:3yiTnUAVPzw:gIN9vFwOqvQ\" border=\"0\" /></a>
</div><img src=\"http://feeds.feedburner.com/~r/FpComplete/~4/F6zWN-sWxgw\" height=\"1\" width=\"1\" />" nil nil "af70c2f29f9fedaf6d5338c6548cabfa") (175 (20949 25792 597506) "http://kenta.blogspot.com/2013/06/kiwzoxbe-deep-maybe.html" "Ken T Takusagawa: [kiwzoxbe] Deep maybe" "noreply@blogger.com (Ken)" "Mon, 24 Jun 2013 08:50:00 +0000" "<p dir=\"ltr\">Given a Haskell record data type, transform it so that each of its fields becomes a Maybe type, and do this recursively into subrecords, including the top level.</p><p dir=\"ltr\">data Foo = Foo Int String ; data Bar = Bar Foo Float</p><p dir=\"ltr\">data FooM = FooM (Maybe Int) (Maybe String) ; type MFoo = Maybe FooM ; data BarM = BarM MFoo (Maybe Float) ; type MBar = Maybe BarM</p><p dir=\"ltr\">Next, transform a function that operates on the original non-Maybe type to work on the new type, inserting Nothing when there is missing needed data.  This is very similar to liftM except deep.  Simple example:</p><p dir=\"ltr\">f :: (Foo -> Bar) -> (MFoo -> MBar)</p><p dir=\"ltr\">This has some feel of reifying laziness: where Foo had a bottom value, MFoo can have a Nothing.</p><p dir=\"ltr\">Given a Nothing in one of the fields of the output, get a trace of which operation in the function, and which Nothing in the input, caused it.</p><p dir=\"ltr\">Generalize to any MonadPlus.</p><p dir=\"ltr\">Avoid confusion between Maybes inserted by this transformation and Maybes that which were present in the original data type.  Perhaps it should be a different Maybe.</p><p dir=\"ltr\">Somewhat inspired by databases which permit \"undefined\" in any field.</p><p dir=\"ltr\">No actual application in mind for this, yet.</p>" nil nil "6cd8c5f54fafa12413a7e05844e0819f") (174 (20949 25792 595919) "http://theorylunch.wordpress.com/2013/05/30/when-does-an-endofunctor-derive-from-an-adjunction/" "Theory Lunch (Institute of Cybernetics, Tallinn): When does an endofunctor derive from an adjunction?" nil "Sun, 23 Jun 2013 15:23:28 +0000" "<p>This is the first of two talks based on Andrea Schalk’s very good introduction to monads, which can be retrieved <a href=\"http://www.cs.man.ac.uk/~schalk/notes/monads.pdf\" target=\"_blank\" title=\"http://www.cs.man.ac.uk/~schalk/notes/monads.pdf‎\">HERE</a></p>
<p>In the following, if <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> is a category, we indicate by <img src=\"http://s0.wp.com/latex.php?latex=%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"|\\mathcal{C}|\" class=\"latex\" title=\"|\\mathcal{C}|\" /> the collection of objects of <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" />, and by <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D%28A%2CB%29&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}(A,B)\" class=\"latex\" title=\"\\mathcal{C}(A,B)\" /> the collection of morphisms in <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> from <img src=\"http://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=333333&s=0\" alt=\"A\" class=\"latex\" title=\"A\" /> to <img src=\"http://s0.wp.com/latex.php?latex=B&bg=ffffff&fg=333333&s=0\" alt=\"B\" class=\"latex\" title=\"B\" />.</p>
<p>As we know, there are two basic ways of defining an adjunction: <span id=\"more-768\"></span></p>
<p><strong>Definition 1.</strong> Let <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{D}\" class=\"latex\" title=\"\\mathcal{D}\" /> be categories; let <img src=\"http://s0.wp.com/latex.php?latex=F+%3A+%5Cmathcal%7BC%7D+%5Cto+%5Cmathcal%7BD%7D&bg=ffffff&fg=333333&s=0\" alt=\"F : \\mathcal{C} \\to \\mathcal{D}\" class=\"latex\" title=\"F : \\mathcal{C} \\to \\mathcal{D}\" /> and <img src=\"http://s0.wp.com/latex.php?latex=G+%3A+%5Cmathcal%7BD%7D+%5Cto+%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"G : \\mathcal{D} \\to \\mathcal{C}\" class=\"latex\" title=\"G : \\mathcal{D} \\to \\mathcal{C}\" /> be functors. An <em>adjunction</em> from <img src=\"http://s0.wp.com/latex.php?latex=F&bg=ffffff&fg=333333&s=0\" alt=\"F\" class=\"latex\" title=\"F\" /> to <img src=\"http://s0.wp.com/latex.php?latex=G&bg=ffffff&fg=333333&s=0\" alt=\"G\" class=\"latex\" title=\"G\" />, written <img src=\"http://s0.wp.com/latex.php?latex=F+%5Cdashv+G&bg=ffffff&fg=333333&s=0\" alt=\"F \\dashv G\" class=\"latex\" title=\"F \\dashv G\" />, is a quadruple <img src=\"http://s0.wp.com/latex.php?latex=%28F%2CG%2C%5Ceta%2C%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F,G,\\eta,\\varepsilon)\" class=\"latex\" title=\"(F,G,\\eta,\\varepsilon)\" /> where <img src=\"http://s0.wp.com/latex.php?latex=%5Ceta%3A+%5Cmathrm%7BId%7D_%5Cmathcal%7BC%7D+%5Cto+GF&bg=ffffff&fg=333333&s=0\" alt=\"\\eta: \\mathrm{Id}_\\mathcal{C} \\to GF\" class=\"latex\" title=\"\\eta: \\mathrm{Id}_\\mathcal{C} \\to GF\" /> (the <em>unit</em> of the adjunction) and <img src=\"http://s0.wp.com/latex.php?latex=%5Cvarepsilon%3A+FG+%5Cto+%5Cmathrm%7BId%7D_%5Cmathcal%7BD%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\varepsilon: FG \\to \\mathrm{Id}_\\mathcal{D}\" class=\"latex\" title=\"\\varepsilon: FG \\to \\mathrm{Id}_\\mathcal{D}\" /> (the <em>counit</em>) are natural transformations such that , for every <img src=\"http://s0.wp.com/latex.php?latex=A+%5Cin+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"A \\in |\\mathcal{C}|\" class=\"latex\" title=\"A \\in |\\mathcal{C}|\" /> and <img src=\"http://s0.wp.com/latex.php?latex=S+%5Cin+%7C%5Cmathcal%7BD%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"S \\in |\\mathcal{D}|\" class=\"latex\" title=\"S \\in |\\mathcal{D}|\" />, <img src=\"http://s0.wp.com/latex.php?latex=G%5Cvarepsilon_S+%5Ccirc+%5Ceta_%7BGS%7D+%3D+%5Cmathrm%7Bid%7D_%7BGS%7D&bg=ffffff&fg=333333&s=0\" alt=\"G\\varepsilon_S \\circ \\eta_{GS} = \\mathrm{id}_{GS}\" class=\"latex\" title=\"G\\varepsilon_S \\circ \\eta_{GS} = \\mathrm{id}_{GS}\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cvarepsilon_%7BFA%7D+%5Ccirc+F%5Ceta_%7BA%7D+%3D+%5Cmathrm%7Bid%7D_%7BFA%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\varepsilon_{FA} \\circ F\\eta_{A} = \\mathrm{id}_{FA}\" class=\"latex\" title=\"\\varepsilon_{FA} \\circ F\\eta_{A} = \\mathrm{id}_{FA}\" />.</p>
<p><strong>Definition 2.</strong> Let <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{D}\" class=\"latex\" title=\"\\mathcal{D}\" /> be categories. We call <em>adjunction quadruple</em> a quadruple <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Csharp%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, (\\cdot)^\\sharp)\" class=\"latex\" title=\"(F, G, \\eta, (\\cdot)^\\sharp)\" /> such that:</p>
<ol>
<li><img src=\"http://s0.wp.com/latex.php?latex=G+%3A+%5Cmathcal%7BD%7D+%5Cto+%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"G : \\mathcal{D} \\to \\mathcal{C}\" class=\"latex\" title=\"G : \\mathcal{D} \\to \\mathcal{C}\" /> is a functor,</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=F+%3A+%7C%5Cmathcal%7BC%7D%7C+%5Cto+%7C%5Cmathcal%7BD%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"F : |\\mathcal{C}| \\to |\\mathcal{D}|\" class=\"latex\" title=\"F : |\\mathcal{C}| \\to |\\mathcal{D}|\" /> is a mapping, and</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%5Ceta&bg=ffffff&fg=333333&s=0\" alt=\"\\eta\" class=\"latex\" title=\"\\eta\" /> associates to every object <img src=\"http://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=333333&s=0\" alt=\"A\" class=\"latex\" title=\"A\" /> a morphism <img src=\"http://s0.wp.com/latex.php?latex=%5Ceta_A+%3A+A+%5Cto+GFA&bg=ffffff&fg=333333&s=0\" alt=\"\\eta_A : A \\to GFA\" class=\"latex\" title=\"\\eta_A : A \\to GFA\" /> so that</li>
<li>for every <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+A+%5Cto+GS&bg=ffffff&fg=333333&s=0\" alt=\"f : A \\to GS\" class=\"latex\" title=\"f : A \\to GS\" /> there exists a unique <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Csharp+%3A+FA+%5Cto+S&bg=ffffff&fg=333333&s=0\" alt=\"f^\\sharp : FA \\to S\" class=\"latex\" title=\"f^\\sharp : FA \\to S\" /> such that <img src=\"http://s0.wp.com/latex.php?latex=Gf%5E%5Csharp+%5Ccirc+%5Ceta_A+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"Gf^\\sharp \\circ \\eta_A = f\" class=\"latex\" title=\"Gf^\\sharp \\circ \\eta_A = f\" />.</li>
</ol>
<p>The two definitions above are equivalent in the following sense. If <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> is an adjunction according to Definition 1, and <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Csharp+%3D+%5Cvarepsilon_S+%5Ccirc+Ff&bg=ffffff&fg=333333&s=0\" alt=\"f^\\sharp = \\varepsilon_S \\circ Ff\" class=\"latex\" title=\"f^\\sharp = \\varepsilon_S \\circ Ff\" />, then <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Csharp%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, (\\cdot)^\\sharp)\" class=\"latex\" title=\"(F, G, \\eta, (\\cdot)^\\sharp)\" /> is an adjunction quadruple according to Definition 2. On the other hand, if <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Cast%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, (\\cdot)^\\ast)\" class=\"latex\" title=\"(F, G, \\eta, (\\cdot)^\\ast)\" /> is an adjunction quadruple according to Definition 2, and <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ccdot%29_%5Cflat&bg=ffffff&fg=333333&s=0\" alt=\"(\\cdot)_\\flat\" class=\"latex\" title=\"(\\cdot)_\\flat\" /> is the inverse operation of <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ccdot%29%5E%5Csharp&bg=ffffff&fg=333333&s=0\" alt=\"(\\cdot)^\\sharp\" class=\"latex\" title=\"(\\cdot)^\\sharp\" />—that is, <img src=\"http://s0.wp.com/latex.php?latex=g_%5Cflat+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"g_\\flat = f\" class=\"latex\" title=\"g_\\flat = f\" /> if and only if <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Csharp+%3D+g&bg=ffffff&fg=333333&s=0\" alt=\"f^\\sharp = g\" class=\"latex\" title=\"f^\\sharp = g\" />—then necessarily <img src=\"http://s0.wp.com/latex.php?latex=%5Ceta_A+%3D+%28%5Cmathrm%7Bid%7D_%7BFA%7D%29_%5Cflat&bg=ffffff&fg=333333&s=0\" alt=\"\\eta_A = (\\mathrm{id}_{FA})_\\flat\" class=\"latex\" title=\"\\eta_A = (\\mathrm{id}_{FA})_\\flat\" />, and by putting <img src=\"http://s0.wp.com/latex.php?latex=Ff+%3D+%28%5Ceta_B+%5Ccirc+f%29%5E%5Csharp&bg=ffffff&fg=333333&s=0\" alt=\"Ff = (\\eta_B \\circ f)^\\sharp\" class=\"latex\" title=\"Ff = (\\eta_B \\circ f)^\\sharp\" /> for <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D%28A%2CB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}(A,B)\" class=\"latex\" title=\"f \\in \\mathcal{C}(A,B)\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cvarepsilon_S+%3D+%28%5Cmathrm%7Bid%7D_%7BGS%7D%29%5E%5Csharp&bg=ffffff&fg=333333&s=0\" alt=\"\\varepsilon_S = (\\mathrm{id}_{GS})^\\sharp\" class=\"latex\" title=\"\\varepsilon_S = (\\mathrm{id}_{GS})^\\sharp\" /> for <img src=\"http://s0.wp.com/latex.php?latex=S+%5Cin+%7C%5Cmathcal%7BD%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"S \\in |\\mathcal{D}|\" class=\"latex\" title=\"S \\in |\\mathcal{D}|\" /> we define an adjunction according to Definition 1.</p>
<p>If <img src=\"http://s0.wp.com/latex.php?latex=%28F%2CG%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F,G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F,G, \\eta, \\varepsilon)\" /> is an adjunction, then <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+GF+%3A+%5Cmathcal%7BC%7D+%5Cto+%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"T = GF : \\mathcal{C} \\to \\mathcal{C}\" class=\"latex\" title=\"T = GF : \\mathcal{C} \\to \\mathcal{C}\" /> is an endofunctor.The first question that comes to our mind is:</p>
<p style=\"text-align: center;\"><em>when does an endofunctor derive from an adjunction?</em></p>
<p>Let us check some basic properties such an endofunctor must satisfy. First of all, <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu+%3A+T%5E2+%5Cto+T&bg=ffffff&fg=333333&s=0\" alt=\"\\mu : T^2 \\to T\" class=\"latex\" title=\"\\mu : T^2 \\to T\" /> defined by <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%3D+G%5Cvarepsilon_%7BFA%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A = G\\varepsilon_{FA}\" class=\"latex\" title=\"\\mu_A = G\\varepsilon_{FA}\" /> is a natural transformation and satisfies</p>
<p style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%5Ccirc+T%5Ceta_A+%3D+%5Cmu_A+%5Ccirc+%5Ceta_%7BTA%7D+%3D+%5Cmathrm%7Bid%7D_%7BTA%7D+%5C%3B%5C%3B+%5Cforall+A+%5Cin+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A \\circ T\\eta_A = \\mu_A \\circ \\eta_{TA} = \\mathrm{id}_{TA} \\;\\; \\forall A \\in |\\mathcal{C}|\" class=\"latex\" title=\"\\mu_A \\circ T\\eta_A = \\mu_A \\circ \\eta_{TA} = \\mathrm{id}_{TA} \\;\\; \\forall A \\in |\\mathcal{C}|\" /></p>
<p style=\"text-align: left;\">Moreover, as <img src=\"http://s0.wp.com/latex.php?latex=%5Cvarepsilon+%3A+FG+%5Cto+%5Cmathrm%7BId%7D_%7B%5Cmathcal%7BD%7D%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\varepsilon : FG \\to \\mathrm{Id}_{\\mathcal{D}}\" class=\"latex\" title=\"\\varepsilon : FG \\to \\mathrm{Id}_{\\mathcal{D}}\" /> is a natural transformation, by choosing <img src=\"http://s0.wp.com/latex.php?latex=f+%3D+%5Cvarepsilon_%7BFA%7D&bg=ffffff&fg=333333&s=0\" alt=\"f = \\varepsilon_{FA}\" class=\"latex\" title=\"f = \\varepsilon_{FA}\" /> we get <img src=\"http://s0.wp.com/latex.php?latex=%5Cvarepsilon_%7BFA%7D+%5Ccirc+%5Cvarepsilon_%7BFGFA%7D+%3D+%5Cvarepsilon_%7BFA%7D+%5Ccirc+FG%5Cvarepsilon_%7BFA%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\varepsilon_{FA} \\circ \\varepsilon_{FGFA} = \\varepsilon_{FA} \\circ FG\\varepsilon_{FA}\" class=\"latex\" title=\"\\varepsilon_{FA} \\circ \\varepsilon_{FGFA} = \\varepsilon_{FA} \\circ FG\\varepsilon_{FA}\" />, which after an application of <img src=\"http://s0.wp.com/latex.php?latex=G&bg=ffffff&fg=333333&s=0\" alt=\"G\" class=\"latex\" title=\"G\" /> yields</p>
<p style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%5Ccirc+%5Cmu_%7BTA%7D+%3D+%5Cmu_A+%5Ccirc+T%5Cmu_A+%5C%3B%5C%3B+%5Cforall+A+%5Cin+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A \\circ \\mu_{TA} = \\mu_A \\circ T\\mu_A \\;\\; \\forall A \\in |\\mathcal{C}|\" class=\"latex\" title=\"\\mu_A \\circ \\mu_{TA} = \\mu_A \\circ T\\mu_A \\;\\; \\forall A \\in |\\mathcal{C}|\" /></p>
<p style=\"text-align: left;\">It will turn out that these two properties are precisely what we need.</p>
<p style=\"text-align: left;\"><strong>Definition 3.</strong> A <em>monad</em> on a category <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> is a triple <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+%28T%2C+%5Ceta%2C+%5Cmu%29&bg=ffffff&fg=333333&s=0\" alt=\"T = (T, \\eta, \\mu)\" class=\"latex\" title=\"T = (T, \\eta, \\mu)\" /> where:</p>
<ol>
<li><img src=\"http://s0.wp.com/latex.php?latex=T+%3A+%5Cmathcal%7BC%7D+%5Cto+%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"T : \\mathcal{C} \\to \\mathcal{C}\" class=\"latex\" title=\"T : \\mathcal{C} \\to \\mathcal{C}\" /> is an endofunctor,</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%5Ceta+%3A+%5Cmathrm%7BId%7D_%5Cmathcal%7BC%7D+%5Cto+T&bg=ffffff&fg=333333&s=0\" alt=\"\\eta : \\mathrm{Id}_\\mathcal{C} \\to T\" class=\"latex\" title=\"\\eta : \\mathrm{Id}_\\mathcal{C} \\to T\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu%3A+T%5E2+%5Cto+T&bg=ffffff&fg=333333&s=0\" alt=\"\\mu: T^2 \\to T\" class=\"latex\" title=\"\\mu: T^2 \\to T\" /> are natural transformations, and</li>
<li>for every <img src=\"http://s0.wp.com/latex.php?latex=A+%5Cin+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"A \\in |\\mathcal{C}|\" class=\"latex\" title=\"A \\in |\\mathcal{C}|\" /> we have <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%5Ccirc+%5Ceta_%7BTA%7D+%3D+%5Cmu_A+%5Ccirc+T%5Ceta_A+%3D+%5Cmathrm%7Bid%7D_%7BTA%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A \\circ \\eta_{TA} = \\mu_A \\circ T\\eta_A = \\mathrm{id}_{TA}\" class=\"latex\" title=\"\\mu_A \\circ \\eta_{TA} = \\mu_A \\circ T\\eta_A = \\mathrm{id}_{TA}\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%5Ccirc+%5Cmu_%7BTA%7D+%3D+%5Cmu_A+%5Ccirc+T%5Cmu_A&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A \\circ \\mu_{TA} = \\mu_A \\circ T\\mu_A\" class=\"latex\" title=\"\\mu_A \\circ \\mu_{TA} = \\mu_A \\circ T\\mu_A\" />,</li>
</ol>
<p>As a very basic example, the <em>free monoid</em> construction is a monad on <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathbf%7BSet%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathbf{Set}\" class=\"latex\" title=\"\\mathbf{Set}\" />, where <img src=\"http://s0.wp.com/latex.php?latex=TA+%3D+A%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"TA = A^\\ast\" class=\"latex\" title=\"TA = A^\\ast\" />, <img src=\"http://s0.wp.com/latex.php?latex=Tf%28s%29+%3D+%5Bf%28a%29+%5C%3B+%5Cmathtt%7Bfor%7D+%5C%3B+a+%5C%3B+%5Cmathtt%7Bin%7D+%5C%3B+s%5D&bg=ffffff&fg=333333&s=0\" alt=\"Tf(s) = [f(a) \\; \\mathtt{for} \\; a \\; \\mathtt{in} \\; s]\" class=\"latex\" title=\"Tf(s) = [f(a) \\; \\mathtt{for} \\; a \\; \\mathtt{in} \\; s]\" />, <img src=\"http://s0.wp.com/latex.php?latex=%5Ceta_A%28a%29+%3D+%5Ba%5D&bg=ffffff&fg=333333&s=0\" alt=\"\\eta_A(a) = [a]\" class=\"latex\" title=\"\\eta_A(a) = [a]\" />, and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A%28%5B%5Ba%5E1_1%2C+%5Cldots%2C+a%5E1_%7Bn_1%7D%5D%2C+%5Cldots%2C+%5Ba%5Em_1%2C+%5Cldots%2C+a%5Em_%7Bn_m%7D%5D%5D+%3D+%5Ba%5E1_1%2C+%5Cldots%2C+a%5E1_%7Bn_1%7D%2C+%5Cldots%2C+a%5Em_1%2C+%5Cldots%2C+a%5Em_%7Bn_m%7D%5D&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A([[a^1_1, \\ldots, a^1_{n_1}], \\ldots, [a^m_1, \\ldots, a^m_{n_m}]] = [a^1_1, \\ldots, a^1_{n_1}, \\ldots, a^m_1, \\ldots, a^m_{n_m}]\" class=\"latex\" title=\"\\mu_A([[a^1_1, \\ldots, a^1_{n_1}], \\ldots, [a^m_1, \\ldots, a^m_{n_m}]] = [a^1_1, \\ldots, a^1_{n_1}, \\ldots, a^m_1, \\ldots, a^m_{n_m}]\" />.</p>
<p>As a less basic example, suppose <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D+%3D+%28S%2C+%5Cleq%29&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C} = (S, \\leq)\" class=\"latex\" title=\"\\mathcal{C} = (S, \\leq)\" /> is a poset: what is a monad on <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" />? First of all, an endofunctor on a poset is a monotone function; next, if there is <img src=\"http://s0.wp.com/latex.php?latex=%5Ceta_A+%3A+A+%5Cto+TA&bg=ffffff&fg=333333&s=0\" alt=\"\\eta_A : A \\to TA\" class=\"latex\" title=\"\\eta_A : A \\to TA\" />, then <img src=\"http://s0.wp.com/latex.php?latex=A+%5Cleq+TA&bg=ffffff&fg=333333&s=0\" alt=\"A \\leq TA\" class=\"latex\" title=\"A \\leq TA\" />; finally, if there is <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%3A+T%5E2A+%5Cto+TA&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A : T^2A \\to TA\" class=\"latex\" title=\"\\mu_A : T^2A \\to TA\" />, then <img src=\"http://s0.wp.com/latex.php?latex=T%5E2A+%5Cleq+TA&bg=ffffff&fg=333333&s=0\" alt=\"T^2A \\leq TA\" class=\"latex\" title=\"T^2A \\leq TA\" />, which together with the previous inequality yields <img src=\"http://s0.wp.com/latex.php?latex=T%5E2A+%3D+TA&bg=ffffff&fg=333333&s=0\" alt=\"T^2A = TA\" class=\"latex\" title=\"T^2A = TA\" />. On the other hand, any nondecreasing idempotent is the endofunctor component of a monad: the monad equations are actually ensured by <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> being a poset, so that any two maps with same domain and same codomain are equal.</p>
<p>We then restate our original problem as follows:</p>
<p style=\"text-align: center;\"><em>given a monad <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+%28T%2C+%5Ceta%2C+%5Cmu%29&bg=ffffff&fg=333333&s=0\" alt=\"T = (T, \\eta, \\mu)\" class=\"latex\" title=\"T = (T, \\eta, \\mu)\" />, find an adjunction <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> such that <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+GF&bg=ffffff&fg=333333&s=0\" alt=\"T = GF\" class=\"latex\" title=\"T = GF\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu+%3D+G+%5Cvarepsilon_F&bg=ffffff&fg=333333&s=0\" alt=\"\\mu = G \\varepsilon_F\" class=\"latex\" title=\"\\mu = G \\varepsilon_F\" /></em></p>
<p>If the adjunction <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> solves the problem above, we say that it <em>generates</em> the monad <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />.</p>
<p>The first solution to this problem was given by the Swiss mathematician Heinrich Kleisli, and is based on an alternative way of defining monads, as it is the case with adjunctions. Let us suppose <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+GF&bg=ffffff&fg=333333&s=0\" alt=\"T = GF\" class=\"latex\" title=\"T = GF\" /> with <img src=\"http://s0.wp.com/latex.php?latex=F+%5Cdashv+G&bg=ffffff&fg=333333&s=0\" alt=\"F \\dashv G\" class=\"latex\" title=\"F \\dashv G\" />. If <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+A+%5Cto+TB+%3D+G%28FB%29&bg=ffffff&fg=333333&s=0\" alt=\"f : A \\to TB = G(FB)\" class=\"latex\" title=\"f : A \\to TB = G(FB)\" />, then <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Csharp+%3A+FA+%5Cto+FB&bg=ffffff&fg=333333&s=0\" alt=\"f^\\sharp : FA \\to FB\" class=\"latex\" title=\"f^\\sharp : FA \\to FB\" />, so that <img src=\"http://s0.wp.com/latex.php?latex=Gf%5E%5Csharp+%3A+TA+%5Cto+TB&bg=ffffff&fg=333333&s=0\" alt=\"Gf^\\sharp : TA \\to TB\" class=\"latex\" title=\"Gf^\\sharp : TA \\to TB\" />: and we know from the definition of monad that <img src=\"http://s0.wp.com/latex.php?latex=Gf%5E%5Csharp+%5Ccirc+%5Ceta_A+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"Gf^\\sharp \\circ \\eta_A = f\" class=\"latex\" title=\"Gf^\\sharp \\circ \\eta_A = f\" />. We can thus define an operator <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ccdot%29%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"(\\cdot)^\\ast\" class=\"latex\" title=\"(\\cdot)^\\ast\" /> that takes <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D%28A%2CTB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}(A,TB)\" class=\"latex\" title=\"f \\in \\mathcal{C}(A,TB)\" /> into <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Cast+%5Cin+%5Cmathcal%7BC%7D%28TA%2CTB%29&bg=ffffff&fg=333333&s=0\" alt=\"f^\\ast \\in \\mathcal{C}(TA,TB)\" class=\"latex\" title=\"f^\\ast \\in \\mathcal{C}(TA,TB)\" /> in a way such that <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Cast+%5Ccirc+%5Ceta_A+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"f^\\ast \\circ \\eta_A = f\" class=\"latex\" title=\"f^\\ast \\circ \\eta_A = f\" /> whatever <img src=\"http://s0.wp.com/latex.php?latex=f&bg=ffffff&fg=333333&s=0\" alt=\"f\" class=\"latex\" title=\"f\" /> is. The simplest example is <img src=\"http://s0.wp.com/latex.php?latex=f+%3D+%5Ceta_A&bg=ffffff&fg=333333&s=0\" alt=\"f = \\eta_A\" class=\"latex\" title=\"f = \\eta_A\" /> itself, so that <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ceta_A%29%5E%5Cast+%5Ccirc+%5Ceta_A+%3D+%5Ceta_A&bg=ffffff&fg=333333&s=0\" alt=\"(\\eta_A)^\\ast \\circ \\eta_A = \\eta_A\" class=\"latex\" title=\"(\\eta_A)^\\ast \\circ \\eta_A = \\eta_A\" />, and <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ceta_A%29%5E%5Cast+%3D+%5Cmathrm%7Bid%7D_%7BTA%7D&bg=ffffff&fg=333333&s=0\" alt=\"(\\eta_A)^\\ast = \\mathrm{id}_{TA}\" class=\"latex\" title=\"(\\eta_A)^\\ast = \\mathrm{id}_{TA}\" /> by uniqueness in the definition of adjunction quadruple. Moreover, if <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+A+%5Cto+TB&bg=ffffff&fg=333333&s=0\" alt=\"f : A \\to TB\" class=\"latex\" title=\"f : A \\to TB\" /> and <img src=\"http://s0.wp.com/latex.php?latex=g+%3A+B+%5Cto+TC&bg=ffffff&fg=333333&s=0\" alt=\"g : B \\to TC\" class=\"latex\" title=\"g : B \\to TC\" />, then</p>
<p style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=g%5E%5Cast+%5Ccirc+f+%3D+Gg%5E%5Csharp+%5Ccirc+%28Gf%5E%5Csharp+%5Ccirc+%5Ceta_A%29+%3D+%28g%5E%5Cast+%5Ccirc+f%5E%5Cast%29+%5Ccirc+%5Ceta_A+%5C%3B%2C&bg=ffffff&fg=333333&s=0\" alt=\"g^\\ast \\circ f = Gg^\\sharp \\circ (Gf^\\sharp \\circ \\eta_A) = (g^\\ast \\circ f^\\ast) \\circ \\eta_A \\;,\" class=\"latex\" title=\"g^\\ast \\circ f = Gg^\\sharp \\circ (Gf^\\sharp \\circ \\eta_A) = (g^\\ast \\circ f^\\ast) \\circ \\eta_A \\;,\" /></p>
<p style=\"text-align: left;\">which implies <img src=\"http://s0.wp.com/latex.php?latex=%28g%5E%5Cast+%5Ccirc+f%29%5E%5Cast+%3D+g%5E%5Cast+%5Ccirc+f%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"(g^\\ast \\circ f)^\\ast = g^\\ast \\circ f^\\ast\" class=\"latex\" title=\"(g^\\ast \\circ f)^\\ast = g^\\ast \\circ f^\\ast\" /> by uniqueness.</p>
<p>This is the base of Kleisli’s solution to our problem, which we will discuss in a future talk.</p>
<br />  <a href=\"http://feeds.wordpress.com/1.0/gocomments/theorylunch.wordpress.com/768/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/theorylunch.wordpress.com/768/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=theorylunch.wordpress.com&blog=43735749&post=768&subd=theorylunch&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "9de0b1bc83135bfdddf8d6ec17a371a4") (173 (20949 25792 592910) "http://www.yesodweb.com/blog/2013/06/first-11-chapters" "Yesod Web Framework: First 11 chapters are Yesod 1.2-compliant" nil "Sun, 23 Jun 2013 13:00:00 +0000" "<p>It's been a while since I've written a post. Besides being <a href=\"https://www.fpcomplete.com/blog/2013/06/beta-sign-up\">very busy at
work</a>, a lot of my time
has gone into getting the Yesod book up-to-date with Yesod version 1.2. And
today, I'm happy to report that the first 11 chapters, comprising the \"basics\"
section of the book, have been converted.</p><p>You can view the new content <a href=\"http://www.yesodweb.com/book-1.2\">at the 1.2
URL</a>. Once the entire book is converted, I'll
switch the URLs, but will continue hosting the 1.1 version of the book <a href=\"http://www.yesodweb.com/book-1.1\">at its
own URL</a>. I intend to continue this pattern
for any future releases as well.</p><p>I intend to continue the conversion process, but I also intend to augment the
book. In particular, I have a number of new examples to add. My current plans
are:</p><ul><li>JSON serving</li><li>Client-side development with Fay</li><li>An updated subsite example based on 1.2 features</li><li>Easy generation of streaming data</li><li>How to store some initialized data in the foundation</li><li>Getting configuration from environment variables</li><li>Writing your own Template Haskell code</li></ul><p>If anyone has suggestions for changes to this list, let me know.</p><p>As for the newly converted content: comments and pull requests are, as always,
welcome!</p>" nil nil "75e76ae2b6e600538f10b9261fdb6330") (172 (20949 25792 592480) "http://neilmitchell.blogspot.com/2013/06/building-llvm-using-shake.html" "Neil Mitchell: Building LLVM using Shake" "noreply@blogger.com (Neil Mitchell)" "Sun, 23 Jun 2013 09:33:08 +0000" "<i>Summary: You can now build LLVM using Shake, and a rebuild with nothing to do goes massively faster than make (0.8s vs 199s) and fractionally faster than Ninja (0.8s vs 0.9s).</i><br /><br />As of <a href=\"https://github.com/ndmitchell/shake\">Shake</a> 0.10.4 the <tt>shake</tt> tool can execute <a href=\"http://martine.github.io/ninja/\">Ninja</a> build files. <a href=\"http://llvm.org/\">LLVM</a> can be built with <a href=\"http://www.cmake.org/\">CMake</a>, and CMake can generate a Ninja build file, so you can compile LLVM with Shake. I've included the full steps I followed at the end of this post.<br /><br />The main thing I wanted to test was how fast a rebuild with nothing to do was using Shake vs Ninja, as Ninja prides itself on having \"a focus on speed\". When compiling LLVM on Windows with GCC, a nothing to do build using make takes 199s, Shake takes 0.8s and Ninja takes 0.9s. The CMake generator does not use one of the latest Ninja build features (the deps keyword), but if it did, Shake would be about 0.1s faster and Ninja would be at least 0.1s faster.<br /><br />Full builds with Shake and Ninja both take about the same time, but with anything higher than 2 CPUs the linker phase ends up contending heavily and the machine thrashes the disk, making robust measurements impossible. The solution would be to use <a href=\"http://neilmitchell.blogspot.co.uk/2013/02/summary-management-of-finite-resources.html\">finite resources</a> on the linkers, something that needs implementing in the CMake Ninja generator, and would then allow more CPUs to be used.<br /><br />Other than speed, why would you use Shake to compile LLVM?<br /><br /><ul><li>If you build with <tt>--report</tt> the file <tt>report.html</tt> will be generated. Open that report file and you can see numerous details about the build - how good the parallel utilisation was, what changed to cause what to rebuild, summary statistics, a dependency graph and more. See the Help page in any generated report for more details.</li><li>If you build with <tt>--progress</tt> the console titlebar will display a predicted completion time, how many seconds until your build completes. The predicted time will be fairly inaccurate the first time round, but future runs are influenced by recorded timings, and can produce useful guesses.</li><li>If your CPU has a preference for functional languages it will make the registers happier.</li></ul><br />Existing Ninja users may also be interested in <a href=\"https://github.com/ndmitchell/shake/blob/master/docs/Ninja.md\">a guide to running Ninja builds with Shake</a>, which gives a few more details on using Shake like Ninja.<br /><br /><b>Compiling LLVM with Shake</b><br /><br />These instructions are how I compiled LLVM with Shake, on Windows, with GCC. I didn't run into any significant problems, but there were two minor niggles I had to work though (both listed below). I compiled LLVM with make, then Ninja, then Shake, to check each phase as I went - but only the final Shake compile is actually necessary.<br /><br /><ul><li>Install Shake with <tt>cabal update && cabal install shake --global</tt>, if you are new to Haskell package installation, see <a href=\"https://github.com/ndmitchell/shake/blob/master/docs/Ninja.md#installing-shake\">here</a>.</li><li>Get LLVM and compile it with make, I followed the instructions at <tt>http://bencode.net/clangonwindows</tt>, which has disappeared in the last few days (I have emailed the web master to see where it went).</li><li>Install <a href=\"http://martine.github.io/ninja/\">Ninja</a>.</li><li>Run CMake over LLVM <a href=\"http://llvm.org/docs/CMake.html\">like this</a>, configuring with <tt>-G Ninja</tt>.</li><li>To build with Ninja I had to edit <tt>build.ninja</tt> line 17697 to delete <tt>lib/clang/3.4/lib/windows/libclang_rt.i386.a,</tt> which won't build on my system and isn't built at all by the make system - I suspect this is a tip/mingw issue. At this stage you can compile LLVM with Ninja.</li><li>Type <tt>touch tools/clang/lib/Basic/CMakeFiles/clang_revision_tag</tt> to create a dummy file. There is a Ninja rule to create such a file, but the rule is wrong since it doesn't actually produce the file, and Shake's sanity checking spots that.</li><li>Run <tt>shake -j2</tt> in the build directory. Come back later and you will have a build.</li><li>Run <tt>shake -j2</tt> again to enjoy the fast nothing to do build.</li></ul>" nil nil "9bd2d47ee046e50d1dbfbf0ed14be51c") (171 (20949 25792 589610) "http://existentialtype.wordpress.com/2013/06/22/whats-the-big-deal-with-hott/" "Robert Harper: =?utf-8?Q?What=E2=80=99s?= the big deal with HoTT?" nil "Sun, 23 Jun 2013 00:25:39 +0000" "<p>Now that the <a href=\"http://homotopytypetheory.org/book\" target=\"_blank\" title=\"Homotopy Type Theory Book\">Homotopy Type Theory</a> book is out, a lot of people are asking “What’s the big deal?”.  The full answer lies within the book itself (or, at any rate, the fullest answer to date), but I am sure that many of us who were involved in its creation will be fielding this question in our own ways to help explain why we are so excited by it.  In fact what I think is really fascinating about HoTT is precisely that there are so many different ways to think about it, according to one’s interests and backgrounds.  For example, one might say it’s a nice way to phrase arguments in homotopy theory that avoids some of the technicalities in the classical proofs by treating spaces and paths synthetically, rather than analytically.  Or one might say that it’s a good language for mechanization of mathematics that provides for the concise formulation of proofs in a form that can be verified by a computer.  Or one might say that it points the way towards a vast extension of the concept of computation that enables us to compute with abstract geometric objects such as spheres or toruses.  Or one might say that it’s a new foundation for mathematics that subsumes set theory by generalizing types from mere sets to arbitrary infinity groupoids,  sets being but particularly simple types (those with no non-trivial higher-dimensional structure).</p>
<p>But what is it about HoTT that makes all these interpretations and applications possible?  What is the key idea that separates HoTT from other approaches that seek to achieve similar ends?  What makes HoTT so special?</p>
<p>In a word the answer is <em>constructivity.</em>  The distinctive feature of HoTT is that it is based on Per Martin-Löf’s Intuitionistic Theory of Types, which was formulated as a foundation for <em>intuitionistic mathematics</em> as originally put forth by Brouwer in the 1930′s, and further developed by Bishop, Gentzen, Heyting, Kolmogorov, Kleene, Lawvere, and Scott, among many others.  Briefly put, the idea of type theory is to codify and systematize the concept of a <em>mathematical construction</em> by characterizing the abstract properties, rather than the concrete realizations, of the objects used in everyday mathematics.  Brouwer’s key insight, which lies at the heart of HoTT, is that <em>proofs are a form of construction</em> no different in kind or character from numbers, geometric figures, spaces, mappings, groups, algebras, or any other mathematical structure.  <a href=\"http://existentialtype.wordpress.com/2012/08/11/extensionality-intensionality-and-brouwers-dictum/\" target=\"_blank\" title=\"Extensionality, Intensionality, and Brouwer’s Dictum\">Brouwer’s dictum</a>, which distinguished his approach from competing alternatives, is that <em>logic is a part of mathematics</em>, rather than <em>mathematics is an application of logic</em>.  Because for him the concept of a construction, including the concept of a proof, is prior to any other form of mathematical activity, including the study of proofs themselves (<em>i.e.</em>, logic).</p>
<p>So under Martin-Löf’s influence HoTT starts with the notion of <em>type</em> as a classification of the notion of <em>construction</em>, and builds upwards from that foundation.  Unlike competing approaches to foundations, <em>proofs are mathematical objects</em> that play a central role in the theory.  This conception is <em>central</em> to the homotopy-theoretic interpretation of type theory, which enriches types to encompass spaces with higher-dimensional structure.  Specifically, the type <img src=\"http://s0.wp.com/latex.php?latex=%5Ctextsf%7BId%7D_A%28M%2CN%29&bg=ffffff&fg=333333&s=0\" alt=\"\\textsf{Id}_A(M,N)\" class=\"latex\" title=\"\\textsf{Id}_A(M,N)\" /> is the type of <em>identifications</em> of <img src=\"http://s0.wp.com/latex.php?latex=M&bg=ffffff&fg=333333&s=0\" alt=\"M\" class=\"latex\" title=\"M\" /> and <img src=\"http://s0.wp.com/latex.php?latex=N&bg=ffffff&fg=333333&s=0\" alt=\"N\" class=\"latex\" title=\"N\" /> within the space <img src=\"http://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=333333&s=0\" alt=\"A\" class=\"latex\" title=\"A\" />.  Identifications may be thought of as <em>proofs</em> that <img src=\"http://s0.wp.com/latex.php?latex=M&bg=ffffff&fg=333333&s=0\" alt=\"M\" class=\"latex\" title=\"M\" /> and <img src=\"http://s0.wp.com/latex.php?latex=N&bg=ffffff&fg=333333&s=0\" alt=\"N\" class=\"latex\" title=\"N\" /> are <em>equal</em> as elements of $A$, or, equivalently, as <em>paths</em> in the space <img src=\"http://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=333333&s=0\" alt=\"A\" class=\"latex\" title=\"A\" /> between points <img src=\"http://s0.wp.com/latex.php?latex=M&bg=ffffff&fg=333333&s=0\" alt=\"M\" class=\"latex\" title=\"M\" /> and <img src=\"http://s0.wp.com/latex.php?latex=N&bg=ffffff&fg=333333&s=0\" alt=\"N\" class=\"latex\" title=\"N\" />.  The fundamental principles of abstraction at the heart of type theory ensure that <em>all constructs of the theory respect these identifications</em>, so that we may treat them as proofs of equality of two elements.  There are three main sources of identifications in HoTT:</p>
<ol>
<li>Reflexivity, stating that everything is equal to itself.</li>
<li>Higher inductive types, defining a type by giving its points, paths, paths between paths, and so on to any dimension.</li>
<li>Univalence, which states that an equivalence between types determines a path between them.</li>
</ol>
<p>I will not attempt here to explain each of these in any detail; everything you need to know is in the HoTT book.  But I will say a few things about their consequences, just to give a flavor of what these new principles give us.</p>
<p>Perhaps the most important conceptual point is that mathematics in HoTT emphasizes the <em>structure of proofs</em> rather than their mere existence.  Rather than settle for a mere logical equivalence between two types (mappings back and forth stating that each implies the other), one instead tends to examine the <em>entire space</em> of proofs of a proposition and how it relates to others.  For example, the univalence axiom itself does not merely state that every equivalence between types gives rise to a path between them, but rather that there is an <em>equivalence</em> between the type of equivalences between two types and the type of paths between them.  Familiar patterns such as “<img src=\"http://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=333333&s=0\" alt=\"A\" class=\"latex\" title=\"A\" /> iff <img src=\"http://s0.wp.com/latex.php?latex=B&bg=ffffff&fg=333333&s=0\" alt=\"B\" class=\"latex\" title=\"B\" />” tend to become “<img src=\"http://s0.wp.com/latex.php?latex=A%5Csimeq+B&bg=ffffff&fg=333333&s=0\" alt=\"A\\simeq B\" class=\"latex\" title=\"A\\simeq B\" />“, stating that the proofs of <img src=\"http://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=333333&s=0\" alt=\"A\" class=\"latex\" title=\"A\" /> and the proofs of <img src=\"http://s0.wp.com/latex.php?latex=B&bg=ffffff&fg=333333&s=0\" alt=\"B\" class=\"latex\" title=\"B\" /> are equivalent.  Of course one may <em>choose </em>neglect this additional information, stating only weaker forms of it using, say, truncation to suppress higher-dimensional information in a type, but the tendency is to <em>embrace</em> the structure and characterize the space of proofs as fully as possible.</p>
<p>A close second in importance is the <em>axiomatic freedom</em> afforded by constructive foundations.  This point has been made many times by many authors in many different settings, but has particular bite in HoTT.   The theory does not commit to (nor does it refute) the infamous <em>Law of the Excluded Middle</em> for arbitrary types: the type <img src=\"http://s0.wp.com/latex.php?latex=A%2B%28A%5Cto+%5Ctextbf%7B0%7D%29&bg=ffffff&fg=333333&s=0\" alt=\"A+(A\\to \\textbf{0})\" class=\"latex\" title=\"A+(A\\to \\textbf{0})\" /> need not always be inhabited.  This property of HoTT is absolutely essential to its expressive power.  Not only does it admit a wider range of interpretations than are possible with the Law included, but it also allows for the <em>selective imposition</em> of the Law where it is needed to recover a classical argument, or where it is important to distinguish the implications of decidability in a given situation.  (Here again I defer to the book itself for full details.)  Similar considerations arise in connection with the many forms of Choice that can be expressed in HoTT, some of which are outright provable, others of which are independent as they are in axiomatic set theory.</p>
<p>Thus, what makes HoTT so special is that it is a<em> constructive</em> theory of mathematics.  Historically, this has meant that it has a <em>computational</em> interpretation, expressed most vividly by the <a href=\"http://existentialtype.wordpress.com/2011/03/27/the-holy-trinity/\" target=\"_blank\" title=\"The Holy Trinity\"><em>propositions as types</em></a> principle.  And yet, for all of its promise, what HoTT currently lacks is a computational interpretation!  What, exactly, does it mean to <em>compute</em> with higher-dimensional objects?  At the moment it is difficult to say for sure, though there seem to be clear intuitions in at least some cases of how to “implement” such a rich type theory.  Alternatively, one may ask whether the term “constructive”, when construed in such a general setting, must inevitably involve a notion of computation.  While it seems obvious on computational grounds that the Law of the Excluded Middle should not be considered universally valid, it becomes less clear why it is so important to omit this Law (and, essentially, no other) in order to obtain the richness of HoTT when no computational interpretation is extant.  From my point of view understanding the <em>computational </em>meaning of higher-dimensional type theory is of paramount importance, because, for me, type theory is and always has been a <em>theory of computation</em> on which the entire edifice of mathematics ought to be built.</p>
<br />Filed under: <a href=\"http://existentialtype.wordpress.com/category/research/\">Research</a> Tagged: <a href=\"http://existentialtype.wordpress.com/tag/homotopy-theory/\">homotopy theory</a>, <a href=\"http://existentialtype.wordpress.com/tag/type-theory/\">type theory</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/existentialtype.wordpress.com/819/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/existentialtype.wordpress.com/819/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=existentialtype.wordpress.com&blog=2157150&post=819&subd=existentialtype&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "aa294495468e3227ea27d6a7c401b7f0") (170 (20949 25792 587816) "http://neilmitchell.blogspot.com/2013/05/three-types-of-build-system-dependency.html" "Neil Mitchell: Three types of build-system dependency" "noreply@blogger.com (Neil Mitchell)" "Sat, 22 Jun 2013 21:05:27 +0000" "<i>Summary: There are three types of dependencies you might want to express in a build system, all of which are supported by Shake.</i><br /><br />A build system, at its heart, is a system which runs commands in an order satisfying user-specified dependencies. But what kind of dependencies can be expressed? This post describes three different types of dependency, only one of which is available in Make, but all of which are available in both <a href=\"https://github.com/ndmitchell/shake#readme\">Shake</a> and <a href=\"http://martine.github.io/ninja/\">Ninja</a>.<br /><br /><b>Feature 1: Static dependencies (available in every build system)</b><br /><br />The most basic form of dependency is a static dependency, where a rule produces an output from some inputs:<br /><br /><pre>-- In Make --<br />result.tar : file1 file2<br />    tar -cf result.tar file1 file2<br /><br />-- In Shake --<br />\"result.tar\" *> \\out -> do<br />    let deps = [\"file1\",\"file2\"]<br />    need deps<br />    cmd \"tar -cf\" [out] deps<br /></pre><br />This rule says that the file <tt>result.tar</tt> depends on the inputs <tt>file1</tt> and <tt>file2</tt>, and provides a command to build <tt>result.tar</tt>. Whenever <tt>file1</tt> or <tt>file2</tt> change, the command will be run, and <tt>result.tar</tt> will be built.<br /><br />Static dependencies occur in almost every build rule, and are supported by all build tools, including Make and Shake.<br /><br /><b>Feature 2: Dynamic dependencies (available in Shake, Ninja, Redo and tup)</b><br /><br />A more advanced dependency is where the list of dependencies itself depends on the results of previous dependencies. Imagine we want to build <tt>result.tar</tt> from the list of files stored in <tt>list.txt</tt>. The dependencies of <tt>result.tar</tt> cannot be specified statically, but depend on <i>the contents</i> of <tt>list.txt</tt>. In Shake we can write:<br /><br /><pre>\"result.tar\" *> \\out -> do<br />    need [\"list.txt\"]<br />    contents <- readFileLines \"list.txt\"<br />    need contents<br />    cmd \"tar -cf\" [out] contents<br /></pre><br />This rule describes how to build <tt>result.tar</tt>. We depend on (<tt>need</tt>) the file <tt>list.txt</tt>. We read each line from <tt>list.txt</tt> into the variable <tt>contents</tt> - being a list of the files that should go into <tt>result.tar</tt>. Next, we depend on all the files in <tt>contents</tt>, and finally call the <tt>tar</tt> program. If either <tt>list.txt</tt> changes, or any of the files listed by <tt>list.txt</tt> change, then <tt>result.tar</tt> will be rebuilt.<br /><br />This feature is necessary in almost every build system, yet is shockingly lacking from most build tools - I am only aware of it being available in <a href=\"https://github.com/ndmitchell/shake#readme\">Shake</a>, <a href=\"http://martine.github.io/ninja/\">Ninja</a>, <a href=\"https://github.com/apenwarr/redo#readme\">Redo</a> and <a href=\"http://gittup.org/tup/\">tup</a>. As a common example, in Make you might write:<br /><br /><pre>result.o : result.c result_header1.h result_header2.h<br />    gcc ...<br /></pre><br />The file <tt>result.o</tt> depends on both the C source file <tt>result.c</tt> and all headers that file includes. But listing the headers both in <tt>result.c</tt> with <tt>#include</tt> directives, and in the Makefile, is a brittle form of duplication. A better approach is for the build system to run <tt>gcc -M result.c</tt> and extract the includes from there. In Shake we can write:<br /><br /><pre>\"result.o\" *> \\out -> do<br />    let src = \"result.c\"<br />    Stdout stdout <- cmd \"gcc -MM\" [src]<br />    need $ src : drop 2 (words stdout)<br />    cmd \"gcc -o\" [out] \"-c\" [src]<br /></pre><br />My experience is that about a quarter of rules require some kind of additional dependency based on previous dependencies. While you can hack round some of the issues in Make, and people have become disturbingly adept at doing so, the result often only approximates the dependencies - building either too much or too little.<br /><br /><b>Feature 3: Multiple outputs from one rule (available in Shake and Ninja)</b><br /><br />The final feature is producing multiple outputs from one command, and is used far more rarely (perhaps one or two rules in a complex build system) - but when needed, is essential. Some programs, such as GHC, can produce two outputs with one command - compiling <tt>Foo.hs</tt> produces both <tt>Foo.o</tt> and <tt>Foo.hi</tt>. As a first approximation, the <tt>.o</tt> file depends on the entire contents of the source file, while the <tt>.hi</tt> file depends only on the type signatures. A single <tt>ghc</tt> invocation needs to do all the work to produce both, but often the <tt>.hi</tt> file will be left unchanged. In Shake we can write:<br /><br /><pre>[\"Foo.hi\",\"Foo.o\"] *>> \\_ -> do<br />    need [\"Foo.hs\"]<br />    cmd \"gcc -c Foo.hs\"<br /></pre><br />While it is often possible to construct a series of dependencies to approximate a single rule producing multiple outputs, it only works in some cases, and is brittle. The only build systems I am aware of which support multiple outputs are <a href=\"https://github.com/ndmitchell/shake#readme\">Shake</a> and <a href=\"http://martine.github.io/ninja/\">Ninja</a>.<br /><br /><b>Essential features</b><br /><br />My standard advice when people ask about writing a build system is \"don't\". If some existing build system (e.g. ghc --make or Cabal) is capable of building your project, use that instead. Custom build systems are necessary for many complex projects, but many projects are not complex. If you have decided your project is complex, you should use a build tool that can express complex dependencies, both for writing the initial system and to provide the flexibility to make the inevitable changes required.<br /><br />Looking only at dependency features, I would consider it unwise to start a complex build system using a tool other than Shake or Ninja, or perhaps either Redo or tup (if you accept the absence of multiple outputs from one rule).<br /><br />Weak dependency specification in build tools, particularly Make, has left its mark on many programs. I recently talked to some OCaml hackers complaining that their tools were not \"Make friendly\" because they produced multiple output files. I wonder what lengths other tools have gone to in order to cope with weak dependency specification...<br /><br /><b>Update:</b> The relative power of tup was reported as a comment, and it appears to have the necessary power, but I haven't yet checked. Following further research into Ninja I suspect it may not be as powerful as originally stated and may not have Feature 2, but am not yet sure." nil nil "0d14184a7efb5c989225d6493150c5b5") (169 (20949 25792 586234) "http://twanvl.nl/blog/agda/subst-from-cong" "Twan van Laarhoven: Substitution from congruence in univalent OTT" nil "Sat, 22 Jun 2013 14:51:00 +0000" "<p>In this post I will show that in an univalence style observational type theory, it is enough to take congruence as a primitive, rather than the more complicated substitution or J axioms. This post is literate Agda, so here are some boring import declarations
</p><pre class=\"agda\"><span class=\"keyword\">module</span> <span class=\"varid\">subst-from-cong</span> <span class=\"keyword\">where</span>
<div class=\"empty-line\"></div>
<span class=\"keyword\">open</span> <span class=\"keyword\">import</span> <span class=\"conid\">Level</span>
<span class=\"keyword\">open</span> <span class=\"keyword\">import</span> <span class=\"conid\">Function</span>
<span class=\"keyword\">open</span> <span class=\"keyword\">import</span> <span class=\"conid\">Data.Unit</span>
<span class=\"keyword\">open</span> <span class=\"keyword\">import</span> <span class=\"conid\">Data.Bool</span>
<span class=\"keyword\">open</span> <span class=\"keyword\">import</span> <span class=\"conid\">Data.Empty</span>
<span class=\"keyword\">open</span> <span class=\"keyword\">import</span> <span class=\"conid\">Data.Product</span>
</pre><p>I will be using the standard propositional equality as a meta equality,
</p><pre class=\"agda\"><span class=\"keyword\">open</span> <span class=\"keyword\">import</span> <span class=\"conid\">Relation.Binary.PropositionalEquality</span> <span class=\"varid\">as</span> <span class=\"conid\">Meta</span> <span class=\"varid\">using</span> (<span class=\"keyglyph\">_</span><span class=\"varop\">≡</span><span class=\"keyglyph\">_</span>)
</pre><p>while postulating a path type (equality type) and its computation rules for me to prove things about,
</p><pre class=\"agda\"><span class=\"keyword\">postulate</span> <span class=\"conid\">Path</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span>} <span class=\"keyglyph\">→</span> (<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>
<span class=\"keyword\">postulate</span> <span class=\"varid\">refl</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span>} <span class=\"keyglyph\">→</span> (<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>) <span class=\"keyglyph\">→</span> (<span class=\"varid\">x</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">x</span>
</pre><p>The idea of Observational Type Theory (OTT) is that <tt><span class=\"conid\">Path</span></tt> is actually defined by case analysis on the structure of the argument type. For the finite types this is simple, there is a path if and only if the values are the same,
</p><pre class=\"agda\"><span class=\"keyword\">postulate</span> <span class=\"conid\">Path-⊤</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> ⊤ <span class=\"varid\">tt</span> <span class=\"varid\">tt</span> <span class=\"varop\">≡</span> ⊤
<div class=\"empty-line\"></div>
<span class=\"keyword\">postulate</span> <span class=\"conid\">Path-Bool00</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">Bool</span> <span class=\"varid\">false</span> <span class=\"varid\">false</span> <span class=\"varop\">≡</span> ⊤
<span class=\"keyword\">postulate</span> <span class=\"conid\">Path-Bool01</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">Bool</span> <span class=\"varid\">false</span> <span class=\"varid\">true</span> <span class=\"varop\">≡</span> ⊥
<span class=\"keyword\">postulate</span> <span class=\"conid\">Path-Bool10</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">Bool</span> <span class=\"varid\">true</span> <span class=\"varid\">false</span> <span class=\"varop\">≡</span> ⊥
<span class=\"keyword\">postulate</span> <span class=\"conid\">Path-Bool11</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">Bool</span> <span class=\"varid\">true</span> <span class=\"varid\">true</span> <span class=\"varop\">≡</span> ⊤
</pre><p>A path for functions is a function to paths, which also means that we have functional extensionality.
</p><pre class=\"agda\"><span class=\"conid\">Π</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} (<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>) (<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> (<span class=\"varid\">a</span> ⊔ <span class=\"varid\">b</span>)
<span class=\"conid\">Π</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span> <span class=\"keyglyph\">=</span> (<span class=\"varid\">x</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span> <span class=\"varid\">x</span>
<div class=\"empty-line\"></div>
<span class=\"keyword\">postulate</span> <span class=\"conid\">Path-Π</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>} (<span class=\"varid\">f</span> <span class=\"varid\">g</span> <span class=\"varop\">:</span> <span class=\"conid\">Π</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>)
<span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">Π</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>) <span class=\"varid\">f</span> <span class=\"varid\">g</span> <span class=\"varop\">≡</span> ((<span class=\"varid\">x</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">B</span> <span class=\"varid\">x</span>) (<span class=\"varid\">f</span> <span class=\"varid\">x</span>) (<span class=\"varid\">g</span> <span class=\"varid\">x</span>))
</pre><p>In their <a href=\"http://www.cs.nott.ac.uk/~txa/publ/obseqnow.pdf\">original OTT paper</a>, Alternkirch et.al. defined equality for types also by structure matching. I.e. Π types are equal to Π types with equal arguments, Σ types are equal to Σ types, etc.
But this is incompatible with the univalence axiom from Homotopy Type Theory. That axiom states that equivalent or isomorphic types are equal. So, what happens if we take isomorphism as our definition of equality between types?
</p><pre class=\"agda\"><span class=\"conid\">Iso</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span>} <span class=\"keyglyph\">→</span> (<span class=\"conid\">A</span> <span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>
<span class=\"conid\">Iso</span> {<span class=\"varid\">a</span>} <span class=\"conid\">A</span> <span class=\"conid\">B</span>
<span class=\"keyglyph\">=</span> <span class=\"conid\">Σ</span> (<span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>) <span class=\"keyglyph\">\\</span><span class=\"varid\">fw</span> <span class=\"keyglyph\">→</span>
<span class=\"conid\">Σ</span> (<span class=\"conid\">B</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">A</span>) <span class=\"keyglyph\">\\</span><span class=\"varid\">bw</span> <span class=\"keyglyph\">→</span>
(<span class=\"keyglyph\">∀</span> <span class=\"varid\">x</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> (<span class=\"varid\">bw</span> (<span class=\"varid\">fw</span> <span class=\"varid\">x</span>)) <span class=\"varid\">x</span>) ×
(<span class=\"keyglyph\">∀</span> <span class=\"varid\">y</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">B</span> (<span class=\"varid\">fw</span> (<span class=\"varid\">bw</span> <span class=\"varid\">y</span>)) <span class=\"varid\">y</span>)
<div class=\"empty-line\"></div>
<span class=\"varid\">id-Iso</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span>} <span class=\"keyglyph\">→</span> (<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">Iso</span> <span class=\"conid\">A</span> <span class=\"conid\">A</span>
<span class=\"varid\">id-Iso</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">=</span> (<span class=\"varid\">id</span> , <span class=\"varid\">id</span> , <span class=\"varid\">refl</span> <span class=\"conid\">A</span> , <span class=\"varid\">refl</span> <span class=\"conid\">A</span>)
<div class=\"empty-line\"></div>
<span class=\"keyword\">postulate</span> <span class=\"conid\">Path-Type</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span>} (<span class=\"conid\">A</span> <span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>)
<span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">Set</span> <span class=\"varid\">a</span>) <span class=\"conid\">A</span> <span class=\"conid\">B</span> <span class=\"varop\">≡</span> <span class=\"conid\">Lift</span> {<span class=\"varid\">a</span>} {<span class=\"varid\">suc</span> <span class=\"varid\">a</span>} (<span class=\"conid\">Iso</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>)
</pre><p>Now suppose that we have a congruence, i.e. that all functions preserve paths. So from a path between <tt><span class=\"varid\">x</span></tt> and <tt><span class=\"varid\">y</span></tt>, we can construct a path between <tt class=\"complex\"><span class=\"varid\">f</span> <span class=\"varid\">x</span></tt> and <tt class=\"complex\"><span class=\"varid\">f</span> <span class=\"varid\">y</span></tt> for any function <tt><span class=\"varid\">f</span></tt>.
</p><pre class=\"agda\"><span class=\"comment\">-- we have congruence for non-dependent functions</span>
<span class=\"keyword\">postulate</span> <span class=\"varid\">cong</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>}
<span class=\"keyglyph\">→</span> (<span class=\"varid\">f</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>) <span class=\"keyglyph\">→</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">x</span> <span class=\"varid\">y</span>} <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">B</span> (<span class=\"varid\">f</span> <span class=\"varid\">x</span>) (<span class=\"varid\">f</span> <span class=\"varid\">y</span>)
</pre><p>Then this is enough to define substitution, since the paths for a type <tt class=\"complex\"><span class=\"conid\">B</span> <span class=\"varid\">x</span></tt> are isomorphisms, and we can apply these in the forward direction
</p><pre class=\"agda\"><span class=\"varid\">subst</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} (<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>) {<span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>} <span class=\"keyglyph\">→</span> (<span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span> <span class=\"varid\">x</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span> <span class=\"varid\">y</span>
<span class=\"varid\">subst</span> <span class=\"conid\">B</span> {<span class=\"varid\">x</span>} {<span class=\"varid\">y</span>} <span class=\"varid\">p</span> <span class=\"varid\">with</span> <span class=\"varid\">Meta.subst</span> <span class=\"varid\">id</span> (<span class=\"conid\">Path-Type</span> (<span class=\"conid\">B</span> <span class=\"varid\">x</span>) (<span class=\"conid\">B</span> <span class=\"varid\">y</span>)) (<span class=\"varid\">cong</span> <span class=\"conid\">B</span> <span class=\"varid\">p</span>)
<span class=\"varop\">...</span> <span class=\"keyglyph\">|</span> <span class=\"varid\">lift</span> (<span class=\"varid\">fw</span> , <span class=\"varid\">bw</span> , <span class=\"keyglyph\">_</span> , <span class=\"keyglyph\">_</span>) <span class=\"keyglyph\">=</span> <span class=\"varid\">fw</span>
</pre><p>With substitution we can now finally define what paths are for dependent Σ types.
A path between pairs is a pair of paths,
</p><pre class=\"agda\"><span class=\"keyword\">postulate</span> <span class=\"conid\">Path-Σ</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>} (<span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">Σ</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>)
<span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">Σ</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>) <span class=\"varid\">x</span> <span class=\"varid\">y</span>
<span class=\"varop\">≡</span> <span class=\"conid\">Σ</span> (<span class=\"conid\">Path</span> <span class=\"conid\">A</span> (<span class=\"varid\">proj₁</span> <span class=\"varid\">x</span>) (<span class=\"varid\">proj₁</span> <span class=\"varid\">y</span>))
(<span class=\"keyglyph\">\\</span><span class=\"varid\">pa</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">B</span> (<span class=\"varid\">proj₁</span> <span class=\"varid\">y</span>)) (<span class=\"varid\">subst</span> <span class=\"conid\">B</span> <span class=\"varid\">pa</span> (<span class=\"varid\">proj₂</span> <span class=\"varid\">x</span>)) (<span class=\"varid\">proj₂</span> <span class=\"varid\">y</span>))
</pre><p>Substitution is not the most general eliminator for paths.
It is not enough to prove properties about paths. For that we need the general induction principle for paths, often called J
</p><pre class=\"agda\"><span class=\"conid\">J</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"varid\">x</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>} <span class=\"keyglyph\">→</span> (<span class=\"conid\">B</span> <span class=\"varop\">:</span> (<span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>)
<span class=\"keyglyph\">→</span> {<span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>} <span class=\"keyglyph\">→</span> (<span class=\"varid\">p</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span> <span class=\"varid\">x</span> (<span class=\"varid\">refl</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span> <span class=\"varid\">y</span> <span class=\"varid\">p</span>
</pre><p>Unfortunately, I was unable to prove J from just congruence. For that I needed an additional lemma,
</p><pre class=\"agda\"><span class=\"keyword\">postulate</span> <span class=\"varid\">subst-refl</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>} <span class=\"keyglyph\">→</span> (<span class=\"varid\">p</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span>)
<span class=\"keyglyph\">→</span> <span class=\"varid\">p</span> <span class=\"varop\">≡</span> <span class=\"varid\">subst</span> (<span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span>) <span class=\"varid\">p</span> (<span class=\"varid\">refl</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span>)
</pre><p>Since <tt class=\"complex\"><span class=\"conid\">Path</span> <span class=\"conid\">A</span></tt> is inductively defined, I believe that <tt class=\"complex\"><span class=\"varid\">subst-refl</span></tt> should be provable by case analysis on <tt><span class=\"conid\">A</span></tt>, but I have not yet done so. We can now implement J by using <tt><span class=\"varid\">subst</span></tt> with a dependent pair.
Note that here I have to manually apply the comptuation rules for <tt class=\"complex\"><span class=\"conid\">Path</span> (<span class=\"conid\">Σ</span> <span class=\"keyglyph\">_</span> <span class=\"keyglyph\">_</span>)</tt> and use the <tt class=\"complex\"><span class=\"varid\">subst-refl</span></tt> lemma.
</p><pre class=\"agda\"><span class=\"conid\">J</span> {<span class=\"conid\">A</span> <span class=\"keyglyph\">=</span> <span class=\"conid\">A</span>} {<span class=\"varid\">x</span> <span class=\"keyglyph\">=</span> <span class=\"varid\">x</span>} <span class=\"conid\">B</span> {<span class=\"varid\">y</span>} <span class=\"varid\">p</span>
<span class=\"keyglyph\">=</span> <span class=\"varid\">subst</span> (<span class=\"varid\">uncurry</span> <span class=\"conid\">B</span>)
(<span class=\"varid\">Meta.subst</span> <span class=\"varid\">id</span> (<span class=\"varid\">Meta.sym</span> <span class=\"varop\">$</span> <span class=\"conid\">Path-Σ</span> (<span class=\"varid\">x</span> , <span class=\"varid\">refl</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span>) (<span class=\"varid\">y</span> , <span class=\"varid\">p</span>)) <span class=\"varop\">$</span>
(<span class=\"varid\">p</span> , <span class=\"varid\">Meta.subst</span> (<span class=\"keyglyph\">\\</span><span class=\"varid\">q</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span>) <span class=\"varid\">q</span> <span class=\"varid\">p</span>) (<span class=\"varid\">subst-refl</span> <span class=\"varid\">p</span>)
(<span class=\"varid\">refl</span> (<span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span>) <span class=\"varid\">p</span>)))
</pre><h2><a name=\"does-it-compute\"></a>Does it compute </h2>
<p>An important question to ask is whether this style of OTT is actually implementable.
We can certainly implement the definitions, but would they allow us to compute?
</p><p>The type <tt class=\"complex\"><span class=\"conid\">Path</span> <span class=\"conid\">A</span></tt> certainly reduces, by definition. Similarly, it is not hard to implemenent <tt><span class=\"varid\">refl</span></tt>.
The hard part is defining what <tt><span class=\"varid\">cong</span></tt> means for various functions, and then proving <tt class=\"complex\"><span class=\"varid\">subst-refl</span></tt>.
Somewhere in there we should put the fact that paths are transitive and symmetric, since we have not used that property so far. For what I have done up till now I could equally well have taken <tt class=\"complex\"><span class=\"conid\">Iso</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span> <span class=\"keyglyph\">=</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span></tt>.
</p><p>Here are the implementations of <tt><span class=\"varid\">refl</span></tt>,
</p><pre class=\"agda\"><span class=\"keyglyph\">_</span><span class=\"varop\">≡[</span><span class=\"keyglyph\">_</span><span class=\"varop\">]≡</span><span class=\"keyglyph\">_</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span>} {<span class=\"conid\">A</span> <span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} <span class=\"keyglyph\">→</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">A</span> <span class=\"varop\">≡</span> <span class=\"conid\">B</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>
<span class=\"varid\">a</span> <span class=\"varop\">≡[</span> <span class=\"varid\">p</span> <span class=\"varop\">]≡</span> <span class=\"varid\">b</span> <span class=\"keyglyph\">=</span> <span class=\"varid\">Meta.subst</span> <span class=\"varid\">id</span> <span class=\"varid\">p</span> <span class=\"varid\">a</span> <span class=\"varop\">≡</span> <span class=\"varid\">b</span>
<div class=\"empty-line\"></div>
<span class=\"keyword\">postulate</span>
<span class=\"varid\">refl-⊤</span>     <span class=\"varop\">:</span> <span class=\"varid\">refl</span> ⊤ <span class=\"varid\">tt</span> <span class=\"varop\">≡[</span> <span class=\"conid\">Path-⊤</span> <span class=\"varop\">]≡</span> <span class=\"varid\">tt</span>
<span class=\"varid\">refl-Bool0</span> <span class=\"varop\">:</span> <span class=\"varid\">refl</span> <span class=\"conid\">Bool</span> <span class=\"varid\">false</span> <span class=\"varop\">≡[</span> <span class=\"conid\">Path-Bool00</span> <span class=\"varop\">]≡</span> <span class=\"varid\">tt</span>
<span class=\"varid\">refl-Bool1</span> <span class=\"varop\">:</span> <span class=\"varid\">refl</span> <span class=\"conid\">Bool</span> <span class=\"varid\">true</span>  <span class=\"varop\">≡[</span> <span class=\"conid\">Path-Bool11</span> <span class=\"varop\">]≡</span> <span class=\"varid\">tt</span>
<span class=\"varid\">refl-Π</span>     <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>} (<span class=\"varid\">f</span> <span class=\"varop\">:</span> <span class=\"conid\">Π</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>)
<span class=\"keyglyph\">→</span> <span class=\"varid\">refl</span> (<span class=\"conid\">Π</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>) <span class=\"varid\">f</span> <span class=\"varop\">≡[</span> <span class=\"conid\">Path-Π</span> <span class=\"varid\">f</span> <span class=\"varid\">f</span> <span class=\"varop\">]≡</span> (<span class=\"keyglyph\">\\</span><span class=\"varid\">x</span> <span class=\"keyglyph\">→</span> <span class=\"varid\">refl</span> (<span class=\"conid\">B</span> <span class=\"varid\">x</span>) (<span class=\"varid\">f</span> <span class=\"varid\">x</span>))
<span class=\"varid\">refl-Type</span>  <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span>} (<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>)
<span class=\"keyglyph\">→</span> <span class=\"varid\">refl</span> (<span class=\"conid\">Set</span> <span class=\"varid\">a</span>) <span class=\"conid\">A</span> <span class=\"varop\">≡[</span> <span class=\"conid\">Path-Type</span> <span class=\"conid\">A</span> <span class=\"conid\">A</span> <span class=\"varop\">]≡</span> <span class=\"varid\">lift</span> (<span class=\"varid\">id-Iso</span> <span class=\"conid\">A</span>)
</pre><p>For <tt class=\"complex\"><span class=\"varid\">refl</span> (<span class=\"conid\">Σ</span> <span class=\"keyglyph\">_</span> <span class=\"keyglyph\">_</span>)</tt> we need yet another lemma, which is a bit a dual to <tt class=\"complex\"><span class=\"varid\">subst-refl₁</span></tt>, allowing <tt><span class=\"varid\">refl</span></tt> in the second argument instead of the third.
</p><pre class=\"agda\"><span class=\"keyword\">postulate</span>
<span class=\"varid\">subst-refl₁</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>} {<span class=\"varid\">x</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>} {<span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">B</span> <span class=\"varid\">x</span>}
<span class=\"keyglyph\">→</span> <span class=\"varid\">y</span> <span class=\"varop\">≡</span> <span class=\"varid\">subst</span> <span class=\"conid\">B</span> (<span class=\"varid\">refl</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span>) <span class=\"varid\">y</span>
<div class=\"empty-line\"></div>
<span class=\"varid\">refl-Σ</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>} (<span class=\"varid\">x</span> <span class=\"varop\">:</span> <span class=\"conid\">Σ</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>)
<span class=\"keyglyph\">→</span> <span class=\"varid\">refl</span> (<span class=\"conid\">Σ</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>) <span class=\"varid\">x</span> <span class=\"varop\">≡[</span> <span class=\"conid\">Path-Σ</span> <span class=\"varid\">x</span> <span class=\"varid\">x</span> <span class=\"varop\">]≡</span>
(<span class=\"varid\">refl</span> <span class=\"conid\">A</span> (<span class=\"varid\">proj₁</span> <span class=\"varid\">x</span>) ,
<span class=\"varid\">Meta.subst</span> (<span class=\"keyglyph\">\\</span><span class=\"varid\">x1</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">B</span> (<span class=\"varid\">proj₁</span> <span class=\"varid\">x</span>)) <span class=\"varid\">x1</span> (<span class=\"varid\">proj₂</span> <span class=\"varid\">x</span>))
(<span class=\"varid\">subst-refl₁</span> {<span class=\"conid\">B</span> <span class=\"keyglyph\">=</span> <span class=\"conid\">B</span>} {<span class=\"varid\">y</span> <span class=\"keyglyph\">=</span> <span class=\"varid\">proj₂</span> <span class=\"varid\">x</span>})
(<span class=\"varid\">refl</span> (<span class=\"conid\">B</span> (<span class=\"varid\">proj₁</span> <span class=\"varid\">x</span>)) (<span class=\"varid\">proj₂</span> <span class=\"varid\">x</span>)))
</pre><p>And here is a start of the implementation of <tt><span class=\"varid\">cong</span></tt>,
</p><pre class=\"agda\"><span class=\"keyword\">postulate</span>
<span class=\"varid\">cong-const</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>} {<span class=\"varid\">x</span> <span class=\"varid\">x'</span>} {<span class=\"varid\">y</span>} {<span class=\"varid\">p</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">x'</span>}
<span class=\"keyglyph\">→</span> <span class=\"varid\">cong</span> (<span class=\"keyglyph\">\\</span><span class=\"varid\">x</span> <span class=\"keyglyph\">→</span> <span class=\"varid\">y</span>) <span class=\"varid\">p</span> <span class=\"varop\">≡</span> <span class=\"varid\">refl</span> <span class=\"conid\">B</span> <span class=\"varid\">y</span>
<span class=\"varid\">cong-id</span>    <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"varid\">x</span> <span class=\"varid\">x'</span>} {<span class=\"varid\">p</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">x'</span>}
<span class=\"keyglyph\">→</span> <span class=\"varid\">cong</span> (<span class=\"keyglyph\">\\</span><span class=\"varid\">x</span> <span class=\"keyglyph\">→</span> <span class=\"varid\">x</span>) <span class=\"varid\">p</span> <span class=\"varop\">≡</span> <span class=\"varid\">p</span>
<span class=\"varid\">cong-∘</span>     <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span> <span class=\"varid\">c</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"varid\">x</span> <span class=\"varid\">x'</span>} {<span class=\"varid\">p</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">x'</span>}
{<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>} {<span class=\"conid\">C</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">c</span>} {<span class=\"varid\">f</span> <span class=\"varop\">:</span> <span class=\"conid\">B</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">C</span>} {<span class=\"varid\">g</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>}
<span class=\"keyglyph\">→</span> <span class=\"varid\">cong</span> (<span class=\"keyglyph\">\\</span><span class=\"varid\">x</span> <span class=\"keyglyph\">→</span> <span class=\"varid\">f</span> (<span class=\"varid\">g</span> <span class=\"varid\">x</span>)) <span class=\"varid\">p</span> <span class=\"varop\">≡</span> <span class=\"varid\">cong</span> <span class=\"varid\">f</span> (<span class=\"varid\">cong</span> <span class=\"varid\">g</span> <span class=\"varid\">p</span>)
<span class=\"comment\">-- etc.</span>
</pre><p>At some point I think you will also need a dependent <tt><span class=\"varid\">cong</span></tt>.
</p><p>But this is enough postulating for one day.
</p>" nil nil "9639c3b5300fc194bc004a619c61a389") (168 (20949 25792 529712) "http://wadler.blogspot.com/2013/06/a-perverted-view-of-impact.html" "Philip Wadler: A perverted view of \"impact\"" "noreply@blogger.com (Philip Wadler)" "Fri, 21 Jun 2013 16:34:31 +0000" "<div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://3.bp.blogspot.com/-5sYTh32tOSQ/UcR-z3Eze2I/AAAAAAAACcI/9AUvZRJBo-M/s1600/impact1.jpg\"><img src=\"http://3.bp.blogspot.com/-5sYTh32tOSQ/UcR-z3Eze2I/AAAAAAAACcI/9AUvZRJBo-M/s320/impact1.jpg\" height=\"160\" border=\"0\" width=\"320\" /></a></div>I think the emphasis on impact in UK research can be counterproductive. Jeremy Gibbons alerted me to this <a href=\"http://www.sciencemag.org/content/340/6138/1265.full\">op-ed by Marc Kirschner</a> in Science, pointing out that the situation is even more severe in the US biomedical community, where the search for \"impact\" leads to focus on human medicine, to the detriment of fundamental studies.<br /><blockquote class=\"tr_bq\">One may be able to recognize good science as it happens, but significant science can only be viewed in the rearview mirror. To pretend otherwise distorts science. DNA restriction enzymes, once the province of obscure microbiological investigation, ultimately enabled the entire recombinant DNA revolution. Measurement of the ratios of heavy and light isotopes of oxygen, once a limited area of geochemistry, eventually allowed the interpretation of prior climate change. What is now promoted as high-impact science is usually a narrow extension of existing experimental designs in a program focused on a set of feasible goals. Fuzzy new directions that might fail, but could open up major new questions, are often dismissed as too speculative and considered low-impact. And in biomedical science, there is an increasing tendency to equate significance to any form of medical relevance. This causes biochemical investigations and research on nonmammalian systems to be treated as intrinsically less valuable than studies on human cells. As a result, biomedicine is losing the historically productive cross-fertilization between model systems and human biology.</blockquote><div><br /></div>" nil nil "6d1161c0103a6846c483e8d0fdb0dc51") (167 (20949 25792 529273) "http://www.joachim-breitner.de/blog/archives/599-Haskell-and-Debian-talk-at-HaL8.html" "Joachim Breitner: Haskell and Debian talk at HaL8" "mail@joachim-breitner.de (nomeata)" "Fri, 21 Jun 2013 16:04:45 +0000" "<p>I just finished my “Haskell und Debian” talk at the Haskell-Workshop <a href=\"http://www.bioinf.uni-leipzig.de/conference-registration/13haskell/de/Start.html\">HaL8 in Leipzig</a>. Unfortunately I was thrown a off track by time constraints and since there were much less beginners and interested visitors in the audience than I had anticipated, so I skipped some parts and improvised others somewhat chaotically, so the presentation was not up to the standards that I expect from my talks. If you have attended (or if you have not) I recommend you have a look <a href=\"http://www.bioinf.uni-leipzig.de/conference-registration/13haskell/papers/paper_1.pdf\">at the extended abstract</a> (in German), which contains what I skipped and is much clearer than what I said.</p>" nil nil "86ffad58b09f38819f08eefb668c7812") (166 (20949 25792 528710) "http://lambdacube3d.wordpress.com/2013/06/21/a-few-thoughts-on-geometry-shaders/" "LambdaCube: A few thoughts on geometry shaders" nil "Fri, 21 Jun 2013 08:34:03 +0000" "<p>We just added a new example to the LambdaCube repository, which shows off <a href=\"https://github.com/csabahruska/lc-dsl/tree/master/samples/cubemap\" title=\"LambdaCube cube mapping example\">cube map based reflections</a>. Reflections are rendered by sampling a cube map, which is created by rendering the world from the centre of the reflecting object in six directions. This is done in a single pass, using a geometry shader to replicate every incoming triangle six times. Here is the final result:</p>
<div style=\"width: 640px;\" id=\"attachment_334\" class=\"wp-caption aligncenter\"><a href=\"http://lambdacube3d.files.wordpress.com/2013/06/cubemap-example1.png\"><img src=\"http://lambdacube3d.files.wordpress.com/2013/06/cubemap-example1.png?w=630&h=354\" alt=\"Reflecting surface simulated with cube mapping\" height=\"354\" class=\"size-full wp-image-334\" width=\"630\" /></a><p class=\"wp-caption-text\">Reflecting surface simulated with cube mapping</p></div>
<p>While the main focus of this blog is language and API design, we need to describe the pipeline structure of the example to put the rest of the discussion into context. The high-level structure corresponds to the following data-flow graph:</p>
<div style=\"width: 640px;\" id=\"attachment_340\" class=\"wp-caption aligncenter\"><a href=\"http://lambdacube3d.files.wordpress.com/2013/06/cubemap-example-pipeline1.png\"><img src=\"http://lambdacube3d.files.wordpress.com/2013/06/cubemap-example-pipeline1.png?w=630&h=261\" alt=\"Pipeline structure for the cube map example\" height=\"261\" class=\"size-full wp-image-340\" width=\"630\" /></a><p class=\"wp-caption-text\">Pipeline structure for the cube map example</p></div>
<p>The most important observation is that several pieces of this graph are reused multiple times. For instance, all geometry goes through the model-view transformation, but sometimes this is performed in a vertex shader (VS), sometimes in a geometry shader (GS). Also, the same lighting equation is used when creating the reflection map as well as the non-reflective parts of the final rendering, so the corresponding fragment shader (FS) is shared.</p>
<h2>The Good</h2>
<p>For us, the most important result of writing this example was that we could express all the above mentioned instances of shared logic in a straightforward way. The high-level graph structure is captured by the top declarations in <strong>sceneRender</strong>’s definition:</p>
<pre style=\"padding-bottom: 0;\"><span style=\"color: #0000ff;\">sceneRender</span> <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">Accumulate</span> accCtx <span style=\"color: #228b22;\">PassAll</span> reflectFrag (<span style=\"color: #228b22;\">Rasterize</span> rastCtx reflectPrims) directRender
<span style=\"color: #a020f0;\">where</span>
directRender <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">Accumulate</span> accCtx <span style=\"color: #228b22;\">PassAll</span> frag (<span style=\"color: #228b22;\">Rasterize</span> rastCtx directPrims) clearBuf
cubeMapRender <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">Accumulate</span> accCtx <span style=\"color: #228b22;\">PassAll</span> frag (<span style=\"color: #228b22;\">Rasterize</span> rastCtx cubePrims) clearBuf6
accCtx <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">AccumulationContext</span> <span style=\"color: #228b22;\">Nothing</span> (<span style=\"color: #228b22;\">DepthOp</span> <span style=\"color: #228b22;\">Less</span> <span style=\"color: #228b22;\">True</span> <span style=\"color: #228b22;\">:.</span> <span style=\"color: #228b22;\">ColorOp</span> <span style=\"color: #228b22;\">NoBlending</span> (one' <span style=\"color: #a0522d;\">::</span> <span style=\"color: #228b22;\">V4B</span>) <span style=\"color: #228b22;\">:.</span> <span style=\"color: #228b22;\">ZT</span>)
rastCtx <span style=\"color: #a0522d;\">=</span> triangleCtx { ctxCullMode <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">CullFront</span> <span style=\"color: #228b22;\">CCW</span> }
clearBuf <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">FrameBuffer</span> (<span style=\"color: #228b22;\">DepthImage</span> n1 1000 <span style=\"color: #228b22;\">:.</span> <span style=\"color: #228b22;\">ColorImage</span> n1 (<span style=\"color: #228b22;\">V4</span> 0<span style=\"color: #a0522d;\">.</span>1 0<span style=\"color: #a0522d;\">.</span>2 0<span style=\"color: #a0522d;\">.</span>6 1) <span style=\"color: #228b22;\">:.</span> <span style=\"color: #228b22;\">ZT</span>)
clearBuf6 <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">FrameBuffer</span> (<span style=\"color: #228b22;\">DepthImage</span> n6 1000 <span style=\"color: #228b22;\">:.</span> <span style=\"color: #228b22;\">ColorImage</span> n6 (<span style=\"color: #228b22;\">V4</span> 0<span style=\"color: #a0522d;\">.</span>05 0<span style=\"color: #a0522d;\">.</span>1 0<span style=\"color: #a0522d;\">.</span>3 1) <span style=\"color: #228b22;\">:.</span> <span style=\"color: #228b22;\">ZT</span>)
worldInput <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">Fetch</span> <span style=\"color: #8b2252;\">\"geometrySlot\"</span> <span style=\"color: #228b22;\">Triangles</span> (<span style=\"color: #228b22;\">IV3F</span> <span style=\"color: #8b2252;\">\"position\"</span>, <span style=\"color: #228b22;\">IV3F</span> <span style=\"color: #8b2252;\">\"normal\"</span>)
reflectInput <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">Fetch</span> <span style=\"color: #8b2252;\">\"reflectSlot\"</span> <span style=\"color: #228b22;\">Triangles</span> (<span style=\"color: #228b22;\">IV3F</span> <span style=\"color: #8b2252;\">\"position\"</span>, <span style=\"color: #228b22;\">IV3F</span> <span style=\"color: #8b2252;\">\"normal\"</span>)
directPrims <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">Transform</span> directVert worldInput
cubePrims <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">Reassemble</span> geom (<span style=\"color: #228b22;\">Transform</span> cubeMapVert worldInput)
reflectPrims <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">Transform</span> directVert reflectInput</pre>
<p>The top-level definition describes the last pass, which draws the reflective capsule – whose geometry is carried by the primitive stream <strong>reflectPrims</strong> – on top of the image emitted by a previous pass called <strong>directRender</strong>. The two preceding passes render the scene without the capsule (<strong>worldInput</strong>) on a screen-sized framebuffer as well as the cube map. We can see that the pipeline section generating the cube map has a <strong>reassemble</strong> phase, which corresponds to the geometry shader. Note that these two passes have no data dependencies between each other, so they can be executed in any order by the back-end.</p>
<p>It’s clear to see how the same fragment shader is used in the first two passes. The more interesting story is finding a way to express the model-view transformation in one place and use it both in <strong>directVert</strong> and <strong>geom</strong>. As it turns out, we can simply extract the common functionality and give it a name. The function we get this way is frequency agnostic, which is reflected in its type:</p>
<pre style=\"padding-bottom: 0;\">    transformGeometry <span style=\"color: #a0522d;\">::</span> <span style=\"color: #228b22;\">Exp</span> f <span style=\"color: #228b22;\">V4F</span> <span style=\"color: #a0522d;\">-></span> <span style=\"color: #228b22;\">Exp</span> f <span style=\"color: #228b22;\">V3F</span> <span style=\"color: #a0522d;\">-></span> <span style=\"color: #228b22;\">Exp</span> f <span style=\"color: #228b22;\">M44F</span> <span style=\"color: #a0522d;\">-></span> (<span style=\"color: #228b22;\">Exp</span> f <span style=\"color: #228b22;\">V4F</span>, <span style=\"color: #228b22;\">Exp</span> f <span style=\"color: #228b22;\">V4F</span>, <span style=\"color: #228b22;\">Exp</span> f <span style=\"color: #228b22;\">V3F</span>)
transformGeometry localPos localNormal viewMatrix <span style=\"color: #a0522d;\">=</span> (viewPos, worldPos, worldNormal)
<span style=\"color: #a020f0;\">where</span>
worldPos <span style=\"color: #a0522d;\">=</span> modelMatrix <span style=\"color: #a0522d;\">@*.</span> localPos
viewPos <span style=\"color: #a0522d;\">=</span> viewMatrix <span style=\"color: #a0522d;\">@*.</span> worldPos
worldNormal <span style=\"color: #a0522d;\">=</span> normalize' (v4v3 (modelMatrix <span style=\"color: #a0522d;\">@*.</span> n3v4 localNormal))</pre>
<p>The simpler use case is <strong>directVert</strong>, which simply wraps the above functionality in a vertex shader:</p>
<pre style=\"padding-bottom: 0;\">    directVert <span style=\"color: #a0522d;\">::</span> <span style=\"color: #228b22;\">Exp</span> <span style=\"color: #228b22;\">V</span> (<span style=\"color: #228b22;\">V3F</span>, <span style=\"color: #228b22;\">V3F</span>) <span style=\"color: #a0522d;\">-></span> <span style=\"color: #228b22;\">VertexOut</span> <span style=\"color: #228b22;\">()</span> (<span style=\"color: #228b22;\">V3F</span>, <span style=\"color: #228b22;\">V3F</span>, <span style=\"color: #228b22;\">V3F</span>)
directVert attr <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">VertexOut</span> viewPos (floatV 1) <span style=\"color: #228b22;\">ZT</span> (<span style=\"color: #228b22;\">Smooth</span> (v4v3 worldPos) <span style=\"color: #228b22;\">:.</span> <span style=\"color: #228b22;\">Smooth</span> worldNormal <span style=\"color: #228b22;\">:.</span> <span style=\"color: #228b22;\">Flat</span> viewCameraPosition <span style=\"color: #228b22;\">:.</span> <span style=\"color: #228b22;\">ZT</span>)
<span style=\"color: #a020f0;\">where</span>
(localPos, localNormal) <span style=\"color: #a0522d;\">=</span> untup2 attr
(viewPos, worldPos, worldNormal) <span style=\"color: #a0522d;\">=</span> transformGeometry (v3v4 localPos) localNormal viewCameraMatrix</pre>
<p>As for the geometry shader…</p>
<h2>The Bad</h2>
<p>… we already mentioned in <a href=\"http://lambdacube3d.wordpress.com/2012/09/07/the-lambdacube-3d-pipeline-model/\" title=\"The LambdaCube 3D pipeline model\">the introduction of our functional pipeline model</a> that we aren’t happy with the current way of expressing geometry shaders. The current approach is a very direct mapping of two nested for loops as an initialisation function and two state transformers – essentially <em>unfold</em> kernels. The outer loop is responsible for one primitive per iteration, while the inner loop emits the individual vertices. Without further ado, here’s the geometry shader needed by the example:</p>
<pre style=\"padding-bottom: 0;\">    geom <span style=\"color: #a0522d;\">::</span> <span style=\"color: #228b22;\">GeometryShader</span> <span style=\"color: #228b22;\">Triangle</span> <span style=\"color: #228b22;\">Triangle</span> <span style=\"color: #228b22;\">()</span> <span style=\"color: #228b22;\">()</span> 6 <span style=\"color: #228b22;\">V3F</span> (<span style=\"color: #228b22;\">V3F</span>, <span style=\"color: #228b22;\">V3F</span>, <span style=\"color: #228b22;\">V3F</span>)
geom <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">GeometryShader</span> n6 <span style=\"color: #228b22;\">TrianglesOutput</span> 18 init prim vert
<span style=\"color: #a020f0;\">where</span>
init attr <span style=\"color: #a0522d;\">=</span> tup2 (primInit, intG 6)
<span style=\"color: #a020f0;\">where</span>
primInit <span style=\"color: #a0522d;\">=</span> tup2 (intG 0, attr)
prim primState <span style=\"color: #a0522d;\">=</span> tup5 (layer, layer, primState', vertInit, intG 3)
<span style=\"color: #a020f0;\">where</span>
(layer, attr) <span style=\"color: #a0522d;\">=</span> untup2 primState
primState' <span style=\"color: #a0522d;\">=</span> tup2 (layer <span style=\"color: #a0522d;\">@+</span> intG 1, attr)
vertInit <span style=\"color: #a0522d;\">=</span> tup3 (intG 0, viewMatrix, attr)
viewMatrix <span style=\"color: #a0522d;\">=</span> indexG (map cubeCameraMatrix [1<span style=\"color: #a0522d;\">..</span>6]) layer
vert vertState <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">GeometryOut</span> vertState' viewPos pointSize <span style=\"color: #228b22;\">ZT</span> (<span style=\"color: #228b22;\">Smooth</span> (v4v3 worldPos) <span style=\"color: #228b22;\">:.</span> <span style=\"color: #228b22;\">Smooth</span> worldNormal <span style=\"color: #228b22;\">:.</span> <span style=\"color: #228b22;\">Flat</span> cubeCameraPosition <span style=\"color: #228b22;\">:.</span> <span style=\"color: #228b22;\">ZT</span>)
<span style=\"color: #a020f0;\">where</span>
(index, viewMatrix, attr) <span style=\"color: #a0522d;\">=</span> untup3 vertState
vertState' <span style=\"color: #a0522d;\">=</span> tup3 (index <span style=\"color: #a0522d;\">@+</span> intG 1, viewMatrix, attr)
(attr0, attr1, attr2) <span style=\"color: #a0522d;\">=</span> untup3 attr
(localPos, pointSize, <span style=\"color: #a020f0;\">_</span>, localNormal) <span style=\"color: #a0522d;\">=</span> untup4 (indexG [attr0, attr1, attr2] index)
(viewPos, worldPos, worldNormal) <span style=\"color: #a0522d;\">=</span> transformGeometry localPos localNormal viewMatrix</pre>
<p>The <strong>init</strong> function’s sole job is to define the initial state and iteration count of the outer loop. The initial state is just a loop counter set to zero plus the input of the shader in a single tuple called <strong>attr</strong>, while the iteration count is <strong>6</strong>. The <strong>prim</strong> function takes care of increasing this counter, specifying the layer for the primitive (equal to the counter), and picking the appropriate view matrix from one of six uniforms. It defines the iteration count (<strong>3</strong>, since we’re drawing triangles) and the initial state of the inner loop, which contains another counter set at zero, the chosen view matrix, and the attribute tuple. Finally, the <strong>vert</strong> function calculates the output attributes using <strong>transformGeometry</strong>, and also its next state, which only differs from the current one in having the counter incremented.</p>
<p>On one hand, we had success in reusing the common logic between different shader stages by simply extracting it as a pure function. On the other, it is obvious at this point that directly mapping imperative loops results in really awkward code. At least it does the job!</p>
<p><span style=\"text-align: center; display: block;\" class=\"embed-youtube\"><iframe class=\"youtube-player\" frameborder=\"0\" height=\"385\" src=\"http://www.youtube.com/embed/9f5oSv1SZiE?version=3&amp;rel=1&amp;fs=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent\" type=\"text/html\" width=\"630\"></iframe></span></p>
<h2>The Next Step?</h2>
<p>We’ve been thinking about alternative ways to model geometry shaders that would allow a more convenient and ‘natural’ manner of expressing our intent. One option we’ve considered lately would be to have the shader yield a list of lists. This would allow us to use scoping to access attributes in the inner loop instead of having to pass them around explicitly, not to mention doing away with explicit loop counters altogether. We could use existing techniques to generate imperative code, e.g. stream fusion. However, it is an open question how we could introduce lists or some similar structure in the language without disrupting other parts, keeping the use of the new feature appropriately constrained. One thing is clear: there has to be a better way.</p>
<br />  <img src=\"http://stats.wordpress.com/b.gif?host=lambdacube3d.wordpress.com&blog=39087425&post=331&subd=lambdacube3d&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "ea15f383268e24c5a2621214856f0745") (165 (20949 25792 526447) "http://existentialtype.wordpress.com/2013/06/20/the-homotopy-type-theory-book-is-out/" "Robert Harper: The Homotopy Type Theory Book is out!" nil "Thu, 20 Jun 2013 19:49:08 +0000" "<p>By now many of you have heard of the development of Homotopy Type Theory (HoTT), an extension of intuitionistic type theory that provides a natural foundation for doing synthetic homotopy theory.  Last year the <a href=\"http://ias.edu\" target=\"_blank\" title=\"Institute for Advanced Study\">Institute for Advanced Study at Princeton</a> sponsored a program on the <a href=\"http://uf-ias-2012.wikispaces.com/\" target=\"_blank\" title=\"Univalent Foundations Program\">Univalent Foundations of Mathematics</a>, which was concerned with developing these ideas.  One important outcome of the year-long program is a full-scale book presenting the main ideas of Homotopy Type Theory itself and showing how to apply them to various branches of mathematics, including homotopy theory, category theory, set theory, and constructive analysis.  The book is the product of a joint effort by dozens of participants in the program, and is intended to document the state of the art as it is known today, and to encourage its further development by the participation of others interested in the topic (i.e., you!).  Among the many directions in which one may take these ideas, the most important (to me) is to develop a constructive (computational) interpretation of HoTT.  Some partial results in this direction have already been obtained, including fascinating work by Thierry Coquand on developing a constructive version of Kan complexes in ITT, by Mike Shulman on proving homotopy canonicity for the natural numbers in a two-dimensional version of HoTT, and by Dan Licata and me on a weak definitional canonicity theorem for a similar two-dimensional theory.  Much work remains to be done to arrive at a fully satisfactory constructive interpretation, which is essential for application of these ideas to computer science.  Meanwhile, though, great progress has been made on using HoTT to formulate and formalize significant pieces of mathematics in a new, and strikingly beautiful, style, that are well-documented in the book.</p>
<p>The book is <a href=\"http://homotopytypetheory.org/book\" target=\"_blank\" title=\"Homotopy Type Theory Book\">freely available on the web</a> in various formats, including a PDF version with active references, an ebook version suitable for your reading device, and may be purchased in hard- or soft-cover from Lulu.  The book itself is open source, and is available at the <a href=\"http://github.com/hott/book\" target=\"_blank\" title=\"HoTT Book Git Hub\">Hott Book Git Hub</a>.  The book is under the Creative Commons  <a href=\"http://creativecommons.org/licenses/by-sa/3.0/\" title=\"Creative Common License\">CC BY-SA</a> license, and will be freely available in perpetuity.</p>
<p>Readers may also be interested in the posts on <a href=\"http://www.homotopytypetheory.org/2013/06/20/the-hott-book/\" target=\"_blank\" title=\"Homotopy Type Theory Book Announcement\">Homotopy Type Theory</a>, the <a href=\"http://golem.ph.utexas.edu/category/2013/06/the_hott_book.html\" title=\"n-Category Cafe Hott Book\">n-Category Cafe</a>, and <a href=\"http://math.andrej.com/2013/06/20/the-hott-book/\" title=\"Mathematics and Computation HoTT Book\">Mathematics and Computation</a> which describe more about the book and the process of its creation.</p>
<br />Filed under: <a href=\"http://existentialtype.wordpress.com/category/research/\">Research</a> Tagged: <a href=\"http://existentialtype.wordpress.com/tag/category-theory/\">category theory</a>, <a href=\"http://existentialtype.wordpress.com/tag/homotopy-theory/\">homotopy theory</a>, <a href=\"http://existentialtype.wordpress.com/tag/type-theory/\">type theory</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/existentialtype.wordpress.com/806/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/existentialtype.wordpress.com/806/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=existentialtype.wordpress.com&blog=2157150&post=806&subd=existentialtype&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "779b0106c5e914f76187985f13ddd5cd") (164 (20949 25792 525728) "http://joyful.com/blog/2013-06-17-darcsden-cleanup.html" "Simon Michael: darcsden cleanup" nil "Wed, 19 Jun 2013 01:15:00 +0000" "<div style=\"font-style: italic;\">June 19, 2013</div>
<h2>darcsden cleanup</h2>
<p>
</p><p>Back to the dev diary. <a href=\"http://joyful.com/2013-06-07-git-hooks-for-site-updates.html\">Last post</a> was 11 days ago, after a two-week opening streak of daily posts. I got blocked on one, then got busy. Press on.</p>
<p>Yesterday I started looking at BSRK Aditya’s <a href=\"http://bsrkaditya.blogspot.com/2013/06/gsoc-2013-enhancing-darcsden-preweek-1.html\">GSOC darcsden enhancements</a>, to review and hopefully deploy on <a href=\"http://hub.darcs.net\">darcs hub</a>. So far he has worked on alternate login methods (github/google), password reminder, and darcs pack support (for faster gets).</p>
<p>This is forcing some darcsden cleanup, my first darcsden work in a while aside from routine ops and support tasks. I’m going to release what’s in trunk as 1.1, and then start assimilating the new work by BSRK, Ganesh Sittampalam and anyone else who feels like chipping in. Started putting together release notes and a hub status update.</p>
<p>The support requests seem to be on the rise - more usage ? I also found a good bug today: viewing a certain 1K troff file causes darcs hub’s memory footprint to <a href=\"http://hub.darcs.net/simon/darcsden/issue/58\">blow up to 1.5G</a> :)</p>
<p>It would be great to have more functionality (like highlighting) broken out into separate, expendable worker processes, erlang style.</p>" nil nil "6e78d671b335a4f5356cf5742d89f7e9") (163 (20949 25792 525323) "http://functionaljobs.com/jobs/154-senior-software-developer-functional-programmer-at-vector-fabrics" "Functional Jobs: Senior software developer/Functional programmer at Vector Fabrics (Full-time)" nil "Tue, 18 Jun 2013 12:44:48 +0000" "<p>Vector Fabrics is hiring: we are looking for a top-notch programmer to extend our program-analysis and parallelization products. You design and implement algorithms to assist the programmer to create a parallel design from a sequential C or C++ program. You work with our international team of world-class computer scientists and experts in the Haskell / OCaml functional programming languages.</p>
<p>Your work is at the forefront of technology, giving you the opportunity to publish your work in major conferences and directly cooperate with processor design companies and domain-specific application vendors.</p>
<p>As we are a startup company, you will quickly have a major impact on our products and get to know all aspects of product creation. You will be part of a strongly committed development team and contribute to our agile development process and automated test suites. Interested? Send your CV, GitHub account or other proof of what you can do to <span class=\"spam-protect\"><span class=\"user\">jobs</span> [at] <span class=\"host\">vectorfabrics [dot] com</span></span>.</p>
<h3>Responsibilities</h3>
<ul>
<li>Design and implement software
optimization (e.g. parallelization)
algorithms for CPUs and GPUs;</li>
<li>Thoroughly test your code, create
automated test suites;</li>
<li>Contribute to our agile development
planning and process;</li>
<li>Analyze complex customer applications
for optimization opportunities and
translate this to new analysis
algorithms.</li>
</ul>
<h3>Profile</h3>
<ul>
<li>Your friends and colleagues describe
you as a superb programmer; your
programming ability is way above
average;</li>
<li>Demonstrable experience in design and
implementation of complex software
applications; prior experience in
functional programming languages is
preferred;</li>
<li>You continuously surprise us with
your creative yet pragmatic solutions
for complex software problems;</li>
<li>You are strongly committed to deliver
working software as early as
possible;</li>
<li>You work against very high quality
standards. Refactoring is your bread
and butter, pair-programming is how
you prefer to review your code;</li>
<li>Whatever technologies, languages, or
development environments you've been
using, we expect you have mastered
them in depth, and we expect that you
will be able to master any
technology, language, or development
environment that we need in the
future;</li>
<li>Excellent command of written and
spoken English.</li>
</ul>
<h3>Education</h3>
<p>MSc, MEng or PhD in Computer Science or significant relevant experience.</p>
<h3>About Vector Fabrics</h3>
<p>Vector Fabrics is a high-tech software company, developing tools for embedded multicore programming. Its technology and expertise is getting widespread recognition in the industry as being innovative and unique in their ability to address heterogeneous multicore application-specific silicon platforms. Due to the advanced nature of its tools, Vector Fabrics operates at the forefront of the next generation of embedded platforms for diverse markets ranging from supercomputers to automotive to cell phones.</p>
<p>Vector Fabrics puts absolute priority on hiring top class individuals in key positions. Vector Fabrics’ team profile is exceptional and its ambition is to hire only individuals that match or surpass that profile. The company pays top salary and offers a challenging, engaging and stimulating work environment with a high degree of responsibility.</p>
<p>Get information on <a href=\"http://functionaljobs.com/jobs/154-senior-software-developer-functional-programmer-at-vector-fabrics\">how to apply</a> for this position.</p>" nil nil "d5eabd288ce667f8447e8202a658e899") (162 (20949 25792 524613) "http://feedproxy.google.com/~r/FpComplete/~3/o-o2AKSmDZc/beta-sign-up" "FP Complete: FP Haskell Center Beta Sign-Up" nil "Mon, 17 Jun 2013 14:42:00 +0000" "<h4>Beta sign-up Blog</h4><p>It’s almost here!  After months of hard work by our engineers, I am pleased to announce that we’ve opened up sign-up for <a href=\"http://feeds.feedburner.com/business/designer-ide\">beta of FP Haskell Center</a>, the world's first commercial Haskell IDE and deployment platform.  The beta will be released by the end of the month, and we are eager to have your active testing and feedback so we can deliver a great product that the market needs in early September.  As an appreciation and reward for being in the beta program, we will offer special incentives to the finished product when available.  Details of the offer will be announced in late July/early August.</p><p>The IDE includes a Haskell compiler and a continually updated set of vetted, tested and supported libraries and code templates.  There is no need to run Cabal or other installers.  The FP Haskell Application Server is used to deploy and run Haskell applications directly in the cloud with no additional effort.  A free shared instance is included with every account. Larger and dedicated instances are available for active project deployments at a reasonable monthly charge.</p><h4>FP Haskell Center’s key features and benefits are:</h4><ul><li>Simplifies the writing and deploying of Haskell applications from a single online dashboard.</li><li>Cloud-based development frees you to move among multiple devices without needing your own functioning Haskell environment.</li><li>Integrated deployment frees you from needing to run a specific OS to match build and production environments.</li><li>A hierarchical module tree for:</li><li>convenient management (renaming, moving, deleting modules or whole trees)</li><li>navigation (much easier to read, expand/collapse)</li><li>Regular, automatic parsing and type checking as feedback inside the editor and unobtrusive error output below.</li><li>Type and documentation inspection of names.</li><li>Integrated access to sample code, School of Haskell tutorials, Haddock documentation service, and Hoogle resource database.</li></ul><p>Sign-up for <a href=\"http://feeds.feedburner.com/business/haskell-center\">beta of FP Haskell Center</a>.</p><div class=\"feedflare\">
<a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=o-o2AKSmDZc:zpOQ0FhJErU:yIl2AUoC8zA\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=yIl2AUoC8zA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=o-o2AKSmDZc:zpOQ0FhJErU:V_sGLiPBpWU\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=o-o2AKSmDZc:zpOQ0FhJErU:V_sGLiPBpWU\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=o-o2AKSmDZc:zpOQ0FhJErU:qj6IDK7rITs\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=qj6IDK7rITs\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=o-o2AKSmDZc:zpOQ0FhJErU:gIN9vFwOqvQ\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=o-o2AKSmDZc:zpOQ0FhJErU:gIN9vFwOqvQ\" border=\"0\" /></a>
</div><img src=\"http://feeds.feedburner.com/~r/FpComplete/~4/o-o2AKSmDZc\" height=\"1\" width=\"1\" />" nil nil "22a6a917ca09fbcd2a3acebe5ebe140a") (161 (20949 25792 524056) "http://feedproxy.google.com/~r/FpComplete/~3/YGZb2pYnjPw/interim-web-site" "FP Complete: Interim Web Site" nil "Mon, 17 Jun 2013 12:42:00 +0000" "<h4>Interim Site blog</h4><p>Welcome to our updated website! FP Complete is evolving into a full-fledged commercial developer of Haskell tools and services, as called for in our original plans.  The previous site showcased the School of Haskell. We have been delighted to see it used by thousands of Haskell learners and teachers, including some authors who’ve taken advantage of its unique Active Code features to help people learn.  Now that we are about to release the FP Haskell Center beta, the School remains an integral part of our offering as a place to teach and learn, but we are even more excited by the new full-powered commercial features.</p><p>This site is an interim redesign, and will be completed when we release FP Haskell Center, the world’s first commercial Haskell IDE and deployment platform, in early September.  The site, and our strategy, are based on 3 pillars:</p><ol><li>We must produce products and services needed by developers who are already using Haskell tools in their work. This is our base.</li><li>At the same time, we need to promote Haskell to the vastly larger non-Haskeller market which on the whole is unaware of Haskell’s existence.  This is a long-term effort that’s absolutely necessary if Haskell is going to have meaningful adoption in the mainstream market.  That’s why you see us putting a lot of effort into high-level discussions and information about what Haskell is, its feature advantages and strategic benefits.  The target audience is business management, engineering management and developers who need to be converted into Haskell supporters and users.  </li><li>In all our efforts, we are always working with the Haskell community.  FP Complete was started in 2012 with the help of some of the leaders of the community and is committed to continue working with the entire community to advance the technology and expand Haskell adoption in the commercial market.  This follows a well-proven model of success for companies commercializing open-source technologies starting with Red Hat.</li></ol><p>In the coming months, we will be continually adding more content to fulfill our goal to be a major resource for all things Haskell.  Things like more whitepapers, case studies, video testimonials, tutorials and sample codes.  If you have any suggestions or things to contribute, be sure to let us know.  As always, we welcome constructive comments from the community.</p><div class=\"feedflare\">
<a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=YGZb2pYnjPw:Cjpscs1vI9g:yIl2AUoC8zA\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=yIl2AUoC8zA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=YGZb2pYnjPw:Cjpscs1vI9g:V_sGLiPBpWU\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=YGZb2pYnjPw:Cjpscs1vI9g:V_sGLiPBpWU\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=YGZb2pYnjPw:Cjpscs1vI9g:qj6IDK7rITs\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=qj6IDK7rITs\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=YGZb2pYnjPw:Cjpscs1vI9g:gIN9vFwOqvQ\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=YGZb2pYnjPw:Cjpscs1vI9g:gIN9vFwOqvQ\" border=\"0\" /></a>
</div><img src=\"http://feeds.feedburner.com/~r/FpComplete/~4/YGZb2pYnjPw\" height=\"1\" width=\"1\" />" nil nil "695d299721c8e0e8cb689c6cdf730c98") (160 (20949 25792 523335) "http://logicaltypes.blogspot.com/2013/06/thoughts-on-kleisli-arrows-in-java-wip.html" "Douglas M. Auclair (geophf): Thoughts on Kleisli Arrows in Java (WIP)" "noreply@blogger.com (geophf)" "Mon, 17 Jun 2013 12:39:32 +0000" "Here are some ramblings as I puzzle my way through on how to represent Kleisli arrows in Java (and why I would want to do that, anyway). This is very much a work in progress, so no solid conclusions from this posting.<br /><br /><br />Categories are abstractions. They have objects and morphisms. The thing of Category theory is that the objects can be anything, as they are atomic, and the morphisms aren't necessarily functions. So, the objects can be numbers, not that we care, or they could be arrows (another term for morphisms), or they could be categories themselves, so the morphisms become morphisms between categories. Or if the objects are arrows then the morphisms are higher-order functions.<br /><br />Neat-o!<br /><br />So, John Baez did some wonderful pieces on higher-order categories in the direction of physical math: topologies and groups and such, and this was replicated in Edward Kmett's work with ... what are they called? Ah, yes: semigroupoids (how could I forget), where the monoids have no zero bases and so identity functions aren't necessary, I suppose.<br /><br />Interesting! Half-monoids!<br /><br />But if we look at Categories as simply that: objects and morphisms, and we look at morphisms as simply arrows from a to b, then does that simplify my implementation of my categories library?<br /><br />Monads no longer are generically typeful but now use inheritance to describe the type families:<br /><br />Monad<a> is the interface and Maybe<a> extends Monad<a> instead of<br /><br />Monad<M extends Monad, a> being the interface as Maybe<a> extends Monad<Maybe, a>.<br /><br />The problem is in the generic functions, how does one grab the 'm' in the monadic type? Or is it as simple as using inheritance and forgetting the thorny problem of genericity, or passing that problem off to the inheritance structure?<br /><br />Same thing for Arrow ...<br /><br />instead of Arrow<a, b, c><br /><br />we have Arrow<b, c><br /><br />and then the Kleisli arrow becomes more simple, perhaps? Because<br /><br />KleisliArrow<m, b, c> extends Arrow<b, m c><br /><br />... but how does that work? Can it work? I don't see how that works.<br /><br />for first :: a b c -> a (b, d) (c, d)<br /><br />how does that work for the KleisliArrow, and for chaining the monadic computation?<br /><br />It appears further research is necessary for me to get a solid grasp of this to be able to implement this properly in Java (as opposed to writing a haskell parser on top of Java, which is also a viable way of going about it, except for the fact that there is political resistance to learning a domain-specific language from devs brought on to code 'only' in language-of-choice X).<br /><br />So that's my problem, because in my 'Monads in Java' article I concluded with a:<br /><br />So you see we can now do the following:<br /><br />f.apply(m).bind(g).bind(h)<br /><br />and I now know that f.apply(m) is a weakness in coding. This should all be strung together with Kleisli arrows and the resulting morphism be run through the Kleisli computer.<br /><br />\"The (explicit) use of apply considered harmful\"?<br /><br />I mean, Gah! How bold! How daring! How so against the grain!<br /><br />And it isn't even really 'harmful' either. More like obtuse or obnoxious. And not even that, more like: inelegant. That's the word: inelegant. And we're not even 'using' apply in the above computation. I mean, we are, but we are always using apply. It's so inherent that now just juxtaposition is now apply, so it's not the '(explicit) use' of apply, it's the '(explicit) call' or '(explicit) invocation' of apply that's inelegant.<br /><br />I mean, when I see the above formulation, I now shudder, whereas before I might've said, with a pause so slight it didn't even register, 'What do we do here? Oh, use apply!' knowing, at the back of my mind, that this didn't sit perfectly right, but what else was there to do?<br /><br />Well, with Kleisli composition, there is nothing to do at all, but just do it<br /><br />runKleisli (f <+> g <+> h) m<br /><br />and we're done.<br /><br />Now, how to represent that in Java, ... well, I do have a KleisliArrow type that does return the underlying arrow, but what about composition ... it probably has that, too:<br /><br />f >>> g >>> h<br /><br />But the gnawing problem there is that KleisliArrow is not related to Arrow, because, properly, it isn't: KleisliArrow on a specific monadic type m IS related to Arrow.<br /><br />And I don't know how to represent that in Java.<br /><br />Yet.<br />" nil nil "33e6e65867758c2349d78b3cb9c29021") (159 (20949 25792 522450) "http://hyperq.github.io/blog/trading-a-hacker-approach.html" "hyperq: Trading: a hacker approach?" nil "Mon, 17 Jun 2013 08:19:00 +0000" "<blockquote>
<p>
You are startled by the sound of an alarm. It is followed by an urgent voice
which warns that the Arcada has been boarded by unknown intruders. It ends
abruptly. <br />
> <br />
<a href=\"http://sarien.net/spacequest#anotherhallway\">start of Space Quest I</a>
</p>
</blockquote>
<p>
Most hackers involved in the world of trading enter from the technology side
of the business. And there's two main gateways are via trader enhancement or
trader replacement. Making traders smarter and faster using technology is one
well worn road. There's lots of room to streamline the human trading process:
automation of regular tasks, expansion of back-testing capabilities and easy
gains to be had in better trader dashboards to get information when and where
needed.
</p>
<p>
Trader replacement is a little harder but also hackable. There's plenty of
tricks out there to shave a few msecs of computation and execution time, and
bringing bigdata testing and conversion of a sometimes fuzzy human rule-set
into a more rigorous computational exercise.
</p>
<p>
Either way, a trading runtime ends up paving the cow-paths of institutional
finance which look somewhat like this:
</p>
<img src=\"http://hyperq.github.io/assets/ats_features_diagram.png\" alt=\"design\" width=\"100%\" />
<p>
Over at <a href=\"http://hyperq.github.io\">hyperq</a>, we've been thinking about the above diagram and how to get
together a decent trading runtime. Now when a wildly ambitious objective meets
a meager resource base you have two options:
</p>
<ul class=\"org-ul\">
<li>go on a <a href=\"http://hyperq.github.io/../blog/trading-a-hacker-approach/ENOxd.jpg\">kamikaze</a> death march
</li>
<li>take the team on a <a href=\"http://www.qt.com.au/news/abolish-fringe-benefits-tax-bring-back-long-lunch-/1895360/\">long lunch</a> and redefine
</li>
</ul>
<p>
Since this is all open source, our long lunch redefinitional musings led us to
computer sciencing the bejesus out of the trading problem domain.
</p>
<p>
Here's the alternative design specification document we wrote on one of the
drink coasters:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-haskell\"><span class=\"org-function-name\">trade</span> <span class=\"org-variable-name\">::</span> [<span class=\"org-type\">MarketData</span> a] <span class=\"org-variable-name\">-></span> <span class=\"org-type\">Book</span> b <span class=\"org-variable-name\">-></span> <span class=\"org-type\">IO</span> [<span class=\"org-type\">Order</span> b]
<span class=\"org-function-name\">main</span> <span class=\"org-variable-name\">=</span> forever <span class=\"org-variable-name\">.</span> <span class=\"org-keyword\">do</span> <span class=\"org-variable-name\">.</span> trade
</pre>
</div>
<p>
Having just cut 3 months out of our critical path we even had time for some
Zork:
</p>
<blockquote>
<p>
You are in an open field west of a big white house with a boarded
front door.
There is a small mailbox here.<br />
> <br />
<a href=\"http://thcnet.net/error/index.php\">Zork</a>
</p>
</blockquote>
<p>
Long lunch over and the new specs still seem sweet. Some immediate ideas:
</p>
<ul class=\"org-ul\">
<li>the concept of market data becomes naturally abstractable.  Data can
include multiple sources, news flow or whatever universe observation you
can think of. Do you need the Market prefix?
</li>
<li>there is an immediate reminder of real world interaction with the IO monad.
</li>
<li>subsequent functions scan more easily and can be categorized - often as a
matter of taste.  For example, a complex event process (CEP), a fashionable
big deal in trading system circles, seems logically to have this type:
<div class=\"org-src-container\">
<pre class=\"src src-haskell\"><span class=\"org-function-name\">cep</span> <span class=\"org-variable-name\">::</span> [<span class=\"org-type\">MarketData</span> a] <span class=\"org-variable-name\">-></span> <span class=\"org-type\">MarketData</span> a
</pre>
</div>
<p>
Whether to put this prior to or inside the trade function then becomes a
matter of taste.
</p>
</li>
<li>Should the input be [Maybe MarketData a]? This puts the real world
likelihood of the data feed being down front and center, rather than
designing a system assuming an idealized world and then panicking when
something breaks.
</li>
</ul>
<p>
More generally, a more hacker approach leads you away from bigdata phd
solutions that dominate hft and algorithmic trading and towards the important,
small and obvious stuff (that may not lend themselves to a phd dissertation).
The market is closed (unexpectedly) - I better not try and trade, or I had
better try and trade elsewhere given the sorry state of Book a. Gee, there's a
lot of volatility out and about today - is it a big news day? The last news
piece of note was a facebook announcement. Wow, facebook really tanked but but
zygna didn't - what gives there? Someone must have forgot to turn the market
feed on. etc etc
</p>
<p>
And I suspect this approach leads further to a big, big gap in the market.
Imagine on a busy day in the market you could slow down time. The e-mini
suddenly drops by 1% in the space of a few heartbeats. What just happened?
Rewind the video tape and look more carefully at the last few minutes. Look
back at the news-flow over the last 10 minutes and look for keywords. Check
other markets - are they all tanking or is it just a local event? Or did some
human just enter an extra zero or three again?
</p>
<p>
If you can do all of that in a few seconds your process is way ahead of the
competition. The HFT guys have already panicked and run away to hide behind
their statistical order flow models. Algorithmic trades are pinging their stop
loss instructions blindly creating what may be a forecastable trend.
Meanwhile, discretionary day traders have just noticed a small section of one
of their screen is flashing red…
</p>
<p>
In this zone, a hacker trader with a hacker-like trading process can find all
sorts of edges and market tells.
</p>
<p>
So do we want our trading process to look and feel like a big finance
organizational structure? Or should for hyperq to have a Roger Wilco attitude:
</p>
<blockquote>
<p>
Anyway, I aborted the launch and jetted out of there in an escape pod. I
crawled into the sleep chamber, and the next thing I knew, I woke up in a
trash freighter! Yeah, things didn't look too good, but I blasted out of the
freighter in an old jalopy I resurrected from the rubble.
~ <a href=\"http://spacequest.wikia.com/wiki/Roger's_Dialogue\">Roger Wilco</a>
</p>
</blockquote>
<p>
Much more fun than a death march to pave the cow-paths.
</p>" nil nil "4e7b987ae5448f94b3bcced9b9139493") (158 (20949 25792 521357) "http://justtesting.org/post/53175916852" "Manuel M T Chakravarty: Data Flow Fusion with Series Expressions in Haskell" nil "Mon, 17 Jun 2013 05:39:34 +0000" "<p>We are currently exploring <em>flow fusion</em>, a new fusion method for purely functional array code that overcomes the main limitation of stream fusion, namely stream fusion’s inability to fuse branching streams. Our current flow-fusion prototype in the Glasgow Haskell Compiler manages to achieve a twofold speedup over stream fusion for computing convex hulls of 2D points using the <a href=\"http://en.wikipedia.org/wiki/QuickHull\">QuickHull</a> algorithm. In fact, the code generated by flow fusion is only a few percent points away from hand-written C code. We have summarised all the details in a draft paper <a href=\"http://www.cse.unsw.edu.au/~chak/papers/BCKR13.html\">Data Flow Fusion with Series Expressions in Haskell</a>.</p>" nil nil "b0293428423ebdd45c9b97ca048f28e6") (157 (20949 25792 521034) "http://gentoohaskell.wordpress.com/2013/06/16/call-for-help-wiki-gentoo-org-documentation/" "The Gentoo Haskell Team: Call for help: wiki.gentoo.org documentation" nil "Sun, 16 Jun 2013 19:30:25 +0000" "<p>I’d like to ask gentoo-haskell community for help. We have a nice <a href=\"http://wiki.gentoo.org\">wiki</a> and our project page have moved <a href=\"http://wiki.gentoo.org/wiki/Project:Haskell\">there</a>. But it seems that we don’t have enough documentation quality for end-user application. As a developers we support proper builds and tests for that packages but we are not expert users for many of them. So I’d like to ask community to add some docs and tips for applications you use. This basically means installation, advanced config (examples), interesting use cases, links to external resources (blog posts/documentation) and so on. It can help a lot for new Gentoo users.</p>
<p>The most interesting projects are:</p>
<ul>
<li><a href=\"http://wiki.gentoo.org/wiki/Pandoc\">pandoc</a></li>
<li><a href=\"http://wiki.gentoo.org/wiki/Git-annex\">git-annex</a></li>
<li><a href=\"http://wiki.gentoo.org/wiki/Gitit\">gitit</a></li>
<li><a href=\"http://wiki.gentoo.org/wiki/yi\">yi</a></li>
<li><a href=\"http://wiki.gentoo.org/wiki/Xmonad\">xmonad</a></li>
</ul>
<p>Thanks!</p>
<br />  <a href=\"http://feeds.wordpress.com/1.0/gocomments/gentoohaskell.wordpress.com/86/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/gentoohaskell.wordpress.com/86/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=gentoohaskell.wordpress.com&blog=7667502&post=86&subd=gentoohaskell&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "572902e9fab39b437b1a73b7587bc288") (156 (20949 25792 520591) "http://lambda.jstolarek.com/2013/06/getting-friendly-with-stg/" "Jan Stolarek: Getting friendly with STG" nil "Thu, 13 Jun 2013 20:45:46 +0000" "<p style=\"text-align: justify;\">I’ve been spending last months on developing GHC. No rocket science so far, just a bit of hacking here and there. The biggest thing I am working on is <a href=\"http://hackage.haskell.org/trac/ghc/ticket/6135\">ticket #6135</a>, which is about changing some of the existing <a href=\"http://hackage.haskell.org/trac/ghc/wiki/Commentary/PrimOps\">PrimOps</a> to return unboxed <code>Int#</code> instead of <code>Bool</code>. This means that the result of comparing two unboxed values will be either an unboxed <code>0#</code> or unboxed <code>1#</code>, instead of a tagged pointer to statically allocated object representing <code>True</code> or <code>False</code>. This modification will allow to write branchless algorithms in Haskell. I promise to write about this one day, but today I want to blog about a different topic.</p>
<p style=\"text-align: justify;\">It so happens that things I’ve been doing in GHC require me to make changes in the code generator. This is a bit challenging for me, because the code generator is something that didn’t interest me much when I started to learn about compilers. Probably the main reason for this is that code generation means dealing with assembly. I’ve been programming for about 16 years and only two languages caused me problems when I tried to learn them. Assembly is one of them<sup><a title=\" In case you’re interested, the other one is Io\" href=\"http://lambda.jstolarek.com/2013/06/getting-friendly-with-stg/#footnote_0_1210\" id=\"identifier_0_1210\" class=\"footnote-link footnote-identifier-link\">1</a></sup>. I have been learning it for one year during my studies and, although I had no problems with understanding the idea behind assembly and writing short snippets of code, writing a larger piece of code always ended up in a headache.</p>
<p style=\"text-align: justify;\">It looks that the time has come to overcome my fear. During last months I’ve been reading a lot of assembly generated by GHC and I even made some attempts at writing assembly code by myself (well, using intrinsics, but I guess that counts). But between Haskell source code and the generated executable there are many intermediate steps. From my observations it seems that many Haskellers have basic knowledge of Core – GHC’s intermediate language. Most have also heard about other two intermediate representations used by GHC – STG and Cmm – but it seems that few people know them, unless they hack the compiler. And since I’m hacking the compiler I should probably have more knowledge about these two representations, right?</p>
<p style=\"text-align: justify;\">There’s a classic paper by Simon Peyton-Jones “Implementing lazy functional languages on stock hardware: the Spineless Tagless G-machine”. It is quite long – 87 pages total – and, being published in 1992, it is mostly out of date. These two things kept me from reading it, although I think that being out of date was only a pretext for me to avoid reading almost 90 pages of text. But, since I need to learn about STG, I finally decided to give it a shot. Reading the paper took my four days. Paper is very well written and in general is an easy read. I was afraid that I might not understand formal description of operational semantics of STG, but it turned out to be well explained so I had no problem with that. The major problem turned out to be the amount of knowledge I had to learn while reading. This resulted in problems with fully understanding last sections of the paper. Not because they are more difficult than the initial ones, but because I didn’t fully remember all the details that were discussed earlier. An important question is which information is not up to date. I’m not yet familiar with the existing implementation, but it seems that many things have changed: the Spineless Tagless G-machine is not tagless any more since the introduction of pointer tagging; curried function are now evaluated using eval/apply convention, while the paper describes push/enter; the paper discusses only compilation to C, while currently C back-end is becoming deprecated in favour of native code generator and LLVM; and finally the layout of closures is now slightly different than the one presented in the paper. I am almost certain that garbage collection is also performed differently. These are the differences that I noticed, which means that really a lot has changed since the publication over 20 years ago. Surprisingly, this doesn’t seem like a big problem, because the most important thing is that the paper presents an idea of how STG works, while the mentioned changes are only not so important details.</p>
<p style=\"text-align: justify;\">So, now that I have a basic idea of how STG works, what comes next? There are a few follow up papers:</p>
<ul>
<li style=\"text-align: justify;\">“The STG runtime system (revised)” – an updated description of STG written in 1999 by Simon Peyton Jones and Simon Marlow. I guess it’s also outdated, but still probably worth reading. It has only 65 pages :)</li>
<li style=\"text-align: justify;\">“Making a Fast Curry. Push-Enter vs. Eval-Apply for Higher-order Languages” – this described the mentioned eval/apply and push/enter strategies. Already read this one.</li>
<li style=\"text-align: justify;\">“Faster Laziness Using Dynamic Pointer Tagging” – this will tell you why STG is not tagless. Read this one also.</li>
</ul>
<p>And once I’ll deal with STG I’ll have to learn about Cmm.</p>
<ol class=\"footnotes\"><li id=\"footnote_0_1210\" class=\"footnote\"> In case you’re interested, the other one is <a href=\"http://iolanguage.org/\">Io</a></li></ol>" nil nil "8c8888c588943fd2f01dff1af6714827") (155 (20949 25792 519662) "http://parenz.wordpress.com/2013/06/10/soc-2013/" "Daniil Frumin: Summer of Code" nil "Wed, 12 Jun 2013 14:17:57 +0000" "<p>Hello, everyone!</p>
<p>I’ve decided to reinstate this blog since I’ve got accepted to this year’s Google Summer of Code program. I’ll blog about my updates, stuff that I’ve been working on and bottlenecks and problems I’ve encountered.</p>
<p>My project is a pastebin site using diagrams and <a href=\"http://weblog.luite.com/wordpress/?p=14\">GHCJS</a> to generate embeddable interactive widgets and static images/text in case when the pasted code does not require additional interaction. My mentor is Luite Stegeman, and Brent Yorgey and other nice people from the diagrams community has agreed to help.</p>
<p>I am very excited about this and happy that I’ve got a whole bunch of smart people to help me with this.</p>
<p>Unfortunately, as we haven’t sorted out a completely safe way to evaluate code coming from 3rd parties, there is no public version hosted anywhere yet. Meanwhile, there is a <a href=\"https://github.com/co-dan/interactive-diagrams\">project on GitHub</a>.</p>
<p>Hopefully, soon I’ll be able to publish a post about my experience with bootstrapping GHCJS.<br />
Until then, stay tuned!</p>
<br /> Tagged: <a href=\"http://parenz.wordpress.com/tag/diagrams/\">diagrams</a>, <a href=\"http://parenz.wordpress.com/tag/ghcjs/\">ghcjs</a>, <a href=\"http://parenz.wordpress.com/tag/haskell-2/\">haskell</a>, <a href=\"http://parenz.wordpress.com/tag/interactive-diagrams/\">interactive-diagrams</a>, <a href=\"http://parenz.wordpress.com/tag/soc/\">soc</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/parenz.wordpress.com/42/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/parenz.wordpress.com/42/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=parenz.wordpress.com&blog=26722965&post=42&subd=parenz&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "c01acb8375d3b6d504e21446e5ed35f7") (154 (20949 25792 519011) "http://blog.moertel.com/posts/2013-06-12-recursion-to-iteration-4-trampolines.html" "Tom Moertel: Tricks of the trade: Recursion to Iteration, Part 4: The Trampoline" nil "Wed, 12 Jun 2013 00:00:00 +0000" "<div class=\"info byline\">Posted by <span><span>Tom Moertel<span></span></span></span></div>
<div class=\"info\">Posted on <time datetime=\"2013-06-12\" itemprop=\"datePublished\">June 12, 2013</time></div>
<div class=\"tags\">Tags: <span><a href=\"http://blog.moertel.com/tags/programming.html\">programming</a>, <a href=\"http://blog.moertel.com/tags/recursion.html\">recursion</a>, <a href=\"http://blog.moertel.com/tags/iteration.html\">iteration</a>, <a href=\"http://blog.moertel.com/tags/python.html\">python</a>, <a href=\"http://blog.moertel.com/tags/recursion-to-iteration series.html\">recursion-to-iteration series</a>, <a href=\"http://blog.moertel.com/tags/tail calls.html\">tail calls</a>, <a href=\"http://blog.moertel.com/tags/data structures.html\">data structures</a>, <a href=\"http://blog.moertel.com/tags/trampolines.html\">trampolines</a></span></div>
<div>
<p>This is the fourth article in <a href=\"http://blog.moertel.com/tags/recursion-to-iteration%20series.html\">a series on converting recursive algorithms into iterative algorithms</a>. If you haven’t read the earlier articles first, you may want to do so before continuing.</p>
<p>In <a href=\"http://blog.moertel.com/posts/2013-05-11-recursive-to-iterative.html\">the first article of our series</a>, we showed that if you can convert an algorithm’s recursive calls into tail calls, you can eliminate those tail calls to create an iterative version of the algorithm using The Simple Method. In this article, we’ll look at another way to eliminate tail calls: the <em>trampoline</em>.</p>
<p>The idea behind the trampoline is this: before making a tail call, manually remove the current execution frame from the stack, eliminating stack build-up.</p>
<h3 id=\"execution-frames-and-the-stack\">Execution frames and the stack</h3>
<p>To understand why we might want to manually remove an execution frame, let’s think about what happens when we call a function. The language runtime needs some place to store housekeeping information and any local variables the function may use, so it allocates a new execution frame on the stack. Then it turns control over to the function. When the function is done, it executes a <code>return</code> statement. This statement tells the runtime to remove the execution frame from the stack and to give control (and any result) back to the caller.</p>
<p>But what if the function doesn’t return right away? What if it makes another function call instead? In that case, the runtime must create a new execution frame for <em>that</em> call and push it onto the stack, on top of the current frame. If the function ends up calling itself many times recursively, each call will add another frame to the stack, and pretty soon we will have eaten up a lot of stack space.</p>
<h3 id=\"eliminating-stack-build-up\">Eliminating stack build-up</h3>
<p>To avoid this problem, some programming languages guarantee that they will recycle the current execution frame whenever a function makes a tail call. That is, if the function calls some other function (or itself recursively) and just returns that function’s result verbatim, that’s a tail call. In that case, the runtime will recycle the current function’s execution frame before transferring control to the other function, making it so that the other function will return its result directly to the original function’s caller. This process is called <em>tail-call elimination</em>.</p>
<p>But in languages like Python that don’t offer tail-call elimination, every call, even if it’s a tail call, pushes a new frame onto the stack. So if we want to prevent stack build-up, we must somehow eliminate the current frame from the stack ourselves, before making a tail call.</p>
<p>But how? The only obvious way to eliminate the current frame is to <code>return</code> to our caller. If we’re to make this work, then, the caller must be willing to help us out. That’s where the trampoline comes in. It’s our co-conspirator in the plot to eliminate stack build-up.</p>
<h3 id=\"the-trampoline\">The trampoline</h3>
<p>Here’s what the trampoline does:</p>
<ol style=\"\">
<li>It calls our function <code>f</code>, making itself the current caller.</li>
<li>When <code>f</code> wants to make a recursive tail call to itself, it returns the instruction <code>call(f)(*args, **kwds)</code>. The language runtime dutifully removes the current execution frame from the stack and returns control to the trampoline, passing it the instruction.</li>
<li>The trampoline interprets the instruction and calls <code>f</code> back, giving it the supplied arguments, and again making itself the caller.</li>
<li>This process repeats until <code>f</code> wants to return a final result <code>z</code>; then it returns the new instruction <code>result(z)</code> instead. As before, the runtime removes the current execution frame from the stack and returns control to the trampoline.</li>
<li>But now when the trampoline interprets the new instruction it will return <code>z</code> to <em>its</em> caller, ending the trampoline dance.</li>
</ol>
<p>Now you can see how the trampoline got its name. When our function uses a <code>return</code> statement to remove its own execution frame from the stack, the trampoline bounces control back to it with new arguments.</p>
<p>Here’s a simple implementation. First, we will encode our instructions to the trampoline as triples. We’ll let <code>call(f)(*args, **kwds)</code> be the triple <code>(f, args, kwds)</code>, and <code>result(z)</code> be the triple <code>(None, z, None)</code>:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> call(f):
<span class=\"co\">\"\"\"Instruct trampoline to call f with the args that follow.\"\"\"</span>
<span class=\"kw\">def</span> g(*args, **kwds):
<span class=\"kw\">return</span> f, args, kwds
<span class=\"kw\">return</span> g
<span class=\"kw\">def</span> result(value):
<span class=\"co\">\"\"\"Instruct trampoline to stop iterating and return a value.\"\"\"</span>
<span class=\"kw\">return</span> <span class=\"ot\">None</span>, value, <span class=\"ot\">None</span></code></pre>
<p>Now we’ll create a decorator to wrap a function with a trampoline that will interpret the instructions that the function returns:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"ch\">import</span> functools
<span class=\"kw\">def</span> with_trampoline(f):
<span class=\"co\">\"\"\"Wrap a trampoline around a function that expects a trampoline.\"\"\"</span>
<span class=\"ot\">@functools.wraps</span>(f)
<span class=\"kw\">def</span> g(*args, **kwds):
h = f
<span class=\"co\"># the trampoline</span>
<span class=\"kw\">while</span> h is not <span class=\"ot\">None</span>:
h, args, kwds = h(*args, **kwds)
<span class=\"kw\">return</span> args
<span class=\"kw\">return</span> g</code></pre>
<p>Note that the trampoline boils down to three lines:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">while</span> h is not <span class=\"ot\">None</span>:
h, args, kwds = h(*args, **kwds)
<span class=\"kw\">return</span> args</code></pre>
<p>Basically, the trampoline keeps calling whatever function is in <code>h</code> until that function returns a <code>result(z)</code> instruction, at which time the loop exits and <code>z</code> is returned. The original recursive tail calls have been boiled down to a <code>while</code> loop. Recursion has become iteration.</p>
<h3 id=\"example-factorial\">Example: factorial</h3>
<p>To see how we might use this implementation, let’s return to the factorial example from <a href=\"http://blog.moertel.com/posts/2013-05-11-recursive-to-iterative.html\">the first article in our series</a>:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> factorial(n):
<span class=\"kw\">if</span> n < <span class=\"dv\">2</span>:
<span class=\"kw\">return</span> <span class=\"dv\">1</span>
<span class=\"kw\">return</span> n * factorial(n - <span class=\"dv\">1</span>)</code></pre>
<p>Step one, as before, is to tail-convert the lone recursive call:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"> <span class=\"kw\">def</span> factorial(n, acc=<span class=\"dv\">1</span>):
<span class=\"kw\">if</span> n < <span class=\"dv\">2</span>:
<span class=\"kw\">return</span> acc
<span class=\"kw\">return</span> factorial(n - <span class=\"dv\">1</span>, acc * n)</code></pre>
<p>Now we can create an equivalent function that uses trampoline idioms:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> trampoline_factorial(n, acc=<span class=\"dv\">1</span>):
<span class=\"kw\">if</span> n < <span class=\"dv\">2</span>:
<span class=\"kw\">return</span> result(acc)
<span class=\"kw\">return</span> call(trampoline_factorial)(n - <span class=\"dv\">1</span>, n * acc)</code></pre>
<p>Note how the <code>return</code> statements have been transformed.</p>
<p>Finally, we can wrap this function with a trampoline to get a callable version that we can use just like the original:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\">factorial = with_trampoline(trampoline_factorial)</code></pre>
<p>Let’s take it for a spin:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\">>>> factorial(<span class=\"dv\">5</span>)
<span class=\"dv\">120</span></code></pre>
<p>To really see what’s going on, be sure to use the Online Python Tutor’s visualizer to step through the original, tail-recursive, and trampoline versions of the function. Just open this link: <a href=\"http://www.pythontutor.com/visualize.html#code=%23+our+trampoline+library%0A%0Aimport+functools%0A%0Adef+call(f)%3A%0A++++%22%22%22Instruct+trampoline+to+call+f+with+the+args+that+follow.%22%22%22%0A++++def+g(*args,+**kwds)%3A%0A++++++++return+f,+args,+kwds%0A++++return+g%0A%0Adef+result(value)%3A%0A++++%22%22%22Instruct+trampoline+to+stop+iterating+and+return+a+value.%22%22%22%0A++++return+None,+value,+None%0A%0Adef+with_trampoline(f)%3A%0A++++%22%22%22Wrap+a+trampoline+around+a+function+that+expects+a+trampoline.%22%22%22%0A++++%40functools.wraps(f)%0A++++def+g(*args,+**kwds)%3A%0A++++++++h+%3D+f%0A++++++++%23+the+trampoline%0A++++++++while+h+is+not+None%3A%0A++++++++++++h,+args,+kwds+%3D+h(*args,+**kwds)%0A++++++++return+args%0A++++return+g%0A%0A%0A%23+original+recursive+version+of+factorial+function%0A%0Adef+factorial(n)%3A%0A++++if+n+%3C+2%3A%0A++++++++return+1%0A++++return+n+*+factorial(n+-+1)%0A%0Aprint+factorial(5)%0A%0A%0A%23+tail-call+recursive+version%0A%0Adef+factorial(n,+acc%3D1)%3A%0A+++++if+n+%3C+2%3A%0A+++++++++return+acc%0A+++++return+factorial(n+-+1,+acc+*+n)%0A%0Aprint+factorial(5)%0A%0A%0A%23+trampoline-based+tail-call+version+(%3D+iterative)%0A%0Adef+trampoline_factorial(n,+acc%3D1)%3A%0A++++if+n+%3C+2%3A%0A++++++++return+result(acc)%0A++++return+call(trampoline_factorial)(n+-+1,+n+*+acc)%0A%0Afactorial+%3D+with_trampoline(trampoline_factorial)%0A%0Aprint+factorial(5)%0A&mode=display&cumulative=false&heapPrimitives=false&drawParentPointers=false&textReferences=false&showOnlyOutputs=false&py=2&curInstr=0\">Visualize the execution</a>. (ProTip: use a new tab.)</p>
<h3 id=\"why-use-the-trampoline\">Why use the trampoline?</h3>
<p>As I mentioned at the beginning of this article, if you can convert a function’s recursive calls into tail calls – which you must do to use a trampoline – you can also use the Simple Method on the function. For example, here’s what the Simple Method does to our original <code>factorial</code> function:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> factorial(n, acc=<span class=\"dv\">1</span>):
<span class=\"kw\">while</span> n > <span class=\"dv\">1</span>:
(n, acc) = (n - <span class=\"dv\">1</span>, acc * n)
<span class=\"kw\">return</span> acc</code></pre>
<p>This version is simpler and more efficient than the trampoline version. So why not use the Simple Method always?</p>
<p>The answer is that the Simple Method is tricky to apply to functions that make tail calls from within loops. Recall that it introduces a loop around a function’s body and replaces recursive tail calls with <code>continue</code> statements. But if the function already has its own loops, replacing a tail call within one of them with a <code>continue</code> statement will restart that inner loop instead of the whole-body loop, as desired. In that case, you must add condition flags to make sure the right loop gets restarted, and that gets old fast. Then, using a trampoline may be a win.</p>
<p>That said, I almost never use trampolines. Getting a function into tail-call form is nine tenths of the battle. If I’ve gone that far already, I’ll usually go the rest of the way to get a tight, iterative version.</p>
<p>Why, then, did we make this effort to understand the trampoline? Two reasons. First, it’s semi-common in programming lore, so it’s best to know about it. Second, it’s a stepping stone to a more-general, more-powerful technique: <em>continuation-passing-style expressions</em>. That’s our subject for next time.</p>
<p>In the meantime, if you want another take on trampolines in Python, Kyle Miller wrote a nice article on the subject: <a href=\"http://web.mit.edu/kmill/www/programming/tailcall.html\">Tail call recursion in Python</a>.</p>
<p>Thanks for reading! As always, if you have questions or comments, please leave a comment on the blog or hit me at <a href=\"https://twitter.com/tmoertel\">@tmoertel</a>.</p>
</div>" nil nil "d110609d0d7f6497c0af1ab073925f0f") (153 (20949 25792 513506) "http://izbicki.me/blog/hlearns-code-is-shorter-and-clearer-than-wekas?utm_source=rss&utm_medium=rss&utm_campaign=hlearns-code-is-shorter-and-clearer-than-wekas" "Mike Izbicki: =?utf-8?Q?HLearn=E2=80=99s?= code is shorter and clearer than =?utf-8?Q?Weka=E2=80=99s?=" nil "Tue, 11 Jun 2013 17:50:09 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /></p>
<p>Haskell code is expressive.  The <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn library</a> uses 6 lines of Haskell to define a function for training a Bayesian classifier; the equivalent code in the <a href=\"http://www.cs.waikato.ac.nz/ml/weka/\">Weka library</a> uses over 100 lines of Java.  That’s a big difference!  In this post, we’ll look at the actual code and see why the Haskell is so much more concise.</p>
<p><strong>But first, a disclaimer:</strong>  It is really hard to fairly compare two code bases this way.  In both libraries, there is a lot of supporting code that goes into defining each classifier, and it’s not obvious what code to include and not include.  For example, both libraries implement interfaces to a number of probability distributions, and this code is not contained in the source count.  The Haskell code takes more advantage of this abstraction, so this is one language-agnostic reason why the Haskell code is shorter.  If you think I’m not doing a fair comparison, here’s some links to the full repositories so you can do it yourself:</p>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\"><a href=\"https://github.com/mikeizbicki/HLearn/blob/master/HLearn-classification/src/HLearn/Models/Classifiers/Bayes.hs\">HLearn’s bayesian classifier source code</a> (74 lines of code)</span></li>
<li><a href=\"https://svn.cms.waikato.ac.nz/svn/weka/trunk/weka/src/main/java/weka/classifiers/bayes/NaiveBayes.java\">Weka’s naive bayes source code</a> (946 lines of code)</li>
</ul>
<p><span id=\"more-2520\"></span></p>
<h3>The HLearn code</h3>
<p>HLearn implements training for a <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">bayesian classifier</a> with these six lines of Haskell:</p>
<pre>newtype Bayes labelIndex dist = Bayes dist
deriving (Read,Show,Eq,Ord,Monoid,Abelian,Group)
instance (Monoid dist, HomTrainer dist) => HomTrainer (Bayes labelIndex dist) where
type Datapoint (Bayes labelIndex dist) = Datapoint dist
train1dp dp = Bayes $ train1dp dp</pre>
<p>This code elegantly captures how to train a Bayesian classifier—just train a probability distribution.  Here’s an explanation:</p>
<ul>
<li>The first two lines define the Bayes data type as a wrapper around a distribution.</li>
<li>The fourth line says that we’re implementing the Bayesian classifier using the HomTrainer type class.  We do this because <strong>the Haskell compiler automatically generates a parallel batch training function, an online training function, and a fast cross-validation function for all HomTrainer instances.</strong></li>
<li>The fifth line says that our data points have the same type as the underlying distribution.</li>
<li>The sixth line says that in order to train, just train the corresponding distribution.</li>
</ul>
<p>We only get the benefits of the HomTrainer type class because the bayesian classifier is a monoid.  But we didn’t even have to specify what the monoid instance for bayesian classifiers looks like!  In this case, it’s automatically derived from the monoid instances for the base distributions using a language extension called <a href=\"http://www.haskell.org/ghc/docs/7.6.1/html/users_guide/deriving.html\">GeneralizedNewtypeDeriving</a>.  For examples of these monoid structures, check out the algebraic structure of the <a href=\"http://izbicki.me/blog/gausian-distributions-are-monoids\">normal</a> and <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical</a> distributions, or more complex distributions using <a href=\"http://izbicki.me/blog/markov-networks-monoids-and-futurama\">Markov networks</a>.</p>
<h3>The Weka code</h3>
<p>Look for these differences between the HLearn and Weka source:</p>
<ul>
<li>In Weka we must separately define the online and batch trainers, whereas Haskell derived these for us automatically.</li>
<li>Weka must perform a variety of error handling that Haskell’s type system takes care of in HLearn.</li>
<li>The Weka code is tightly coupled to the underlying probability distribution, whereas the Haskell code was generic enough to handle any distribution. This means that while Weka must make the “naive bayes assumption” that all attributes are independent of each other, HLearn can support any dependence structure.</li>
<li>Weka’s code is made more verbose by for loops and if statements that aren’t necessary for HLearn.</li>
<li>The Java code requires extensive comments to maintain readability, but the Haskell code is simple enough to be self-documenting (at least once you know how to read Haskell).</li>
<li>Weka does not have parallel training, fast cross-validation, data point subtraction, or weighted data points, but HLearn does.</li>
</ul>
<pre>/**
* Generates the classifier.
*
* @param instances set of instances serving as training data
* @exception Exception if the classifier has not been generated
* successfully
*/
public void buildClassifier(Instances instances) throws Exception {
// can classifier handle the data?
getCapabilities().testWithFail(instances);
// remove instances with missing class
instances = new Instances(instances);
instances.deleteWithMissingClass();
m_NumClasses = instances.numClasses();
// Copy the instances
m_Instances = new Instances(instances);
// Discretize instances if required
if (m_UseDiscretization) {
m_Disc = new weka.filters.supervised.attribute.Discretize();
m_Disc.setInputFormat(m_Instances);
m_Instances = weka.filters.Filter.useFilter(m_Instances, m_Disc);
} else {
m_Disc = null;
}
// Reserve space for the distributions
m_Distributions = new Estimator[m_Instances.numAttributes() - 1]
[m_Instances.numClasses()];
m_ClassDistribution = new DiscreteEstimator(m_Instances.numClasses(),
true);
int attIndex = 0;
Enumeration enu = m_Instances.enumerateAttributes();
while (enu.hasMoreElements()) {
Attribute attribute = (Attribute) enu.nextElement();
// If the attribute is numeric, determine the estimator
// numeric precision from differences between adjacent values
double numPrecision = DEFAULT_NUM_PRECISION;
if (attribute.type() == Attribute.NUMERIC) {
m_Instances.sort(attribute);
if ( (m_Instances.numInstances() > 0)
    && !m_Instances.instance(0).isMissing(attribute)) {
  double lastVal = m_Instances.instance(0).value(attribute);
  double currentVal, deltaSum = 0;
  int distinct = 0;
  for (int i = 1; i < m_Instances.numInstances(); i++) { 	
Instance currentInst = m_Instances.instance(i); 	
if (currentInst.isMissing(attribute)) {
break; 	
}
	    currentVal = currentInst.value(attribute);
	    if (currentVal != lastVal) {
	      deltaSum += currentVal - lastVal;
	      lastVal = currentVal;
	      distinct++;
	    }
	  }
	  if (distinct > 0) {
    numPrecision = deltaSum / distinct;
  }
}
}
for (int j = 0; j < m_Instances.numClasses(); j++) {
switch (attribute.type()) {
case Attribute.NUMERIC:
  if (m_UseKernelEstimator) {
    m_Distributions[attIndex][j] =
      new KernelEstimator(numPrecision);
  } else {
    m_Distributions[attIndex][j] =
      new NormalEstimator(numPrecision);
  }
  break;
case Attribute.NOMINAL:
  m_Distributions[attIndex][j] =
    new DiscreteEstimator(attribute.numValues(), true);
  break;
default:
  throw new Exception(\"Attribute type unknown to NaiveBayes\");
}
}
attIndex++;
}
// Compute counts
Enumeration enumInsts = m_Instances.enumerateInstances();
while (enumInsts.hasMoreElements()) {
Instance instance =
(Instance) enumInsts.nextElement();
updateClassifier(instance);
}
// Save space
m_Instances = new Instances(m_Instances, 0);
}</pre>
<p>And the code for online learning is:</p>
<pre>/**
* Updates the classifier with the given instance.
*
* @param instance the new training instance to include in the model
* @exception Exception if the instance could not be incorporated in
* the model.
*/
public void updateClassifier(Instance instance) throws Exception {
if (!instance.classIsMissing()) {
Enumeration enumAtts = m_Instances.enumerateAttributes();
int attIndex = 0;
while (enumAtts.hasMoreElements()) {
Attribute attribute = (Attribute) enumAtts.nextElement();
if (!instance.isMissing(attribute)) {
  m_Distributions[attIndex][(int)instance.classValue()].
addValue(instance.value(attribute), instance.weight());
}
attIndex++;
}
m_ClassDistribution.addValue(instance.classValue(),
instance.weight());
}
}</pre>
<h3>Conclusion</h3>
<p>Every algorithm implemented in HLearn uses similarly concise code.  I invite you to <a href=\"https://github.com/mikeizbicki/HLearn/\">browse the repository</a> and see for yourself.  The most complicated algorithm is for Markov chains which use only <a href=\"https://github.com/mikeizbicki/HLearn/blob/master/HLearn-markov/src/HLearn/Models/Markov/MarkovChain.hs\">6 lines for training, and about 20 for defining the Monoid</a>.</p>
<p>You can expect lots of tutorials on how to incorporate the HLearn library into Haskell programs over the next few months.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2520\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "a2eed72f1858331b6796fee4e1e76ae7") (152 (20949 25792 511765) "http://wadler.blogspot.com/2013/06/iain-banks.html" "Philip Wadler: Iain Banks" "noreply@blogger.com (Philip Wadler)" "Tue, 11 Jun 2013 08:24:56 +0000" "<div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://1.bp.blogspot.com/-0cLAVwyWSKU/Ubbaw7r7N9I/AAAAAAAACKI/DItsN5fXHQE/s1600/scotsbanks-003.jpg\"><img src=\"http://1.bp.blogspot.com/-0cLAVwyWSKU/Ubbaw7r7N9I/AAAAAAAACKI/DItsN5fXHQE/s400/scotsbanks-003.jpg\" title=\"Writer Iain Banks seen in front of the Scottish Parliament Building at Holyrood in Edinburgh. Photograph: Murdo MacLeod (Observer)\" height=\"240\" width=\"400\" alt=\"Writer Iain Banks seen in front of the Scottish Parliament Building at Holyrood in Edinburgh. Photograph: Murdo MacLeod (Observer)\" border=\"0\" /></a></div>In April, Iain Banks discovered he had cancer of the gall bladder, and proposed to his girl friend by requesting she `do me the honour of becoming my widow'.  Yesterday his death was announced.  In his honour, here is something he <a href=\"http://www.guardian.co.uk/culture/2011/aug/28/scottish-independence-snp-iain-banks?INTCMP=SRCH\">wrote for the Observer</a>.  See also this <a href=\"http://www.guardian.co.uk/books/2013/jun/10/iain-banks-ken-macleod-science-fiction\">tribute from Ken McLeod</a>.<br /><blockquote class=\"tr_bq\"><div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://1.bp.blogspot.com/-0cLAVwyWSKU/Ubbaw7r7N9I/AAAAAAAACKI/DItsN5fXHQE/s1600/scotsbanks-003.jpg\"></a></div>These days, I support the idea of an independent Scotland. It's with a  heavy heart in some ways; I think I'd still sacrifice an independent  Scotland for a socialist UK, but… I can't really see that happening.  What I can imagine is England continuing to turn to the right and  eventually leaving the EU altogether.<br /><br />Scotland, though, could have  a viable future either as a completely independent country or – more  likely – within Europe. The European ideal is taking a battering right  now, certainly, and the gloss has come off comparing our prospects to  Ireland's or Iceland's, but it remains both possible and plausible that  Scotland could become a transparent, low-inequality society on the  Scandinavian model, with fair, non-regressive taxes, strong unions, a  nuclear-free policy, a non-punitive tertiary education system,  enlightened social policies in general and long-term support for green  energy programmes.<br /><br />We'd need to make sure our banks were small  enough to fail, and there are problems of poverty, ill health and  religious tribalism that will take decades to overcome. But with the  advantages and attractions that Scotland already has, and, more  importantly, taking into account the morale boost, the sheer  energisation of a whole people that would come about because we would  finally have our destiny at least largely back in our own hands again – I  think we could do it.<br /><br />And that we should.</blockquote>" nil nil "8510fdd9ba7c0ba403464d9449971edf") (151 (20949 25792 507936) "http://theorylunch.wordpress.com/2013/06/06/an-initial-solution-to-the-monad-problem-and-then-some-more/" "Theory Lunch (Institute of Cybernetics, Tallinn): An initial solution to the monad problem, and then some more" nil "Mon, 10 Jun 2013 11:27:02 +0000" "<p>This is the second of two talks about monads, based on <a href=\"http://www.cs.man.ac.uk/~schalk/notes/monads.pdf\" target=\"_blank\" title=\"http://www.cs.man.ac.uk/~schalk/notes/monads.pdf\">the very good notes by Andrea Schalk</a> and continuing <a href=\"http://theorylunch.wordpress.com/2013/05/30/when-does-an-endofunctor-derive-from-an-adjunction/\" target=\"_blank\" title=\"http://theorylunch.wordpress.com/2013/05/30/when-does-an-endofunctor-derive-from-an-adjunction/\">the one I gave on the 30th of May</a>. Recall that we are trying to solve the following problem:</p>
<p style=\"text-align: center;\"><em>given a monad <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+%28T%2C+%5Ceta%2C+%5Cmu%29&bg=ffffff&fg=333333&s=0\" alt=\"T = (T, \\eta, \\mu)\" class=\"latex\" title=\"T = (T, \\eta, \\mu)\" />, find an adjunction <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> such that <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+GF&bg=ffffff&fg=333333&s=0\" alt=\"T = GF\" class=\"latex\" title=\"T = GF\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu+%3D+G+%5Cvarepsilon_F&bg=ffffff&fg=333333&s=0\" alt=\"\\mu = G \\varepsilon_F\" class=\"latex\" title=\"\\mu = G \\varepsilon_F\" /></em></p>
<p>If the adjunction <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> solves the problem above, we say that it <em>generates</em> the monad <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />.</p>
<p>The first solution to this problem was given by the Swiss mathematician Heinrich Kleisli, and is based on an alternative way of defining monads, as it is the case with adjunctions. <span id=\"more-885\"></span> Let us suppose <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+GF&bg=ffffff&fg=333333&s=0\" alt=\"T = GF\" class=\"latex\" title=\"T = GF\" /> with <img src=\"http://s0.wp.com/latex.php?latex=F+%5Cdashv+G&bg=ffffff&fg=333333&s=0\" alt=\"F \\dashv G\" class=\"latex\" title=\"F \\dashv G\" />. If <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+A+%5Cto+TB+%3D+G%28FB%29&bg=ffffff&fg=333333&s=0\" alt=\"f : A \\to TB = G(FB)\" class=\"latex\" title=\"f : A \\to TB = G(FB)\" />, then <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Csharp+%3A+FA+%5Cto+FB&bg=ffffff&fg=333333&s=0\" alt=\"f^\\sharp : FA \\to FB\" class=\"latex\" title=\"f^\\sharp : FA \\to FB\" />, so that <img src=\"http://s0.wp.com/latex.php?latex=Gf%5E%5Csharp+%3A+TA+%5Cto+TB&bg=ffffff&fg=333333&s=0\" alt=\"Gf^\\sharp : TA \\to TB\" class=\"latex\" title=\"Gf^\\sharp : TA \\to TB\" />: and we know from the definition of monad that <img src=\"http://s0.wp.com/latex.php?latex=Gf%5E%5Csharp+%5Ccirc+%5Ceta_A+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"Gf^\\sharp \\circ \\eta_A = f\" class=\"latex\" title=\"Gf^\\sharp \\circ \\eta_A = f\" />. We can thus define an operator <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ccdot%29%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"(\\cdot)^\\ast\" class=\"latex\" title=\"(\\cdot)^\\ast\" /> that takes <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D%28A%2CTB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}(A,TB)\" class=\"latex\" title=\"f \\in \\mathcal{C}(A,TB)\" /> into <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Cast+%3D+Gf%5E%5Csharp+%5Cin+%5Cmathcal%7BC%7D%28TA%2CTB%29&bg=ffffff&fg=333333&s=0\" alt=\"f^\\ast = Gf^\\sharp \\in \\mathcal{C}(TA,TB)\" class=\"latex\" title=\"f^\\ast = Gf^\\sharp \\in \\mathcal{C}(TA,TB)\" /> so that <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Cast+%5Ccirc+%5Ceta_A+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"f^\\ast \\circ \\eta_A = f\" class=\"latex\" title=\"f^\\ast \\circ \\eta_A = f\" /> whatever <img src=\"http://s0.wp.com/latex.php?latex=f&bg=ffffff&fg=333333&s=0\" alt=\"f\" class=\"latex\" title=\"f\" /> is. The simplest example is <img src=\"http://s0.wp.com/latex.php?latex=f+%3D+%5Ceta_A&bg=ffffff&fg=333333&s=0\" alt=\"f = \\eta_A\" class=\"latex\" title=\"f = \\eta_A\" /> itself, which yields <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ceta_A%29%5E%5Cast+%5Ccirc+%5Ceta_A+%3D+%5Ceta_A&bg=ffffff&fg=333333&s=0\" alt=\"(\\eta_A)^\\ast \\circ \\eta_A = \\eta_A\" class=\"latex\" title=\"(\\eta_A)^\\ast \\circ \\eta_A = \\eta_A\" />, so that <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ceta_A%29%5E%5Csharp+%3D+%5Cmathrm%7Bid%7D_%7BFA%7D&bg=ffffff&fg=333333&s=0\" alt=\"(\\eta_A)^\\sharp = \\mathrm{id}_{FA}\" class=\"latex\" title=\"(\\eta_A)^\\sharp = \\mathrm{id}_{FA}\" /> by uniqueness in the definition of adjunction quadruple, and <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ceta_A%29%5E%5Cast+%3D+%5Cmathrm%7Bid%7D_%7BTA%7D&bg=ffffff&fg=333333&s=0\" alt=\"(\\eta_A)^\\ast = \\mathrm{id}_{TA}\" class=\"latex\" title=\"(\\eta_A)^\\ast = \\mathrm{id}_{TA}\" />. Moreover, if <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+A+%5Cto+TB&bg=ffffff&fg=333333&s=0\" alt=\"f : A \\to TB\" class=\"latex\" title=\"f : A \\to TB\" /> and <img src=\"http://s0.wp.com/latex.php?latex=g+%3A+B+%5Cto+TC&bg=ffffff&fg=333333&s=0\" alt=\"g : B \\to TC\" class=\"latex\" title=\"g : B \\to TC\" />, then <img src=\"http://s0.wp.com/latex.php?latex=g%5E%5Cast+%5Ccirc+f+%3D+g%5E%5Cast+%5Ccirc+f%5E%5Cast+%5Ccirc+%5Ceta_A&bg=ffffff&fg=333333&s=0\" alt=\"g^\\ast \\circ f = g^\\ast \\circ f^\\ast \\circ \\eta_A\" class=\"latex\" title=\"g^\\ast \\circ f = g^\\ast \\circ f^\\ast \\circ \\eta_A\" />, which implies <img src=\"http://s0.wp.com/latex.php?latex=%28g%5E%5Cast+%5Ccirc+f%29%5E%5Cast+%3D+g%5E%5Cast+%5Ccirc+f%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"(g^\\ast \\circ f)^\\ast = g^\\ast \\circ f^\\ast\" class=\"latex\" title=\"(g^\\ast \\circ f)^\\ast = g^\\ast \\circ f^\\ast\" /> by uniqueness.</p>
<p><strong>Definition 4.</strong> A <em>Kleisli triple</em> on a category <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> is a triple <img src=\"http://s0.wp.com/latex.php?latex=%28T%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Cast%29&bg=ffffff&fg=333333&s=0\" alt=\"(T, \\eta, (\\cdot)^\\ast)\" class=\"latex\" title=\"(T, \\eta, (\\cdot)^\\ast)\" /> where:</p>
<ol>
<li><img src=\"http://s0.wp.com/latex.php?latex=T+%3A+%7C%5Cmathcal%7BC%7D%7C+%5Cto+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"T : |\\mathcal{C}| \\to |\\mathcal{C}|\" class=\"latex\" title=\"T : |\\mathcal{C}| \\to |\\mathcal{C}|\" /> is a function,</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%5Ceta_A+%5Cin+%5Cmathcal%7BC%7D%28A%2C+TA%29&bg=ffffff&fg=333333&s=0\" alt=\"\\eta_A \\in \\mathcal{C}(A, TA)\" class=\"latex\" title=\"\\eta_A \\in \\mathcal{C}(A, TA)\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=A+%5Cin+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"A \\in |\\mathcal{C}|\" class=\"latex\" title=\"A \\in |\\mathcal{C}|\" />, and</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Cast+%5Cin+%5Cmathcal%7BC%7D%28TA%2CTB%29&bg=ffffff&fg=333333&s=0\" alt=\"f^\\ast \\in \\mathcal{C}(TA,TB)\" class=\"latex\" title=\"f^\\ast \\in \\mathcal{C}(TA,TB)\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D%28A%2CTB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}(A,TB)\" class=\"latex\" title=\"f \\in \\mathcal{C}(A,TB)\" /></li>
</ol>
<p>such that the following equations are satisfied:</p>
<ol>
<li><img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Cast+%5Ccirc+%5Ceta_A+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"f^\\ast \\circ \\eta_A = f\" class=\"latex\" title=\"f^\\ast \\circ \\eta_A = f\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+A+%5Cto+TB&bg=ffffff&fg=333333&s=0\" alt=\"f : A \\to TB\" class=\"latex\" title=\"f : A \\to TB\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%28%5Ceta_A%29%5E%5Cast+%3D+%5Cmathrm%7Bid%7D_%7BTA%7D&bg=ffffff&fg=333333&s=0\" alt=\"(\\eta_A)^\\ast = \\mathrm{id}_{TA}\" class=\"latex\" title=\"(\\eta_A)^\\ast = \\mathrm{id}_{TA}\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=333333&s=0\" alt=\"A\" class=\"latex\" title=\"A\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%28g%5E%5Cast+%5Ccirc+f%29%5E%5Cast+%3D+g%5E%5Cast+%5Ccirc+f%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"(g^\\ast \\circ f)^\\ast = g^\\ast \\circ f^\\ast\" class=\"latex\" title=\"(g^\\ast \\circ f)^\\ast = g^\\ast \\circ f^\\ast\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+A+%5Cto+TB&bg=ffffff&fg=333333&s=0\" alt=\"f : A \\to TB\" class=\"latex\" title=\"f : A \\to TB\" />, <img src=\"http://s0.wp.com/latex.php?latex=g+%3A+B+%5Cto+TC&bg=ffffff&fg=333333&s=0\" alt=\"g : B \\to TC\" class=\"latex\" title=\"g : B \\to TC\" />.</li>
</ol>
<p>If <img src=\"http://s0.wp.com/latex.php?latex=%28F%2CG%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Csharp%29&bg=ffffff&fg=333333&s=0\" alt=\"(F,G, \\eta, (\\cdot)^\\sharp)\" class=\"latex\" title=\"(F,G, \\eta, (\\cdot)^\\sharp)\" /> is an adjunction quadruple then <img src=\"http://s0.wp.com/latex.php?latex=%28GF%2C+%5Ceta%2C+G%28%5Ccdot%29%5E%5Csharp%29&bg=ffffff&fg=333333&s=0\" alt=\"(GF, \\eta, G(\\cdot)^\\sharp)\" class=\"latex\" title=\"(GF, \\eta, G(\\cdot)^\\sharp)\" /> is a Kleisli triple.</p>
<p><strong>Theorem 1.</strong> Let <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> be a category.</p>
<ol>
<li>If <img src=\"http://s0.wp.com/latex.php?latex=%28T%2C+%5Ceta%2C+%5Cmu%29&bg=ffffff&fg=333333&s=0\" alt=\"(T, \\eta, \\mu)\" class=\"latex\" title=\"(T, \\eta, \\mu)\" /> is a monad on <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" />, and if <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Cast+%3D+%5Cmu_B+%5Ccirc+Tf&bg=ffffff&fg=333333&s=0\" alt=\"f^\\ast = \\mu_B \\circ Tf\" class=\"latex\" title=\"f^\\ast = \\mu_B \\circ Tf\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+A+%5Cto+TB&bg=ffffff&fg=333333&s=0\" alt=\"f : A \\to TB\" class=\"latex\" title=\"f : A \\to TB\" />, then <img src=\"http://s0.wp.com/latex.php?latex=%28T%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Cast%29&bg=ffffff&fg=333333&s=0\" alt=\"(T, \\eta, (\\cdot)^\\ast)\" class=\"latex\" title=\"(T, \\eta, (\\cdot)^\\ast)\" /> is a Kleisli triple on <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" />.</li>
<li>If <img src=\"http://s0.wp.com/latex.php?latex=%28T%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Cast%29&bg=ffffff&fg=333333&s=0\" alt=\"(T, \\eta, (\\cdot)^\\ast)\" class=\"latex\" title=\"(T, \\eta, (\\cdot)^\\ast)\" /> is a Kleisli triple on <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" />, and if <img src=\"http://s0.wp.com/latex.php?latex=Tf+%3D+%28%5Ceta_B+%5Ccirc+f%29%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"Tf = (\\eta_B \\circ f)^\\ast\" class=\"latex\" title=\"Tf = (\\eta_B \\circ f)^\\ast\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+A+%5Cto+B&bg=ffffff&fg=333333&s=0\" alt=\"f : A \\to B\" class=\"latex\" title=\"f : A \\to B\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%3D+%28%5Cmathrm%7Bid%7D_%7BTA%7D%29%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A = (\\mathrm{id}_{TA})^\\ast\" class=\"latex\" title=\"\\mu_A = (\\mathrm{id}_{TA})^\\ast\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=333333&s=0\" alt=\"A\" class=\"latex\" title=\"A\" />, then <img src=\"http://s0.wp.com/latex.php?latex=%28T%2C+%5Ceta%2C+%5Cmu%29&bg=ffffff&fg=333333&s=0\" alt=\"(T, \\eta, \\mu)\" class=\"latex\" title=\"(T, \\eta, \\mu)\" /> is a monad on <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" />.</li>
<li>The two operations from the previous points are each other’s converse.</li>
</ol>
<p><em>Proof:</em> Point 1 follows from naturality of <img src=\"http://s0.wp.com/latex.php?latex=%5Ceta&bg=ffffff&fg=333333&s=0\" alt=\"\\eta\" class=\"latex\" title=\"\\eta\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu&bg=ffffff&fg=333333&s=0\" alt=\"\\mu\" class=\"latex\" title=\"\\mu\" /> and the three monad laws:</p>
<ul>
<li><img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Cast+%5Ccirc+%5Ceta_A+%3D+%5Cmu_B+%5Ccirc+Tf+%5Ccirc+%5Ceta_A+%3D+%5Cmu_B+%5Ccirc+%5Ceta_%7BTB%7D+%5Ccirc+f+%3D+%5Cmathrm%7Bid%7D_%7BTB%7D+%5Ccirc+f+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"f^\\ast \\circ \\eta_A = \\mu_B \\circ Tf \\circ \\eta_A = \\mu_B \\circ \\eta_{TB} \\circ f = \\mathrm{id}_{TB} \\circ f = f\" class=\"latex\" title=\"f^\\ast \\circ \\eta_A = \\mu_B \\circ Tf \\circ \\eta_A = \\mu_B \\circ \\eta_{TB} \\circ f = \\mathrm{id}_{TB} \\circ f = f\" /></li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%28%5Ceta_A%29%5E%5Cast+%3D+%5Cmu_%7BTA%7D+%5Ccirc+%5Ceta_A+%3D+%5Cmathrm%7Bid%7D_%7BTA%7D&bg=ffffff&fg=333333&s=0\" alt=\"(\\eta_A)^\\ast = \\mu_{TA} \\circ \\eta_A = \\mathrm{id}_{TA}\" class=\"latex\" title=\"(\\eta_A)^\\ast = \\mu_{TA} \\circ \\eta_A = \\mathrm{id}_{TA}\" /></li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%28g%5E%5Cast+%5Ccirc+f%29%5E%5Cast+%3D+%5Cmu_C+%5Ccirc+T%5Cmu_C+%5Ccirc+T%5E2g+%5Ccirc+Tf+%3D+%5Cmu_C+%5Ccirc+%5Cmu_%7BTC%7D+%5Ccirc+T%5E2g+%5Ccirc+Tf+%3D+%5Cmu_C+%5Ccirc+Tg+%5Ccirc+%5Cmu_B+%5Ccirc+Tf+%3D+g%5E%5Cast+%5Ccirc+f%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"(g^\\ast \\circ f)^\\ast = \\mu_C \\circ T\\mu_C \\circ T^2g \\circ Tf = \\mu_C \\circ \\mu_{TC} \\circ T^2g \\circ Tf = \\mu_C \\circ Tg \\circ \\mu_B \\circ Tf = g^\\ast \\circ f^\\ast\" class=\"latex\" title=\"(g^\\ast \\circ f)^\\ast = \\mu_C \\circ T\\mu_C \\circ T^2g \\circ Tf = \\mu_C \\circ \\mu_{TC} \\circ T^2g \\circ Tf = \\mu_C \\circ Tg \\circ \\mu_B \\circ Tf = g^\\ast \\circ f^\\ast\" /></li>
</ul>
<p>For point 2, functoriality of <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />, naturality of <img src=\"http://s0.wp.com/latex.php?latex=%5Ceta&bg=ffffff&fg=333333&s=0\" alt=\"\\eta\" class=\"latex\" title=\"\\eta\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu&bg=ffffff&fg=333333&s=0\" alt=\"\\mu\" class=\"latex\" title=\"\\mu\" />, and monad laws follow from Kleisli laws:</p>
<ul>
<li><img src=\"http://s0.wp.com/latex.php?latex=T%28g+%5Ccirc+f%29+%3D+%28%5Ceta_C+%5Ccirc+g+%5Ccirc+f%29%5E%5Cast+%3D+%28%28%5Ceta_C+%5Ccirc+g%29%5E%5Cast+%5Ccirc+%5Ceta_B+%5Ccirc+f%29%5E%5Cast+%3D+%28%5Ceta_C+%5Ccirc+g%29%5E%5Cast+%5Ccirc+%28%5Ceta_B+%5Ccirc+f%29%5E%5Cast+Tg+%5Ccirc+Tf&bg=ffffff&fg=333333&s=0\" alt=\"T(g \\circ f) = (\\eta_C \\circ g \\circ f)^\\ast = ((\\eta_C \\circ g)^\\ast \\circ \\eta_B \\circ f)^\\ast = (\\eta_C \\circ g)^\\ast \\circ (\\eta_B \\circ f)^\\ast Tg \\circ Tf\" class=\"latex\" title=\"T(g \\circ f) = (\\eta_C \\circ g \\circ f)^\\ast = ((\\eta_C \\circ g)^\\ast \\circ \\eta_B \\circ f)^\\ast = (\\eta_C \\circ g)^\\ast \\circ (\\eta_B \\circ f)^\\ast Tg \\circ Tf\" /></li>
<li><img src=\"http://s0.wp.com/latex.php?latex=T%5Cmathrm%7Bid%7D_A+%3D+%28%5Ceta_A%29%5E%5Cast+%3D+%5Cmathrm%7Bid%7D_%7BTA%7D&bg=ffffff&fg=333333&s=0\" alt=\"T\\mathrm{id}_A = (\\eta_A)^\\ast = \\mathrm{id}_{TA}\" class=\"latex\" title=\"T\\mathrm{id}_A = (\\eta_A)^\\ast = \\mathrm{id}_{TA}\" /></li>
<li><img src=\"http://s0.wp.com/latex.php?latex=Tf+%5Ccirc+%5Ceta_A+%3D+%28%5Ceta_B+%5Ccirc+f%29%5E%5Cast+%5Ccirc+%5Ceta_A+%3D+%5Ceta_B+%5Ccirc+f&bg=ffffff&fg=333333&s=0\" alt=\"Tf \\circ \\eta_A = (\\eta_B \\circ f)^\\ast \\circ \\eta_A = \\eta_B \\circ f\" class=\"latex\" title=\"Tf \\circ \\eta_A = (\\eta_B \\circ f)^\\ast \\circ \\eta_A = \\eta_B \\circ f\" /></li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_B+%5Ccirc+T%5E2f+%3D+%28%5Cmathrm%7Bid%7D_%7BTB%7D%5E%5Cast+%5Ccirc+%5Ceta_%7BTB%7D+%5Ccirc+%28%5Ceta_B+%5Ccirc+f%29%5E%5Cast%29%5E%5Cast+%3D+%28%5Ceta_B+%5Ccirc+Tf%29%5E%7B%5Cast%5Cast%7D+%3D+%28%28%5Ceta_B+%5Ccirc+f%29%5E%5Cast+%5Ccirc+%5Cmathrm%7Bid%7D_%7BTA%7D%29%5E%5Cast+%3D+Tf+%5Ccirc+%5Cmu_A&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_B \\circ T^2f = (\\mathrm{id}_{TB}^\\ast \\circ \\eta_{TB} \\circ (\\eta_B \\circ f)^\\ast)^\\ast = (\\eta_B \\circ Tf)^{\\ast\\ast} = ((\\eta_B \\circ f)^\\ast \\circ \\mathrm{id}_{TA})^\\ast = Tf \\circ \\mu_A\" class=\"latex\" title=\"\\mu_B \\circ T^2f = (\\mathrm{id}_{TB}^\\ast \\circ \\eta_{TB} \\circ (\\eta_B \\circ f)^\\ast)^\\ast = (\\eta_B \\circ Tf)^{\\ast\\ast} = ((\\eta_B \\circ f)^\\ast \\circ \\mathrm{id}_{TA})^\\ast = Tf \\circ \\mu_A\" /></li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%5Ccirc+%5Ceta_%7BTA%7D+%3D+%28%5Cmathrm%7Bid%7D_%7BTA%7D%29%5E%5Cast+%5Ccirc+%5Ceta_%7BTA%7D+%3D+%5Cmathrm%7Bid%7D_%7BTA%7D+%3D+%28%5Cmathrm%7Bid%7D_%7BTA%7D+%5Ccirc+%5Ceta_A%29%5E%5Cast+%3D+%28%28%5Cmathrm%7Bid%7D_%7BTA%7D%29%5E%5Cast+%5Ccirc+%5Ceta_%7BTA%7D+%5Ccirc+%5Ceta_A%29%5E%5Cast+%3D+%5Cmu_A+%5Ccirc+T%5Ceta_A&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A \\circ \\eta_{TA} = (\\mathrm{id}_{TA})^\\ast \\circ \\eta_{TA} = \\mathrm{id}_{TA} = (\\mathrm{id}_{TA} \\circ \\eta_A)^\\ast = ((\\mathrm{id}_{TA})^\\ast \\circ \\eta_{TA} \\circ \\eta_A)^\\ast = \\mu_A \\circ T\\eta_A\" class=\"latex\" title=\"\\mu_A \\circ \\eta_{TA} = (\\mathrm{id}_{TA})^\\ast \\circ \\eta_{TA} = \\mathrm{id}_{TA} = (\\mathrm{id}_{TA} \\circ \\eta_A)^\\ast = ((\\mathrm{id}_{TA})^\\ast \\circ \\eta_{TA} \\circ \\eta_A)^\\ast = \\mu_A \\circ T\\eta_A\" /></li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%5Ccirc+%5Cmu_%7BTA%7D+%3D+%28%5Cmathrm%7Bid%7D_%7BTA%7D%5E%5Cast+%5Ccirc+%5Cmathrm%7Bid%7D_%7BT%5E2A%7D%29%5E%5Cast+%3D+%28%5Cmathrm%7Bid%7D_A+%5Ccirc+%5Cmathrm%7Bid%7D_%7BTA%7D%5E%5Cast%29%5E%5Cast+%3D+%28%5Cmathrm%7Bid%7D_%7BTA%7D%5E%5Cast+%5Ccirc+%5Ceta_%7BTA%7D+%5Ccirc+%5Cmathrm%7Bid%7D_%7BTA%7D%5E%5Cast%29%5E%5Cast+%3D+%5Cmu_A+%5Ccirc+T%5Cmu_A&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A \\circ \\mu_{TA} = (\\mathrm{id}_{TA}^\\ast \\circ \\mathrm{id}_{T^2A})^\\ast = (\\mathrm{id}_A \\circ \\mathrm{id}_{TA}^\\ast)^\\ast = (\\mathrm{id}_{TA}^\\ast \\circ \\eta_{TA} \\circ \\mathrm{id}_{TA}^\\ast)^\\ast = \\mu_A \\circ T\\mu_A\" class=\"latex\" title=\"\\mu_A \\circ \\mu_{TA} = (\\mathrm{id}_{TA}^\\ast \\circ \\mathrm{id}_{T^2A})^\\ast = (\\mathrm{id}_A \\circ \\mathrm{id}_{TA}^\\ast)^\\ast = (\\mathrm{id}_{TA}^\\ast \\circ \\eta_{TA} \\circ \\mathrm{id}_{TA}^\\ast)^\\ast = \\mu_A \\circ T\\mu_A\" /></li>
</ul>
<p>Point 3 is straightforward. <img src=\"http://s0.wp.com/latex.php?latex=%5CBox&bg=ffffff&fg=333333&s=0\" alt=\"\\Box\" class=\"latex\" title=\"\\Box\" /></p>
<p>Considering again the free monoid example, the corresponding Kleisli triple has</p>
<p style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Cast%28s%29+%3D+%5B+x+%5C%3B+%5Cmathtt%7Bfor%7D+%5C%3B+x+%5C%3B+%5Cmathtt%7Bin%7D+%5C%3B+f%28a%29+%5C%3B+%5Cmathtt%7Bfor%7D+%5C%3B+a+%5C%3B+%5Cmathtt%7Bin%7D+%5C%3B+s+%5D&bg=ffffff&fg=333333&s=0\" alt=\"f^\\ast(s) = [ x \\; \\mathtt{for} \\; x \\; \\mathtt{in} \\; f(a) \\; \\mathtt{for} \\; a \\; \\mathtt{in} \\; s ]\" class=\"latex\" title=\"f^\\ast(s) = [ x \\; \\mathtt{for} \\; x \\; \\mathtt{in} \\; f(a) \\; \\mathtt{for} \\; a \\; \\mathtt{in} \\; s ]\" /></p>
<p>Theorem 1 says that we can restate our problem as follows:</p>
<p style=\"text-align: center;\"><em>given a Kleisli triple <img src=\"http://s0.wp.com/latex.php?latex=%28T%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Cast%29&bg=ffffff&fg=333333&s=0\" alt=\"(T, \\eta, (\\cdot)^\\ast)\" class=\"latex\" title=\"(T, \\eta, (\\cdot)^\\ast)\" />,</em><em> find an adjunction quadruple <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Csharp%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, (\\cdot)^\\sharp)\" class=\"latex\" title=\"(F, G, \\eta, (\\cdot)^\\sharp)\" /> such that <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+GF&bg=ffffff&fg=333333&s=0\" alt=\"T = GF\" class=\"latex\" title=\"T = GF\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ccdot%29%5E%5Cast+%3D+G%28%28%5Ccdot%29%5E%5Csharp%29&bg=ffffff&fg=333333&s=0\" alt=\"(\\cdot)^\\ast = G((\\cdot)^\\sharp)\" class=\"latex\" title=\"(\\cdot)^\\ast = G((\\cdot)^\\sharp)\" /></em></p>
<p>If <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+GF&bg=ffffff&fg=333333&s=0\" alt=\"T = GF\" class=\"latex\" title=\"T = GF\" /> with <img src=\"http://s0.wp.com/latex.php?latex=F+%5Cdashv+G&bg=ffffff&fg=333333&s=0\" alt=\"F \\dashv G\" class=\"latex\" title=\"F \\dashv G\" />, then for every <img src=\"http://s0.wp.com/latex.php?latex=A%2CB+%5Cin+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"A,B \\in |\\mathcal{C}|\" class=\"latex\" title=\"A,B \\in |\\mathcal{C}|\" /> there is an isomorphism <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D%28FA%2CFB%29+%5Ccong+%5Cmathcal%7BC%7D%28A%2CTB%29&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{D}(FA,FB) \\cong \\mathcal{C}(A,TB)\" class=\"latex\" title=\"\\mathcal{D}(FA,FB) \\cong \\mathcal{C}(A,TB)\" />: this observation is at the base of Kleisli’s construction.</p>
<p><strong>Definition 5.</strong> Let <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+%28T%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Cast%29&bg=ffffff&fg=333333&s=0\" alt=\"T = (T, \\eta, (\\cdot)^\\ast)\" class=\"latex\" title=\"T = (T, \\eta, (\\cdot)^\\ast)\" /> be a Kleisli triple on a category <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" />. The <em>Kleisli category </em>of <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" /> is the category <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D_T&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}_T\" class=\"latex\" title=\"\\mathcal{C}_T\" /> defined as follows:</p>
<ul>
<li><img src=\"http://s0.wp.com/latex.php?latex=%7C%5Cmathcal%7BC%7D_T%7C+%3D+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"|\\mathcal{C}_T| = |\\mathcal{C}|\" class=\"latex\" title=\"|\\mathcal{C}_T| = |\\mathcal{C}|\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D_T%28A%2CB%29+%3D+%5Cmathcal%7BC%7D%28A%2CTB%29&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}_T(A,B) = \\mathcal{C}(A,TB)\" class=\"latex\" title=\"\\mathcal{C}_T(A,B) = \\mathcal{C}(A,TB)\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%5Cmathrm%7Bid%7D_%7BA%7D%5E%7B%5Cmathcal%7BC%7D_T%7D+%3D+%5Ceta_A&bg=ffffff&fg=333333&s=0\" alt=\"\\mathrm{id}_{A}^{\\mathcal{C}_T} = \\eta_A\" class=\"latex\" title=\"\\mathrm{id}_{A}^{\\mathcal{C}_T} = \\eta_A\" />, that is, the identity of <img src=\"http://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=333333&s=0\" alt=\"A\" class=\"latex\" title=\"A\" /> in <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D_T&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}_T\" class=\"latex\" title=\"\\mathcal{C}_T\" /> is <img src=\"http://s0.wp.com/latex.php?latex=%5Ceta_A&bg=ffffff&fg=333333&s=0\" alt=\"\\eta_A\" class=\"latex\" title=\"\\eta_A\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=g+%5Cbullet+f+%3D+g%5E%5Cast+%5Ccirc+f&bg=ffffff&fg=333333&s=0\" alt=\"g \\bullet f = g^\\ast \\circ f\" class=\"latex\" title=\"g \\bullet f = g^\\ast \\circ f\" />, that is, the composition of <img src=\"http://s0.wp.com/latex.php?latex=f&bg=ffffff&fg=333333&s=0\" alt=\"f\" class=\"latex\" title=\"f\" /> and <img src=\"http://s0.wp.com/latex.php?latex=g&bg=ffffff&fg=333333&s=0\" alt=\"g\" class=\"latex\" title=\"g\" /> in <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D_T&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}_T\" class=\"latex\" title=\"\\mathcal{C}_T\" /> is the composition of <img src=\"http://s0.wp.com/latex.php?latex=f&bg=ffffff&fg=333333&s=0\" alt=\"f\" class=\"latex\" title=\"f\" /> and <img src=\"http://s0.wp.com/latex.php?latex=g%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"g^\\ast\" class=\"latex\" title=\"g^\\ast\" /> in <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" />.</li>
</ul>
<p><strong>Theorem 2.</strong> <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D_T&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}_T\" class=\"latex\" title=\"\\mathcal{C}_T\" /> is a category.</p>
<p><em>Proof:</em> If <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D_T%28A%2CB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}_T(A,B)\" class=\"latex\" title=\"f \\in \\mathcal{C}_T(A,B)\" />, then <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cbullet+%5Cmathrm%7Bid%7D_%7BA%7D%5E%7B%5Cmathcal%7BC%7D_T%7D+%3D+f%5E%5Cast+%5Ccirc+%5Ceta_A+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"f \\bullet \\mathrm{id}_{A}^{\\mathcal{C}_T} = f^\\ast \\circ \\eta_A = f\" class=\"latex\" title=\"f \\bullet \\mathrm{id}_{A}^{\\mathcal{C}_T} = f^\\ast \\circ \\eta_A = f\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathrm%7Bid%7D_%7BB%7D%5E%7B%5Cmathcal%7BC%7D_T%7D+%5Cbullet+f+%3D+%28%5Ceta_B%29%5E%5Cast+%5Ccirc+f+%3D+%5Cmathrm%7Bid%7D_%7BTB%7D+%5Ccirc+f+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"\\mathrm{id}_{B}^{\\mathcal{C}_T} \\bullet f = (\\eta_B)^\\ast \\circ f = \\mathrm{id}_{TB} \\circ f = f\" class=\"latex\" title=\"\\mathrm{id}_{B}^{\\mathcal{C}_T} \\bullet f = (\\eta_B)^\\ast \\circ f = \\mathrm{id}_{TB} \\circ f = f\" /> by the Kleisli laws. If <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D_T%28A%2CB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}_T(A,B)\" class=\"latex\" title=\"f \\in \\mathcal{C}_T(A,B)\" />, <img src=\"http://s0.wp.com/latex.php?latex=g+%5Cin+%5Cmathcal%7BC%7D_T%28B%2CC%29&bg=ffffff&fg=333333&s=0\" alt=\"g \\in \\mathcal{C}_T(B,C)\" class=\"latex\" title=\"g \\in \\mathcal{C}_T(B,C)\" />, and <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D_T%28C%2CD%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}_T(C,D)\" class=\"latex\" title=\"f \\in \\mathcal{C}_T(C,D)\" />, then <img src=\"http://s0.wp.com/latex.php?latex=%28h+%5Cbullet+g%29+%5Cbullet+f+%3D+%28h%5E%5Cast+%5Ccirc+g%29%5E%5Cast+%5Ccirc+f+%3D+h%5E%5Cast+%5Ccirc+g%5E%5Cast+%5Ccirc+f+%3D+h+%5Cbullet+%28g+%5Cbullet+f%29.&bg=ffffff&fg=333333&s=0\" alt=\"(h \\bullet g) \\bullet f = (h^\\ast \\circ g)^\\ast \\circ f = h^\\ast \\circ g^\\ast \\circ f = h \\bullet (g \\bullet f).\" class=\"latex\" title=\"(h \\bullet g) \\bullet f = (h^\\ast \\circ g)^\\ast \\circ f = h^\\ast \\circ g^\\ast \\circ f = h \\bullet (g \\bullet f).\" /> <img src=\"http://s0.wp.com/latex.php?latex=%5CBox&bg=ffffff&fg=333333&s=0\" alt=\"\\Box\" class=\"latex\" title=\"\\Box\" /></p>
<p>Our plan is to construct an adjunction quadruple <img src=\"http://s0.wp.com/latex.php?latex=%28F_T%2C+G_T%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Csharp%29&bg=ffffff&fg=333333&s=0\" alt=\"(F_T, G_T, \\eta, (\\cdot)^\\sharp)\" class=\"latex\" title=\"(F_T, G_T, \\eta, (\\cdot)^\\sharp)\" />, with <img src=\"http://s0.wp.com/latex.php?latex=F_T+%3A+%5Cmathcal%7BC%7D+%5Cto+%5Cmathcal%7BC%7D_T&bg=ffffff&fg=333333&s=0\" alt=\"F_T : \\mathcal{C} \\to \\mathcal{C}_T\" class=\"latex\" title=\"F_T : \\mathcal{C} \\to \\mathcal{C}_T\" /> and <img src=\"http://s0.wp.com/latex.php?latex=G_T+%3A+%5Cmathcal%7BC%7D_T+%5Cto+%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"G_T : \\mathcal{C}_T \\to \\mathcal{C}\" class=\"latex\" title=\"G_T : \\mathcal{C}_T \\to \\mathcal{C}\" />, such that <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+G_T+F_T&bg=ffffff&fg=333333&s=0\" alt=\"T = G_T F_T\" class=\"latex\" title=\"T = G_T F_T\" /> and <img src=\"http://s0.wp.com/latex.php?latex=G_T+f%5E%5Csharp+%3D+f%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"G_T f^\\sharp = f^\\ast\" class=\"latex\" title=\"G_T f^\\sharp = f^\\ast\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D_T%28A%2CB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}_T(A,B)\" class=\"latex\" title=\"f \\in \\mathcal{C}_T(A,B)\" />. We do this as follows:</p>
<ul>
<li><img src=\"http://s0.wp.com/latex.php?latex=F_T+A+%3D+A&bg=ffffff&fg=333333&s=0\" alt=\"F_T A = A\" class=\"latex\" title=\"F_T A = A\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=A+%5Cin+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"A \\in |\\mathcal{C}|\" class=\"latex\" title=\"A \\in |\\mathcal{C}|\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=G_T+A+%3D+TA&bg=ffffff&fg=333333&s=0\" alt=\"G_T A = TA\" class=\"latex\" title=\"G_T A = TA\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=A+%5Cin+%7C%5Cmathcal%7BC%7D_T%7C&bg=ffffff&fg=333333&s=0\" alt=\"A \\in |\\mathcal{C}_T|\" class=\"latex\" title=\"A \\in |\\mathcal{C}_T|\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=G_T+f+%3D+f%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"G_T f = f^\\ast\" class=\"latex\" title=\"G_T f = f^\\ast\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D_T%28A%2CB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}_T(A,B)\" class=\"latex\" title=\"f \\in \\mathcal{C}_T(A,B)\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Csharp+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"f^\\sharp = f\" class=\"latex\" title=\"f^\\sharp = f\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D%28A%2C+G_T+B%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}(A, G_T B)\" class=\"latex\" title=\"f \\in \\mathcal{C}(A, G_T B)\" />.</li>
</ul>
<p>Let us quickly check that <img src=\"http://s0.wp.com/latex.php?latex=G_T&bg=ffffff&fg=333333&s=0\" alt=\"G_T\" class=\"latex\" title=\"G_T\" /> is indeed a functor.<em></em> If <img src=\"http://s0.wp.com/latex.php?latex=A+%5Cin+%7C%5Cmathcal%7BC%7D_T%7C&bg=ffffff&fg=333333&s=0\" alt=\"A \\in |\\mathcal{C}_T|\" class=\"latex\" title=\"A \\in |\\mathcal{C}_T|\" /> then <img src=\"http://s0.wp.com/latex.php?latex=G_T+%5Cmathrm%7Bid%7D_%7BA%7D%5E%7B%5Cmathcal%7BC%7D_T%7D+%3D+%28%5Ceta_A%29%5E%5Cast+%3D+%5Cmathrm%7Bid%7D_%7BTA%7D+%3D+%5Cmathrm%7Bid%7D_%7BG_T+A%7D&bg=ffffff&fg=333333&s=0\" alt=\"G_T \\mathrm{id}_{A}^{\\mathcal{C}_T} = (\\eta_A)^\\ast = \\mathrm{id}_{TA} = \\mathrm{id}_{G_T A}\" class=\"latex\" title=\"G_T \\mathrm{id}_{A}^{\\mathcal{C}_T} = (\\eta_A)^\\ast = \\mathrm{id}_{TA} = \\mathrm{id}_{G_T A}\" />. If <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D_T%28A%2CB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}_T(A,B)\" class=\"latex\" title=\"f \\in \\mathcal{C}_T(A,B)\" /> and <img src=\"http://s0.wp.com/latex.php?latex=g+%5Cin+%5Cmathcal%7BC%7D_T%28B%2CC%29&bg=ffffff&fg=333333&s=0\" alt=\"g \\in \\mathcal{C}_T(B,C)\" class=\"latex\" title=\"g \\in \\mathcal{C}_T(B,C)\" />, then <img src=\"http://s0.wp.com/latex.php?latex=G_T%28g+%5Cbullet+f%29+%3D+%28g%5E%5Cast+%5Ccirc+f%29%5E%5Cast+%3D+g%5E%5Cast+%5Ccirc+f%5E%5Cast+%3D+G_Tg+%5Ccirc+G_Tf&bg=ffffff&fg=333333&s=0\" alt=\"G_T(g \\bullet f) = (g^\\ast \\circ f)^\\ast = g^\\ast \\circ f^\\ast = G_Tg \\circ G_Tf\" class=\"latex\" title=\"G_T(g \\bullet f) = (g^\\ast \\circ f)^\\ast = g^\\ast \\circ f^\\ast = G_Tg \\circ G_Tf\" />. We are only left to determine, for every <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D%28A%2C+G_T+B%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}(A, G_T B)\" class=\"latex\" title=\"f \\in \\mathcal{C}(A, G_T B)\" />, a unique <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Csharp+%5Cin+%5Cmathcal%7BC%7D_T%28F_T+A%2C+B%29&bg=ffffff&fg=333333&s=0\" alt=\"f^\\sharp \\in \\mathcal{C}_T(F_T A, B)\" class=\"latex\" title=\"f^\\sharp \\in \\mathcal{C}_T(F_T A, B)\" /> such that <img src=\"http://s0.wp.com/latex.php?latex=G_T+f%5E%5Csharp+%5Ccirc+%5Ceta_A+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"G_T f^\\sharp \\circ \\eta_A = f\" class=\"latex\" title=\"G_T f^\\sharp \\circ \\eta_A = f\" />: but the entire construction leads to the choice <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Csharp+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"f^\\sharp = f\" class=\"latex\" title=\"f^\\sharp = f\" />! Indeed, <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D_T%28F_T+A%2C+B%29+%3D+%5Cmathcal%7BC%7D_T%28A%2CB%29+%3D+%5Cmathcal%7BC%7D%28A%2CTB%29+%3D+%5Cmathcal%7BC%7D%28A%2C+G_T+B%29&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}_T(F_T A, B) = \\mathcal{C}_T(A,B) = \\mathcal{C}(A,TB) = \\mathcal{C}(A, G_T B)\" class=\"latex\" title=\"\\mathcal{C}_T(F_T A, B) = \\mathcal{C}_T(A,B) = \\mathcal{C}(A,TB) = \\mathcal{C}(A, G_T B)\" />, and <img src=\"http://s0.wp.com/latex.php?latex=G_Tf+%5Ccirc+%5Ceta_A+%3D+f%5E%5Cast+%5Ccirc+%5Ceta_A+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"G_Tf \\circ \\eta_A = f^\\ast \\circ \\eta_A = f\" class=\"latex\" title=\"G_Tf \\circ \\eta_A = f^\\ast \\circ \\eta_A = f\" /> by the Kleisli laws. Observe that the functor <img src=\"http://s0.wp.com/latex.php?latex=G_T&bg=ffffff&fg=333333&s=0\" alt=\"G_T\" class=\"latex\" title=\"G_T\" /> is the one that does all the work, while the function <img src=\"http://s0.wp.com/latex.php?latex=F_T&bg=ffffff&fg=333333&s=0\" alt=\"F_T\" class=\"latex\" title=\"F_T\" /> is little more than a placeholder.</p>
<p>By our identification of adjunctions with adjunction quadruples (see the previous talk) we also get <img src=\"http://s0.wp.com/latex.php?latex=F_T+f+%3D+%28%5Ceta_B+%5Ccirc+f%29%5E%5Csharp+%3D+%5Ceta_B+%5Ccirc+f&bg=ffffff&fg=333333&s=0\" alt=\"F_T f = (\\eta_B \\circ f)^\\sharp = \\eta_B \\circ f\" class=\"latex\" title=\"F_T f = (\\eta_B \\circ f)^\\sharp = \\eta_B \\circ f\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D%28A%2CB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}(A,B)\" class=\"latex\" title=\"f \\in \\mathcal{C}(A,B)\" />, and <img src=\"http://s0.wp.com/latex.php?latex=%28%5Cvarepsilon_T%29_S+%3D+%28%5Cmathrm%7Bid%7D_%7BG_T+S%7D%5E%7B%5Cmathcal%7BC%7D%7D%29%5E%5Csharp+%3D+%5Cmathrm%7Bid%7D_%7BTS%7D+%5Cin+%5Cmathcal%7BC%7D%28G_TF_TS%2C+TS%29+%3D+%5Cmathcal%7BC%7D_T%28F_TG_TS%2C+S%29&bg=ffffff&fg=333333&s=0\" alt=\"(\\varepsilon_T)_S = (\\mathrm{id}_{G_T S}^{\\mathcal{C}})^\\sharp = \\mathrm{id}_{TS} \\in \\mathcal{C}(G_TF_TS, TS) = \\mathcal{C}_T(F_TG_TS, S)\" class=\"latex\" title=\"(\\varepsilon_T)_S = (\\mathrm{id}_{G_T S}^{\\mathcal{C}})^\\sharp = \\mathrm{id}_{TS} \\in \\mathcal{C}(G_TF_TS, TS) = \\mathcal{C}_T(F_TG_TS, S)\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=S+%5Cin+%7C%5Cmathcal%7BC%7D_T%7C+%3D+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"S \\in |\\mathcal{C}_T| = |\\mathcal{C}|\" class=\"latex\" title=\"S \\in |\\mathcal{C}_T| = |\\mathcal{C}|\" />.</p>
<p>Kleisli’s solution is not the only one, but just one among many: and, in a sense that will be clear later, the “simplest” one. Another solution was constructed by Eilenberg and Moore, and is based on a completely different approach: instead of keeping the objects and specializing the morphisms, one expands the objects and redefines the morphisms.</p>
<p><strong>Definition 6.</strong> Let <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> be a category and let <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+%28T%2C+%5Ceta%2C+%5Cmu%29&bg=ffffff&fg=333333&s=0\" alt=\"T = (T, \\eta, \\mu)\" class=\"latex\" title=\"T = (T, \\eta, \\mu)\" /> be a monad on <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" />.</p>
<ol>
<li>A <em><img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebra</em> on <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> is a pair <img src=\"http://s0.wp.com/latex.php?latex=a+%3D+%28A%2Ca%29&bg=ffffff&fg=333333&s=0\" alt=\"a = (A,a)\" class=\"latex\" title=\"a = (A,a)\" /> where <img src=\"http://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=333333&s=0\" alt=\"A\" class=\"latex\" title=\"A\" /> is an object in <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> and <img src=\"http://s0.wp.com/latex.php?latex=a+%3A+TA+%5Cto+A&bg=ffffff&fg=333333&s=0\" alt=\"a : TA \\to A\" class=\"latex\" title=\"a : TA \\to A\" /> is such that <img src=\"http://s0.wp.com/latex.php?latex=a+%5Ccirc+%5Ceta_A+%3D+%5Cmathrm%7Bid%7D_A&bg=ffffff&fg=333333&s=0\" alt=\"a \\circ \\eta_A = \\mathrm{id}_A\" class=\"latex\" title=\"a \\circ \\eta_A = \\mathrm{id}_A\" /> and <img src=\"http://s0.wp.com/latex.php?latex=a+%5Ccirc+%5Cmu_A+%3D+a+%5Ccirc+Ta&bg=ffffff&fg=333333&s=0\" alt=\"a \\circ \\mu_A = a \\circ Ta\" class=\"latex\" title=\"a \\circ \\mu_A = a \\circ Ta\" />.</li>
<li>A morphism of <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebras from a <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebra <img src=\"http://s0.wp.com/latex.php?latex=a+%3D+%28A%2Ca%29&bg=ffffff&fg=333333&s=0\" alt=\"a = (A,a)\" class=\"latex\" title=\"a = (A,a)\" /> to a <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebra <img src=\"http://s0.wp.com/latex.php?latex=b+%3D+%28B%2Cb%29&bg=ffffff&fg=333333&s=0\" alt=\"b = (B,b)\" class=\"latex\" title=\"b = (B,b)\" /> is an arrow <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D%28A%2CB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}(A,B)\" class=\"latex\" title=\"f \\in \\mathcal{C}(A,B)\" /> such that <img src=\"http://s0.wp.com/latex.php?latex=b+%5Ccirc+Tf+%3D+f+%5Ccirc+a&bg=ffffff&fg=333333&s=0\" alt=\"b \\circ Tf = f \\circ a\" class=\"latex\" title=\"b \\circ Tf = f \\circ a\" />.</li>
<li>The category of <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebras on <img src=\"http://s0.wp.com/latex.php?latex=C&bg=ffffff&fg=333333&s=0\" alt=\"C\" class=\"latex\" title=\"C\" /> is the category <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D%5ET&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}^T\" class=\"latex\" title=\"\\mathcal{C}^T\" /> which has <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebras as objects, morphisms of <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebras as morphisms, and where identities and composition are defined as in <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" />.</li>
</ol>
<p>If <img src=\"http://s0.wp.com/latex.php?latex=T%3DM&bg=ffffff&fg=333333&s=0\" alt=\"T=M\" class=\"latex\" title=\"T=M\" /> is the free monoid construction, then an <img src=\"http://s0.wp.com/latex.php?latex=M&bg=ffffff&fg=333333&s=0\" alt=\"M\" class=\"latex\" title=\"M\" />-algebra is a function <img src=\"http://s0.wp.com/latex.php?latex=a+%3A+A%5E%5Cast+%5Cto+A&bg=ffffff&fg=333333&s=0\" alt=\"a : A^\\ast \\to A\" class=\"latex\" title=\"a : A^\\ast \\to A\" /> such that</p>
<ul>
<li><img src=\"http://s0.wp.com/latex.php?latex=a%5Bx%5D+%3D+x&bg=ffffff&fg=333333&s=0\" alt=\"a[x] = x\" class=\"latex\" title=\"a[x] = x\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=x+%5Cin+A&bg=ffffff&fg=333333&s=0\" alt=\"x \\in A\" class=\"latex\" title=\"x \\in A\" />, and</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=a%5Bu%5E1_1+%5Ccdots+u%5E1_%7Bn_1%7D+%5Ccdots+u%5Em_1+%5Ccdots+u%5Em_%7Bn_m%7D%5D+%3D+a%5Ba%5Bu%5E1_1+%5Ccdots+u%5E1_%7Bn_1%7D%5D+%5Ccdots+a%5Bu%5Em_1+%5Ccdots+u%5Em_%7Bn_m%7D%5D%5D&bg=ffffff&fg=333333&s=0\" alt=\"a[u^1_1 \\cdots u^1_{n_1} \\cdots u^m_1 \\cdots u^m_{n_m}] = a[a[u^1_1 \\cdots u^1_{n_1}] \\cdots a[u^m_1 \\cdots u^m_{n_m}]]\" class=\"latex\" title=\"a[u^1_1 \\cdots u^1_{n_1} \\cdots u^m_1 \\cdots u^m_{n_m}] = a[a[u^1_1 \\cdots u^1_{n_1}] \\cdots a[u^m_1 \\cdots u^m_{n_m}]]\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=u%5E1_1%2C+%5Cldots%2C+u%5E1_%7Bn_1%7D%2C+%5Cldots%2C+u%5Em_1%2C+%5Cldots%2C+u%5Em_%7Bn_m%7D+%5Cin+A&bg=ffffff&fg=333333&s=0\" alt=\"u^1_1, \\ldots, u^1_{n_1}, \\ldots, u^m_1, \\ldots, u^m_{n_m} \\in A\" class=\"latex\" title=\"u^1_1, \\ldots, u^1_{n_1}, \\ldots, u^m_1, \\ldots, u^m_{n_m} \\in A\" />.</li>
</ul>
<p>As <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" /> is a monad, for every object <img src=\"http://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=333333&s=0\" alt=\"A\" class=\"latex\" title=\"A\" /> of <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> there is a <em>free <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebra</em> <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%3D+%28TA%2C+%5Cmu_A%29&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A = (TA, \\mu_A)\" class=\"latex\" title=\"\\mu_A = (TA, \\mu_A)\" />, and every arrow <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D%28A%2CB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}(A,B)\" class=\"latex\" title=\"f \\in \\mathcal{C}(A,B)\" /> induces a morphism of free <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebras <img src=\"http://s0.wp.com/latex.php?latex=Tf+%5Cin+%5Cmathcal%7BC%7D%5ET%28%5Cmu_A%2C+%5Cmu_B%29&bg=ffffff&fg=333333&s=0\" alt=\"Tf \\in \\mathcal{C}^T(\\mu_A, \\mu_B)\" class=\"latex\" title=\"Tf \\in \\mathcal{C}^T(\\mu_A, \\mu_B)\" />. Moreover, <em>any</em> <img src=\"http://s0.wp.com/latex.php?latex=a+%5Cin+%5Cmathcal%7BC%7D%28TA%2CA%29&bg=ffffff&fg=333333&s=0\" alt=\"a \\in \\mathcal{C}(TA,A)\" class=\"latex\" title=\"a \\in \\mathcal{C}(TA,A)\" /><em></em> is, by definition, also a morphism from <img src=\"http://s0.wp.com/latex.php?latex=%28TA%2C+%5Cmu_A%29&bg=ffffff&fg=333333&s=0\" alt=\"(TA, \\mu_A)\" class=\"latex\" title=\"(TA, \\mu_A)\" /> to <img src=\"http://s0.wp.com/latex.php?latex=%28TA%2C+a%29&bg=ffffff&fg=333333&s=0\" alt=\"(TA, a)\" class=\"latex\" title=\"(TA, a)\" /> in <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D%5ET&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}^T\" class=\"latex\" title=\"\\mathcal{C}^T\" />.</p>
<p>This time, our plan is to construct an adjunction <img src=\"http://s0.wp.com/latex.php?latex=%28F%5ET%2C+G%5ET%2C+%5Ceta%2C+%5Cmu%29&bg=ffffff&fg=333333&s=0\" alt=\"(F^T, G^T, \\eta, \\mu)\" class=\"latex\" title=\"(F^T, G^T, \\eta, \\mu)\" /> such that <img src=\"http://s0.wp.com/latex.php?latex=F%5ET+%3A+%5Cmathcal%7BC%7D+%5Cto+%5Cmathcal%7BC%7D%5ET&bg=ffffff&fg=333333&s=0\" alt=\"F^T : \\mathcal{C} \\to \\mathcal{C}^T\" class=\"latex\" title=\"F^T : \\mathcal{C} \\to \\mathcal{C}^T\" />, <img src=\"http://s0.wp.com/latex.php?latex=G%5ET+%3A+%5Cmathcal%7BC%7D%5ET+%5Cto+%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"G^T : \\mathcal{C}^T \\to \\mathcal{C}\" class=\"latex\" title=\"G^T : \\mathcal{C}^T \\to \\mathcal{C}\" />, <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+G%5ET+F%5ET&bg=ffffff&fg=333333&s=0\" alt=\"T = G^T F^T\" class=\"latex\" title=\"T = G^T F^T\" />, and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%3D+G%5ET+%5Cvarepsilon_%7BF%5ET+A%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A = G^T \\varepsilon_{F^T A}\" class=\"latex\" title=\"\\mu_A = G^T \\varepsilon_{F^T A}\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=A+%5Cin+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"A \\in |\\mathcal{C}|\" class=\"latex\" title=\"A \\in |\\mathcal{C}|\" />. We do this as follows:</p>
<ul>
<li><img src=\"http://s0.wp.com/latex.php?latex=F%5ET+A+%3D+%5Cmu_A+%3D+%28TA%2C+%5Cmu_A%29&bg=ffffff&fg=333333&s=0\" alt=\"F^T A = \\mu_A = (TA, \\mu_A)\" class=\"latex\" title=\"F^T A = \\mu_A = (TA, \\mu_A)\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=F%5ET+f+%3D+Tf&bg=ffffff&fg=333333&s=0\" alt=\"F^T f = Tf\" class=\"latex\" title=\"F^T f = Tf\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=G%5ET+a+%3D+A&bg=ffffff&fg=333333&s=0\" alt=\"G^T a = A\" class=\"latex\" title=\"G^T a = A\" /> if <img src=\"http://s0.wp.com/latex.php?latex=a+%3A+TA+%5Cto+A&bg=ffffff&fg=333333&s=0\" alt=\"a : TA \\to A\" class=\"latex\" title=\"a : TA \\to A\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=G%5ET+f+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"G^T f = f\" class=\"latex\" title=\"G^T f = f\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%5Cvarepsilon%5ET_a+%3D+a&bg=ffffff&fg=333333&s=0\" alt=\"\\varepsilon^T_a = a\" class=\"latex\" title=\"\\varepsilon^T_a = a\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=a+%3D+%28A%2Ca%29+%5Cin+%7C%5Cmathcal%7BC%7D%5ET%7C&bg=ffffff&fg=333333&s=0\" alt=\"a = (A,a) \\in |\\mathcal{C}^T|\" class=\"latex\" title=\"a = (A,a) \\in |\\mathcal{C}^T|\" />.</li>
</ul>
<p>Then clearly <img src=\"http://s0.wp.com/latex.php?latex=G%5ET+F%5ET+%3D+T&bg=ffffff&fg=333333&s=0\" alt=\"G^T F^T = T\" class=\"latex\" title=\"G^T F^T = T\" />, while naturality of <img src=\"http://s0.wp.com/latex.php?latex=%5Cvarepsilon&bg=ffffff&fg=333333&s=0\" alt=\"\\varepsilon\" class=\"latex\" title=\"\\varepsilon\" /> follows from the properties of free <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebras with respect to <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebra morphisms. In addition, if <img src=\"http://s0.wp.com/latex.php?latex=S+%3D+a+%3D+%28A%2Ca%29+%5Cin+%7C%5Cmathcal%7BC%7D%5ET%7C&bg=ffffff&fg=333333&s=0\" alt=\"S = a = (A,a) \\in |\\mathcal{C}^T|\" class=\"latex\" title=\"S = a = (A,a) \\in |\\mathcal{C}^T|\" /> then <img src=\"http://s0.wp.com/latex.php?latex=G%5ET+%5Cvarepsilon%5ET_S+%5Ccirc+%5Ceta_%7BG%5ET+S%7D+%3D+a+%5Ccirc+%5Ceta_A+%3D+%5Cmathrm%7Bid%7D_%7BG%5ET+S%7D&bg=ffffff&fg=333333&s=0\" alt=\"G^T \\varepsilon^T_S \\circ \\eta_{G^T S} = a \\circ \\eta_A = \\mathrm{id}_{G^T S}\" class=\"latex\" title=\"G^T \\varepsilon^T_S \\circ \\eta_{G^T S} = a \\circ \\eta_A = \\mathrm{id}_{G^T S}\" />, and if <img src=\"http://s0.wp.com/latex.php?latex=A+%5Cin+%5Cmathrm%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"A \\in \\mathrm{C}\" class=\"latex\" title=\"A \\in \\mathrm{C}\" /> then <img src=\"http://s0.wp.com/latex.php?latex=%5Cvarepsilon%5ET_%7BF%5ET+A%7D+%5Ccirc+F%5ET+%5Ceta_A+%3D+%5Cmu_A+%5Ccirc+T%5Ceta_A+%5Cmathrm%7Bid%7D_%7BTA%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\varepsilon^T_{F^T A} \\circ F^T \\eta_A = \\mu_A \\circ T\\eta_A \\mathrm{id}_{TA}\" class=\"latex\" title=\"\\varepsilon^T_{F^T A} \\circ F^T \\eta_A = \\mu_A \\circ T\\eta_A \\mathrm{id}_{TA}\" />. We thus have a full-featured adjunction: this time, <img src=\"http://s0.wp.com/latex.php?latex=F%5ET&bg=ffffff&fg=333333&s=0\" alt=\"F^T\" class=\"latex\" title=\"F^T\" /> is doing all the work, and <img src=\"http://s0.wp.com/latex.php?latex=G%5ET&bg=ffffff&fg=333333&s=0\" alt=\"G^T\" class=\"latex\" title=\"G^T\" /> is just a forgetful functor.</p>
<p><strong>Theorem 3.</strong> Let <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+%28T%2C+%5Ceta%2C+%5Cmu%29&bg=ffffff&fg=333333&s=0\" alt=\"T = (T, \\eta, \\mu)\" class=\"latex\" title=\"T = (T, \\eta, \\mu)\" /> be a monad on a <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" />. Identify the monad <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" /> with the corresponding Kleisli triple <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+%28T%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Cast%29&bg=ffffff&fg=333333&s=0\" alt=\"T = (T, \\eta, (\\cdot)^\\ast)\" class=\"latex\" title=\"T = (T, \\eta, (\\cdot)^\\ast)\" />. The Kleisli category <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D_T&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}_T\" class=\"latex\" title=\"\\mathcal{C}_T\" /> is equivalent to the full subcategory of <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D%5ET&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}^T\" class=\"latex\" title=\"\\mathcal{C}^T\" /> generated by the free <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebras.</p>
<p><em>Proof:</em> Define a functor <img src=\"http://s0.wp.com/latex.php?latex=J+%3A+%5Cmathcal%7BC%7D_T+%5Cto+%5Cmathcal%7BC%7D%5ET&bg=ffffff&fg=333333&s=0\" alt=\"J : \\mathcal{C}_T \\to \\mathcal{C}^T\" class=\"latex\" title=\"J : \\mathcal{C}_T \\to \\mathcal{C}^T\" /> by setting <img src=\"http://s0.wp.com/latex.php?latex=JA+%3D+%5Cmu_A+%3D+%28TA%2C+%5Cmu_A%29&bg=ffffff&fg=333333&s=0\" alt=\"JA = \\mu_A = (TA, \\mu_A)\" class=\"latex\" title=\"JA = \\mu_A = (TA, \\mu_A)\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=A+%5Cin+%7C%5Cmathcal%7BC%7D_T%7C+%3D+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"A \\in |\\mathcal{C}_T| = |\\mathcal{C}|\" class=\"latex\" title=\"A \\in |\\mathcal{C}_T| = |\\mathcal{C}|\" />, and <img src=\"http://s0.wp.com/latex.php?latex=Jf+%3D+%5Cmu_B+%5Ccirc+Tf+%3D+f%5E%5Cast+%5Cin+%5Cmathcal%7BC%7D%5ET%28JA%2C+JB%29&bg=ffffff&fg=333333&s=0\" alt=\"Jf = \\mu_B \\circ Tf = f^\\ast \\in \\mathcal{C}^T(JA, JB)\" class=\"latex\" title=\"Jf = \\mu_B \\circ Tf = f^\\ast \\in \\mathcal{C}^T(JA, JB)\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D_T%28A%2CB%29+%3D+%5Cmathcal%7BC%7D%28A%2C+TB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}_T(A,B) = \\mathcal{C}(A, TB)\" class=\"latex\" title=\"f \\in \\mathcal{C}_T(A,B) = \\mathcal{C}(A, TB)\" />. Then <img src=\"http://s0.wp.com/latex.php?latex=J&bg=ffffff&fg=333333&s=0\" alt=\"J\" class=\"latex\" title=\"J\" /> is a faithful functor, because if <img src=\"http://s0.wp.com/latex.php?latex=f%2Cg+%5Cin+%5Cmathcal%7BC%7D_T%28A%2CB%29&bg=ffffff&fg=333333&s=0\" alt=\"f,g \\in \\mathcal{C}_T(A,B)\" class=\"latex\" title=\"f,g \\in \\mathcal{C}_T(A,B)\" />, then <img src=\"http://s0.wp.com/latex.php?latex=f+%3D+%5Cmu_B+%5Ccirc+%5Ceta_%7BTB%7D+%5Ccirc+f+%3D+%5Cmu_B+%5Ccirc+Tf+%5Ccirc+%5Ceta_A&bg=ffffff&fg=333333&s=0\" alt=\"f = \\mu_B \\circ \\eta_{TB} \\circ f = \\mu_B \\circ Tf \\circ \\eta_A\" class=\"latex\" title=\"f = \\mu_B \\circ \\eta_{TB} \\circ f = \\mu_B \\circ Tf \\circ \\eta_A\" /> and similarly <img src=\"http://s0.wp.com/latex.php?latex=g+%3D+%5Cmu_B+%5Ccirc+%5Ceta_%7BTB%7D+%5Ccirc+g+%3D+%5Cmu_B+%5Ccirc+Tg+%5Ccirc+%5Ceta_A&bg=ffffff&fg=333333&s=0\" alt=\"g = \\mu_B \\circ \\eta_{TB} \\circ g = \\mu_B \\circ Tg \\circ \\eta_A\" class=\"latex\" title=\"g = \\mu_B \\circ \\eta_{TB} \\circ g = \\mu_B \\circ Tg \\circ \\eta_A\" />, so that <img src=\"http://s0.wp.com/latex.php?latex=f+%3D+g&bg=ffffff&fg=333333&s=0\" alt=\"f = g\" class=\"latex\" title=\"f = g\" /> if <img src=\"http://s0.wp.com/latex.php?latex=Jf+%3D+Jg&bg=ffffff&fg=333333&s=0\" alt=\"Jf = Jg\" class=\"latex\" title=\"Jf = Jg\" />. But <img src=\"http://s0.wp.com/latex.php?latex=J&bg=ffffff&fg=333333&s=0\" alt=\"J\" class=\"latex\" title=\"J\" /> is also full, because if <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+%28TA%2C+%5Cmu_A%29+%5Cto+%28TB%2C+%5Cmu_B%29&bg=ffffff&fg=333333&s=0\" alt=\"f : (TA, \\mu_A) \\to (TB, \\mu_B)\" class=\"latex\" title=\"f : (TA, \\mu_A) \\to (TB, \\mu_B)\" /> is a morphism of free <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebras, then from the laws of monads follows that <img src=\"http://s0.wp.com/latex.php?latex=f+%3D+J%28f+%5Ccirc+%5Ceta_A%29&bg=ffffff&fg=333333&s=0\" alt=\"f = J(f \\circ \\eta_A)\" class=\"latex\" title=\"f = J(f \\circ \\eta_A)\" />. <img src=\"http://s0.wp.com/latex.php?latex=%5CBox&bg=ffffff&fg=333333&s=0\" alt=\"\\Box\" class=\"latex\" title=\"\\Box\" /></p>
<p>But things get even more interesting than this! Let <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+%28T%2C+%5Ceta%2C+%5Cmu%29&bg=ffffff&fg=333333&s=0\" alt=\"T = (T, \\eta, \\mu)\" class=\"latex\" title=\"T = (T, \\eta, \\mu)\" /> be a monad: let us consider <em>all</em> the adjunctions <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> that generate <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />. What can be a <em>morphism</em> of such adjunctions? First, if <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> is a solution with <img src=\"http://s0.wp.com/latex.php?latex=F+%3A+%5Cmathcal%7BC%7D+%5Cto+%5Cmathcal%7BD%7D&bg=ffffff&fg=333333&s=0\" alt=\"F : \\mathcal{C} \\to \\mathcal{D}\" class=\"latex\" title=\"F : \\mathcal{C} \\to \\mathcal{D}\" />, and <img src=\"http://s0.wp.com/latex.php?latex=%28F%27%2C+G%27%2C+%5Ceta%2C+%5Cvarepsilon%27%29&bg=ffffff&fg=333333&s=0\" alt=\"(F', G', \\eta, \\varepsilon')\" class=\"latex\" title=\"(F', G', \\eta, \\varepsilon')\" /> is a solution with <img src=\"http://s0.wp.com/latex.php?latex=F%27+%3A+%5Cmathcal%7BC%7D+%5Cto+%5Cmathcal%7BD%7D%27&bg=ffffff&fg=333333&s=0\" alt=\"F' : \\mathcal{C} \\to \\mathcal{D}'\" class=\"latex\" title=\"F' : \\mathcal{C} \\to \\mathcal{D}'\" />, we may consider a functor <img src=\"http://s0.wp.com/latex.php?latex=L+%3A+%5Cmathcal%7BD%7D+%5Cto+%5Cmathcal%7BD%27%7D&bg=ffffff&fg=333333&s=0\" alt=\"L : \\mathcal{D} \\to \\mathcal{D'}\" class=\"latex\" title=\"L : \\mathcal{D} \\to \\mathcal{D'}\" /> as a morphism from <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> to <img src=\"http://s0.wp.com/latex.php?latex=%28F%27%2C+G%27%2C+%5Ceta%2C+%5Cvarepsilon%27%29&bg=ffffff&fg=333333&s=0\" alt=\"(F', G', \\eta, \\varepsilon')\" class=\"latex\" title=\"(F', G', \\eta, \\varepsilon')\" />. Next, we want that the equalities <img src=\"http://s0.wp.com/latex.php?latex=GF+%3D+T+%3D+G%27F%27&bg=ffffff&fg=333333&s=0\" alt=\"GF = T = G'F'\" class=\"latex\" title=\"GF = T = G'F'\" /> are not affected by mid-way application of <img src=\"http://s0.wp.com/latex.php?latex=L&bg=ffffff&fg=333333&s=0\" alt=\"L\" class=\"latex\" title=\"L\" />: this translates into the two conditions <img src=\"http://s0.wp.com/latex.php?latex=L+%5Ccirc+F+%3D+F%27&bg=ffffff&fg=333333&s=0\" alt=\"L \\circ F = F'\" class=\"latex\" title=\"L \\circ F = F'\" /> and <img src=\"http://s0.wp.com/latex.php?latex=G%27+%5Ccirc+L+%3D+G&bg=ffffff&fg=333333&s=0\" alt=\"G' \\circ L = G\" class=\"latex\" title=\"G' \\circ L = G\" />. Finally, as the previous point yields <img src=\"http://s0.wp.com/latex.php?latex=LFG+%3D+F%27G%27L&bg=ffffff&fg=333333&s=0\" alt=\"LFG = F'G'L\" class=\"latex\" title=\"LFG = F'G'L\" />, we want that <img src=\"http://s0.wp.com/latex.php?latex=L&bg=ffffff&fg=333333&s=0\" alt=\"L\" class=\"latex\" title=\"L\" /> does not interfere with the counits: that is, <img src=\"http://s0.wp.com/latex.php?latex=L%5Cvarepsilon+%3D+%5Cvarepsilon%27_L&bg=ffffff&fg=333333&s=0\" alt=\"L\\varepsilon = \\varepsilon'_L\" class=\"latex\" title=\"L\\varepsilon = \\varepsilon'_L\" />.</p>
<p><strong>Definition 7.</strong> Let <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+%28T%2C+%5Ceta%2C+%5Cmu%29&bg=ffffff&fg=333333&s=0\" alt=\"T = (T, \\eta, \\mu)\" class=\"latex\" title=\"T = (T, \\eta, \\mu)\" /> be a monad on a category <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> and let <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" />, <img src=\"http://s0.wp.com/latex.php?latex=%28F%27%2C+G%27%2C+%5Ceta%2C+%5Cvarepsilon%27%29&bg=ffffff&fg=333333&s=0\" alt=\"(F', G', \\eta, \\varepsilon')\" class=\"latex\" title=\"(F', G', \\eta, \\varepsilon')\" /> be two adjunctions that generate <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />, with <img src=\"http://s0.wp.com/latex.php?latex=F+%3A+%5Cmathcal%7BC%7D+%5Cto+%5Cmathcal%7BD%7D&bg=ffffff&fg=333333&s=0\" alt=\"F : \\mathcal{C} \\to \\mathcal{D}\" class=\"latex\" title=\"F : \\mathcal{C} \\to \\mathcal{D}\" /> and <img src=\"http://s0.wp.com/latex.php?latex=F%27+%3A+%5Cmathcal%7BC%7D+%5Cto+%5Cmathcal%7BD%7D%27&bg=ffffff&fg=333333&s=0\" alt=\"F' : \\mathcal{C} \\to \\mathcal{D}'\" class=\"latex\" title=\"F' : \\mathcal{C} \\to \\mathcal{D}'\" />, respectively. A <em><img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-preserving functor</em> from <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> to <img src=\"http://s0.wp.com/latex.php?latex=%28F%27%2C+G%27%2C+%5Ceta%2C+%5Cvarepsilon%27%29&bg=ffffff&fg=333333&s=0\" alt=\"(F', G', \\eta, \\varepsilon')\" class=\"latex\" title=\"(F', G', \\eta, \\varepsilon')\" /> is a functor <img src=\"http://s0.wp.com/latex.php?latex=L+%3A+%5Cmathcal%7BD%7D+%5Cto+%5Cmathcal%7BD%7D%27&bg=ffffff&fg=333333&s=0\" alt=\"L : \\mathcal{D} \\to \\mathcal{D}'\" class=\"latex\" title=\"L : \\mathcal{D} \\to \\mathcal{D}'\" /> such that <img src=\"http://s0.wp.com/latex.php?latex=L+%5Ccirc+F+%3D+F%27&bg=ffffff&fg=333333&s=0\" alt=\"L \\circ F = F'\" class=\"latex\" title=\"L \\circ F = F'\" />, <img src=\"http://s0.wp.com/latex.php?latex=G%27+%5Ccirc+L+%3D+G&bg=ffffff&fg=333333&s=0\" alt=\"G' \\circ L = G\" class=\"latex\" title=\"G' \\circ L = G\" />, and <img src=\"http://s0.wp.com/latex.php?latex=L%5Cvarepsilon+%3D+%5Cvarepsilon%27_L&bg=ffffff&fg=333333&s=0\" alt=\"L\\varepsilon = \\varepsilon'_L\" class=\"latex\" title=\"L\\varepsilon = \\varepsilon'_L\" />.</p>
<p>It is straightforward to see that <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-generating adjunctions together with <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-preserving functors form a category <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathrm%7BAdj%7D%28T%29&bg=ffffff&fg=333333&s=0\" alt=\"\\mathrm{Adj}(T)\" class=\"latex\" title=\"\\mathrm{Adj}(T)\" />: composition is provided by the usual composition of functors, while the identity of <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> in <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathrm%7BAdj%7D%28T%29&bg=ffffff&fg=333333&s=0\" alt=\"\\mathrm{Adj}(T)\" class=\"latex\" title=\"\\mathrm{Adj}(T)\" /> is the identity functor of <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{D}\" class=\"latex\" title=\"\\mathcal{D}\" /> if <img src=\"http://s0.wp.com/latex.php?latex=F+%3A+%5Cmathcal%7BC%7D+%5Cto+%5Cmathcal%7BD%7D&bg=ffffff&fg=333333&s=0\" alt=\"F : \\mathcal{C} \\to \\mathcal{D}\" class=\"latex\" title=\"F : \\mathcal{C} \\to \\mathcal{D}\" />.</p>
<p>To confirm that our intuition is correct, let us verify that <img src=\"http://s0.wp.com/latex.php?latex=J&bg=ffffff&fg=333333&s=0\" alt=\"J\" class=\"latex\" title=\"J\" /> satisfies the three given equations:</p>
<ul>
<li><img src=\"http://s0.wp.com/latex.php?latex=J+F_T+A+%3D+JA+%3D+%28T_A%2C+%5Cmu_A%29+%3D+F%5ET+A&bg=ffffff&fg=333333&s=0\" alt=\"J F_T A = JA = (T_A, \\mu_A) = F^T A\" class=\"latex\" title=\"J F_T A = JA = (T_A, \\mu_A) = F^T A\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=J+F_T+f+%3D+%5Cmu_B+%5Ccirc+T%28%5Ceta_B+%5Ccirc+f%29+%3D+%5Cmu_B+%5Ccirc+T%5Ceta_B+%5Ccirc+Tf+%3D+%5Cmathrm%7Bid%7D_%7BTB%7D+%5Ccirc+Tf+%3D+F%5ETf&bg=ffffff&fg=333333&s=0\" alt=\"J F_T f = \\mu_B \\circ T(\\eta_B \\circ f) = \\mu_B \\circ T\\eta_B \\circ Tf = \\mathrm{id}_{TB} \\circ Tf = F^Tf\" class=\"latex\" title=\"J F_T f = \\mu_B \\circ T(\\eta_B \\circ f) = \\mu_B \\circ T\\eta_B \\circ Tf = \\mathrm{id}_{TB} \\circ Tf = F^Tf\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=G%5ET+J+A+%3D+G%5ET+%28TA%2C+%5Cmu_A%29+%3D+TA+%3D+G_T+A&bg=ffffff&fg=333333&s=0\" alt=\"G^T J A = G^T (TA, \\mu_A) = TA = G_T A\" class=\"latex\" title=\"G^T J A = G^T (TA, \\mu_A) = TA = G_T A\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=G%5ET+J+f+%3D+G%5ET+%28%5Cmu_B+%5Ccirc+Tf%29+%3D+%5Cmu_B+%5Ccirc+Tf+%3D+f%5E%5Cast+%3D+G_T+f&bg=ffffff&fg=333333&s=0\" alt=\"G^T J f = G^T (\\mu_B \\circ Tf) = \\mu_B \\circ Tf = f^\\ast = G_T f\" class=\"latex\" title=\"G^T J f = G^T (\\mu_B \\circ Tf) = \\mu_B \\circ Tf = f^\\ast = G_T f\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=J%28%5Cvarepsilon_T%29_S+%3D+J%5Cmathrm%7Bid%7D_%7BTS%7D%3D+%5Cmu_S+%5Ccirc+T%5Cmathrm%7Bid%7D_%7BTS%7D+%3D+%5Cmu_S+%3D+%5Cvarepsilon%5ET_%7B%28TS%2C+%5Cmu_S%29%7D+%3D+%5Cvarepsilon%5ET_%7BJS%7D&bg=ffffff&fg=333333&s=0\" alt=\"J(\\varepsilon_T)_S = J\\mathrm{id}_{TS}= \\mu_S \\circ T\\mathrm{id}_{TS} = \\mu_S = \\varepsilon^T_{(TS, \\mu_S)} = \\varepsilon^T_{JS}\" class=\"latex\" title=\"J(\\varepsilon_T)_S = J\\mathrm{id}_{TS}= \\mu_S \\circ T\\mathrm{id}_{TS} = \\mu_S = \\varepsilon^T_{(TS, \\mu_S)} = \\varepsilon^T_{JS}\" />.</li>
</ul>
<p><strong>Theorem 4.</strong> Let <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+%28T%2C+%5Ceta%2C+%5Cmu%29&bg=ffffff&fg=333333&s=0\" alt=\"T = (T, \\eta, \\mu)\" class=\"latex\" title=\"T = (T, \\eta, \\mu)\" /> be a monad. Then the Kleisli adjunction is the initial object of <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathrm%7BAdj%7D%28T%29&bg=ffffff&fg=333333&s=0\" alt=\"\\mathrm{Adj}(T)\" class=\"latex\" title=\"\\mathrm{Adj}(T)\" />, the Eilenberg-Moore adjunction is the final object. In particular, <img src=\"http://s0.wp.com/latex.php?latex=J&bg=ffffff&fg=333333&s=0\" alt=\"J\" class=\"latex\" title=\"J\" /> is the only arrow in <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathrm%7BAdj%7D%28T%29&bg=ffffff&fg=333333&s=0\" alt=\"\\mathrm{Adj}(T)\" class=\"latex\" title=\"\\mathrm{Adj}(T)\" /> from the former to the latter.</p>
<p><em>Proof:</em> If <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> is the Kleisli adjunction, then the only choice for <img src=\"http://s0.wp.com/latex.php?latex=L&bg=ffffff&fg=333333&s=0\" alt=\"L\" class=\"latex\" title=\"L\" /> is <img src=\"http://s0.wp.com/latex.php?latex=LA+%3D+F%27A&bg=ffffff&fg=333333&s=0\" alt=\"LA = F'A\" class=\"latex\" title=\"LA = F'A\" /> and <img src=\"http://s0.wp.com/latex.php?latex=Lf+%3D+%5Cvarepsilon%27_%7BF%27B%7D+%5Ccirc+F%27+f&bg=ffffff&fg=333333&s=0\" alt=\"Lf = \\varepsilon'_{F'B} \\circ F' f\" class=\"latex\" title=\"Lf = \\varepsilon'_{F'B} \\circ F' f\" />. If <img src=\"http://s0.wp.com/latex.php?latex=%28F%27%2C+G%27%2C+%5Ceta%2C+%5Cvarepsilon%27%29&bg=ffffff&fg=333333&s=0\" alt=\"(F', G', \\eta, \\varepsilon')\" class=\"latex\" title=\"(F', G', \\eta, \\varepsilon')\" /> is the Eilenberg-Moore adjunction, then the only choice for <img src=\"http://s0.wp.com/latex.php?latex=L&bg=ffffff&fg=333333&s=0\" alt=\"L\" class=\"latex\" title=\"L\" /> is <img src=\"http://s0.wp.com/latex.php?latex=LS+%3D+%28GS%2C+G+%5Cvarepsilon_S%29&bg=ffffff&fg=333333&s=0\" alt=\"LS = (GS, G \\varepsilon_S)\" class=\"latex\" title=\"LS = (GS, G \\varepsilon_S)\" /> and <img src=\"http://s0.wp.com/latex.php?latex=Lf+%3D+Gf&bg=ffffff&fg=333333&s=0\" alt=\"Lf = Gf\" class=\"latex\" title=\"Lf = Gf\" />. <img src=\"http://s0.wp.com/latex.php?latex=%5CBox&bg=ffffff&fg=333333&s=0\" alt=\"\\Box\" class=\"latex\" title=\"\\Box\" /></p>
<br />  <a href=\"http://feeds.wordpress.com/1.0/gocomments/theorylunch.wordpress.com/885/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/theorylunch.wordpress.com/885/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=theorylunch.wordpress.com&blog=43735749&post=885&subd=theorylunch&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "92e03d16b542face905b39bb94f05733") (150 (20949 25792 498434) "http://kenta.blogspot.com/2013/06/sjhltpdo-unscope-symbol.html" "Ken T Takusagawa: [sjhltpdo] Unscope symbol" "noreply@blogger.com (Ken)" "Mon, 10 Jun 2013 08:49:00 +0000" "<p dir=\"ltr\"><code>let { foo = ... } in let { hide foo } in foo</code></p><p dir=\"ltr\">This should cause the compiler to signal an error.  We wish to assert that a certain symbol is not used within an inner scope, perhaps to avoid programmer typos of similar symbols.  \"hide foo\" can also be a statement in <code>do</code> notation.</p><p dir=\"ltr\">If we have <a href=\"http://kenta.blogspot.com/2013/04/isjnkupe-local-types-and-imports.html\">local imports</a>, then perhaps syntax like <code>let { import OUTER-SCOPE hiding (foo) }</code>, where <code>OUTER-SCOPE</code> is a new keyword.</p><p dir=\"ltr\">We could also hide everything in the outer scope except a few symbols.  <code>let { import OUTER-SCOPE(foo); import Prelude }</code>.</p>" nil nil "df2433ea452286105d65b846b31f5c96") (149 (20949 25792 498107) "http://winterkoninkje.dreamwidth.org/84469.html" "wren ng thornton: Dungeon World: Assassin class" nil "Sun, 09 Jun 2013 00:32:03 +0000" "<p>After far too long, I've finally found a new roleplaying group. We're using <a href=\"http://www.dungeon-world.com/\">Dungeon World</a>, a lightweight system I've never used before. It's a class-based system, which I've never been too fond of, but it does seem like it gets rid of most of the things I hate about class-based systems. The core book only gives the standard D&D-style classes, but they give some guidelines on making up your own classes. For my character I worked with the GM to come up with a new <a href=\"http://llama.freegeek.org/~wren/resources/blog/assassin.pdf\">Assassin</a> class which combines some of the traits of the Thief and the Fighter. I tried to make sure it's balanced against the other classes and doesn't obviate the Thief/Fighter, but not having used DW before it's hard to be sure. If you've used DW and have any comments, I'd be interested in hearing them.</p>
<p><i>Edit:</i> I've posted a new version which adjusts the damage option for the Death Dealer and Assassin's Strike moves. Also included is a discussion about how different ways of doing DD/AS would affect DPS, which is necessary for doing a fair comparison against other classes. If you run a game with this class, let me know how it goes.</p><br /><br /><img src=\"http://www.dreamwidth.org/tools/commentcount?user=winterkoninkje&ditemid=84469\" alt=\"comment count unavailable\" height=\"12\" style=\"vertical-align: middle;\" width=\"30\" /> comments" nil nil "677779af46b7f0a7a41798fc7f4bc722") (148 (20949 25792 497725) "http://joyful.com/blog/2013-06-08-zwiki-styling.html" "Simon Michael: Zwiki styling" nil "Sat, 08 Jun 2013 19:15:00 +0000" "<div style=\"font-style: italic;\">June  8, 2013</div>
<h2>Zwiki styling</h2>
<p>
</p><p><a href=\"http://joyful.com/2013-06-07-git-hooks-for-site-updates..html\">Yesterday</a>.</p>
<p>Next backlog item: <a href=\"https://trello.com/card/5127f6bb0698a36663002981/16\">style the wiki more like hledger.org</a>.</p>
<p>The wiki software is my own <a href=\"http://zwiki.org\">Zwiki</a> engine. I haven’t skinned a zwiki for a few years, but with the docs (<a href=\"http://zwiki.org/CustomizingAppearance\">CustomizingAppearance</a>, <a href=\"http://zwiki.org/QuickReference#skin-templates\">QuickReference -> skin templates</a>, <a href=\"http://zwiki.org/zwikidir/skins/zwiki\">standard templates</a>) plus experience, it went pretty smoothly.</p>
<p>Zwiki config changes at this point:</p>
<ul>
<li>pasted the standard maintemplate.pt into a Page Template with the same name in the wiki folder, with the hledger.org stylesheet and nav buttons added (in the head and body respectively)</li>
<li>added a style override to give the <code>#content</code> div a zero margin</li>
<li>renamed FrontPage to “hledger wiki”, and configured the new name in a <code>default_page</code> property on the wiki folder</li>
<li>disabled the icon in the zwiki page header by adding a <code>site_logo</code> folder property containing an empty html comment</li>
<li>committed a bugfix for a broken image border that was appearing in the rating form</li>
</ul>
<p>What didn’t work: rewording Zwiki’s “home” navigation link. My custom <code>links.pt</code> page template should do the trick, but it’s being ignored. This is unsatisfying, I suppose I will dig in and debug it, after a suitable cooling-off-and-reflection period.</p>
<p>Zope is still very impressive, and pleasing to use.</p>
<p>Here’s the <a href=\"http://hledger.org/wiki\">wiki</a>, now looking like part of hledger.org.</p>" nil nil "587c4c21b3bdb01689dda4bc38769898") (147 (20949 25792 497260) "http://joyful.com/blog/2013-06-07-git-hooks-for-site-updates.html" "Simon Michael: git pull hook, github service hook for quick site updates" nil "Sat, 08 Jun 2013 00:30:00 +0000" "<div style=\"font-style: italic;\">June  8, 2013</div>
<h2>git pull hook, github service hook for quick site updates</h2>
<p>
</p><p>Finished the hledger.org updating task begun <a href=\"http://joyful.com/2013-06-06-blog-tinkering-hledger.org.html\">yesterday</a>. There were a few parts to this.</p>
<p>I added an executable `.git/hooks/post-merge’ script in the website repo:</p>
<pre class=\"sourceCode bash\"><code class=\"sourceCode bash\"><span class=\"co\">#!/bin/sh</span>
<span class=\"co\">#</span>
<span class=\"co\"># Rebuild the website after a pull.</span>
<span class=\"kw\">exec</span> make site</code></pre>
<p>Now it runs <code>make site</code> (rebuilding the hakyll script and any changed site content as necessary) after a successful git pull to this repo.</p>
<p>Then I configured a github service hook, using my setup for ledger-cli.org as a guide. Added another <a href=\"http://hub.darcs.net/simon/github-listener\">github listener</a> daemon to <code>/etc/supervisord.conf</code>:</p>
<pre><code>[program:hledger.org-webhook]
command=/src/github-listener/github-listener-yesod 10000 'sudo -u simon git pull'
directory=/src/hledger.org
priority=3
redirect_stderr=true
autostart=true
autorestart=true
environment=LANG=\"en_US.UTF-8\"</code></pre>
<p>activated it using <a href=\"http://supervisord.org\">supervisorctl</a>:</p>
<pre><code>supervisor> update
hledger.org-webhook: added process group
supervisor> status
...
hledger.org-webhook              RUNNING    pid 31379, uptime 0:00:02
...</code></pre>
<p>and configure a <a href=\"https://help.github.com/articles/post-receive-hooks\">webhook</a> in the hledger repo on github, posting to <code>http://hledger.org:10000/</code>. Now any change landing in the github repo causes an immediate update of hledger.org.</p>" nil nil "8b412f3327c0909169bf9d3852242f82") (146 (20949 25792 496799) "http://joyful.com/blog/2013-06-06-blog-tinkering-hledger.org.html" "Simon Michael: Blog tinkering, hledger.org" nil "Fri, 07 Jun 2013 01:00:00 +0000" "<div style=\"font-style: italic;\">June  7, 2013</div>
<h2>Blog tinkering, hledger.org</h2>
<p>
</p><h3 id=\"a-better-ghci-fix\">A better ghci fix</h3>
<p>I forgot to commit <a href=\"http://joyful.com/2013-06-05-ghci-fix.html\">last night’s ghci fix</a>, which is good because I <a href=\"https://github.com/simonmichael/hledger/commit/39f6ec9f04a5f077ac8e0f4036d81d5185c23c4a\">improved it</a> today, fixing the code duplication.</p>
<h3 id=\"blog-tinkering\">Blog tinkering</h3>
<p>Thanks to help from #hakyll, I spent some time figuring out how to safely update published blog posts without having them reappear as new on Planet Haskell. The problem seemed to be that I wasn’t setting a separate <code>updated</code> date, which caused the <code>published</code> date to change, which caused the post to reappear as new, at least in my feed reader.</p>
<p>Solution: Start blog posts with metadata like this:</p>
<pre><code>---
title:     6/6
author:    Simon Michael
published: 2013-06-06 16:00:00PDT
updated:   2013-06-06 17:00:00PDT
---</code></pre>
<h3 id=\"hledger.org\">hledger.org</h3>
<p>Worked on the next hledger backlog item, improving the website update process. Did some file cleanup and testing.</p>
<p>I found that I had broken hledger.org several days ago, when I gratuitously enhanced:</p>
<pre><code>RewriteRule ^/bugs?/?$   https://github.com/simonmichael/hledger/issues [L,NE]</code></pre>
<p>to:</p>
<pre><code>RewriteRule ^/(bugs|issues)?/?$   https://github.com/simonmichael/hledger/issues [L,NE]</code></pre>
<p>Doh. Fixed it:</p>
<pre><code>RewriteRule ^/(bugs?|issues)/?$   https://github.com/simonmichael/hledger/issues [L,NE]</code></pre>
<p>Next: yes, the cron job for updating the site is reporting an error - though it seems to successfully update the site all the same:</p>
<pre><code>From github.com:simonmichael/hledger
47ebc21..e87f492  master     -> origin/master
Updating 47ebc21..e87f492
Fast-forward
README.md |    2 +-
1 file changed, 1 insertion(+), 1 deletion(-)
cd site; ghc site.hs -L/usr/lib -package-db ~/src/joyful.com/cabal-dev/packages-*.conf
cd site; ./site build
Initialising...
Creating store...
Creating provider...
Running rules...
Checking for out-of-date items
Compiling
site: _site/README.html: commitBuffer: invalid argument (invalid character)
updated README.md
make: *** [site] Error 1</code></pre>
<p>Re-enabling <code>export LANG=en_US.UTF-8</code> in the Makefile seems to have fixed it. I have a non-ascii character in the site footer. Setting the LANG environment variable is the quick way to configure a locale, which used to be very much required to avoid encoding errors with GHC 6, but which I thought was less necessary with GHC 7. Perhaps not.</p>" nil nil "9600c2a5d128c8bf5478662f9b5ffee6") (145 (20949 25792 496059) "http://tomschrijvers.blogspot.com/2013/06/ppdp-13-last-call-for-papers.html" "Tom Schrijvers: PPDP '13: Last Call for Papers" "noreply@blogger.com (Tom Schrijvers)" "Thu, 06 Jun 2013 15:56:18 +0000" "<div style=\"text-align: left;\" dir=\"ltr\"><br />=====================================================================<br /><br />                        Last Call for papers<br />               15th International Symposium on<br />       Principles and Practice of Declarative Programming<br />                           PPDP 2013<br /><br /><span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Special Issue of Science of Computer Programming (SCP)<br /><br />            Madrid, Spain, September 16-18, 2013<br />                 (co-located with LOPSTR 2013)<br /><br />              http://users.ugent.be/~tschrijv/PPDP2013/<br /><br />======================================================================<br /><br />PPDP 2013 is a forum that brings together researchers from the declarative<br />programming communities, including those working in the logic, constraint and<br />functional programming paradigms, but also embracing a variety of other<br />paradigms such as visual programming, executable specification languages,<br />database languages, and knowledge representation languages.<br /><br />The goal is to stimulate research in the use of logical formalisms and methods<br />for specifying, performing, and analysing computations, including mechanisms<br />for mobility, modularity, concurrency, object-orientation, security,<br />verification and static analysis. Papers related to the use of declarative<br />paradigms and tools in industry and education are especially solicited. Topics<br />of interest include, but are not limited to:<br /><br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Functional programming<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Logic programming<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Answer-set programming<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Functional-logic programming<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Declarative visual languages<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Constraint Handling Rules<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Parallel implementation and concurrency<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Monads, type classes and dependent type systems<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Declarative domain-specific languages<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Termination, resource analysis and the verification of declarative programs<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Transformation and partial evaluation of declarative languages<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Language extensions for security and tabulation<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Probabilistic modelling in a declarative language and modelling reactivity<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Memory management and the implementation of declarative systems<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Practical experiences and industrial application<br /><br />This year the conference will be co-located with the 23nd International<br />Symposium on Logic-Based Program Synthesis and Transformation (LOPSTR 2013) and<br />held in cooperation with ACM SIGPLAN.  The conference will be held in Madrid,<br />Spain. Previous symposia were held at Leuven (Belgium), Odense (Denmark),<br />Hagenberg (Austria), Coimbra (Portugal), Valencia (Spain), Wroclaw (Poland),<br />Venice (Italy), Lisboa (Portugal), Verona (Italy), Uppsala (Sweden), Pittsburgh<br />(USA), Florence (Italy), Montreal (Canada), and Paris (France).<br /><br />Papers must describe original work, be written and presented in English, and<br />must not substantially overlap with papers that have been published or that are<br />simultaneously submitted to a journal, conference, or workshop with refereed<br />proceedings. Work that already appeared in unpublished or informally published<br />workshop proceedings may be submitted (please contact the PC chair in case of<br />questions).  Proceedings will be published in the ACM International Conference<br />Proceedings Series.<br /><br /><br />After the symposium, a selection of the best papers will be invited to extend<br />their submissions in the light of the feedback solicited at the symposium.  The<br />papers are expected to include at least 30% extra material over and above the<br />PPDP version. Then, after another round of reviewing, these revised papers will<br />be published in a special issue of SCP with a target publication date by<br />Elsevier of 2014.<br /><br />Important Dates<br /><br /><span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Abstract Submission: <span style=\"white-space: pre;\" class=\"Apple-tab-span\">  </span>June 10, 2013<br /><span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Paper submission: <span style=\"white-space: pre;\" class=\"Apple-tab-span\">  </span>June 13, 2013<br /><span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Notification: <span style=\"white-space: pre;\" class=\"Apple-tab-span\">   </span>July 18, 2013<br /><span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Camera-ready: <span style=\"white-space: pre;\" class=\"Apple-tab-span\">   </span>August 4, 2013<br /><br /><span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Symposium: <span style=\"white-space: pre;\" class=\"Apple-tab-span\">   </span>September 16-18, 2013 <br /><br /><span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Invites for SCP: <span style=\"white-space: pre;\" class=\"Apple-tab-span\">  </span>October 2, 2013<br /><span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Submission of SCP: <span style=\"white-space: pre;\" class=\"Apple-tab-span\">  </span>December 11, 2013<br /><span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Notification from SCP: <span style=\"white-space: pre;\" class=\"Apple-tab-span\">  </span>February 22, 2014<br /><span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Camera-ready for SCP: <span style=\"white-space: pre;\" class=\"Apple-tab-span\">  </span>March 14, 2014<br /><br />Authors should submit an electronic copy of the paper (written in English) in<br />PDF.  Each submission must include on its first page the paper title; authors<br />and their affiliations; abstract; and three to four keywords. The keywords will<br />be used to assist us in selecting appropriate reviewers for the paper. Papers<br />should consist of no more than 12 pages, formatted following the ACM SIG<br />proceedings template (option 1). The 12 page limit must include references but<br />excludes well-marked appendices not intended for publication. Referees are not<br />required to read the appendices, and thus papers should be intelligible without<br />them.<br /><br />Program Committee<br /><br />Sergio Antoy               Portland State University, USA<br />Manuel Carro               IMDEA Software Institute, Spain<br />Iliano Cervesato           Carnegie Mellon University, Qatar<br />Agostino Dovier            Universita degli Studi di Udine, Italy<br />Maria Garcia de la Banda   Monash University, Australia<br />Ralf Hinze                 University of Oxford, UK<br />Yukiyoshi Kameyama         University of Tsukuba, Japan<br />Oleg Kiselyov              USA<br />Yanhong Annie Liu          State University of New York at Stony Brook, USA<br />Stefan Monnier             Universite de Montreal, Canada<br />Alan Mycroft               University of Cambrige, UK<br />Bruno C. d. S. Oliveira<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>   National University of Singapore, Singapore<br />Alberto Pettorossi         Universita di Roma Tor Vergata, Italy<br />Enrico Pontelli            New Mexico State University, USA<br />Kristoffer Rose            IBM Research, USA<br />Sukyoung Ryu               KAIST, South Korea<br />Vitor Santos Costa         University of Porto, Portugal<br />Torsten Schaub             University Potsdam, Germany<br />Tom Schrijvers             Ghent University, Belgium<br />Martin Sulzmann            Hochschule Karlsruhe, Germany<br />Wouter Swierstra           Universiteit Utrecht, The Netherlands<br />Tarmo Uustalu              Institute of Cybernetics, Estonia<br />Janis Voigtlaender         University of Bonn, Germany<br />Meng Wang                  Chalmers University of Technology, Sweden<br />Jan Wielemaker             Universiteit van Amsterdam, The Netherlands<br /><br />Program Chair<br /><br />    Tom Schrijvers<br />    Department of Applied Mathematics and Computer Science<br />    Ghent University<br />    9000 Gent, Belgium<br /><br />General Chair<br /><br />    Ricardo Pena<br />    Facultad de Informatica<br />    Universidad Complutense de Madrid<br />    28040 Madrid, Spain<br /><div><br /></div></div>" nil nil "b08992db795cb1bba13198d8e1942060") (144 (20949 15567 82991) "http://neilmitchell.blogspot.com/2013/06/building-llvm-using-shake.html" "Neil Mitchell: Building LLVM using Shake" "noreply@blogger.com (Neil Mitchell)" "Sat, 22 Jun 2013 21:01:00 +0000" "<i>Summary: You can now build LLVM using Shake, and a rebuild with nothing to do goes massively faster than make (0.8s vs 199s) and fractionally faster than Ninja (0.8s vs 0.9s).</i><br /><br />As of <a href=\"https://github.com/ndmitchell/shake\">Shake</a> 0.10.4 the <tt>shake</tt> tool can execute <a href=\"http://martine.github.io/ninja/\">Ninja</a> build files. <a href=\"http://llvm.org/\">LLVM</a> can be built with <a href=\"http://www.cmake.org/\">CMake</a>, and CMake can generate a Ninja build file, so you can compile LLVM with Shake. I've included the full steps I followed at the end of this post.<br /><br />The main thing I wanted to test was how fast a rebuild with nothing to do was using Shake vs Ninja, as Ninja prides itself on having \"a focus on speed\". When compiling LLVM on Windows with GCC, a nothing to do build using make takes 199s, Shake takes 0.8s and Ninja takes 0.9s. The CMake generator does not use one of the latest Ninja build features (the deps keyword), but if it did, Shake would be about 0.1s faster and Ninja would be at least 0.1s faster.<br /><br />Full builds with Shake and Ninja both take about the same time, but with anything higher than 2 CPUs the linker phase ends up contending heavily and the machine thrashes the disk, making robust measurements impossible. The solution would be to use <a href=\"http://neilmitchell.blogspot.co.uk/2013/02/summary-management-of-finite-resources.html\">finite resources</a> on the linkers, something that needs implementing in the CMake Ninja generator, and would then allow more CPUs to be used.<br /><br />Other than speed, why would you use Shake to compile LLVM?<br /><br /><ul><li>If you build with <tt>--report</tt> the file <tt>report.html</tt> will be generated. Open that report file and you can see numerous details about the build - how good the parallel utilisation was, what changed to cause what to rebuild, summary statistics, a dependency graph and more. See the Help page in any generated report for more details.</li><li>If you build with <tt>--progress</tt> the console titlebar will display a predicted completion time, how many seconds until your build completes. The predicted time will be fairly inaccurate the first time round, but future runs are influenced by recorded timings, and can produce useful guesses.</li><li>If your CPU has a preference for functional languages it will make the registers happier.</li></ul><br />Existing Ninja users may also be interested in <a href=\"https://github.com/ndmitchell/shake/blob/master/docs/Ninja.md\">a guide to running Ninja builds with Shake</a>, which gives a few more details on using Shake like Ninja.<br /><br /><b>Compiling LLVM with Shake</b><br /><br />These instructions are how I compiled LLVM with Shake, on Windows, with GCC. I didn't run into any significant problems, but there were two minor niggles I had to work though (both listed below). I compiled LLVM with make, then Ninja, then Shake, to check each phase as I went - but only the final Shake compile is actually necessary.<br /><br /><ul><li>Install Shake with <tt>cabal update && cabal install shake --global</tt>, if you are new to Haskell package installation, see <a href=\"https://github.com/ndmitchell/shake/blob/master/docs/Ninja.md#installing-shake\">here</a>.</li><li>Get LLVM and compile it with make, I followed the instructions at <tt>http://bencode.net/clangonwindows</tt>, which has disappeared in the last few days (I have emailed the web master to see where it went).</li><li>Install <a href=\"http://martine.github.io/ninja/\">Ninja</a>.</li><li>Run CMake over LLVM <a href=\"http://llvm.org/docs/CMake.html\">like this</a>, configuring with <tt>-G Ninja</tt>.</li><li>To build with Ninja I had to edit <tt>build.ninja</tt> line 17697 to delete <tt>lib/clang/3.4/lib/windows/libclang_rt.i386.a,</tt> which won't build on my system and isn't built at all by the make system - I suspect this is a tip/mingw issue. At this stage you can compile LLVM with Ninja.</li><li>Type <tt>touch tools/clang/lib/Basic/CMakeFiles/clang_revision_tag</tt> to create a dummy file. There is a Ninja rule to create such a file, but the rule is wrong since it doesn't actually produce the file, and Shake's sanity checking spots that.</li><li>Run <tt>shake -j2</tt> in the build directory. Come back later and you will have a build.</li><li>Run <tt>shake -j2</tt> again to enjoy the fast nothing to do build.</li></ul>" nil nil "4af6d2b2497aec80b9814659087428c8") (143 (20947 56086 995663) "http://winterkoninkje.dreamwidth.org/84727.html" "wren ng thornton: Bitties" nil "Wed, 03 Jul 2013 03:57:07 +0000" "<p>Just got back from <a href=\"http://www.cs.cornell.edu/Conferences/MFPS29/\">MFPS</a>-<a href=\"http://lii.rwth-aachen.de/lics/lics13/\">LICS</a>-<a href=\"http://csf2013.seas.harvard.edu/index.html\">CSF</a> saturday night. T'was the first LICS I've been to, and my first time in the deep south. I had fun overall. Definitely enjoyed the French Quarter with its narrower streets, delightful architecture, and other non-American features. And I ran into the Pride parade the day after arriving; I seem to have a knack for that ;)  The humidity was killer though.</p>
<p>The slides from my <a href=\"http://www.indiana.edu/~iulg/nlcs.html\">NLCS</a> talk are <a href=\"http://llama.freegeek.org/~wren/pubs/chiastic_nlcs2013.pdf\">available here</a>. I've been having some issues with my bibtex2html script, so they're not linked to on the publications page yet; but they will be once I get that issue fixed.</p>
<p>In less happy news, I got some bloodwork back today. Cholesterol is far far too high, and I'm getting into the pre-diabetic range for bloodsugar levels. So, I'm starting a major diet change in hopes of getting those under control. Apparently lack of protein is a big part of the problem (for me), which is ironic since most americans get far too much. Damn midwestern genes. Went grocery shopping today; it's profoundly difficult to get a 1::1 carbs-to-protein ratio as a vegetarian.</p><br /><br /><img src=\"http://www.dreamwidth.org/tools/commentcount?user=winterkoninkje&ditemid=84727\" alt=\"comment count unavailable\" height=\"12\" style=\"vertical-align: middle;\" width=\"30\" /> comments" nil nil "8d99624ed918906bbb4ced559b60a631") (142 (20947 56086 995286) "http://winterkoninkje.dreamwidth.org/83774.html" "wren ng thornton: Upcoming talk" nil "Wed, 03 Jul 2013 03:43:14 +0000" "<p>Next month I'll be giving a talk at the <a href=\"http://www.indiana.edu/~iulg/nlcs.html\">NLCS</a> workshop, on the chiastic lambda-calculi I first presented at NASSLLI 2010 (<a href=\"http://llama.freegeek.org/~wren/pubs/ccgjp_nasslli2010.pdf\">slides</a>[1]). After working out some of the metatheory for one of my quals, I gave more recent talks at our local PL Wonks and CLingDing seminars (<a href=\"http://llama.freegeek.org/~wren/pubs/chiastic_plwonks2013.pdf\">slides</a>). The NASSLLI talk was more about the linguistic motivations and the general idea, whereas the PLWonks/CLingDing talks were more about the formal properties of the calculus itself. For NLCS I hope to combine these threads a bit better— which has always been the challenge with this work.</p>
<p>NLCS is collocated with this year's <a href=\"http://lii.rwth-aachen.de/lics/lics13/\">LICS</a> (and MFPS and CSF). I'll also be around for LICS itself, and in town for MFPS though probably not attending. So if you're around, feel free to stop by and chat.</p>
<p>[1] N.B., the NASSLLI syntax is a bit different than the newer version: square brackets were used instead of angle brackets (the latter were chosen because they typeset better in general); juxtaposition was just juxtaposition rather than being made explicit; and the left- vs right-chiastic distinction was called chi vs ksi (however, it turns out that ksi already has an important meaning in type theory).</p>
<p><i>Edit 2013.07.02:</i> the slides are <a href=\"http://llama.freegeek.org/~wren/pubs/chiastic_nlcs2013.pdf\">available here</a>.</p><br /><br /><img src=\"http://www.dreamwidth.org/tools/commentcount?user=winterkoninkje&ditemid=83774\" alt=\"comment count unavailable\" height=\"12\" style=\"vertical-align: middle;\" width=\"30\" /> comments" nil nil "db8826ca76c6d2fb61f6a5ce5b33ab88") (141 (20947 56086 994717) "http://feedproxy.google.com/~r/ezyang/~3/zSgfaMODNkM/" "Edward Z. Yang: No grammar? No problem!" nil "Wed, 03 Jul 2013 02:17:02 +0000" "<div class=\"document\">
<p>One day, you’re strolling along fields of code, when suddenly you spot a syntax construct that you don’t understand.</p>
<p>Perhaps you’d ask your desk-mate, who’d tell you in an instant what it was.</p>
<p>Perhaps your programming toolchain can tell you. (Perhaps the IDE would you mouse over the construct, or you’re using Coq which let’s you <tt class=\"docutils literal\">Locate</tt> custom notations.)</p>
<p>Perhaps you’d pull up the manual (or, more likely, one of many tutorials) and scan through looking for the syntax construct in question.</p>
<p>But when all this fails, what is one to do?  What if the code in question is written in an internal language for a compiler, whose details have changed since it was last documented, for which the documentation is out of date?</p>
<p><em>No problem.</em> As long as you’re willing to roll up your sleeves and take a look at the source code of the compiler in question, you can frequently resolve your question for less effort than it would have taken to look up the syntax in the manual (and it’s guaranteed to be up-to-date too!)  The key is that  modern compilers all use parser generators, and the input to these are essentially executable specifications.</p>
<hr class=\"docutils\" />
<p>I’ll give two examples from GHC.  The first is from C--, GHC’s high-level assembly language. Consider this function:</p>
<pre class=\"literal-block\">INFO_TABLE_RET(stg_maskUninterruptiblezh_ret, RET_SMALL, W_ info_ptr)
return (P_ ret)
{
StgTSO_flags(CurrentTSO) =
%lobits32(
(TO_W_(StgTSO_flags(CurrentTSO))
| TSO_BLOCKEX)
& ~TSO_INTERRUPTIBLE
);
return (ret);
}
</pre>
<p>Some aspects of this definition are familiar to someone who has written C before, but there are some mysterious bits. For example, what does the <tt class=\"docutils literal\">return (P_ ret)</tt> mean in the preamble?</p>
<p>The first order of business is to find the relevant file.  When the code in question has very distinctive keywords (as this one does), a grep will often do the trick:</p>
<pre class=\"literal-block\">ezyang@javelin:~/Dev/ghc-clean/rts$ grep -R INFO_TABLE_RET ../compiler/
../compiler/cmm/CmmParse.y:INFO_TABLE_RET ( label, FRAME_TYPE, info_ptr, field1, ..., fieldN )
../compiler/cmm/CmmParse.y:        'INFO_TABLE_RET'{ L _ (CmmT_INFO_TABLE_RET) }
../compiler/cmm/CmmParse.y:        | 'INFO_TABLE_RET' '(' NAME ',' INT ')'
../compiler/cmm/CmmParse.y:        | 'INFO_TABLE_RET' '(' NAME ',' INT ',' formals0 ')'
../compiler/cmm/CmmParse.y:-- is.  That is, for an INFO_TABLE_RET we want the return convention,
../compiler/cmm/CmmLex.x:  | CmmT_INFO_TABLE_RET
../compiler/cmm/CmmLex.x:   ( \"INFO_TABLE_RET\",     CmmT_INFO_TABLE_RET ),
</pre>
<p>File extensions can also be dead giveaways; GHC uses a parser generator named Happy, and the file extension of Happy files is <tt class=\"docutils literal\">.y</tt>:</p>
<pre class=\"literal-block\">ezyang@javelin:~/Dev/ghc-clean/rts$ find ../compiler -name *.y
../compiler/cmm/CmmParse.y
../compiler/parser/ParserCore.y
</pre>
<p>From there, we can search the file for keywords or symbols (check for the string token name if a lexer is used; also, make sure to quote alphanumeric literals).  A symbol can show up in multiple places, as it does for return:</p>
<pre class=\"literal-block\">maybe_conv :: { Convention }
: {- empty -}        { NativeNodeCall }
| 'return'           { NativeReturn }
</pre>
<p>and:</p>
<pre class=\"literal-block\">stmt    :: { CmmParse () }
: ';'                                   { return () }
...
| 'goto' NAME ';'
{ do l <- lookupLabel $2; emit (mkBranch l) }
| 'return' '(' exprs0 ')' ';'
{ doReturn $3 }
</pre>
<p>Guessing from the names of the productions and the contexts, it seems more likely that <tt class=\"docutils literal\">maybe_conv</tt> is the relevant production. It is used here:</p>
<pre class=\"literal-block\">cmmproc :: { CmmParse () }
: info maybe_conv maybe_formals maybe_body
{ do ((entry_ret_label, info, stk_formals, formals), agraph) <-
getCodeR $ loopDecls $ do {
(entry_ret_label, info, stk_formals) <- $1;
formals <- sequence (fromMaybe [] $3);
$4;
return (entry_ret_label, info, stk_formals, formals) }
let do_layout = isJust $3
code (emitProcWithStackFrame $2 info
entry_ret_label stk_formals formals agraph
do_layout ) }
</pre>
<p>Now, if you really need to know <em>exactly</em> how it is lade out, you can go and checkout how <tt class=\"docutils literal\">emitProcWithStackFrame</tt> is implemented.  Alternately, you might hope there is a useful comment in the source file which explains what is up:</p>
<pre class=\"literal-block\">A stack frame is written like this:
INFO_TABLE_RET ( label, FRAME_TYPE, info_ptr, field1, ..., fieldN )
return ( arg1, ..., argM )
{
... code ...
}
where field1 ... fieldN are the fields of the stack frame (with types)
arg1...argN are the values returned to the stack frame (with types).
The return values are assumed to be passed according to the
NativeReturn convention.
</pre>
<hr class=\"docutils\" />
<p>The second example is for STG, which you can ask GHC to print out using <tt class=\"docutils literal\"><span class=\"pre\">-ddump-stg</span></tt>. Now, there is no parser for STG, so instead you’ll have to look at the <em>pretty-printer</em>. Not too difficult. Take this simple function:</p>
<pre class=\"literal-block\">Gnam.$WKST =
\\r [tpl_sl4 tpl_sl6]
case tpl_sl4 of tpl_sl8 {
__DEFAULT ->
case tpl_sl6 of tpl_sl9 {
__DEFAULT -> Gnam.KST [tpl_sl8 tpl_sl9];
};
};
</pre>
<p>Some aspects are familiar. But what does the <tt class=\"docutils literal\">\\r</tt> mean?</p>
<p>Once again, we have to find the relevant source file.  Since STG is printed out only when we pass the <tt class=\"docutils literal\"><span class=\"pre\">-ddump-stg</span></tt> flag, a good start is to trace the flag through the source code:</p>
<pre class=\"literal-block\">ezyang@javelin:~/Dev/ghc-clean/compiler$ grep -R ddump-stg .
./main/DynFlags.hs:  , Flag \"ddump-stg\"               (setDumpFlag Opt_D_dump_stg)
ezyang@javelin:~/Dev/ghc-clean/compiler$ grep -R Opt_D_dump_stg .
./main/DynFlags.hs:   | Opt_D_dump_stg
./main/DynFlags.hs:  , Flag \"ddump-stg\"               (setDumpFlag Opt_D_dump_stg)
./simplStg/SimplStg.lhs:        ; dumpIfSet_dyn dflags Opt_D_dump_stg \"STG syntax:\"
</pre>
<p>That’s a good sign! Popping open <tt class=\"docutils literal\">SimpleStg.lhs</tt> gives us:</p>
<pre class=\"literal-block\">; dumpIfSet_dyn dflags Opt_D_dump_stg \"STG syntax:\"
(pprStgBindings un_binds)
</pre>
<p>And the location of <tt class=\"docutils literal\">pprStgBindings</tt> (<tt class=\"docutils literal\">compiler/stgSyn/StgSyn.lhs</tt>) is in fact the ticket.</p>
<p>STG is pretty small, and as it turns out if you just do a quick scan of the file you’re likely to find what you need. But in case you don’t, you can still figure things out deliberately. Suppose we search for a quoted backslash:</p>
<pre class=\"literal-block\">pprStgExpr (StgLam bndrs body)
= sep [ char '\\\\' <+> ppr_list (map (pprBndr LambdaBind) bndrs)
<+> ptext (sLit \"->\"),
pprStgExpr body ]
where ppr_list = brackets . fsep . punctuate comma
...
-- general case
pprStgRhs (StgRhsClosure cc bi free_vars upd_flag srt args body)
= sdocWithDynFlags $ \\dflags ->
hang (hsep [if gopt Opt_SccProfilingOn dflags then ppr cc else empty,
pp_binder_info bi,
ifPprDebug (brackets (interppSP free_vars)),
char '\\\\' <> ppr upd_flag, pprMaybeSRT srt, brackets (interppSP args)])
4 (ppr body)
</pre>
<p>Which is it? As it turns out:</p>
<pre class=\"literal-block\">StgLam is used *only* during CoreToStg's work. Before CoreToStg has
finished it encodes (\\x -> e) as (let f = \\x -> e in f)
</pre>
<p>Since <tt class=\"docutils literal\"><span class=\"pre\">-ddump-stg</span></tt> is post-CoreToSTG, we must be looking at <tt class=\"docutils literal\">StgRhsClosure</tt>, and <tt class=\"docutils literal\">ppr upd_flag</tt> looks like the ticket.  <tt class=\"docutils literal\">r</tt> must be an <tt class=\"docutils literal\">upd_flag</tt>, whatever that is. An <tt class=\"docutils literal\">UpdateFlag</tt>, as it turns out:</p>
<pre class=\"literal-block\">data UpdateFlag = ReEntrant | Updatable | SingleEntry
instance Outputable UpdateFlag where
ppr u = char $ case u of
ReEntrant   -> 'r'
Updatable   -> 'u'
SingleEntry -> 's'
</pre>
<p>The <tt class=\"docutils literal\">r</tt> indicates the function is re-entrant! (Of course, as for what that means, you’ll have to consult other documentation.)</p>
<hr class=\"docutils\" />
<p>Of course, in an ideal world, all of this would be documented. But even if it is not, there is no reason why you can’t help yourself. If your codebase is as nice as GHC’s, there will be plenty of breadcrumbs and comments to help you out. I hope this gives some insight into one possible thought process when you encounter something you don’t know, and don’t know how to learn. (Of course, sometimes it’s just best to ignore it!)</p>
</div>
<img src=\"http://feeds.feedburner.com/~r/ezyang/~4/zSgfaMODNkM\" height=\"1\" width=\"1\" />" nil nil "56bbf01a6602377366c5e22567f26e54") (140 (20947 56086 992802) "http://praisecurseandrecurse.blogspot.com/2013/07/the-polar-game-in-haskell-day-5-array-v.html" "Paul Potts: The Polar Game in Haskell, Day 5: Array v. List" "noreply@blogger.com (Paul Potts)" "Tue, 02 Jul 2013 23:25:00 +0000" "<p>So, a little more progress in learning me a Haskell: I've managed to implement the board using an immutable array. There's good news and bad news here. If you're an old hand at functional programming, you probably know all this and more, but I needed to do a little thinking on purely functional data structures. I have not really been satisfied with the amount of code necessary to manage my 2-D board in a list. I spent some time doodling some possible alternative implementation before concluding that purely functional data structures -- in which nodes are never mutated -- are hard. Anything I might be accustomed to doing with double or multiply-linked lists is pretty much a washout, since you can't ever share structure. In fact, I think one data structure I came up with might not be constructible at all without being able to mutate links between nodes. So I'm starting to understand why the tutorials all advise me to stick with lists.</p> <p>Nevertheless, this is a small problem, and efficiency is not my biggest concern, at least not in the learning phase. I wanted to figure out how to use an immutable array. The tutorials have not been very satisfying. They seem to assume that anything this trivial is too trivial to demonstrate. But here's what I did.</p> <p>First, the type of an array in Haskell encodes the number of dimensions and the node type, but not the size. You set that when you call the constructor. Here's a 2-D array type for my board:</p> <pre>type BoardArray = Array ( Int, Int ) Tile</pre> <p>I specified some bounds:</p> <pre>max_row :: Int<br />max_row = 3<br /><br />max_col :: Int<br />max_col = 23</pre> <p>And I should point out one of the fundamental problems with using arrays: it's very easy to kill your program by exceeding the array bounds. There is a similar problem with <b>head</b>, but when writing functions with pattern-matching and guards there are pretty accepted conventions for dealing with empty lists. I suppose one could use guard patterns on all array accesses, but it starts to seem a little silly.</p> <p>The next thing is that a given array works with some auxiliary types. The <b>//</b> operator takes an array and a list of tuples and builds a new array with updated content. The type of that list of tuples is this:</p> <pre>type TileAssocList = [ ( ( Int, Int ), Tile ) ]</pre> <p>For accessing multiple items in an array, the <b>range</b> method builds lists of indexing tuples. The syntax to range requires tuples of tuples, with the parentheses piling up, so I wrapped it up in a function:</p> <pre>make_2d_range :: Int -> Int -> Int -> Int -> [ ( Int, Int ) ]<br />make_2d_range y0 x0 y1 x1 = range ( ( y0, x0 ), ( y1, x1 ) )</pre> <p>So how does that work? It just iterates coordinates, permuting from higher indices to lower, like so:</p> <pre>*Main> make_range 0 0 0 1<br />[(0,0),(0,1)]<br /><br />*Main> make_range 0 0 1 3<br />[(0,0),(0,1),(0,2),(0,3),(1,0),(1,1),(1,2),(1,3)]</pre> <p>For this problem domain, I need to know how reversed ranges work. For example, when the penguin is facing West, I want to build a range and a list of tiles in reverse index order. Can range do that for me?</p> <pre>*Main> make_range 0 23 0 0<br />[]</pre> <p>Ah... no. I guess that would have been too easy. So I'll have to account for those cases specially. Here's a function to get the penguin's view out of a 2-D array of tiles, in the form of a tile association list I can use to create a freshly created \"modified\" array (it's not really modified, but a new one is created with the updates from that list applied):</p> <pre>view_array :: BoardArray -> Pos -> Dir -> TileAssocList<br />view_array board pos dir =<br />    let row = ( posY pos )<br />        col = ( posX pos )<br />        coord_list = case dir of<br />            East  -> if ( col == max_col )<br />                     then []<br />                     else make_2d_range row ( col + 1 ) row max_col<br />            South -> if ( row == max_row )<br />                     then []<br />                     else make_2d_range ( row + 1 ) col max_row col<br />            West ->  if ( col == 0 )<br />                     then []<br />                     else make_2d_range row 0 row ( col - 1 )<br />            North -> if ( row == 0 )<br />                     then []<br />                     else make_2d_range 0 col ( row - 1 ) col<br />        tile_assoc = zip coord_list ( map ( (!) board )<br />                                           coord_list )<br />    in case dir of<br />        East -> tile_assoc<br />        South -> tile_assoc<br />        West -> reverse tile_assoc<br />        North -> reverse tile_assoc</pre> <p>That's not so bad. The key to this function is the <b>!</b> operator -- this gets a tuple and an array and returns an element -- and I zip the elements up with their coordinate tuples. Note that a lot of the bulk of this function is handling the edge cases, because we don't want to apply an out-of-range coordinate tuple to <b>!</b>. There may still be a shorter, clearer implementation possible. By comparison, here's a list-of-lists version factored a bit using currying to make it as self-documenting as I could get it -- note the use of <b>id</b> to let me return a general function as <b>orient</b>. I'm sure it doesn't impress FP whizzes, but I'm kinda proud of it -- I feel like I'm starting to use Haskell a little more idiomatically:</p> <pre>view_list :: BoardList -> Pos -> Dir -> [Tile]<br />view_list board pos dir =<br />    let row = ( posY pos )<br />        col = ( posX pos )<br />        transposed = elem dir [ South, North ]<br />        reversed = elem dir [ West, North ]<br />        orient | reversed = reverse<br />               | otherwise = id<br />        trim = case dir of<br />            East -> drop ( col + 1 )<br />            South -> drop ( row + 1 )<br />            West -> take col<br />            North -> take row<br />        extract | transposed = ( transpose board ) !! col<br />                | otherwise = board !! row  <br />    in orient $ trim $ extract</pre> <p>Testing <b>view_list</b>:</p> <pre>*Main> view_list init_board_list (Pos 0 0) East<br />[Empty,Empty,Empty,Empty,Empty,Empty,Empty,Empty,Empty,Empty,Empty,Empty,<br />Empty,Empty,Tree,Empty,Empty,Empty,Empty,Empty,Ice_Block,Empty,Empty]<br /><br />*Main> view_array init_board_array (Pos 0 0) East<br />[((0,1),Empty),((0,2),Empty),((0,3),Empty),((0,4),Empty),<br />((0,5),Empty),((0,6),Empty),((0,7),Empty),((0,8),Empty),<br />((0,9),Empty),((0,10),Empty),((0,11),Empty),((0,12),Empty),<br />((0,13),Empty),((0,14),Empty),((0,15),Tree),((0,16),Empty),<br />((0,17),Empty),((0,18),Empty),((0,19),Empty),((0,20),Empty),<br />((0,21),Ice_Block),((0,22),Empty),((0,23),Empty)]</pre> <p>Now we can write <b>step</b>. Here's the list version I've presented before:</p> <pre>step_list :: [Tile] -> ( Bool, [Tile] )<br />step_list [] = ( False, [] )<br />step_list ts = if walkable (head ts) then ( True, ts )<br />                                     else ( False, collide ts )</pre> <p>The array version is a little more complicated, because I want to strip the list I pass to <b>collide</b> down to just a list of tiles, in order to retain that clean logic for dealing with just a list of tiles. So I unzip my coordinate tuples from my tiles, get a potentially updated tile list, and zip it back together. That complicates it a bit, like so:</p> <pre>step_array :: TileAssocList -> ( Bool, TileAssocList )<br />step_array [] = ( False, [] )<br />step_array tile_assoc = if ( walkable $ head tile_list )<br />                        then ( True, tile_assoc )<br />                        else ( False, zip coord_list<br />                               ( collide tile_list ) )<br />    where ( coord_list, tile_list ) = unzip tile_assoc</pre> <p>I'm going to have to uglify my nice collide method a bit because I need to return at least one additional value -- indicating whether <b>collide</b> consumed a heart, so that we can keep score of the game.</p> <p>Next up, you can see the array and list solutions start to diverge hugely. It's hard to merge the list-based board back together with the potentially updated tile list to create the next immutable list-based board. My original method was pretty hideous. With Jeff's refactoring it's still a lot of code. (Note: I don't have this completely working yet; I'm getting a run-time error about bad patterns I haven't quite figured out yet):</p> <pre>next_board_list :: BoardList -> Pos -> Dir -> ( Bool, BoardList )<br />next_board_list board pos dir =<br />    let ( penguin_could_move, updated_view_list ) = <br />        step_list $ view_list board pos dir<br />    in ( penguin_could_move, update_board_from_view_list <br />         board pos dir updated_view_list )<br /><br />apply_view_list_to_row :: [Tile] -> Int -> Bool -> [Tile] -> [Tile]<br />apply_view_list_to_row orig pos True update =<br />    take ( pos + 1 ) orig ++ ( init update )<br />apply_view_to_row orig pos False update =<br />    ( reverse ( init update ) ) ++ ( drop pos orig )<br /><br />apply_view_list_to_rows :: BoardList -> Int -> Int -> <br />    Bool -> [Tile] -> BoardList<br />apply_view_list_to_rows orig row pos is_forward update =<br />    take row orig ++<br />    nest ( apply_view_to_row ( orig !! row ) pos is_forward update ) ++<br />    drop ( row + 1 ) orig<br /><br />update_board_from_view_list :: BoardList -> Pos -> Dir -> <br />    [Tile] -> BoardList<br />update_board_from_view_list board pos dir updated_view_list<br />    | is_eastwest = apply_view_list_to_rows board<br />                        ( posY pos ) ( posX pos )<br />                        is_forward updated_view_list<br />    | otherwise = transpose ( apply_view_list_to_rows ( transpose board )<br />                              ( posX pos ) ( posY pos ) <br />                              is_forward updated_view_list )<br />    where is_forward = elem dir [ East, South ]<br />          is_eastwest = elem dir [ East, West ]</pre> <p>By comparison, the array is much more suited to create an updated version of itself, given a list of elements to update. This is handled by the <b>//</b> function, in this simple function to create the next board in array form, called from <b>step_array</b>:</p> <pre>next_board_array :: BoardArray -> Pos -> Dir -> ( Bool, BoardArray )<br />next_board_array board pos dir =<br />    let ( penguin_could_move, updated_view ) =<br />        step_array $ view_array board pos dir<br />    in ( penguin_could_move, board // updated_view )</pre> <p>I like that -- it looks like we're working with the data structure rather than against it, although the overhead to manage the ranges and lists still feels to me more complicated than it should be. That complexity carries over elsewhere: for example, pretty-printing the array requires that range logic again. In fact I wind up just wrapping up and re-using the logic to pretty-print the list, so you can see how much additional code I needed:</p> <pre>pretty_tiles :: [Tile] -> String<br />pretty_tiles [] = \"\\n\"<br />pretty_tiles (t:ts) = case t of<br />                 Empty     -> \"___\"<br />                 Mountain  -> \"mt \"<br />                 House     -> \"ho \"<br />                 Ice_Block -> \"ic \"<br />                 Heart     -> \"he \"<br />                 Bomb      -> \"bo \"<br />                 Tree      -> \"tr \"<br />             ++ pretty_tiles ts<br /><br />pretty_board_list :: BoardList -> String<br />pretty_board_list [] = \"\"<br />pretty_board_list (ts:tss) = pretty_tiles ts ++ pretty_board_list tss<br /><br />split_tile_list :: [ Tile ] -> [ [ Tile ] ]<br />split_tile_list [] = []<br />split_tile_list ts = [ take tiles_in_row ts ] ++<br />                     ( split_tile_list $ ( drop tiles_in_row ) ts )<br />    where tiles_in_row = max_col + 1<br /><br />pretty_board_array :: BoardArray -> String <br />pretty_board_array board = pretty_board_list split_tiles<br />    where full_range = make_2d_range 0 0 max_row max_col<br />          all_tiles = map ( (!) board ) full_range<br />          split_tiles = split_tile_list all_tiles</pre> <p>As an aside, it seems like there ought to be at least one standard list split function, but it looks like folks don't really agree on how it should work</p> <p>So there it is -- the array is kind of a mixed blessing here. I haven't done any large-scale profiling on it, to determine if the need to generate a whole new array each pass is a big loss, compared to the potential structure-sharing in the list implementation. It simplifies some of the code dramatically, while adding a layer of dealing with ranges and lists of tuples everywhere -- as soon as we want to pull items out of the array, or merge them back in to a new array, we're dealing with lists again. Still, given the ugliness of the list merge code, it seems like the more natural choice for this kind of small game board data structure.</p>" nil nil "ec01a3b208c066be357a7b47b937d43b") (139 (20947 56086 989387) "http://joyful.com/blog/2013-07-01-june-review.html" "Simon Michael: June review" nil "Mon, 01 Jul 2013 23:00:00 +0000" "<div style=\"font-style: italic;\">July  1, 2013</div>
<h2>June review</h2>
<p>
</p><p>The beginning of a new month. Here’s a quick update.</p>
<p>No hledger release today as there isn’t much new to ship, following a month with several <a href=\"http://hledger.org/NEWS.html\">bugfix releases</a> and otherwise mostly infrastructural work (build and dev tool fixes, wiki styling, site update hook). 8/1 is the likely next release date. Oh, <a href=\"http://newartisans.com/\">John</a> and I also had a nice voice chat - nice to escape the IRC window isn’t it - reviewing our glorious *ledger plans, and I happily accepted his <a href=\"https://github.com/simonmichael/hledger/commit/a05e7a5a671af25b220eb4f152ad935687faef1a\">first hledger patch</a> - thanks John! :)</p>
<p>My free hacking time in recent weeks went more towards <a href=\"http://darcs.net\">darcs</a>:</p>
<ul>
<li><p>Unix shell helpers to get one-line-per-patch output from darcs (awesome!)</p>
<pre class=\"sourceCode bash\"><code class=\"sourceCode bash\"><span class=\"co\"># show darcs changes, push, pull etc. output with one patch per line</span>
<span class=\"co\"># Eg:</span>
<span class=\"co\"># dch --last 3</span>
<span class=\"co\"># darcs pull --dry | d1</span>
<span class=\"kw\">alias</span> darcsoneline=<span class=\"st\">\"egrep '^\\w' -A1 | egrep -v '^(--|The remote repository has|Would pu)' | sed '</span><span class=\"ot\">$!</span><span class=\"st\">N;s/\\n/ /'\"</span>
<span class=\"kw\">alias</span> d1=darcsoneline
<span class=\"kw\">function</span><span class=\"fu\"> dch()</span> <span class=\"kw\">{</span>
<span class=\"kw\">darcs</span> changes <span class=\"ot\">$*</span> <span class=\"kw\">|</span> <span class=\"kw\">darcsoneline</span>
<span class=\"kw\">}</span></code></pre></li>
<li><p>Support for BSRK Aditya’s <a href=\"http://hub.darcs.net/Aditya/darcsden-gsoc/changes\">GSOC work</a>. Together with Ganesh Sittampalam we did several rounds of code review and BSRK’s nice enhancements should be appearing on darcs hub soon.</p></li>
<li><p>Also driven by the above, updated <a href=\"http://hub.darcs.net/simon/darcsden/changes\">darcsden</a> and HSP for current GHC and libraries, and made it easy for me to build and deploy again. Also merged <a href=\"http://hub.darcs.net/ganesh/darcsden-service/changes\">Ganesh’s improvements</a> for MS Windows compatibility. This will be released as darcsden 1.1 shortly.</p></li>
<li><p>Ongoing <a href=\"http://hub.darcs.net\">darcs hub</a> ops/maintenance, including a fix for <a href=\"http://hub.darcs.net/simon/darcsden/issue/59\">this interesting segfault</a>, and a server upgrade from ubuntu 12.04 to 13.04. This last caused about <s>45m</s><a href=\"http://stats.pingdom.com/olo874j6ixzj/632910/2013/06\">1h20m of downtime >:(</a> late last night as I wrestled with the unfamiliar couchdb migration process and erlang stack traces. (For reference: just copy /var/lib/couchdb/1.0.1/* to 1.2.0/, but <em>don’t forget to preserve file ownership</em>.) At least it got resolved it before month-end at pingdom, so there’s a chance to get uptime back up where it should be - 3 or 4 nines - in July!</p></li>
</ul>" nil nil "5584ac7e57c46406bcd0820dccddee71") (138 (20947 56086 970799) "http://joyful.com/blog/2013-06-17-darcsden-cleanup.html" "Simon Michael: darcsden cleanup" nil "Wed, 19 Jun 2013 01:15:00 +0000" "<div style=\"font-style: italic;\">June 19, 2013</div>
<h2>darcsden cleanup</h2>
<p>
</p><p>Back to the dev diary. <a href=\"http://joyful.com/2013-06-07-git-hooks-for-site-updates.html\">Last post</a> was 11 days ago, after a two-week opening streak of daily posts. I got blocked on one, then got busy. Press on.</p>
<p>Yesterday I started looking at BSRK Aditya’s <a href=\"http://bsrkaditya.blogspot.com/2013/06/gsoc-2013-enhancing-darcsden-preweek-1.html\">GSOC darcsden enhancements</a>, to review and hopefully deploy on <a href=\"http://hub.darcs.net\">darcs hub</a>. So far he has worked on alternate login methods (github/google), password reminder, and darcs pack support (for faster gets).</p>
<p>This is forcing some darcsden cleanup, my first darcsden work in a while aside from routine ops and support tasks. I’m going to release what’s in trunk as 1.1, and then start assimilating the new work by BSRK, Ganesh Sittampalam and anyone else who feels like chipping in. Started putting together release notes and a hub status update.</p>
<p>The support requests seem to be on the rise - more usage ? I also found a good bug today: viewing a certain 1K troff file causes darcs hub’s memory footprint to <a href=\"http://hub.darcs.net/simon/darcsden/issue/58\">blow up to 1.5G</a> :)</p>
<p>It would be great to have more functionality (like highlighting) broken out into separate, expendable worker processes, erlang style.</p>" nil nil "2fb3adb43a6ea3d7ec74500c951e4ad2") (137 (20947 56086 913134) "http://joyful.com/blog/2013-06-08-zwiki-styling.html" "Simon Michael: Zwiki styling" nil "Sat, 08 Jun 2013 19:15:00 +0000" "<div style=\"font-style: italic;\">June  8, 2013</div>
<h2>Zwiki styling</h2>
<p>
</p><p><a href=\"http://joyful.com/2013-06-07-git-hooks-for-site-updates..html\">Yesterday</a>.</p>
<p>Next backlog item: <a href=\"https://trello.com/card/5127f6bb0698a36663002981/16\">style the wiki more like hledger.org</a>.</p>
<p>The wiki software is my own <a href=\"http://zwiki.org\">Zwiki</a> engine. I haven’t skinned a zwiki for a few years, but with the docs (<a href=\"http://zwiki.org/CustomizingAppearance\">CustomizingAppearance</a>, <a href=\"http://zwiki.org/QuickReference#skin-templates\">QuickReference -> skin templates</a>, <a href=\"http://zwiki.org/zwikidir/skins/zwiki\">standard templates</a>) plus experience, it went pretty smoothly.</p>
<p>Zwiki config changes at this point:</p>
<ul>
<li>pasted the standard maintemplate.pt into a Page Template with the same name in the wiki folder, with the hledger.org stylesheet and nav buttons added (in the head and body respectively)</li>
<li>added a style override to give the <code>#content</code> div a zero margin</li>
<li>renamed FrontPage to “hledger wiki”, and configured the new name in a <code>default_page</code> property on the wiki folder</li>
<li>disabled the icon in the zwiki page header by adding a <code>site_logo</code> folder property containing an empty html comment</li>
<li>committed a bugfix for a broken image border that was appearing in the rating form</li>
</ul>
<p>What didn’t work: rewording Zwiki’s “home” navigation link. My custom <code>links.pt</code> page template should do the trick, but it’s being ignored. This is unsatisfying, I suppose I will dig in and debug it, after a suitable cooling-off-and-reflection period.</p>
<p>Zope is still very impressive, and pleasing to use.</p>
<p>Here’s the <a href=\"http://hledger.org/wiki\">wiki</a>, now looking like part of hledger.org.</p>" nil nil "af63fdf556208f43ba0bea09e89e937f") (136 (20947 56086 912677) "http://joyful.com/blog/2013-06-07-git-hooks-for-site-updates.html" "Simon Michael: git pull hook, github service hook for quick site updates" nil "Sat, 08 Jun 2013 00:30:00 +0000" "<div style=\"font-style: italic;\">June  8, 2013</div>
<h2>git pull hook, github service hook for quick site updates</h2>
<p>
</p><p>Finished the hledger.org updating task begun <a href=\"http://joyful.com/2013-06-06-blog-tinkering-hledger.org.html\">yesterday</a>. There were a few parts to this.</p>
<p>I added an executable `.git/hooks/post-merge’ script in the website repo:</p>
<pre class=\"sourceCode bash\"><code class=\"sourceCode bash\"><span class=\"co\">#!/bin/sh</span>
<span class=\"co\">#</span>
<span class=\"co\"># Rebuild the website after a pull.</span>
<span class=\"kw\">exec</span> make site</code></pre>
<p>Now it runs <code>make site</code> (rebuilding the hakyll script and any changed site content as necessary) after a successful git pull to this repo.</p>
<p>Then I configured a github service hook, using my setup for ledger-cli.org as a guide. Added another <a href=\"http://hub.darcs.net/simon/github-listener\">github listener</a> daemon to <code>/etc/supervisord.conf</code>:</p>
<pre><code>[program:hledger.org-webhook]
command=/src/github-listener/github-listener-yesod 10000 'sudo -u simon git pull'
directory=/src/hledger.org
priority=3
redirect_stderr=true
autostart=true
autorestart=true
environment=LANG=\"en_US.UTF-8\"</code></pre>
<p>activated it using <a href=\"http://supervisord.org\">supervisorctl</a>:</p>
<pre><code>supervisor> update
hledger.org-webhook: added process group
supervisor> status
...
hledger.org-webhook              RUNNING    pid 31379, uptime 0:00:02
...</code></pre>
<p>and configure a <a href=\"https://help.github.com/articles/post-receive-hooks\">webhook</a> in the hledger repo on github, posting to <code>http://hledger.org:10000/</code>. Now any change landing in the github repo causes an immediate update of hledger.org.</p>" nil nil "3ee5dc5150a06bd1b8db96213b6ca3b8") (135 (20946 55674 501299) "http://parenz.wordpress.com/2013/06/29/vado/" "Daniil Frumin: Agile development and deployment in the cloud with Haskell and vado" nil "Tue, 02 Jul 2013 13:26:14 +0000" "<p>
In this post I would like to give you an update on vado – a piece of<br />
software for running programs on vagrant VMs (or any other ssh server,<br />
actually), projects I’ve contributed briefly to.
</p>
<div id=\"outline-container-sec-1\" class=\"outline-2\">
<h2 id=\"sec-1\"><span class=\"section-number-2\">1</span> New build system</h2>
<div id=\"text-1\" class=\"outline-text-2\">
<p>
The <a href=\"http://parenz.wordpress.com/2013/06/12/ghcjs-build/\">old</a> <a href=\"http://github.com/ghcjs/ghcjs-build\">build system</a> for ghcjs was a little bit messy. Basically, it was<br />
just one Puppet configuration file that contained a hardcoded shell<br />
script as a resource that is supposed to be written to the home<br />
directory and executed. I decided to clean it up a notch and take more<br />
of a Puppet approach to the whole thing.
</p>
<p>
You can find the new set of build script on the GitHub:<br />
<a href=\"https://github.com/ghcjs/ghcjs-build\">https://github.com/ghcjs/ghcjs-build</a>
</p>
<p>
And since the errors are now printed to the screen it’s<br />
easy to see which stage the build is going through and if anything<br />
goes wrong you see an error trace for the current stage.
</p>
<p>
The <a href=\"https://github.com/ghcjs/ghcjs-build/tree/prebuilt\">prebuilt</a> version has also been updated by<br />
<a href=\"http://weblog.luite.com/wordpress/\">Luite Stegeman</a>.
</p>
</div>
</div>
<div id=\"outline-container-sec-2\" class=\"outline-2\">
<h2 id=\"sec-2\"><span class=\"section-number-2\">2</span> Vado</h2>
<div id=\"text-2\" class=\"outline-text-2\">
</div>
<div id=\"outline-container-sec-2-1\" class=\"outline-3\">
<h3 id=\"sec-2-1\"><span class=\"section-number-3\">2.1</span> Vado intro</h3>
<div id=\"text-2-1\" class=\"outline-text-3\">
<p>
Hamish Mackenzie and I have been working on <a href=\"https://github.com/hamishmack/vado\">vado</a> – a quick way to run<br />
commands on a remote ssh server. Just mount the directory you want to<br />
run the command in using <a href=\"http://fuse.sourceforge.net/sshfs.html\">sshfs</a>, in that directory (or its<br />
subdirectory) run vado like this:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">vado ls -l
</pre>
</div>
<p>
vado will run ‘mount’ to identify the user account, server name and<br />
the remote directory to run the command in. It will then run ssh to<br />
connect to the server and run the command.
</p>
<p>
You can also pass ssh options like this:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">vado -t htop
</pre>
</div>
<p>
This tells vado to pass -t to ssh (forces pseudo-tty allocation and<br />
makes programs like vim and htop work nicely).
</p>
<p>
I will explain below how to set up vado for multiple remote<br />
servers/sshfs mount points and how to develop Haskell projects on a<br />
remote server/VM nicely using Emacs and ghc-mod.
</p>
</div>
</div>
<div id=\"outline-container-sec-2-2\" class=\"outline-3\">
<h3 id=\"sec-2-2\"><span class=\"section-number-3\">2.2</span> .vadosettings</h3>
<div id=\"text-2-2\" class=\"outline-text-3\">
<p>
Vado is not tied to vagrant, but can be used with it and is faster<br />
than <code>vagrant ssh</code>. If the user and host detected in <code>mount</code> are<br />
specified in the <code>~/.vadosettings</code> file, then the specified key and<br />
port will be used.
</p>
<p>
The contents of the <code>~/.vadosettings</code> file is basically a Haskell<br />
list of <code>MountSettings</code> datastructures and we use standard <code>Read</code> and<br />
<code>Show</code> type-classes for serialization.
</p>
<p>
The <code>MountSettings</code> data type is defined as follows:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-haskell\"><span style=\"color: #b5bd68;\">-- | Mount point settings</span>
<span style=\"color: #b294bb;\">data</span> <span style=\"color: #f0c674;\">MountSettings</span> <span style=\"color: #cc6666;\">=</span> <span style=\"color: #f0c674;\">MountSettings</span> {
sshfsUser <span style=\"color: #cc6666;\">::</span> <span style=\"color: #f0c674;\">Text</span>
, sshfsHost <span style=\"color: #cc6666;\">::</span> <span style=\"color: #f0c674;\">Text</span>
, sshfsPort <span style=\"color: #cc6666;\">::</span> <span style=\"color: #f0c674;\">Int</span>
, idFile <span style=\"color: #cc6666;\">::</span> <span style=\"color: #f0c674;\">FilePath</span>
} <span style=\"color: #b294bb;\">deriving</span> (<span style=\"color: #f0c674;\">Show</span>, <span style=\"color: #f0c674;\">Read</span>)
</pre>
</div>
<p>
If the file is not present or incorrectly formatted<br />
then the default settings for vagrant will be used:
</p>
<ul class=\"org-ul\">
<li>User: vagrant
</li>
<li>Host: 127.0.0.1
</li>
<li>Port: 2222
</li>
<li>Key file: <code>~/.vagrant.d/insecure_private_key</code>
</li>
</ul>
</div>
<div id=\"outline-container-sec-2-2-1\" class=\"outline-4\">
<h4 id=\"sec-2-2-1\"><span class=\"section-number-4\">2.2.1</span> Example .vadosettings file</h4>
<div id=\"text-2-2-1\" class=\"outline-text-4\">
<p>
An example settings file might look like this:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-haskell\">[
<span style=\"color: #f0c674;\">MountSettings</span> {
sshfsUser <span style=\"color: #cc6666;\">=</span> <span style=\"color: #b5bd68;\">\"vagrant\"</span>
, sshfsHost <span style=\"color: #cc6666;\">=</span> <span style=\"color: #b5bd68;\">\"localhost\"</span>
, sshfsPort <span style=\"color: #cc6666;\">=</span> 2222
, idFile <span style=\"color: #cc6666;\">=</span> <span style=\"color: #b5bd68;\">\"/Users/dan/.vagrant.d/insecure_private_key\"</span>
},
<span style=\"color: #f0c674;\">MountSettings</span> {
sshfsUser <span style=\"color: #cc6666;\">=</span> <span style=\"color: #b5bd68;\">\"admin\"</span>
, sshfsHost <span style=\"color: #cc6666;\">=</span> <span style=\"color: #b5bd68;\">\"server.local\"</span>
, sshfsPort <span style=\"color: #cc6666;\">=</span> 2233
, idFile <span style=\"color: #cc6666;\">=</span> <span style=\"color: #b5bd68;\">\"/Users/dan/keys/local_server_key\"</span>
}
]
</pre>
</div>
</div>
</div>
</div>
<div id=\"outline-container-sec-2-3\" class=\"outline-3\">
<h3 id=\"sec-2-3\"><span class=\"section-number-3\">2.3</span> Vamount</h3>
<div id=\"text-2-3\" class=\"outline-text-3\">
<p>
Of course, using <code>vado</code> requires mounting the sshfs beforehand. But<br />
it gets tedious typing out
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">sshfs vagrant@localhost:/home/vagrant ../vm/ -p2222
-reconnect,defer_permissions,negative_vncache,<span style=\"color: #cc6666;\">volname</span>=ghcjs,<span style=\"color: #cc6666;\">IdentityFile</span>=~/.vagrant.d/insecure_private_key
</pre>
</div>
<p>
every time. A tool called <code>vamount</code> which is bundled together<br />
with <code>vado</code> can be used for mounting remote filesystems based on<br />
<code>~/.vadosettings</code> file.
</p>
<p>
You can use it like this:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">vamount [ssh options] remote_path [profile <span style=\"color: #969896;\">#</span><span style=\"color: #969896;\">]</span>
</pre>
</div>
<p>
The <code>remote_path</code> from the remote server specified in the<br />
~/.vadosettings file under number [profile #] will be mounted in the<br />
current directory using sshfs.
</p>
<p>
The profile number count starts from 1. If the [profile #] is absent<br />
or is 0 then the default (vagrant) configuration will be used.
</p>
</div>
</div>
<div id=\"outline-container-sec-2-4\" class=\"outline-3\">
<h3 id=\"sec-2-4\"><span class=\"section-number-3\">2.4</span> Vado and ghc-mod</h3>
<div id=\"text-2-4\" class=\"outline-text-3\">
<p>
<a href=\"http://www.mew.org/~kazu/proj/ghc-mod/en/\">ghc-mod</a> is a backend designed command to enrich Haskell programming on<br />
editors like Emacs and Vim and it also features a front-end for Emacs<br />
as a set of elisp scripts. It’s a really cool piece of software and if<br />
you have not tried it yet I highly recommend you to invest into<br />
installing and using it.
</p>
<p>
What we would like, however, is to edit files on the mounted<br />
filesystem using Emacs on the host machine, but run ghc-mod inside the<br />
VM. In order to do that we need to install ghc-mod both on our host<br />
machine and on the VM.
</p>
<p>
While installing ghc-mod on the host machine running the latest<br />
haskell-platform is pretty straightforward it is harder to do so on<br />
the VM running GHC 7.7 due to the fact that many libraries are not<br />
ready for GHC 7.7 and base 4.7 yet. We have to resort to installing<br />
most of the things from source.
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\"><span style=\"color: #969896;\"># </span><span style=\"color: #969896;\">run this on the guest machine</span>
mkdir ghcmod && <span style=\"color: #D0D0FF;\">cd</span> ghcmod
<span style=\"color: #969896;\"># </span><span style=\"color: #969896;\">patching installing convertible</span>
cabal unpack convertible
<span style=\"color: #D0D0FF;\">cd</span> convertible*
wget http://co-dan.github.io/patched/convertible.patch
patch -p1 Data/Convertible/Utils.hs convertible.patch
cabal install
<span style=\"color: #D0D0FF;\">cd</span> ..
<span style=\"color: #969896;\"># </span><span style=\"color: #969896;\">installing ghc-syb-utils</span>
git clone https://github.com/co-dan/ghc-syb.git
<span style=\"color: #D0D0FF;\">cd</span> ghc-syb/utils/
cabal install
<span style=\"color: #D0D0FF;\">cd</span> ../..
<span style=\"color: #969896;\"># </span><span style=\"color: #969896;\">finally getting and installing ghc-mod</span>
git clone https://github.com/co-dan/ghc-mod.git
<span style=\"color: #D0D0FF;\">cd</span> ghc-mod
cabal install
</pre>
</div>
<p>
Ghc-mod itself uses the GHC API extensively so it’s no surprise we<br />
have to change at least some code. Now that we have installed ghc-mod<br />
on the guest VM we need to set up our host’s Emacs configuration to<br />
communicate properly with the VM. First of all put this in your Emacs<br />
config:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-elisp\"><span style=\"color: #7f7f7f;\">(</span>setq load-path <span style=\"color: #7f7f7f;\">(</span>cons <span style=\"color: #b5bd68;\">\"~/Library/Haskell/ghc-7.6.3/lib/ghc-mod-2.0.3/share\"</span> load-path<span style=\"color: #7f7f7f;\">))</span>
<span style=\"color: #7f7f7f;\">(</span>autoload 'ghc-init <span style=\"color: #b5bd68;\">\"ghc\"</span> nil t<span style=\"color: #7f7f7f;\">)</span>
<span style=\"color: #7f7f7f;\">(</span>add-hook 'haskell-mode-hook <span style=\"color: #7f7f7f;\">(</span><span style=\"color: #b294bb;\">lambda</span> <span style=\"color: #7f7f7f;\">()</span> <span style=\"color: #7f7f7f;\">(</span>ghc-init<span style=\"color: #7f7f7f;\">)))</span>
<span style=\"color: #969896;\">;; </span><span style=\"color: #969896;\">(setq ghc-module-command \"ghc-mod\")</span>
<span style=\"color: #7f7f7f;\">(</span>setq ghc-module-command <span style=\"color: #b5bd68;\">\"~/vado-ghc-mod.sh\"</span><span style=\"color: #7f7f7f;\">)</span>
</pre>
</div>
<p>
<code>~/vado-ghc-mod.sh</code> should contain the following:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\"><span style=\"color: #969896;\">#</span><span style=\"color: #969896;\">!/bin/</span><span style=\"color: #b294bb;\">bash</span>
<span style=\"color: #cc6666;\">VADO</span>=/Users/dan/Library/Haskell/bin/vado
<span style=\"color: #cc6666;\">LOCAL_PATH</span>=/Users/dan/projects/ghcjs/mnt/
<span style=\"color: #cc6666;\">REMOTE_PATH</span>=/home/vagrant/
$<span style=\"color: #cc6666;\">VADO</span> -t ghc-mod ${<span style=\"color: #cc6666;\">@</span>//$<span style=\"color: #cc6666;\">LOCAL_PATH</span>/$<span style=\"color: #cc6666;\">REMOTE_PATH</span>} | sed <span style=\"color: #b5bd68;\">\"s,$REMOTE_PATH,$LOCAL_PATH,g\"</span>
</pre>
</div>
<p>
I know that it’s a hack, but it does work and I guess that’s what<br />
shell scripts are for ;)
</p>
<p>
Now go to <code>~/.bashrc</code> on the <i>guest machine</i> and make sure that the<br />
<code>PATH</code> variable is <a href=\"http://stackoverflow.com/questions/820517/bashrc-at-ssh-login\">set correctly</a>:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\"><span style=\"color: #cc6666;\">PATH</span>=/home/vagrant/ghcjs/bin:/home/vagrant/.cabal/bin:/home/vagrant/ghc/bin:/home/vagrant/jsshell:/home/vagrant/node-v0.10.10-linux-x86/bin:$<span style=\"color: #cc6666;\">PATH</span>
<span style=\"color: #969896;\"># </span><span style=\"color: #969896;\">PATH is set *before* this line:</span>
[ -z <span style=\"color: #b5bd68;\">\"$PS1\"</span> ] && <span style=\"color: #b294bb;\">return</span>
<span style=\"color: #969896;\"># </span><span style=\"color: #969896;\"><snip></span>
</pre>
</div>
<p>
And that’s it, you should be done!
</p>
<p>Before (ghc-mod running on the host machine):<br />
<a href=\"http://parenz.files.wordpress.com/2013/06/ghcmod-before.png\"><img src=\"http://parenz.files.wordpress.com/2013/06/ghcmod-before.png?w=600&h=306\" alt=\"ghcmod-before\" height=\"306\" class=\"alignnone size-medium wp-image-66\" width=\"600\" /></a></p>
<p>After (ghc-mod running inside <a href=\"https://github.com/ghcjs/ghcjs-build\">ghcjs-build</a> VM):<br />
<a href=\"http://parenz.files.wordpress.com/2013/06/ghcmod-after.png\"><img src=\"http://parenz.files.wordpress.com/2013/06/ghcmod-after.png?w=600&h=306\" alt=\"ghcmod-after\" height=\"306\" class=\"alignnone size-medium wp-image-65\" width=\"600\" /></a></p>
</div>
</div>
</div>
<div id=\"outline-container-sec-3\" class=\"outline-2\">
<h2 id=\"sec-3\"><span class=\"section-number-2\">3</span> Conclusion and future work</h2>
<div id=\"text-3\" class=\"outline-text-2\">
<p>
We’ve seen how a small but useful tool <code>vado</code> can make our life easier if<br />
we want to develop Haskell projects on a remote server or on a<br />
virtual machine. You can get Vado from GitHub: <a href=\"https://github.com/hamishmack/vado\">https://github.com/hamishmack/vado</a>
</p>
<p>
Next week we are planning on releasing our first version of<br />
interactive-diagrams pastesite (not going to be very interactive<br />
though) and writing out its security model.
</p>
<p>
Meanwhile check Luite’s <a href=\"http://weblog.luite.com/wordpress/?p=127\">post</a> on using Sodium FRP library for creating<br />
Functional Reactive Web interfaces. It’s astonishing how easily you<br />
can just get a FRP library, compile to JavaScript and make nifty web<br />
apps with it.
</p>
</div>
</div>
<br /> Tagged: <a href=\"http://parenz.wordpress.com/tag/ghcjs/\">ghcjs</a>, <a href=\"http://parenz.wordpress.com/tag/haskell-2/\">haskell</a>, <a href=\"http://parenz.wordpress.com/tag/soc/\">soc</a>, <a href=\"http://parenz.wordpress.com/tag/vm/\">vm</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/parenz.wordpress.com/64/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/parenz.wordpress.com/64/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=parenz.wordpress.com&blog=26722965&post=64&subd=parenz&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "1077250fd66e87bb5d79ba483a1e8877") (134 (20946 49852 366664) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_8737\"></span>, where <span id=\"tex_8183\"></span> is the number of “folds” and <span id=\"tex_7114\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_7143\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "9e4ff0aeeea6d385493fa853b31c20c0") (133 (20946 42380 578787) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_2914\"></span>, where <span id=\"tex_9114\"></span> is the number of “folds” and <span id=\"tex_6617\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_1826\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "d5bd3213990b3292a5d49649e64580d1") (132 (20946 37594 578384) "http://feedproxy.google.com/~r/ezyang/~3/tSmwYHznwqQ/" "Edward Z. Yang: HoTT exercises in Coq (in progress)" nil "Mon, 01 Jul 2013 20:21:18 +0000" "<div class=\"document\">
<p>I spent some of my plane ride yesterday working on Coq versions of the exercises in <a href=\"http://homotopytypetheory.org/book/\" class=\"reference external\">The HoTT book</a>. I got as far as 1.6 (yeah, not very far, perhaps I should make a GitHub repo if other folks are interested in contributing skeletons. Don't know what to do about the solutions though).  All of these have been test solved.</p>
<p>You will need HoTT/coq in order to run this development; instructions on <a href=\"https://github.com/HoTT/HoTT/blob/master/INSTALL.txt\" class=\"reference external\">how to install it are here.</a></p>
<pre class=\"literal-block\">Require Import HoTT.
Definition admit {T: Type} : T. Admitted.
(* Exercise 1.1 *)
Definition mycompose {A B C : Type} (g : B -> C) (f : A -> B) : A -> C := admit.
Goal forall (A B C D : Type) (f : A -> B) (g : B -> C) (h : C -> D),
mycompose h (mycompose g f) = mycompose (mycompose h g) f.
Admitted.
(* Exercise 1.2 *)
Section ex_1_2_prod.
Variable A B : Type.
Check @fst.
Check @snd.
Definition my_prod_rec (C : Type) (g : A -> B -> C) (p : A * B) : C := admit.
Goal fst = my_prod_rec A (fun a => fun b => a). Admitted.
Goal snd = my_prod_rec B (fun a => fun b => b). Admitted.
End ex_1_2_prod.
Section ex_1_2_sig.
Variable A : Type.
Variable B : A -> Type.
Check @projT1.
Check @projT2.
Definition my_sig_rec (C : Type) (g : forall (x : A), B x -> C) (p : exists (x : A), B x) : C := admit.
Goal @projT1 A B = my_sig_rec A (fun a => fun b => a). Admitted.
(* What goes wrong when you try to prove this for projT2? *)
End ex_1_2_sig.
(* Exercise 1.3 *)
Definition refl {A : Type} (x : A) : x = x := 1%path.
Section ex_1_3_prod.
Variable A B : Type.
(* Given by the book *)
Definition uppt : forall (x : A * B), ((fst x, snd x) = x) :=
fun p => match p with (a,b) => refl (a,b) end.
Definition my_prod_ind (C : A * B -> Type) (g : forall (x : A) (y : B), C (x, y)) (x : A * B) : C x := admit.
Goal forall C g a b, my_prod_ind C g (a, b) = g a b. Admitted.
End ex_1_3_prod.
Section ex_1_3_sig.
Variable A : Type.
Variable B : A -> Type.
Definition sig_uppt : forall (x : exists (a : A), B a), ((projT1 x; projT2 x) = x) := admit.
Definition mysig_ind (C : (exists (a : A), B a) -> Type) (g : forall (a : A) (b : B a), C (a; b)) (x : exists (a : A), B a) : C x := admit.
Goal forall C g a b, mysig_ind C g (a; b) = g a b. Admitted.
End ex_1_3_sig.
(* Exercise 1.4 *)
Fixpoint iter (C : Type) (c0 : C) (cs : C -> C) (n : nat) : C :=
match n with
| 0 => c0
| S n' => cs (iter C c0 cs n')
end.
Definition mynat_rec (C : Type) : C -> (nat -> C -> C) -> nat -> C := admit.
Eval compute in mynat_rec (list nat) nil (@cons nat) 2.
Eval compute in nat_rect (fun _ => list nat) nil (@cons nat) 2.
(* Exercise 1.5 *)
Definition mycoprod (A B : Type) := exists (x : Bool), Bool_rect (fun _ => Type) A B x.
Section ex_1_5.
Variable A B : Type.
Definition inl := existT (Bool_rect (fun _ => Type) A B) true.
Definition inr := existT (Bool_rect (fun _ => Type) A B) false.
Definition mycoprod_ind (C : mycoprod A B -> Type)
(l : forall (a : A), C (inl a))
(r : forall (b : B), C (inr b))
(x : mycoprod A B) : C x := admit.
Goal forall C l r x, mycoprod_ind C l r (inl x) = l x. Admitted.
Goal forall C l r x, mycoprod_ind C l r (inr x) = r x. Admitted.
End ex_1_5.
(* Exercise 1.6 *)
Definition myprod (A B : Type) := forall (x : Bool), Bool_rect (fun _ => Type) A B x.
Section ex_1_6.
Context `{Funext}.
Variable A B : Type.
Definition mypr1 (p : myprod A B) := p true.
Definition mypr2 (p : myprod A B) := p false.
Definition mymkprod (a : A) (b : B) : myprod A B := Bool_rect (Bool_rect (fun _ => Type) A B) a b.
Definition myprod_ind (C : myprod A B -> Type)
(g : forall (x : A) (y : B), C (mymkprod x y)) (x : myprod A B) : C x := admit.
Goal forall C g a b, myprod_ind C g (mymkprod a b) = g a b. Admitted.
End ex_1_6.
</pre>
<p>Actually, I lied. I haven't proved the last goal in exercise 1.6; my trouble is I don't know how to get function extensionality to compute, but I’m sure it’s something simple...</p>
</div>
<img src=\"http://feeds.feedburner.com/~r/ezyang/~4/tSmwYHznwqQ\" height=\"1\" width=\"1\" />" nil nil "00c72c0d3632ef1e609639e02f072f60") (131 (20946 37594 496792) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_510\"></span>, where <span id=\"tex_2094\"></span> is the number of “folds” and <span id=\"tex_8091\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_418\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "30a077d3167d92ca2db62951d2fb0061") (130 (20945 42499 903671) "http://feedproxy.google.com/~r/FpComplete/~3/WtRkqbxIn5Q/fp-haskell-center-beta-announcement" "FP Complete: FP Haskell Center Beta Released, and Beta Accounts Activated" nil "Sun, 30 Jun 2013 19:51:00 +0000" "<h3>Beta Release Blog</h3><p>It’s here! After months of hard work by our engineers, and only 9 months since we announced our plans in ICFP last September, I am pleased to announce that we’ve released the <a href=\"https://www.fpcomplete.com/business/designer-ide\">beta of FP Haskell Center</a>, the world's first commercial Haskell IDE and deployment platform.  We’ve received great response with nearly 1,000 sign-ups already.  Since we want to have a smooth beta process and a good user experience, we are going to activate beta accounts selectively, in ever increasing numbers, in the next few weeks as we test new features and load factors.  We will notify users via email that their account is ready to be activated; some of you who are reading this may already have received the message.  We expect to have “open enrollment” for all before the end of July.  </p><p><a href=\"https://www.fpcomplete.com/blog/2013/06/fp-haskell-center-beta-demo\">Watch a video</a> walkthrough of the highlighted features.  There’s still time to <a href=\"https://www.fpcomplete.com/business/designer-ide\">sign-up</a>.</p><p>As an appreciation and reward for being in the beta program, we will offer a special discount only to beta customers who buy an annual subscription to the GA product before the official release date in early September.  We are working on our pricing and offering plans, and expect to have them completed by early August, so stay tuned.</p><p>FP Haskell Center has two integrated components that allow you to develop and deploy Haskell applications in the cloud from a single platform.  The FP Haskell Development Environment is an IDE that includes a Haskell compiler and a continually updated set of vetted, tested and supported libraries and code templates. There is no need to run Cabal or other installers. The FP Haskell Application Server is used to deploy and run Haskell applications directly in the cloud with no additional effort. A free shared instance is included with every account. Larger and dedicated instances are available for active project deployments at a reasonable monthly charge.</p><p>For further information and sign up, <a href=\"https://www.fpcomplete.com/business/designer-ide\">please go here</a>.</p><div class=\"feedflare\">
<a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=WtRkqbxIn5Q:EMKkzrydVc4:yIl2AUoC8zA\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=yIl2AUoC8zA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=WtRkqbxIn5Q:EMKkzrydVc4:V_sGLiPBpWU\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=WtRkqbxIn5Q:EMKkzrydVc4:V_sGLiPBpWU\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=WtRkqbxIn5Q:EMKkzrydVc4:qj6IDK7rITs\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=qj6IDK7rITs\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=WtRkqbxIn5Q:EMKkzrydVc4:gIN9vFwOqvQ\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=WtRkqbxIn5Q:EMKkzrydVc4:gIN9vFwOqvQ\" border=\"0\" /></a>
</div><img src=\"http://feeds.feedburner.com/~r/FpComplete/~4/WtRkqbxIn5Q\" height=\"1\" width=\"1\" />" nil nil "edec5e773dc3c376472ffe33581f3ee4") (129 (20945 42499 819964) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_7143\"></span>, where <span id=\"tex_657\"></span> is the number of “folds” and <span id=\"tex_8261\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_3875\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "88d93a056afb6614f83e6c21ed3227ad") (128 (20945 34652 382661) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_9019\"></span>, where <span id=\"tex_1428\"></span> is the number of “folds” and <span id=\"tex_4097\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_8787\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "65af1b9fdea122048bee73ed2f295d81") (127 (20945 27240 6754) "http://www.yesodweb.com/blog/2013/07/runtime-lucius-mixins" "Yesod Web Framework: Runtime Lucius: now with mixins!" nil "Mon, 01 Jul 2013 13:00:00 +0000" "<p>About two months ago, <a href=\"http://www.yesodweb.com/blog/2013/04/mixin-support-in-lucius\">I announced that Lucius now had mixin
support</a>.
Unfortunately, it was missing something important: support in runtime Lucius.
Many of you have probably never used runtime Lucius, but it's the component
underlying Lucius's ability to do live code reloading during development. So
without this feature, it's impossible to use mixins when using <code>yesod devel</code>.</p><p>As of <code>shakespeare-css</code> 1.0.6.1, this is no longer a problem: mixins should now
work perfectly with <code>yesod devel</code>. In order to take advantage of this, just add
a minimum bound on your shakespeare-css constraint in your cabal file. (The
next release of yesod-platform will include this change.)</p><p>If anyone finds any problems, let me know.</p>" nil nil "e5c90f2bdabb21a02596b3ff3a553944") (126 (20945 27239 927746) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_3822\"></span>, where <span id=\"tex_5149\"></span> is the number of “folds” and <span id=\"tex_7521\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_110\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "1a3917e9ad2f845bfbe9e5464e49d1d8") (125 (20945 14387 195654) "http://lambda.jstolarek.com/2013/06/msr-internship-and-some-retrospection/" "Jan Stolarek: MSR internship and some retrospection" nil "Sun, 30 Jun 2013 20:00:38 +0000" "<p style=\"text-align: justify;\">I feel I can finally write about: I got accepted for a three-month internship at Microsoft Research Cambridge! This means I will be developing GHC and, hopefully, doing some serious research on the subject of functional programming and compiler implementation. My internship starts tomorrow, on 1st July. I’m not yet 100% certain about the exact topic of my research, so I’ll refrain from going into any kind of technical details for now and I will focus on my personal experience with functional programming. I feel this is really a good moment to summarize the past 1,5 year. I learned about functional programming at the very beginning of 2012 and since then I progressed from knowing completely nothing to being in Cambridge – something I would have not imagined 18 months ago.</p>
<p style=\"text-align: justify;\">Somewhere around July 2011 I finished writing my PhD. I had yet to deal with many formalities – which in the end took 8 months – but the most important part of my work was done and I only continued research on a few minor subjects that I ran into while writing a PhD. Somewhere in October I decided I need a break from all my current research topic – I finally wanted some time to pursue topics that interested me all along and for which I never had time. Compiler construction and theory of automata were two main topics I had in mind. That was the plan, but it wasn’t meant to work out, at least not yet. Somewhere around December 2012 I stumbled upon a book <a href=\"http://lambda.jstolarek.com/2012/04/7-languages-in-7-weeks-book-review/\">“Seven languages in seven weeks”</a>, which was my first contact with functional programming. I didn’t follow the book exactly. I read chapters about Ruby, Io, Prolog (so much fun!), Scala and Erlang, but instead of reading chapter about Clojure I went for Scheme. I read <a href=\"http://www.schemers.org/Documents/Standards/R5RS/\">R5RS</a> language specification and <a href=\"http://lambda.jstolarek.com/2013/01/the-little-schemer-book-review/\">The Little Schemer</a> and when I reached the chapter about Haskell I decided to read <a href=\"http://learnyouahaskell.com/chapters\">Learn You A Haskell</a> instead. At that point I already knew that Haskell is <em>the</em> functional programming language and I think that this was the moment I started having some serious plans about functional programming. But at the same time I was figuring out how to learn about compilers. It was April when <a href=\"http://lambda.jstolarek.com/2012/04/stanford-opens-new-online-courses-about-compilers-and-automata/\">Stanford University announced their two online courses on Compilers and Automata</a> – these were really godsend. The Compilers course ended in late June. This concludes my first six months of contact with FP and I think that these months were extremely intense. I learned theoretical and practical foundations of compilers, a new programming paradigm and some new languages designed in that paradigm. I also started reading research papers on functional programming, with a focus on implementation of GHC. At that point I didn’t even try to work on the source code, but I was trying to understand how the compiler is designed.</p>
<p style=\"text-align: justify;\">The next six months, from July to December, were not as fruitful. I picked up interest in doing data-parallel computations in Haskell, as this seemed to be an active topic of research and also related to my PhD work. I made a failed attempt of an efficient parallel implementation of a wavelet transform. Although I wasn’t successful, my time was not wasted: I learned how to write, test and benchmark libraries in Haskell and also read a lot of papers on FP. I also got in touch with <a href=\"http://www.cse.unsw.edu.au/~benl/\">Ben Lippmeier</a>, who pointed me to one problem with GHC he needed fixed. This was somewhere in January 2013. I already started reading the source code of GHC in December, but now I finally had a particular problem to solve. It was the time to start working on GHC. That is mostly what I did during the last six months, although I also managed to spend some time on theory (more papers and <a href=\"http://lambda.jstolarek.com/2013/02/to-mock-a-mockingbird-or-how-i-learned-to-stop-worrying-and-learned-combinatory-logic/\">a book on combinatory logic</a>).</p>
<p style=\"text-align: justify;\">As for the internship, I decided to apply for it in February. I polished my CV and cover letter (many thanks go to my friend <a href=\"http://www.mareklab.org/\">Marek</a> for his help) and sent my application at the beginning of March. After an interview with Geoffrey Mainland and Simon Peyton Jones I got acceptance notification at the beginning of April. And here I am in Cambridge, over 1300km from home, waiting for my first day at Microsoft Research.</p>" nil nil "7b89d995cf9d4ed26a83825b79e01588") (124 (20945 14387 194586) "http://parenz.wordpress.com/2013/06/29/vado/" "Daniil Frumin: Agile development and deployment in the cloud with Haskell and vado" nil "Sun, 30 Jun 2013 19:16:28 +0000" "<p>
In this post I would like to give you an update on vado – a piece of<br />
software for running programs on vagrant VMs (or any other ssh server,<br />
actually), projects I’ve contributed briefly to.
</p>
<div id=\"outline-container-sec-1\" class=\"outline-2\">
<h2 id=\"sec-1\"><span class=\"section-number-2\">1</span> New build system</h2>
<div id=\"text-1\" class=\"outline-text-2\">
<p>
The <a href=\"http://parenz.wordpress.com/2013/06/12/ghcjs-build/\">old</a> <a href=\"http://github.com/ghcjs/ghcjs-build\">build system</a> for ghcjs was a little bit messy. Basically, it was<br />
just one Puppet configuration file that contained a hardcoded shell<br />
script as a resource that is supposed to be written to the home<br />
directory and executed. I decided to clean it up a notch and take more<br />
of a Puppet approach to the whole thing.
</p>
<p>
You can find the new set of build script on the GitHub:<br />
<a href=\"https://github.com/ghcjs/ghcjs-build\">https://github.com/ghcjs/ghcjs-build</a>
</p>
<p>
And since the errors are now printed to the screen it’s<br />
easy to see which stage the build is going through and if anything<br />
goes wrong you see an error trace for the current stage.
</p>
<p>
The <a href=\"https://github.com/ghcjs/ghcjs-build/tree/prebuilt\">prebuilt</a> version has also been updated by<br />
<a href=\"http://weblog.luite.com/wordpress/\">Luite Stegeman</a>.
</p>
</div>
</div>
<div id=\"outline-container-sec-2\" class=\"outline-2\">
<h2 id=\"sec-2\"><span class=\"section-number-2\">2</span> Vado</h2>
<div id=\"text-2\" class=\"outline-text-2\">
</div>
<div id=\"outline-container-sec-2-1\" class=\"outline-3\">
<h3 id=\"sec-2-1\"><span class=\"section-number-3\">2.1</span> Vado intro</h3>
<div id=\"text-2-1\" class=\"outline-text-3\">
<p>
Hamish Mackenzie and I have been working on <a href=\"https://github.com/hamishmack/vado\">vado</a> – a quick way to run<br />
commands on a remote ssh server. Just mount the directory you want to<br />
run the command in using <a href=\"http://fuse.sourceforge.net/sshfs.html\">sshfs</a>, in that directory (or its<br />
subdirectory) run vado like this:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">vado ls -l
</pre>
</div>
<p>
vado will run ‘mount’ to identify the user account, server name and<br />
the remote directory to run the command in. It will then run ssh to<br />
connect to the server and run the command.
</p>
<p>
You can also pass ssh options like this:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">vado -t htop
</pre>
</div>
<p>
This tells vado to pass -t to ssh (forces pseudo-tty allocation and<br />
makes programs like vim and htop work nicely).
</p>
<p>
I will explain below how to set up vado for multiple remote<br />
servers/sshfs mount points and how to develop Haskell projects on a<br />
remote server/VM nicely using Emacs and ghc-mod.
</p>
</div>
</div>
<div id=\"outline-container-sec-2-2\" class=\"outline-3\">
<h3 id=\"sec-2-2\"><span class=\"section-number-3\">2.2</span> .vadosettings</h3>
<div id=\"text-2-2\" class=\"outline-text-3\">
<p>
Vado is not tied to vagrant, but can be used with it and is faster<br />
than <code>vagrant ssh</code>. If the user and host detected in <code>mount</code> are<br />
specified in the <code>~/.vadosettings</code> file, then the specified key and<br />
port will be used.
</p>
<p>
The contents of the <code>~/.vadosettings</code> file is basically a Haskell<br />
list of <code>MountSettings</code> datastructures and we use standard <code>Read</code> and<br />
<code>Show</code> type-classes for serialization.
</p>
<p>
The <code>MountSettings</code> data type is defined as follows:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-haskell\"><span style=\"color: #b5bd68;\">-- | Mount point settings</span>
<span style=\"color: #b294bb;\">data</span> <span style=\"color: #f0c674;\">MountSettings</span> <span style=\"color: #cc6666;\">=</span> <span style=\"color: #f0c674;\">MountSettings</span> {
sshfsUser <span style=\"color: #cc6666;\">::</span> <span style=\"color: #f0c674;\">Text</span>
, sshfsHost <span style=\"color: #cc6666;\">::</span> <span style=\"color: #f0c674;\">Text</span>
, sshfsPort <span style=\"color: #cc6666;\">::</span> <span style=\"color: #f0c674;\">Int</span>
, idFile <span style=\"color: #cc6666;\">::</span> <span style=\"color: #f0c674;\">FilePath</span>
} <span style=\"color: #b294bb;\">deriving</span> (<span style=\"color: #f0c674;\">Show</span>, <span style=\"color: #f0c674;\">Read</span>)
</pre>
</div>
<p>
If the file is not present or incorrectly formatted<br />
then the default settings for vagrant will be used:
</p>
<ul class=\"org-ul\">
<li>User: vagrant
</li>
<li>Host: 127.0.0.1
</li>
<li>Port: 2222
</li>
<li>Key file: <code>~/.vagrant.d/insecure_private_key</code>
</li>
</ul>
</div>
<div id=\"outline-container-sec-2-2-1\" class=\"outline-4\">
<h4 id=\"sec-2-2-1\"><span class=\"section-number-4\">2.2.1</span> Example .vadosettings file</h4>
<div id=\"text-2-2-1\" class=\"outline-text-4\">
<p>
An example settings file might look like this:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-haskell\">[
<span style=\"color: #f0c674;\">MountSettings</span> {
sshfsUser <span style=\"color: #cc6666;\">=</span> <span style=\"color: #b5bd68;\">\"vagrant\"</span>
, sshfsHost <span style=\"color: #cc6666;\">=</span> <span style=\"color: #b5bd68;\">\"localhost\"</span>
, sshfsPort <span style=\"color: #cc6666;\">=</span> 2222
, idFile <span style=\"color: #cc6666;\">=</span> <span style=\"color: #b5bd68;\">\"/Users/dan/.vagrant.d/insecure_private_key\"</span>
},
<span style=\"color: #f0c674;\">MountSettings</span> {
sshfsUser <span style=\"color: #cc6666;\">=</span> <span style=\"color: #b5bd68;\">\"admin\"</span>
, sshfsHost <span style=\"color: #cc6666;\">=</span> <span style=\"color: #b5bd68;\">\"server.local\"</span>
, sshfsPort <span style=\"color: #cc6666;\">=</span> 2233
, idFile <span style=\"color: #cc6666;\">=</span> <span style=\"color: #b5bd68;\">\"/Users/dan/keys/local_server_key\"</span>
}
]
</pre>
</div>
</div>
</div>
</div>
<div id=\"outline-container-sec-2-3\" class=\"outline-3\">
<h3 id=\"sec-2-3\"><span class=\"section-number-3\">2.3</span> Vamount</h3>
<div id=\"text-2-3\" class=\"outline-text-3\">
<p>
Of course, using <code>vado</code> requires mounting the sshfs beforehand. But<br />
it gets tedious typing out
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">sshfs vagrant@localhost:/home/vagrant ../vm/ -p2222
-reconnect,defer_permissions,negative_vncache,<span style=\"color: #cc6666;\">volname</span>=ghcjs,<span style=\"color: #cc6666;\">IdentityFile</span>=~/.vagrant.d/insecure_private_key
</pre>
</div>
<p>
every time. A tool called <code>vamount</code> which is bundled together<br />
with <code>vado</code> can be used for mounting remote filesystems based on<br />
<code>~/.vadosettings</code> file.
</p>
<p>
You can use it like this:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">vamount [ssh options] remote_path [profile <span style=\"color: #969896;\">#</span><span style=\"color: #969896;\">]</span>
</pre>
</div>
<p>
The <code>remote_path</code> from the remote server specified in the<br />
~/.vadosettings file under number [profile #] will be mounted in the<br />
current directory using sshfs.
</p>
<p>
The profile number count starts from 1. If the [profile #] is absent<br />
or is 0 then the default (vagrant) configuration will be used.
</p>
</div>
</div>
<div id=\"outline-container-sec-2-4\" class=\"outline-3\">
<h3 id=\"sec-2-4\"><span class=\"section-number-3\">2.4</span> Vado and ghc-mod</h3>
<div id=\"text-2-4\" class=\"outline-text-3\">
<p>
<a href=\"http://www.mew.org/~kazu/proj/ghc-mod/en/\">ghc-mod</a> is a backend designed command to enrich Haskell programming on<br />
editors like Emacs and Vim and it also features a front-end for Emacs<br />
as a set of elisp scripts. It’s a really cool piece of software and if<br />
you have not tried it yet I highly recommend you to invest into<br />
installing and using it.
</p>
<p>
What we would like, however, is to edit files on the mounted<br />
filesystem using Emacs on the host machine, but run ghc-mod inside the<br />
VM. In order to do that we need to install ghc-mod both on our host<br />
machine and on the VM.
</p>
<p>
While installing ghc-mod on the host machine running the latest<br />
haskell-platform is pretty straightforward it is harder to do so on<br />
the VM running GHC 7.7 due to the fact that many libraries are not<br />
ready for GHC 7.7 and base 4.7 yet. We have to resort to installing<br />
most of the things from source.
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\"><span style=\"color: #969896;\"># </span><span style=\"color: #969896;\">run this on the guest machine</span>
mkdir ghcmod && <span style=\"color: #D0D0FF;\">cd</span> ghcmod
<span style=\"color: #969896;\"># </span><span style=\"color: #969896;\">patching installing convertible</span>
cabal unpack convertible
<span style=\"color: #D0D0FF;\">cd</span> convertible*
wget http://co-dan.github.io/patched/convertible.patch
patch -p1 Data/Convertible/Utils.hs convertible.patch
cabal install
<span style=\"color: #D0D0FF;\">cd</span> ..
<span style=\"color: #969896;\"># </span><span style=\"color: #969896;\">installing ghc-syb-utils</span>
git clone https://github.com/co-dan/ghc-syb.git
<span style=\"color: #D0D0FF;\">cd</span> ghc-syb/utils/
cabal install
<span style=\"color: #D0D0FF;\">cd</span> ../..
<span style=\"color: #969896;\"># </span><span style=\"color: #969896;\">finally getting and installing ghc-mod</span>
git clone https://github.com/co-dan/ghc-mod.git
<span style=\"color: #D0D0FF;\">cd</span> ghc-mod
cabal install
</pre>
</div>
<p>
Ghc-mod itself uses the GHC API extensively so it’s no surprise we<br />
have to change at least some code. Now that we have installed ghc-mod<br />
on the guest VM we need to set up our host’s Emacs configuration to<br />
communicate properly with the VM. First of all put this in your Emacs<br />
config:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-elisp\"><span style=\"color: #7f7f7f;\">(</span>setq load-path <span style=\"color: #7f7f7f;\">(</span>cons <span style=\"color: #b5bd68;\">\"~/Library/Haskell/ghc-7.6.3/lib/ghc-mod-2.0.3/share\"</span> load-path<span style=\"color: #7f7f7f;\">))</span>
<span style=\"color: #7f7f7f;\">(</span>autoload 'ghc-init <span style=\"color: #b5bd68;\">\"ghc\"</span> nil t<span style=\"color: #7f7f7f;\">)</span>
<span style=\"color: #7f7f7f;\">(</span>add-hook 'haskell-mode-hook <span style=\"color: #7f7f7f;\">(</span><span style=\"color: #b294bb;\">lambda</span> <span style=\"color: #7f7f7f;\">()</span> <span style=\"color: #7f7f7f;\">(</span>ghc-init<span style=\"color: #7f7f7f;\">)))</span>
<span style=\"color: #969896;\">;; </span><span style=\"color: #969896;\">(setq ghc-module-command \"ghc-mod\")</span>
<span style=\"color: #7f7f7f;\">(</span>setq ghc-module-command <span style=\"color: #b5bd68;\">\"~/vado-ghc-mod.sh\"</span><span style=\"color: #7f7f7f;\">)</span>
</pre>
</div>
<p>
<code>~/vado-ghc-mod.sh</code> should contain the following:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\"><span style=\"color: #969896;\">#</span><span style=\"color: #969896;\">!/bin/</span><span style=\"color: #b294bb;\">bash</span>
<span style=\"color: #cc6666;\">VADO</span>=/Users/dan/Library/Haskell/bin/vado
<span style=\"color: #cc6666;\">LOCAL_PATH</span>=/Users/dan/projects/ghcjs/mnt/
<span style=\"color: #cc6666;\">REMOTE_PATH</span>=/home/vagrant/
<span style=\"color: #D0D0FF;\">cd</span> $<span style=\"color: #cc6666;\">LOCAL_PATH</span>
$<span style=\"color: #cc6666;\">VADO</span> -t ghc-mod ${<span style=\"color: #cc6666;\">@</span>//$<span style=\"color: #cc6666;\">LOCAL_PATH</span>/$<span style=\"color: #cc6666;\">REMOTE_PATH</span>} | sed <span style=\"color: #b5bd68;\">\"s,$REMOTE_PATH,$LOCAL_PATH,g\"</span>
</pre>
</div>
<p>
I know that it’s a hack, but it does work and I guess that’s what<br />
shell scripts are for ;)
</p>
<p>
Now go to <code>~/.bashrc</code> on the <i>guest machine</i> and make sure that the<br />
<code>PATH</code> variable is <a href=\"http://stackoverflow.com/questions/820517/bashrc-at-ssh-login\">set correctly</a>:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\"><span style=\"color: #cc6666;\">PATH</span>=/home/vagrant/ghcjs/bin:/home/vagrant/.cabal/bin:/home/vagrant/ghc/bin:/home/vagrant/jsshell:/home/vagrant/node-v0.10.10-linux-x86/bin:$<span style=\"color: #cc6666;\">PATH</span>
<span style=\"color: #969896;\"># </span><span style=\"color: #969896;\">PATH is set *before* this line:</span>
[ -z <span style=\"color: #b5bd68;\">\"$PS1\"</span> ] && <span style=\"color: #b294bb;\">return</span>
<span style=\"color: #969896;\"># </span><span style=\"color: #969896;\"><snip></span>
</pre>
</div>
<p>
And that’s it, you should be done!
</p>
<p>Before (ghc-mod running on the host machine):<br />
<a href=\"http://parenz.files.wordpress.com/2013/06/ghcmod-before.png\"><img src=\"http://parenz.files.wordpress.com/2013/06/ghcmod-before.png?w=600&h=306\" alt=\"ghcmod-before\" height=\"306\" class=\"alignnone size-medium wp-image-66\" width=\"600\" /></a></p>
<p>After (ghc-mod running inside <a href=\"https://github.com/ghcjs/ghcjs-build\">ghcjs-build</a> VM):<br />
<a href=\"http://parenz.files.wordpress.com/2013/06/ghcmod-after.png\"><img src=\"http://parenz.files.wordpress.com/2013/06/ghcmod-after.png?w=600&h=306\" alt=\"ghcmod-after\" height=\"306\" class=\"alignnone size-medium wp-image-65\" width=\"600\" /></a></p>
</div>
</div>
</div>
<div id=\"outline-container-sec-3\" class=\"outline-2\">
<h2 id=\"sec-3\"><span class=\"section-number-2\">3</span> Conclusion and future work</h2>
<div id=\"text-3\" class=\"outline-text-2\">
<p>
We’ve seen how a small but useful tool <code>vado</code> can make our life easier if<br />
we want to develop Haskell projects on a remote server or on a<br />
virtual machine. You can get Vado from GitHub: <a href=\"https://github.com/hamishmack/vado\">https://github.com/hamishmack/vado</a>
</p>
<p>
Next week we are planning on releasing our first version of<br />
interactive-diagrams pastesite (not going to be very interactive<br />
though) and writing out its security model.
</p>
<p>
Meanwhile check Luite’s <a href=\"http://weblog.luite.com/wordpress/?p=127\">post</a> on using Sodium FRP library for creating<br />
Functional Reactive Web interfaces. It’s astonishing how easily you<br />
can just get a FRP library, compile to JavaScript and make nifty web<br />
apps with it.
</p>
</div>
</div>
<br /> Tagged: <a href=\"http://parenz.wordpress.com/tag/ghcjs/\">ghcjs</a>, <a href=\"http://parenz.wordpress.com/tag/haskell-2/\">haskell</a>, <a href=\"http://parenz.wordpress.com/tag/soc/\">soc</a>, <a href=\"http://parenz.wordpress.com/tag/vm/\">vm</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/parenz.wordpress.com/64/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/parenz.wordpress.com/64/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=parenz.wordpress.com&blog=26722965&post=64&subd=parenz&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "23dd5df297dc0020f4d100cfcef2ce53") (123 (20945 14387 192426) "http://jpmoresmau.blogspot.com/2013/06/eclipsefp-253-released.html" "JP Moresmau: EclipseFP 2.5.3 released" "noreply@blogger.com (JP Moresmau)" "Sun, 30 Jun 2013 18:20:49 +0000" "Hello, I've just released a new version of EclipseFP, 2.5.3. This is a minor release for bug fixes, general stability and hopefully better performance.<br /><br />You can find the release notes here: <a href=\"https://raw.github.com/JPMoresmau/eclipsefp/master/docs/releasenotes/net.sf.eclipsefp.haskell_2.5.3.txt\">https://raw.github.com/JPMoresmau/eclipsefp/master/docs/releasenotes/net.sf.eclipsefp.haskell_2.5.3.txt</a>.<br /><br />I don't have a lot of time for EclipseFP at the moment, being busy on other projects, but I'm well aware that there are a few enhancements that people have asked for in the queue. I'll try to address these later on, and of course I'll happily accept pull request on <a href=\"https://github.com/JPMoresmau/eclipsefp\">https://github.com/JPMoresmau/eclipsefp</a>.<br /><br />As usual install or update by pointing your Eclipse to <span style=\"background-color: white; font-family: monospace; font-size: 12px; line-height: 19px;\">http://eclipsefp.sf.net/updates.</span><br /><span style=\"background-color: white; font-family: monospace; font-size: 12px; line-height: 19px;\"><br /></span>Happy Haskell Hacking!" nil nil "a87220f31b8e30c79a8cfc534119fb89") (122 (20945 14387 192051) "http://blog.darcs.net/2013/06/darcs-news-104.html" "Darcs: darcs news #104" "noreply@blogger.com (guillaume)" "Sun, 30 Jun 2013 11:29:10 +0000" "<h3 id=\"news-and-discussions\">News and discussions</h3><ol style=\"\"><li>Google Summer of Code 2013 has begun! BSRK and José will post updates on their blogs:<br /> <ul><li><a href=\"http://bsrkaditya.blogspot.com/search/label/darcs\"><code class=\"url\">http://bsrkaditya.blogspot.com/search/label/darcs</code></a></li><li><a href=\"http://blog.jlneder.com.ar/search/label/darcs\"><code class=\"url\">http://blog.jlneder.com.ar/search/label/darcs</code></a></li></ul></li></ol><h3 id=\"issues-resolved-8\">Issues resolved (8)</h3><dl><dt>issue2163 Radoslav Dorcik</dt><dd><ul><li>new option for amend, select author for patch stealing.</li><li><a href=\"http://bugs.darcs.net/issue2163\"><code class=\"url\">http://bugs.darcs.net/issue2163</code></a></li></ul></dd><dt>issue2227 Ganesh Sittampalam</dt><dd><ul><li>move the rebase patch to the end before an amend-record</li><li><a href=\"http://bugs.darcs.net/issue2227\"><code class=\"url\">http://bugs.darcs.net/issue2227</code></a></li></ul></dd><dt>issue2248 Ganesh Sittampalam</dt><dd><ul><li>always clean up rebase-in-progress state</li><li><a href=\"http://bugs.darcs.net/issue2248\"><code class=\"url\">http://bugs.darcs.net/issue2248</code></a></li></ul></dd><dt>issue2250 BSRK Aditya</dt><dd><ul><li>tabbing in usageHelper - pad by max length of command name</li><li><a href=\"http://bugs.darcs.net/issue2250\"><code class=\"url\">http://bugs.darcs.net/issue2250</code></a></li></ul></dd><dt>issue2311 Sebastian Fischer</dt><dd><ul><li>posthook for 'get' should run in created repo</li><li><a href=\"http://bugs.darcs.net/issue2311\"><code class=\"url\">http://bugs.darcs.net/issue2311</code></a></li></ul></dd><dt>issue2312 Sebastian Fischer</dt><dd><ul><li>posthooks for 'record' and 'amend-record' should receive DARCS_PATCHES</li><li><a href=\"http://bugs.darcs.net/issue2312\"><code class=\"url\">http://bugs.darcs.net/issue2312</code></a></li></ul></dd><dt>issue2320 Jose Luis Neder</dt><dd><ul><li>save prompted author name in ~/.darcs/author instead of ./_darcs/prefs/author</li><li><a href=\"http://bugs.darcs.net/issue2320\"><code class=\"url\">http://bugs.darcs.net/issue2320</code></a></li></ul></dd><dt>issue2321 Jose Luis Neder</dt><dd><ul><li>when no patch name given, directly invoke text editor</li><li><a href=\"http://bugs.darcs.net/issue2321\"><code class=\"url\">http://bugs.darcs.net/issue2321</code></a></li></ul></dd></dl><h3 id=\"patches-applied-20\">Patches applied (20)</h3><dl><dt>2013-06-09 Guillaume Hoffmann</dt><dd><ul><li>make nano the default text editor instead of vi</li></ul></dd><dt>2013-06-20 BSRK Aditya</dt><dd><ul><li>Resolve issue2250: tabbing in usageHelper - pad by max length of command name</li></ul></dd><dt>2013-06-16 Guillaume Hoffmann</dt><dd><ul><li>remove word repetition in fileHelpAuthor string</li></ul></dd><dt>2013-06-16 Jose Luis Neder</dt><dd><ul><li>resolve issue2320: save prompted author name in ~/.darcs/author instead of ./_darcs/prefs/author</li><li>resolve issue2321: when no patch name given, directly invoke text editor</li></ul></dd><dt>2013-04-30 Guillaume Hoffmann</dt><dd><ul><li>remove repository flag DryRun parameter when not used or always NoDryRun</li></ul></dd><dt>2013-04-05 Ganesh Sittampalam</dt><dd><ul><li>fix test for Windows</li></ul></dd><dt>2013-03-10 Sebastian Fischer</dt><dd><ul><li>Follow-up on patch1066 resolving issue2312.</li><li>resolve issue2312: posthooks for 'record' and 'amend-record' should receive DARCS_PATCHES</li><li>Added tests for issue2312: posthooks for 'record' and 'amend-record' should receive DARCS_PATCHES</li></ul></dd><dt>2013-02-16 Ganesh Sittampalam</dt><dd><ul><li>resolve issue2227: move the rebase patch to the end before an amend-record</li><li>tidy command definitions in Darcs.UI.Commands.Rebase</li><li>resolve issue2248: always clean up rebase-in-progress state</li><li>add --ignore-times option to rebase commands that read the working dir</li></ul></dd><dt>2013-03-08 Sebastian Fischer</dt><dd><ul><li>resolve issue2311: posthook for 'get' should run in created repo</li><li>Added tests for Issue 2311.</li></ul></dd><dt>2013-06-03 Guillaume Hoffmann</dt><dd><ul><li>haddocks for functions that look for user e-mail</li></ul></dd><dt>2013-03-02 Radoslav Dorcik</dt><dd><ul><li>Resolve issue2163: new option for amend, select author for patch stealing.</li></ul></dd><dt>2013-05-29 BSRK Aditya</dt><dd><ul><li>Export doOptimizeHTTP from Optimize module</li><li>Increase efficiency of patch index update by more efficient extraction</li></ul></dd></dl>See <a href=\"http://wiki.darcs.net/DarcsWeeklyNews/2013-06-30\">darcs wiki entry</a> for details." nil nil "d1984c0a17d48ef8a084e126494e9f2a") (121 (20945 14387 191318) "http://wadler.blogspot.com/2013/06/knowledge-economy.html" "Philip Wadler: Knowledge Economy" "noreply@blogger.com (Philip Wadler)" "Sun, 30 Jun 2013 11:20:54 +0000" "<div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://2.bp.blogspot.com/-5FG3qlbvISc/UdATLL5FduI/AAAAAAAACdk/5DgXlPXknxY/s242/ke-logo.gif\"><img src=\"http://2.bp.blogspot.com/-5FG3qlbvISc/UdATLL5FduI/AAAAAAAACdk/5DgXlPXknxY/s400/ke-logo.gif\" height=\"208\" border=\"0\" width=\"400\" /></a></div><div style=\"clear: both; text-align: justify;\" class=\"separator\">UCU writes:</div><blockquote class=\"tr_bq\"><span style=\"background-color: white; color: #222222; text-align: start;\"><span style=\"font-family: inherit;\">Wednesday’s spending review was bad news for universities, colleges and students. Student visa charges will go up, student grants will be frozen and funding aimed at encouraging the poorest students to apply to university will be axed. On Thursday, Danny Alexander announced plans to sell off student loans. All this in the same week that the OECD research showed the UK falling behind in investment in higher education at a time when demand for highly skilled graduates is still rising faster than supply.</span></span></blockquote>Sign up to the <a href=\"http://www.knowledgeeconomy.org.uk/\">Knowledge Economy campaign</a>.<br /><div style=\"clear: both; text-align: center;\" class=\"separator\"><br /></div><div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://3.bp.blogspot.com/-PWs4Y4eMJZg/UdASqk29BeI/AAAAAAAACdg/6iOJK4FXLTE/s1600/ke1.tiff\"><img src=\"http://3.bp.blogspot.com/-PWs4Y4eMJZg/UdASqk29BeI/AAAAAAAACdg/6iOJK4FXLTE/s640/ke1.tiff\" height=\"188\" border=\"0\" width=\"640\" /></a></div><div style=\"clear: both; text-align: center;\" class=\"separator\"><br /></div><br /><div style=\"clear: both; text-align: center;\" class=\"separator\"></div><br />" nil nil "7581b30ff1d90d8410eaea11bab61ed2") (120 (20945 14387 190793) "http://praisecurseandrecurse.blogspot.com/2013/06/the-polar-game-in-haskell-day-4-12.html" "Paul Potts: The Polar Game in Haskell, Day 4 1/2: Folding a Penguin" "noreply@blogger.com (Paul Potts)" "Sat, 29 Jun 2013 19:03:00 +0000" "<p>So, just a quick update today. While I was cooking bacon this morning I looked at comments and tried to implement an idea I had last night. Roland suggested I could get rid of <b>Edge</b>. I had already been asking myself this. Using a special flag value for the edge-of-board case came from the Objective-C version where I wanted to avoid reading tiles outside the bounds of the board array. When using lists there is a built-in termination condition, so Edge is gone completely.</p> <p>Roland also suggested a simplified next_ppos, like so:</p> <pre>next_ppos :: Pos -> Dir -> Pos<br />next_ppos pos dir = Pos ( posY pos + fst step ) ( posX pos + snd step )<br />    where step = delta dir<br />          delta East = ( 0, 1 )<br />          delta South = ( 1, 0 )<br />          delta West = ( 0, -1 )<br />          delta North = ( -1, 0 )</pre> <p>So that's in there now. Thanks, Roland!</p> <p>The next thing I wanted to do is get rid of that ugly test code with all the nested calls to next_world. I was re-reading <i>Learn You a Haskell</i> and it occurred to me that this sort of thing -- distilling a list -- is what <i>folds</i> are for. And then, a minute later, that I don't actually want to <i>fold</i> the worlds down to one final world -- I want to capture all the intermediate worlds as we process a list of moves. And that's what a <i>scan</i> is for. So we're conducting surveillance on the penguin as he goes about his business. GHCI tells me that the type of <b>scanl</b> is <b>(a -> b -> a) -> a -> [b] -> [a]</b>. So I'm calling it with a function that takes a <b>World</b> and a <b>Dir</b> and returns a <b>World</b>. That's the <b>(a -> b -> a)</b> part. Then it gets an initial <b>World</b>, that's the <b>a</b>, and a list of elements of type <b>Dir</b>, that's the <b>[b]</b>, and returns a list of elements of type <b>World</b>, that's <b>[a]</b>.</p> <pre>moves_to_dirs :: [(Dir, Int)] -> [Dir]<br />moves_to_dirs [] = []<br />moves_to_dirs (m:ms) = replicate ( snd m ) ( fst m ) ++ moves_to_dirs ms<br /><br />moves_board_1 = [(East,21),(South,2), (East,3),(North,2),(West,2)]<br /><br />move_sequence :: [(Dir,Int)] -> [World]<br />move_sequence repeats = scanl next_world init_world steps<br />    where steps = moves_to_dirs repeats<br /><br />main :: IO ()<br />main = do<br />    mapM_ putStrLn pretty_worlds<br />    where worlds = move_sequence moves_board_1</pre> <p>And that gives me the whole shebang, ending in:</p> <pre>penguin @: Pos {posY = 0, posX = 22}, facing: West, hearts: 3<br />tr __________________________________________tr _______________ic ______<br />tr ___bo ___mt ___he ic he ___________________________tr ______tr ______<br />tr _____________________________________________he _________mt ho ______<br />tr tr ____________tr ___________________________________________________<br /><br />penguin @: Pos {posY = 0, posX = 21}, facing: West, hearts: 3<br />tr __________________________________________tr ic _____________________<br />tr ___bo ___mt ___he ic he ___________________________tr ______tr ______<br />tr _____________________________________________he _________mt ho ______<br />tr tr ____________tr ___________________________________________________</pre> <p>Oh, if you just want to see the final result, foldl will work here. Their types are identical, except that foldl returns a single <b>a</b> (in this case, a <b>World</b>) instead of a list of elements of type <b>World</b>. So a function to make use of that just returns a single <b>World</b>, but everything else is the same. Like so:</p> <pre>move_sequence' :: [(Dir,Int)] -> World<br />move_sequence' repeats = foldl next_world init_world steps<br />    where steps = moves_to_dirs repeats</pre> <p>And then I can display both:</p> <pre>main :: IO ()<br />main = do<br />    mapM_ putStrLn pretty_worlds <br />    putStrLn pretty_final_world<br />    where worlds = move_sequence moves_board_1<br />          final_world = move_sequence' moves_board_1<br />          pretty_worlds = map pretty_world worlds</pre> <p>I like it -- examples of fold and scan that are a little more complex than the usual textbook examples. Personally I'd rather read more of those and less about how we can implement some simple math operation that can be trivially implemented in a dozen other, more readable ways.</p> <p>Oh, and it's not thoroughly tested or finished by any means, but if you'd like to play with this code, it's on github now: <a href=\"https://github.com/paulrpotts/arctic-slide-haskell\">https://github.com/paulrpotts/arctic-slide-haskell</a>. Comments are welcome as always.</p>" nil nil "2937163cc3ea7f642ea5600cd8db448a") (119 (20945 14387 190012) "http://lpuppet.banquise.net/blog/2013/06/28/full-rewrite-in-progress/" "language-puppet: Full rewrite in progress" nil "Fri, 28 Jun 2013 20:24:00 +0000" "<p>In the process of writing the language-puppet library, I learned quite a lot about Haskell and its libraries. The first part of language-puppet that was written was the parser. At that time I did not understand monads, brute-forced the do-notation until it seemed to do what I wanted, and generally made all kind of blunders. The other problem was that I was learning Puppet too, at a time when it was changing a lot and nothing was really documented. This led to unfortunate decisions that I already <a href=\"http://lpuppet.banquise.net/blog/2012/10/08/types-used-in-the-interpretation-stage/\">documented</a>.</p>
<p>I dediced to rewrite everything from scratch, by directly implementing all I could find in the
<a href=\"http://docs.puppetlabs.com/puppet/3/reference/\">reference</a>. I started a new parser during the weekend, encoding as many verifications as possible in
it, and then tried it on real manifests. Boy, was I naïve ! It did not work at all. The specification is good for learning the language or dissipating
some common misconceptions, but is of moderate use for my purpose. I relaxed most of the checks and it seems to work now.</p>
<p><img src=\"http://lpuppet.banquise.net/images/lpuppet-parser-color.png\" alt=\"Alt text\" /></p>
<p>On the technical side, I am now using the <a href=\"http://hackage.haskell.org/package/parsers\">parsers</a> package, which has a very nice interface. I considered
using <a href=\"http://hackage.haskell.org/package/trifecta\">trifecta</a> as the underlying parser. Its error messages are gorgeous, but it turns out it is not trivial to get my own <em>lexeme</em>
system in place with it. I went with <a href=\"http://hackage.haskell.org/package/parsec\">parsec</a>, and, instead of using the
<a href=\"http://hackage.haskell.org/package/parsec-parsers\">parsec-parsers</a> package, wrote my own instances (to be honest I copy-pasted those of the package
and added a non-default definition for <em>token</em>). Edward Kmett was nice enough to give me pointers on how to do this with trifecta, but this did look quite
clumsy. He hinted that he might work on a monad-transformer approach to this problem, so I am just waiting for this to happen. The nice thing about
the parsers approach is that switching now is trivial.</p>
<p>As can be seen on the previous screenshot, I am using a <a href=\"http://hackage.haskell.org/package/ansi-wl-pprint\">nice pretty printing library</a> that let me
(ab)use color.</p>
<p>Another huge difference is that I now use strict type whenever possible. The previous version seemed to be able to support an arbitrary number of worker threads with
300mb of storage for my catalogs, whereas the Puppet version could go up to 800mb for a single thread. I would like to at least halve this figure for
the next version.</p>
<p>The next step is to write the new <em>daemon</em> infrastructure. I already have a generic <a href=\"https://github.com/bartavelle/filecache\">file-cache</a> module that
let you cache things related to files. When a file is modified, the cached value is automagically invalidated (using inotify). I hope this will work
well in practice and will not be blocking all the other threads.</p>" nil nil "6d140c593e83a96e51a56d0aaedd9567") (118 (20945 14387 189151) "http://praisecurseandrecurse.blogspot.com/2013/06/the-polar-game-in-haskell-day-4.html" "Paul Potts: The Polar Game in Haskell, Day 4" "noreply@blogger.com (Paul Potts)" "Fri, 28 Jun 2013 20:07:00 +0000" "<p>OK, things are getting meaty: I've made some minor modifications to <b>World</b>:</p> <pre>data World = World { wBoard :: Board, wPenguinPos :: Pos,<br />                     wPenguinDir :: Dir, wHeartCount :: Int }<br />                     deriving (Show)</pre> <p>This extracts the sequence of tiles in front of the penguin, for various directions, from a nested list representation of the board:</p> <pre>view :: Board -> Pos -> Dir -> [Tile]<br />view board pos East = ( drop ( posX pos + 1 ) $<br />    board !! ( posY pos ) ) ++ [Edge]<br />view board pos South = ( drop ( posY pos + 1 ) $<br />    ( transpose board ) !! ( posX pos ) ) ++ [Edge]<br />view board pos West = ( reverse $ take ( posX pos ) $<br />    board !! ( posY pos ) ) ++ [Edge]<br />view board pos North = ( reverse $ take ( posY pos ) $<br />    ( transpose board ) !! ( posX pos ) ) ++ [Edge]</pre> <p>I have fleshed out slide and collide after some testing; I haven't tested all my known cases yet. Maybe tomorrow. Here is how I create the initial world:</p> <pre>init_world :: World<br />init_world = ( World init_board ( Pos 0 0 ) South 3 )</pre> <p>South because in the south-facing representation, the penguin's face is visible (although of course I don't have a GUI yet).</p> <p>A little utility function for clarity:</p> <pre>nest :: [a] -> [[a]]<br />nest xs = [xs]</pre> <p>And now, deep breath, the logic to build the next board out of the current board combined with a replaced list of tiles that may have been changed due to object interaction. It gets pretty ugly here when we're undoing the appending of Edge with init, and undoing the reversing that view has done when looking North and West, and working with the transposed board for North and South. There are some extra line breaks in there that are not in the working code. I have an issue with my <b>let</b> clauses not compiling correctly if I break the lines. I'm sure there's a prettier workaround, and I will look that up, but after going down a rabbit hole of Haskell syntax, I have timed out for today and right now I'm just happy it runs:</p> <pre>next_board :: Board -> Pos -> Dir -> ( Bool, Board )<br />next_board board pos East =<br />    let ( penguin_could_move, updated_view ) =<br />        step $ view board pos East<br />    in (<br />        penguin_could_move,<br />        take ( posY pos ) board ++<br />        nest (<br />            ( take ( posX pos + 1 )<br />                ( board !! ( posY pos ) ) ) ++<br />            ( init updated_view ) ) ++<br />        drop ( posY pos + 1 ) board )<br />next_board board pos South =<br />    let ( penguin_could_move, updated_view ) =<br />        step $ view board pos South<br />    in (<br />        penguin_could_move,<br />        transpose (<br />            take ( posX pos ) ( transpose board ) ++<br />            nest (<br />                ( take ( posY pos + 1 )<br />                    ( ( transpose board ) !! ( posX pos ) ) ) ++<br />                ( init updated_view ) ) ++<br />        drop ( posX pos + 1 ) ( transpose board ) ) )<br />next_board board pos West =<br />    let ( penguin_could_move, updated_view ) =<br />        step $ view board pos West<br />    in (<br />        penguin_could_move,<br />        take ( posY pos ) board ++<br />        nest (<br />            ( reverse ( init updated_view ) ) ++<br />            ( drop ( posX pos )<br />                ( board !! ( posY pos ) ) ) ) ++<br />        drop ( posY pos + 1 ) board )<br />next_board board pos North =<br />    let ( penguin_could_move, updated_view ) =<br />        step $ view board pos North<br />    in (<br />        penguin_could_move,<br />            transpose (<br />            take ( posX pos ) ( transpose board ) ++<br />            nest (<br />                ( reverse ( init updated_view ) ) ++<br />                ( drop ( posY pos )<br />                    ( ( transpose board ) !! ( posX pos ) ) ) ) ++<br />            drop ( posX pos + 1 ) ( transpose board ) ) )</pre> <p>That... seems like way too much code, and I would like to kill it in favor of using a real array type -- soon. The tutorials were pretty insistent that I try to use lists. I'm pretty sure this is not what they meant. I will say that I was really impressed, writing this, how much of it worked the first time, as soon as I got it past the compiler. But that doesn't necessarily mean this is the best possible design for this code.</p> <p>Anyway, updating penguin pos:</p> <pre>next_ppos :: Pos -> Dir -> Pos<br />next_ppos pos East = ( Pos ( posY pos ) ( posX pos + 1 ) )<br />next_ppos pos South = ( Pos ( posY pos + 1 ) ( posX pos ) )<br />next_ppos pos West = ( Pos ( posY pos ) ( posX pos - 1 ) )<br />next_ppos pos North = ( Pos ( posY pos - 1 ) ( posX pos ) )</pre> <p>And, updating the world. I had a similar problem with the line-broken <b>let</b> clause here:</p> <pre>next_world :: World -> Dir-> World<br />next_world old_world move_dir =<br />    let ( can_move, board ) = next_board ( wBoard old_world )<br />        ( wPenguinPos old_world ) ( wPenguinDir old_world )<br />    in<br />        if ( move_dir /= wPenguinDir old_world )<br />        then ( World ( wBoard old_world ) ( wPenguinPos old_world )<br />                   move_dir ( wHeartCount old_world ) )<br />        else ( World board<br />                   ( next_ppos ( wPenguinPos old_world )<br />                               ( wPenguinDir old_world ) )<br />                   ( wPenguinDir old_world )<br />                   ( wHeartCount old_world ) )</pre> <p>Now, some pretty-printing, since it gets pretty tedious to visualize the board from reading the dumped-out list in GHCI:</p> <pre>pretty_tiles :: [Tile] -> String<br />pretty_tiles [] = \"\\n\"<br />pretty_tiles (t:ts) = case t of<br />                 Empty     -> \"___ \"<br />                 Mountain  -> \"mtn \"<br />                 House     -> \"hou \"<br />                 Ice_Block -> \"ice \"<br />                 Heart     -> \"hea \"<br />                 Bomb      -> \"bom \"<br />                 Tree      -> \"tre \"<br />                 Edge      -> \"### \"<br />             ++ pretty_tiles ts<br /><br />pretty_board :: Board -> String<br />pretty_board [] = \"\"<br />pretty_board (ts:tss) = pretty_tiles ts ++ pretty_board tss<br /><br />pretty_world :: World -> String<br />pretty_world world =<br />    \"penguin @: \" ++ show ( wPenguinPos world ) ++<br />    \", facing: \"  ++ show ( wPenguinDir world ) ++<br />    \", hearts: \"  ++ show ( wHeartCount world ) ++<br />    \"\\n\" ++ pretty_board ( wBoard world )</pre> <p>And here's where the rubber meets the road -- or, rather, fails to. I need state, at least simulated state. I messed with state monads for a while but I'm not quite ready. I will tackle that another day. I messed with trying to capture a list in a closure and append a series of successive worlds to it but while that would work fine in Scheme, Lisp, or Dylan I realized that in Haskell I was just fighting the entire language design. So I gave in and did this stupid thing for now, just so I could see my world updating and start to validate that all the tile interactions on the board work:</p> <pre>main :: IO ()<br />main = do<br />    putStrLn \"ArcticSlide start\"<br />    let world0 = init_world<br />    putStrLn $ pretty_world world0<br /><br />    -- 21 East<br />    let world5  = next_world ( next_world ( next_world ( next_world (<br />        next_world world0  East ) East ) East ) East ) East<br />    let world10 = next_world ( next_world ( next_world ( next_world (<br />        next_world world5  East ) East ) East ) East ) East<br />    let world15 = next_world ( next_world ( next_world ( next_world (<br />        next_world world10 East ) East ) East ) East ) East<br />    let world20 = next_world ( next_world ( next_world ( next_world (<br />        next_world world15 East ) East ) East ) East ) East<br />    let world21 = next_world world20 East<br />    putStrLn $ pretty_world world21<br />    -- 2 South<br />    let world23 = next_world ( next_world world21 South ) South<br />    putStrLn $ pretty_world world23<br />    -- 3 East<br />    let world26 = next_world ( next_world (<br />        next_world world23 East ) East ) East<br />    putStrLn $ pretty_world world26<br />    -- 2 North<br />    let world28 = next_world ( next_world world26 North ) North<br />    putStrLn $ pretty_world world28<br />    -- 2 West<br />    let world30 = next_world ( next_world world28 West ) West<br />    putStrLn $ pretty_world world30</pre> <p>That is far from what I'd like to be doing eventually with managing game moves, and I still haven't put in any handling for the heart count, but it works:</p> <pre>ArcticSlide start<br />penguin @: Pos {posY = 0, posX = 0}, facing: South, hearts: 3<br />tr __________________________________________tr _______________ic ______<br />tr ___bo ___mt ___he ic he ___________________________tr ______tr ______<br />tr _____________________________________________he _________mt ho ______<br />tr tr ____________tr ___________________________________________________<br /><br />...<br /><br />penguin @: Pos {posY = 0, posX = 22}, facing: North, hearts: 3<br />tr __________________________________________tr _______________ic ______<br />tr ___bo ___mt ___he ic he ___________________________tr ______tr ______<br />tr _____________________________________________he _________mt ho ______<br />tr tr ____________tr ___________________________________________________<br /><br />penguin @: Pos {posY = 0, posX = 21}, facing: West, hearts: 3<br />tr __________________________________________tr ic _____________________<br />tr ___bo ___mt ___he ic he ___________________________tr ______tr ______<br />tr _____________________________________________he _________mt ho ______<br />tr tr ____________tr ___________________________________________________<br /></pre> <p>Aaaand... the penguin has pushed the ice block in the upper right to the west, and it has slid west and become blocked by the tree. That's... good, right? My brain is a little fried. All that to update a game board. I need a break, and maybe a stiff drink. I'm going to have to fortify myself before I successfully tackle the state monad. But I am determined!</p>" nil nil "99ee8d6a74004aefc0db264560efeed3") (117 (20945 14387 144339) "http://praisecurseandrecurse.blogspot.com/2013/06/the-polar-game-in-haskell-day-3.html" "Paul Potts: The Polar Game in Haskell, Day 3" "noreply@blogger.com (Paul Potts)" "Fri, 28 Jun 2013 01:12:00 +0000" "<p>More phone interviews, more coding. On my laptop, amidst a gaggle of fighting children, during a thunderstorm, with our basement flooding, with the kind assistance of some friendly commentors, a little more progress. Let's change <b>Pos</b></p> <pre>data Pos = Pos { posY :: Int, posX :: Int }<br />    deriving (Show, Eq)</pre> <p>And define a game world:</p> <pre>data World = World { board :: Board, penguinPos :: Pos,<br />                          penguinDir :: Dir,<br />                          heartCount :: Int } deriving (Show)</pre> <p>It was painful, took an embarrassingly long time, and this can't possibly be how I want to keep it indefinitely, but I finished <b>slice</b> which treats a list of lists of tiles like a 2-dimensional array and gives us what the penguin sees before him, looking in a given direction:</p> <pre>slice :: Board -> Pos -> Dir -> [Tile]<br />slice board pos East = ( drop ( posX pos ) $ <br />    board !! ( posY pos ) ) ++ [Edge]<br />slice board pos South = ( drop ( posY pos ) $ <br />    ( transpose board ) !! ( posX pos ) ) ++ [Edge]<br />slice board pos West = ( reverse $ take ( posX pos + 1 ) $ <br />    board !! ( posY pos ) ) ++ [Edge]<br />slice board pos North = ( reverse $ take ( posY pos + 1 ) $ <br />    ( transpose board ) !! ( posX pos ) ) ++ [Edge]</pre> <p>Let's just leave that as it is for now and use it, with the intent of replacing it with a real array of some sort later on. I still have to figure out how to merge a modified penguin track with an unmodified board to create the next state of the entire board... that's not going to be pretty, but it's doable.</p> <p>So, one of the things I really love about Haskell is that once you get these pieces, they really do start come together nicely. Let's go ahead and define the first board. I could make it from the strings or a run-length encoding or something, but for now let's just bite the bullet and build the list the hard way:</p> <pre>get_initial_board :: [[Tile]]<br />get_initial_board = [[Tree,Empty,Empty,Empty,Empty,Empty,<br />                      Empty,Empty,Empty,Empty,Empty,Empty,<br />                      Empty,Empty,Empty,Tree,Empty,Empty,<br />                      Empty,Empty,Empty,Ice_Block,Empty,Empty],<br />                     [Tree,Empty,Bomb,Empty,Mountain,Empty,<br />                      Heart,Ice_Block,Heart,Empty,Empty,Empty,<br />                      Empty,Empty,Empty,Empty,Empty,Empty,<br />                      Tree,Empty,Empty,Tree,Empty,Empty],<br />                     [Tree,Empty,Empty,Empty,Empty,Empty,<br />                      Empty,Empty,Empty,Empty,Empty,Empty,<br />                      Empty,Empty,Empty,Empty,Heart,Empty,<br />                      Empty,Empty,Mountain,House,Empty,Empty],<br />                     [Tree,Tree,Empty,Empty,Empty,Empty,<br />                      Tree,Empty,Empty,Empty,Empty,Empty,<br />                      Empty,Empty,Empty,Empty,Empty,Empty,<br />                      Empty,Empty,Empty,Empty,Empty,Empty]]<br /><br />penguin_view :: Board -> Pos -> Dir -> [Tile]<br />penguin_view board pos dir = drop 1 $ slice board pos dir</pre> <p>So now we can actually start doing stuff with this. Here's what's in front of the penguin when he looks at the board from different points, in different directions:</p> <a href=\"http://4.bp.blogspot.com/-7lLSOnNaHd8/Ua4uWuQMFmI/AAAAAAAADBs/8ByFzRW9Ccs/s1600/level_1_blown_up.tiff\"><img src=\"http://4.bp.blogspot.com/-7lLSOnNaHd8/Ua4uWuQMFmI/AAAAAAAADBs/8ByFzRW9Ccs/s640/level_1_blown_up.tiff\" height=\"120\" border=\"0\" width=\"512\" /></a> <pre>*Main> penguin_view get_initial_board (Pos 0 0) East<br />[Empty,Empty,Empty,Empty,Empty,Empty,Empty,Empty,Empty,<br />Empty,Empty,Empty,Empty,Empty,Tree,Empty,Empty,Empty,Empty,<br />Empty,Ice_Block,Empty,Empty,Edge]<br /><br />*Main> penguin_view get_initial_board (Pos 0 0) South<br />[Tree,Tree,Tree,Edge]<br /><br />*Main> penguin_view get_initial_board (Pos 0 0) West<br />[Edge]<br /><br />*Main> penguin_view get_initial_board (Pos 0 0) North<br />[Edge]<br /><br />*Main> penguin_view get_initial_board (Pos 3 21) North<br />[House,Tree,Ice_Block,Edge]</pre> <p>Fun! Tomorrow, if I can manage it... an updated world.</p>" nil nil "cd156fb19829a0e207e5bbc2f788a431") (116 (20945 14387 113814) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_635\"></span>, where <span id=\"tex_5669\"></span> is the number of “folds” and <span id=\"tex_3690\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_6360\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "b7a60f562fd66b7a9a4081054395adc6") (115 (20941 47656 550654) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_4120\"></span>, where <span id=\"tex_5799\"></span> is the number of “folds” and <span id=\"tex_7138\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_4516\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "a29de488ef5250e4814771cbf284ab45") (114 (20941 43077 507817) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_4537\"></span>, where <span id=\"tex_3947\"></span> is the number of “folds” and <span id=\"tex_8487\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_6091\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "c8195d5d51e954ab03fffa4a88158065") (113 (20941 38058 954177) "http://wadler.blogspot.com/2013/06/parallel-prefix-scan-and-mapreduce.html" "Philip Wadler: Parallel prefix scan and MapReduce" "noreply@blogger.com (Philip Wadler)" "Fri, 28 Jun 2013 12:25:45 +0000" "<div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://2.bp.blogspot.com/-xZnXzPFujn8/Uc1_cVu63CI/AAAAAAAACdA/zp4IE1PRG54/s445/MapReduce.png\"><img src=\"http://2.bp.blogspot.com/-xZnXzPFujn8/Uc1_cVu63CI/AAAAAAAACdA/zp4IE1PRG54/s400/MapReduce.png\" height=\"341\" border=\"0\" width=\"400\" /></a></div>The <a href=\"http://dl.acm.org/citation.cfm?id=1327492\">MapReduce</a> paper begins its discussion of related work as follows:<br /><blockquote class=\"tr_bq\">Many systems have provided restricted programming<br />models and used the restrictions to parallelize the computation<br />automatically. For example, an associative function<br />can be computed over all prefixes of an <i>N</i> element<br />array in log <i>N</i> time on <i>N</i> processors using parallel prefix<br />computations.</blockquote>Has anyone implemented parallel prefix scan as an extension to MapReduce or a similar framework such as Hadoop, and did it prove useful?" nil nil "afea56fb50cb0c7fb97f1fd1d6a5c7fb") (112 (20941 34168 794143) "http://wadler.blogspot.com/2013/06/parallel-prefix-scan-and-mapreduce.html" "Philip Wadler: Parallel prefix scan and MapReduce" "noreply@blogger.com (Philip Wadler)" "Fri, 28 Jun 2013 12:23:38 +0000" "<div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://2.bp.blogspot.com/-xZnXzPFujn8/Uc1_cVu63CI/AAAAAAAACdA/zp4IE1PRG54/s445/MapReduce.png\"><img src=\"http://2.bp.blogspot.com/-xZnXzPFujn8/Uc1_cVu63CI/AAAAAAAACdA/zp4IE1PRG54/s400/MapReduce.png\" height=\"341\" border=\"0\" width=\"400\" /></a></div>The <a href=\"http://dl.acm.org/citation.cfm?id=1327492\">MapReduce</a> paper begins its discussion of related work as follows:<br /><blockquote class=\"tr_bq\">Many systems have provided restricted programming<br />models and used the restrictions to parallelize the computation<br />automatically. For example, an associative function<br />can be computed over all prefixes of an <i>N</i> element<br />array in log <i>N</i> time on <i>N</i> processors using parallel prefix<br />computations.</blockquote>Has anyone implemented parallel prefix scan as an extension to MapReduce or a similar framework such as Hadoop, and did it prove useful?" nil nil "0df589e0a9c61d271eafa5b3487f6c52") (111 (20941 17517 388149) "http://praisecurseandrecurse.blogspot.com/2013/06/the-polar-game-in-haskell-day-3.html" "Paul Potts: The Polar Game in Haskell, Day 3" "noreply@blogger.com (Paul Potts)" "Fri, 28 Jun 2013 01:12:00 +0000" "<p>More phone interviews, more coding. On my laptop, amidst a gaggle of fighting children, during a thunderstorm, with our basement flooding, with the kind assistance of some friendly commentors, a little more progress. Let's change <b>Pos</b></p> <pre>data Pos = Pos { posY :: Int, posX :: Int }<br />    deriving (Show, Eq)</pre> <p>And define a game world:</p> <pre>data World = World { board :: Board, penguinPos :: Pos, penguinDir :: Dir,<br />                     heartCount :: Int } deriving (Show)</pre> <p>It was painful, took an embarrassingly long time, and this can't possibly be how I want to keep it indefinitely, but I finished <b>slice</b> which treats a list of lists of tiles like a 2-dimensional array and gives us what the penguin sees before him, looking in a given direction:</p> <pre>slice :: Board -> Pos -> Dir -> [Tile]<br />slice board pos East = ( drop ( posX pos ) $ <br />    board !! ( posY pos ) ) ++ [Edge]<br />slice board pos South = ( drop ( posY pos ) $ <br />    ( transpose board ) !! ( posX pos ) ) ++ [Edge]<br />slice board pos West = ( reverse $ take ( posX pos + 1 ) $ <br />    board !! ( posY pos ) ) ++ [Edge]<br />slice board pos North = ( reverse $ take ( posY pos + 1 ) $ <br />    ( transpose board ) !! ( posX pos ) ) ++ [Edge]</pre> <p>Let's just leave that as it is for now and use it, with the intent of replacing it with a real array of some sort later on. I still have to figure out how to merge a modified penguin track with an unmodified board to create the next state of the entire board... that's not going to be pretty, but it's doable.</p> <p>So, one of the things I really love about Haskell is that once you get these pieces, they really do start come together nicely. Let's go ahead and define the first board. I could make it from the strings or a run-length encoding or something, but for now let's just bite the bullet and build the list the hard way:</p> <pre>get_initial_board :: [[Tile]]<br />get_initial_board = [[Tree,Empty,Empty,Empty,Empty,Empty,<br />                      Empty,Empty,Empty,Empty,Empty,Empty,<br />                      Empty,Empty,Empty,Tree,Empty,Empty,<br />                      Empty,Empty,Empty,Ice_Block,Empty,Empty],<br />                     [Tree,Empty,Bomb,Empty,Mountain,Empty,<br />                      Heart,Ice_Block,Heart,Empty,Empty,Empty,<br />                      Empty,Empty,Empty,Empty,Empty,Empty,<br />                      Tree,Empty,Empty,Tree,Empty,Empty],<br />                     [Tree,Empty,Empty,Empty,Empty,Empty,<br />                      Empty,Empty,Empty,Empty,Empty,Empty,<br />                      Empty,Empty,Empty,Empty,Heart,Empty,<br />                      Empty,Empty,Mountain,House,Empty,Empty],<br />                     [Tree,Tree,Empty,Empty,Empty,Empty,<br />                      Tree,Empty,Empty,Empty,Empty,Empty,<br />                      Empty,Empty,Empty,Empty,Empty,Empty,<br />                      Empty,Empty,Empty,Empty,Empty,Empty]]<br /><br />penguin_view :: Board -> Pos -> Dir -> [Tile]<br />penguin_view board pos dir = drop 1 $ slice board pos dir</pre> <p>So now we can actually start doing stuff with this. Here's what's in front of the penguin when he looks at the board from different points, in different directions:</p> <a href=\"http://4.bp.blogspot.com/-7lLSOnNaHd8/Ua4uWuQMFmI/AAAAAAAADBs/8ByFzRW9Ccs/s1600/level_1_blown_up.tiff\"><img src=\"http://4.bp.blogspot.com/-7lLSOnNaHd8/Ua4uWuQMFmI/AAAAAAAADBs/8ByFzRW9Ccs/s640/level_1_blown_up.tiff\" height=\"120\" border=\"0\" width=\"512\" /></a> <pre>*Main> penguin_view get_initial_board (Pos 0 0) East<br />[Empty,Empty,Empty,Empty,Empty,Empty,Empty,Empty,Empty,Empty,Empty,Empty,Empty,Empty,Tree,Empty,Empty,Empty,Empty,Empty,Ice_Block,Empty,Empty,Edge]<br /><br />*Main> penguin_view get_initial_board (Pos 0 0) South<br />[Tree,Tree,Tree,Edge]<br /><br />*Main> penguin_view get_initial_board (Pos 0 0) West<br />[Edge]<br /><br />*Main> penguin_view get_initial_board (Pos 0 0) North<br />[Edge]<br /><br />*Main> penguin_view get_initial_board (Pos 3 21) North<br />[House,Tree,Ice_Block,Edge]</pre> <p>Fun! Tomorrow, if I can manage it... an updated world.</p>" nil nil "21685732a0f8447ed37274f5715c40f1") (110 (20941 17517 387235) "http://feedproxy.google.com/~r/FpComplete/~3/LJ7ZmluBNOk/fp-haskell-center-beta-demo" "FP Complete: FP Haskell Center Beta Demo" nil "Thu, 27 Jun 2013 19:51:00 +0000" "<p>Thanks to the roughly 1000 people who have already
<a href=\"https://www.fpcomplete.com/business/haskell-center\">requested beta accounts</a> to try FP Haskell Center.
We are about to start admitting beta users in small groups,
and in the meantime I thought you all might enjoy a detailed demo. Enjoy!</p><p><a href=\"http://www.youtube.com/watch?v=cyyDmQKcHMs\">FP Haskell Center Beta Demo</a> on YouTube.</p><div class=\"feedflare\">
<a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=LJ7ZmluBNOk:MzhjMDnd8lU:yIl2AUoC8zA\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=yIl2AUoC8zA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=LJ7ZmluBNOk:MzhjMDnd8lU:V_sGLiPBpWU\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=LJ7ZmluBNOk:MzhjMDnd8lU:V_sGLiPBpWU\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=LJ7ZmluBNOk:MzhjMDnd8lU:qj6IDK7rITs\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=qj6IDK7rITs\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=LJ7ZmluBNOk:MzhjMDnd8lU:gIN9vFwOqvQ\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=LJ7ZmluBNOk:MzhjMDnd8lU:gIN9vFwOqvQ\" border=\"0\" /></a>
</div><img src=\"http://feeds.feedburner.com/~r/FpComplete/~4/LJ7ZmluBNOk\" height=\"1\" width=\"1\" />" nil nil "2467f214f95140f2335b3ebb03f406c4") (109 (20941 17517 271582) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_9787\"></span>, where <span id=\"tex_2416\"></span> is the number of “folds” and <span id=\"tex_70\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_724\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "104ea18e962a68ec303a00607923a3b3") (108 (20940 21559 637127) "http://theorylunch.wordpress.com/2013/06/27/having-lunch-in-a-garden-of-eden/" "Theory Lunch (Institute of Cybernetics, Tallinn): Having lunch in a Garden of Eden" nil "Thu, 27 Jun 2013 13:30:53 +0000" "<p>Today I talked about the Garden-of-Eden theorem, the first rigorous result in cellular automata theory.</p>
<p>I wrote a post about it in my new blog, dedicated to cellular automata, which I launched this week. The post contains extended proofs and examples, and most important, fixes several errors I had made during the talk. I might update it later, by adding figures—which are well known to take their time.</p>
<p>Link: <a href=\"http://anotherblogonca.wordpress.com/2013/06/27/in-a-garden-of-eden/\" target=\"_blank\">http://anotherblogonca.wordpress.com/2013/06/27/in-a-garden-of-eden/</a></p>
<br />  <a href=\"http://feeds.wordpress.com/1.0/gocomments/theorylunch.wordpress.com/1017/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/theorylunch.wordpress.com/1017/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=theorylunch.wordpress.com&blog=43735749&post=1017&subd=theorylunch&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "e3a58f5f2aabdc78ef17622784e9b15e") (107 (20940 7905 551634) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_5805\"></span>, where <span id=\"tex_4655\"></span> is the number of “folds” and <span id=\"tex_9437\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_3966\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "0c5231a2301e77d36f196e49ca9f3f95") (106 (20939 63903 514915) "http://praisecurseandrecurse.blogspot.com/2013/06/the-polar-game-in-haskell-day-2.html" "Paul Potts: The Polar Game in Haskell, Day 2" "noreply@blogger.com (Paul Potts)" "Wed, 26 Jun 2013 20:59:00 +0000" "<p>Another short day since I had several phone interviews. Thanks to the folks who left comments!</p> <p>I got a little further today; I feel like I'm starting to understand Haskell's data handling a little bit better. It's a cliché but I think the hard part is un-learning, and understanding what something like this <i>doesn't</i> do. So here's where it stands now -- not finished by any means, but coming along, with painful slowness as I continue to learn:</p> <pre>data Dir = North | East | South | West<br />    deriving (Show, Eq)<br /><br />data Pos y x = Pos Int Int<br />    deriving (Show, Eq)<br /><br />-- N.B.: capitalization of initial letters in posY, posX is<br />-- semantically important!<br />posY ( Pos y x ) = y<br />posX ( Pos y x ) = x<br /><br />data Tile = Empty | Tree | Mountain | House | Ice_Block |<br />    Bomb | Heart | Edge deriving (Show, Eq)<br /><br />-- Different types of tiles have different properties in<br />-- different interaction contexts: <br /><br />-- The penguin can walk through empty tiles or trees (forest)<br />walkable :: Tile -> Bool<br />walkable t = ( t == Empty ) || ( t == Tree )<br /><br />-- But everything except empty tiles will block sliding objects<br />blocking :: Tile -> Bool<br />blocking t = ( t /= Empty )<br /><br />-- A subset of tiles are movable (and will slide until blocked)<br />movable :: Tile -> Bool<br />movable t = ( t == Bomb ) || ( t == Heart ) || ( t == Ice_Block )<br /><br />-- A subset of tiles aren't movable; note that this set<br />-- overlaps blocking and that Tree is both walkable and fixed<br />fixed :: Tile -> Bool<br />fixed t = ( t == House ) || ( t == Mountain ) || ( t == Edge )</pre> <p>That all should be fairly non-controversial, I think. The predicate approach to classifying tiles in different contexts may actually make more sense in Haskell, given that I can then use these predicates as guards. The replacement for a simple struct, <b>Pos</b>, still feels awkward -- I haven't really dug into whether it could be improved with record syntax, or some other technique. For now it's there because it works.</p> <p>All the beginner tutorials say \"don't use arrays, don't use arrays, don't use arrays!\" At least not until I reach the stage where I need to optimize the implementation. So I'll try that. Let's try a list, and I'll extract \"slices\" from it, lists starting at a given <b>Pos</b> going in one of four different directions. Eventually I want the slice function to terminate the slices with <b>Edge</b> tiles that aren't actually stored in the list. So... I have to think about this some more, but here's a single case, sort of taken care of:</p> <pre>type Board = [[Tile]]<br /><br />slice :: Board -> Pos y x -> Dir -> [Tile]<br />slice board pos East = drop ( posX pos )<br />    $ head $ drop ( posY pos ) board<br />slice _ _ _ = error \"slice: not handled yet!\"</pre> <p>I don't have <b>slide</b> finished, but here's a version of collide that works, at least a little:</p> <pre>collide :: [Tile] -> [Tile]<br />collide (t:(Empty:ts)) | movable t =<br />    [Empty] ++ collide (t:ts)<br />collide (Bomb:(Mountain:ts)) = [Empty, Empty] ++ ts<br />collide (Heart:House:ts) = [Empty, House] ++ ts<br />collide (_) = error \"collide: unexpected case!\"</pre> <p>The nested pattern <b>(Bomb:(Mountain:ts))</b> was sort of a flash of inspiration -- but it appears that maybe both this version and the <b>(Heart:House:ts)</b> version work the same -- I think -- so perhaps it's kind of pointless. It seemed to go along with the \"destructure it the way you would structure it\" idea, although I would normally not build a list out of cons cells unless it was irregular in some way.</p> <p>Here's the penguin step function, returning True if the penguin can move onto the tile at the head of the list:</p> <pre>step :: [Tile] -> ( Bool, [Tile] )<br />step [] = error \"step: empty list!\"<br />step ts = if walkable (head ts) then ( True, ts )<br />                                else ( False, collide ts )</pre> <p>And there's a move, which \"absorbs\" the case where the penguin is turned to face a different direction. It's not really done; the idea is that it will give back the board, basically generating a new world. For now we kind of punt on the question of how to rebuild the board out of the existing board and the modified \"slice\" -- and so the I just return a list as the first element of the tuple. In the first case where the penguin hasn't moved, that doesn't actually make sense, but it satisfies GHC for now (wow, she's kind of a harsh mistress, but you've got to love those thigh-high black leather boots!)</p> <pre>move :: Board -> Pos y x -> Dir -> Dir -><br />    ( [Tile], Pos y x, Dir, Dir )<br />move board pos move_dir penguin_dir =<br />    if move_dir /= penguin_dir<br />    then ( head board, pos, move_dir, move_dir )<br />    else ( collide $ slice board (Pos 1 0) penguin_dir,<br />        pos, penguin_dir, penguin_dir )<br /></pre> <p>Boy, that's tuple-icious... not sure I like it, but it's a start. So:</p> <pre>*Main> walkable Tree<br />True<br />*Main> :t Pos<br />Pos :: Int -> Int -> Pos y x<br />*Main> let slice = [Heart, House]<br />*Main> collide slice<br />[Empty,House]<br />*Main> let slice = [Bomb, Empty, Mountain]<br />*Main> collide slice<br />[Empty,House]<br />*Main> let board = [[Empty, Tree, Empty, Edge],<br />    [Bomb, Empty, Mountain, Edge]]<br />*Main> move board (Pos 1 0) West East<br />([Empty,Tree,Empty,Edge],Pos 1 0,West,West)<br />*Main> move board (Pos 1 0) East East<br />([Empty,Empty,Empty,Edge],Pos 1 0,East,East)</pre> <p>More tomorrow if I can manage it! Oh, and it's here, such as it is: <a href=\"https://github.com/paulrpotts/arctic-slide-haskell\">https://github.com/paulrpotts/arctic-slide-haskell</a></p>" nil nil "ed0db1108bf58437927ffc92efe503a6") (105 (20939 63903 513547) "http://blog.plover.com/prog/git-vacillation.html" "Mark Jason Dominus: Rewriting published history in Git" "mjd@plover.com (Mark Dominus)" "Wed, 26 Jun 2013 18:19:00 +0000" "<a href=\"http://blog.plover.com/prog/git-habits.html\">My earlier article about my
habits using Git</a> attracted some comment, most of which was
favorable. But one recurring comment was puzzlement about my seeming
willingness to rewrite published history.  In practice, this was not
at all a problem, I think for three reasons:<p>
</p><ol>
<li>Rewriting published history is not nearly as confusing as
people seem to think it will be.
</li><li>I worked in a very small shop with very talented developers, so
the necessary communication was easy.
</li><li>Our repository setup and workflow were very well-designed and
unusually effective, and made a lot of things easier, including this one.
</li></ol>
This article is about item 3.  Here's what they do at my previous
workplace to avoid most of the annoyances of people rewriting
published history.<p>
If there are <i>N</i> developers, there are <i>N</i>+1 repositories.</p><p>
There is a master repository to which only a few very responsible
persons can push. It is understood that history in this repository
should almost never be rewritten, only in the most exceptional
circumstances.  We usually call this master repository
<tt>gitbox</tt>.  It has only a couple of branches, typically
<tt>master</tt> and <tt>deployed</tt>.
You had better not push incomplete work to <tt>master</tt>, because
if you do someone is likely to deploy it.
When you deploy a new version
from <tt>master</tt>, you advance <tt>deployed</tt> up to
<tt>master</tt> to match.</p><p>
In addition, each developer has their own semi-public repository,
named after them, which everyone can read, but which nobody but them
can write.  Mine is <tt>mjd</tt>, and that's what we call it when
discussing it, but my personal git configuration calls it
<tt>origin</tt>. When I <tt>git push origin master</tt> I am pushing
to this semi-public repo.</p><p>
It is understood that this semi-public repository is my sandbox and I
am free to rewrite whatever history I want in it.  People building
atop my branches in this repo, therefore, know that they should be
prepared for me to rewrite the history they see there, or to contact
me if they want me to desist for some reason.</p><p></p><p>
When I get the changes in my own semi-public repository the way I want
them, <i>then</i> I push the changes up to gitbox.  Nothing is
considered truly \"published\" until it is on the master repo.</p><p>
When a junior programmer is ready to deploy to the master repository,
they can't do it themselves, because they only have read access on the
master.  Instead, they publish to their own semi-private repository,
and then notify a senior programmer to review the changes.  The senior
programmer will then push those changes to the master repository and
deploy them.</p><p>
</p><p align=\"center\"><img src=\"http://pic.blog.plover.com/prog/git-vacillation/git%20repos.png\" /></p>
The semi-public <tt>mjd</tt> repo has lots of benefits.  I can rewrite
my branches 53 times a day (and I do!) but nobody will
care. Conversely, I don't need to know or care how much my co-workers
vacillate.<p>
If I do work from three or four different machines, I can use the
<tt>mjd</tt> repo to exchange commits between them.  At the end of the
day I will push my work-in-progress up to the <tt>mjd</tt> repo, and
then if I want to look at it later that evening, I can fetch the
work-in-progress to my laptop or another home computer.</p><p></p><p>
I can create and abandon many topic branches without cluttering up the
master repository's history.  If I want to send a change or a new test
file to a co-worker, I can push it to <tt>mjd</tt> and then point them
at the branch there.</p><p>
A related note: There is a lot of FUD around the rewriting of
published history.  For example, the \"gitinfo\" robot on the #git IRC
channel has a canned message:</p><p>
</p><blockquote>
Rewriting public history is a very bad idea.  Anyone else who
may have pulled the old history will have to <tt>git pull
--rebase</tt> and even worse things if they have tagged or
branched, so you must publish your humiliation so they know
what to do.  You will need to <tt>git push -f</tt> to force the push.
The server may not allow this.  <tt>See receive.denyNonFastForwards</tt>
(git-config)<p>
</p></blockquote>
I think this grossly exaggerates the problems.  Very bad!
Humiliation!  The server may deny you!  But dealing with a rebased
upstream branch is not very hard. It is at worst annoying: you have to
rebase your subsequent work onto the rewritten branch and move any
refs that pointed to that branch.  If you don't have any subsequent
work, you might still have to move refs, if you have any that point to
it, but you might not have any.<p>
[ Thanks to Rik Signes for helping me put this together. ]</p><p></p>" nil nil "d7d7d7c6adf8a452eea524f9742e0743") (104 (20939 63903 512266) "http://blog.plover.com/prog/git-habits.html" "Mark Jason Dominus: My Git Habits" "mjd@plover.com (Mark Dominus)" "Wed, 26 Jun 2013 18:19:00 +0000" "Miles Gould asked his Twitter followers whether they used <tt>git-add
-p</tt> or <tt>git-commit -a</tt> and how often.  My reply was too
long for Twitter, so here it is.<p>
First the short version: I use <tt>git-add -p</tt> frequently, and
<tt>git-commit -a</tt> almost never. The exception is when I'm working
on the repo that holds my blog, where I rarely commit changes to more
than one or two files at a time.  Then I'll usually just
<tt>git-commit -a -m ...</tt>.</p><p>
But I use <tt>git-add -p</tt> all the time. Typically what will happen
is that I will be developing some fairly complicated feature.  It will
necessitate a bunch of changes and reshuffling elsewhere in the
system.  I'll make commits on the topic branch as I go along without
worrying too much about whether the commits are neatly packaged.</p><p>
Often I'll be in the middle of something, with a dirty work tree, when
it's time to leave for the day.  Then I'll just commit everything with
the subject <tt>WIP</tt> (\"work-in-progress\").  First thing the next
morning I'll <tt>git-reset HEAD^</tt> and continue where I left
off.</p><p>
So the model is that the current head is usually a terrible mess,
accumulating changes as it moves forward in time.  When I'm done, I
will merge the topic into master and run the tests. </p><p>
If they pass, I am not finished.  The merge I just created is only a
draft merge.  The topic branch is often full of all sorts of garbage,
commits where I tried one approach, found it didn't work later on, and
then tried a different approach, places where I committed debugging
code, and so on. So it is now time to clean up the topic branch.  Only
the cleaned-up topic branch gets published.</p><p>
</p><h3>Cleaning up messy topic branches</h3>
The core of the cleanup procedure is to reset the head back to the
last place that look good, possibly all the way back to the merge-base
if that is not too long ago.  This brings all the topic changes into
the working directory. Then:<p>
</p><ol>
<li>Compose the commits: Repeat until the working tree is clean:<br />
<ol>
<li>Eyeball the output of <tt>git-diff</tt>
</li><li>Think of an idea for an intelligible commit
</li><li>Use <tt>git-add -p</tt> to stage the planned commit
</li><li>Use <tt>git diff --cached</tt> to make sure it makes sense
</li><li>Commit it
</li></ol>
</li><li>Order the commits: Use <tt>git-rebase --interactive</tt>
</li></ol>
Notice that this separates the work of composing the commits from the
work of ordering them.  This is more important than it might appear.
It would be extremely difficult to try to do these at the same time.
I can't know the sensible order for the commits until I know what the
commits are!  But it's very hard to know what the commits are without
actually making them.<p>
By separating these tasks, I can proceed something like this: I
eyeball the diff, and the first thing I see is something about the
penguin feature.  I can immediately say \"Great, I'll make up a commit
of all the stuff related to the penguin feature\", and proceed to the
<tt>git-add -p</tt> step without worrying that there might be other
stuff that should precede the penguin feature in the commit sequence.
I can focus on just getting the penguin commit right without needing
to think about any of the other changes.</p><p>
When the time comes to put the commits in order, I can do it well
because by then I have abstracted away all the details, and reduced
each group of changes to a single atomic unit with a one-line
description.</p><p>
For the most complicated cases, I will print out the diffs, read them
over, and mark them up in six colors of highlighter: code to throw
away gets marked in orange; code that I suspect is erroneous is pink.
I make many notes in pen to remind me how I want to divide up the
changes into commits.  When a commit occurs to me I'll jot a numbered
commit message, and then mark all the related parts of the diff with
that number.  Once I have the commits planned, I'll reset the topic
ref and then run through the procedure above, using <tt>git-add
-p</tt> repeatedly to construct the commits I planned on paper. Since
I know ahead of time what they are I might do them in the right order,
but more likely I'll just do them in the order I thought of them and
then reorder them at the end, as usual.</p><p>
For simple cases I'll just do a series of <tt>git-rebase
--interactive</tt> passes, pausing at any leftover <tt>WIP</tt>
commits to run the loop above, reordering the commits to squash
related commits together, and so on.</p><p>
The very simplest cases of all require no cleanup, of course.</p><p>
For example, here's my current topic branch, called <tt>c-domain</tt>,
with the oldest commits at the top:</p><p>
</p><pre>        055a2f7 correction to bulk consumer template
d9630bd DomainActivator half of Pobox Domain consumer
ebebb4a Add HasDomain role to provide ->domain reader for domain consumers
ade6ac6 stubbed domain test
e170e77 start templates for Pobox domain consumers
067ca81 stubbed Domain::ThumbTwiddler
685a3ee cost calculations for DomainActivator
ec8b1cc test fixes; trivial domain test passes now
845b1f2 rename InvoiceCharge::CreateDomain to ..::RegisterDomain
(e)     6083a97 add durations to Domain consumers and charges
c64fda0 tests for Domain::Activator consumer
41e4292 repeat activator tests for 1-year and 3-year durations
7d68065 tests for activator's replacement
(d)     87f3b09 move days_in_year to Moonpig::Util
3cd9f3b WIP
e5063d4 add test for sent invoice in domain.t
c8dbf41 WIP
9e6ffa4 add missing MakesReplacement stuff
fc13059 bring in Net::OpenSRS module
(c)     52c18fb OpenSRS interface
893f16f notes about why domain queries might fail
(b)     f64361f rename \"croak\" method to \"fail\" to avoid conflicts
4e500ec Domain::Activator initial_invoice_charge_pairs
(a)     3c5cdd4 WIP
</pre>
3c5cdd4 (a) was the end-of-day state for yesterday; I made it and
pushed it just before I dashed out the door to go home.  Such commits
rarely survive beyond the following morning, but if I didn't make them,
I wouldn't be able to continue work from home if the mood took me to
do that.<p>
f64361f (b) is a prime candidate for later squashing.  5c218fb (c)
introduced a module with a \"croak\" method.  This turned out to be a
stupid idea, because this conflicted with the <tt>croak</tt> function
from Perl's <tt>Carp</tt> module, which we use everywhere.  I needed
to rename it.  By then, the intervening commit already existed.  I
probably should have squashed these right away, but I didn't think of
it at the time.  No problem!  Git means never having to say \"If only
I'd realized sooner.\"</p><p>
Similarly, 6083a97 (e) added a days_in_year function that I later
decided at 87f3b09 (d) should be in a utility module  in a
different repository.  87f3b09 will eventually be squashed into
6083a97 so that days_in_year never appears in this code at all.</p><p>
I don't know what is in the WIP commits c8dbf41 or 3cd9f3b, for which
I didn't invent commit messages. I don't know why those are left in
the tree, but I can figure it out later.</p><p>
</p><h3>An example cleanup</h3>
Now I'm going to clean up this branch.  First I <tt>git-checkout -b
cleanup c-domain</tt> so that if something goes awry I can start over
completely fresh by doing <tt>git-reset --hard c-domain</tt>.  That's
probably superfluous in this case because <tt>origin/c-domain</tt> is
also pointing to the same place, and <tt>origin</tt> is my private
repo, but hey, branches are cheap.<p>
The first order of business is to get rid of those <tt>WIP</tt>
commits.  I'll <tt>git-reset HEAD^</tt> to bring 3c5cdd4 into the
working directory, then use <tt>git-status</tt> to see how many
changes there are:</p><p>
</p><pre>         M lib/Pobox/Moonpig/Consumer/Domain/Activator.pm
M lib/Pobox/Moonpig/Role/HasDomain.pm
M lib/Pobox/Moonpig/TemplateSet.pm
?? bin/register_domains
M t/consumer/domain.t
?? t/lib/MockOpenSRS.pm
</pre>
(This is the output from <tt>git-status --short</tt>, for which I have
an alias, <tt>git s</tt>.  I use this probably 99 times as often as
plain <tt>git-status</tt>.)<p>
Not too bad, probably no need for a printout.  The new
<tt>bin/register-domains</tt> program can go in right away by itself:</p><p>
</p><pre>        % <b>git add bin</b>
% <b>git commit -m 'new register_domains utility program'</b>
</pre>
Next I'll deal with that new mock object class in
<tt>t/lib/MockOpenSRS.pm</tt>.  I'll add that, then use <tt>git-add
-p</tt> to add the related changes from the other files:<p>
</p><pre>        % <b>git add t/lib</b>
% <b>git add -p</b>
...
% <b>git s</b>
MM lib/Pobox/Moonpig/Consumer/Domain/Activator.pm
M lib/Pobox/Moonpig/Role/HasDomain.pm
M lib/Pobox/Moonpig/TemplateSet.pm
A  t/lib/MockOpenSRS.pm
MM t/consumer/domain.t
% <b>git ix</b>
...
</pre>
The <tt>git ix</tt> command at the end there is an alias for <tt>git diff
--cached</tt>: it displays what's staged in the index.  The output
looks good, so I'll commit it:<p>
</p><pre>        % <b>git commit -m 'mock OpenSRS object; add tests'</b>
</pre>
Now I want to see if those tests actually pass.  Maybe I forgot
something!
<pre>        % <b>git stash</b>
% <b>make test</b>
...
OK
% <b>git stash pop</b>
</pre>
The <tt>git-stash</tt> command hides the unrelated changes from the
test suite so that I can see if the tests I just put into
<tt>t/consumer/domain.t</tt> work properly.  They do, so I bring back
the stashed changes and continue.  If they didn't, I'd probably amend
the last commit with <tt>git commit --amend</tt> and try again.<p>
Continuing:</p><p>
</p><pre>        % <b>git diff</b>
...
% <b>git add -p lib/Pobox/Moonpig/Role/HasDomain.pm</b>
...
% <b>git commit -m 'Domains do not have explicit start dates'</b>
% <b>git diff</b>
...
% <b>git add -p</b>
...
% <b>git commit --fixup :/mock</b>
</pre>
That last bit should have been part of the \"mock OpenSRS object\"
commit, but I forgot it. So I make a fixup commit, which I'll merge
into the main commit later on.  A fixup commit is one whose subject
begins with <tt>fixup!</tt>. Did you know that you can name a commit
by writing <tt>:/<i>text</i></tt>, and it names the most recent commit
whose message contains that text?<p>
It goes on like that for a while:</p><p>
</p><pre>        % <b>git diff</b>
...
% <b>git add -p ...</b>
...
% <b>git commit -m 'Activator consumer can generate special charges'</b>
% <b>git diff</b>
...
% <b>git checkout lib/Pobox/Moonpig/Role/HasDomain.pm</b>
</pre>
The only uncommitted change left in <tt>HasDomain.pm</tt> was a
superfluous line, so I just threw it away.<p>
</p><pre>        % <b>git diff</b>
...
% <b>git add -u</b>
% <b>git commit -m 'separate templates for domain-registering and domain-renewing consumers'</b>
</pre>
By this time all the remaining changes belong in the same commit, so I
use <tt>git-add -u</tt> to add them all at once.  The working tree is
now clean.  The history is as I showed above, except that in place of
the final <tt>WIP</tt> commit, I have:<p>
</p><pre>        a3c0b92 new register_domains utility program
53d704d mock OpenSRS object; add tests
a24acd8 Domains do not have explicit start dates
17a915d fixup! mock OpenSRS object; add tests
86e472b Activator consumer can generate special charges
5b2ad2b separate templates for domain-registering and domain-renewing consumers
</pre>
(Again the oldest commit is first.)  Now I'll get rid of that
<tt>fixup!</tt>:<p>
</p><pre>        % <b>git rebase -i --autosquash HEAD~6</b>
</pre>
Because of <tt>--autosquash</tt>, the <tt>git-rebase</tt> menu is
reordered so that the fixup commit is put just after
the commit it fixes up, and its default action is 'fixup' instead of
'pick'.  So I don't need to edit the rebase instructions at all.  But
I might as well take the opportunity to put the commits in the right
order.  The result is:<p>
</p><pre>        a3c0b92 new register_domains utility program
ea8dacd Domains do not have explicit start dates
297366a separate templates for domain-registering and domain-renewing consumers
4ef0e28 mock OpenSRS object; add tests
c3ab1eb Activator consumer can generate special charges
</pre>
I have two tools for dealing with cleaned-up
branches like this one.  One is <a href=\"https://github.com/mjdominus/git-util/blob/master/git-vee\"><tt>git-vee</tt></a>, which compares two branches. It's
just a wrapper around the command <tt>git log --decorate --cherry-mark
--oneline --graph --boundary <i>A</i>\"...\"<i>B</i></tt>.  <p>
Here's a
comparison the original <tt>c-domain</tt> branch and my new
<tt>cleanup</tt> version:</p><p>
</p><pre>        % <b>git vee c-domain</b>
* c3ab1eb (HEAD, cleanup) Activator consumer can generate special charges
* 4ef0e28 mock OpenSRS object; add tests
* 297366a separate templates for domain-registering and domain-renewing consumer
* ea8dacd Domains do not have explicit start dates
* a3c0b92 new register_domains utility program
| * 3c5cdd4 (origin/c-domain, c-domain) WIP
|/
o 4e500ec Domain::Activator initial_invoice_charge_pairs
</pre>
This clearly shows where the original and cleaned up branches diverge,
and what the differences are.  I also use <tt>git-vee</tt> to compare
pre- and post-rebase versions of branches (with <tt>git-vee
ORIG_HEAD</tt>) and local branches with their remote tracking branches
after fetching (with <tt>git-vee remote</tt> or just plain
<tt>git-vee</tt>).<p>
A cleaned-up branch should usually have the same final tree as the
tree at the end of the original branch.  I have another tool, <a href=\"https://github.com/mjdominus/git-util/blob/master/git-treehash\"><tt>git-treehash</tt></a>,
which compares trees.  By default it compares <tt>HEAD</tt> with
<tt>ORIG_HEAD</tt>, so after I use git-rebase to squash or to split
commits, I sometimes run \"git treehash\" to make sure that the tree
hasn't changed.  In this example, I do:</p><p>
</p><pre>        % <b>git treehash c-domain HEAD</b>
d360408d1afa90e0176aaa73bf8d3cae641a0850 HEAD
f0fd6ea0de7dbe60520e2a69fbec210260370d78 c-domain
</pre>
which tells me that they are <i>not</i> the same.  Most often this
happens because I threw away all the debugging code that I put in
earlier, but this time it was because of that line of superfluous code
I eliminated from <tt>HasDomain.pm</tt>.  When the treehashes differ, I'll use
<tt>git-diff</tt> to make sure that the difference is innocuous:<p>
</p><pre>        % <b>git diff c-domain</b>
diff --git a/lib/Pobox/Moonpig/Role/HasDomain.pm b/lib/Pobox/Moonpig/Role/HasDomain.pm
index 3d8bb8c..21cb752 100644
--- a/lib/Pobox/Moonpig/Role/HasDomain.pm
+++ b/lib/Pobox/Moonpig/Role/HasDomain.pm
@@ -5,7 +5,6 @@ use Carp qw(croak confess);
use ICG::Handy qw(is_domain);
use Moonpig::Types qw(Factory Time);
use Moose::Util::TypeConstraints qw(duck_type enum subtype);
-use MooseX::SetOnce;
with (
'Moonpig::Role::StubBuild',
</pre>
Okay then.<p>
The next task is probably to deal with the older WIP commits.  This
time I'll omit all the details.  But the enclosing procedure looks
like this:</p><p>
</p><pre>        % <b>git checkout -b wip-cleanup c8dbf41</b>
% <b>git reset HEAD^</b>
% ... (a lot of git-add -p as above) ...
...
% <b>git vee c8dbf41</b>
* 4c6ff45 (wip-cleanup) get rid of unused twiddler test
* b328de5 test full payment cycle
* 201a4f2 abstract out pay_invoice operation
* 55ae45e add upper limit (default 30d) to wait_until utility
| * c8dbf41 WIP
|/
o e5063d4 add test for sent invoice in domain.t
% <b>git treehash c8dbf41 HEAD</b>
7f52ba68923e2ede8fda407ffa9c06c5c48338ae
% <b>git checkout cleanup</b>
% <b>git rebase wip-cleanup</b>
</pre>
The output of <tt>git-treehash</tt> says that the tree at the end of
the <tt>wip-cleanup</tt> branch is identical to the one in the WIP
commit it is supposed to replace, so it's perfectly safe to rebase the
rest of the <tt>cleanup</tt> branch onto it, replacing the one WIP
commit with the four new commits in <tt>wip-cleanup</tt>.  Now the
cleaned up branch looks like this:<p>
</p><pre>        % <b>git vee c-domain</b>
* a425aa1 (HEAD, cleanup) Activator consumer can generate special charges
* 2bb0932 mock OpenSRS object; add tests
* a77bfcb separate templates for domain-registering and domain-renewing consumer
* 4c44db2 Domains do not have explicit start dates
* fab500f new register_domains utility program
= 38018b6 Domain::Activator initial_invoice_charge_pairs
= aebbae6 rename \"croak\" method to \"fail\" to avoid conflicts
= 45a224d notes about why domain queries might fail
= 80e4a90 OpenSRS interface
= 27f4562 bring in Net::OpenSRS module
= f5cb624 add missing MakesReplacement stuff
* 4c6ff45 (wip-cleanup) get rid of unused twiddler test
* b328de5 test full payment cycle
* 201a4f2 abstract out pay_invoice operation
* 55ae45e add upper limit (default 30d) to wait_until utility
| * 3c5cdd4 (origin/c-domain, c-domain) WIP
| = 4e500ec Domain::Activator initial_invoice_charge_pairs
| = f64361f rename \"croak\" method to \"fail\" to avoid conflicts
| = 893f16f notes about why domain queries might fail
| = 52c18fb OpenSRS interface
| = fc13059 bring in Net::OpenSRS module
| = 9e6ffa4 add missing MakesReplacement stuff
| * c8dbf41 WIP
|/
o e5063d4 add test for sent invoice in domain.t
</pre>
<tt>git-vee</tt> marks a commit with an equal sign instead of a star
if it's equivalent to a commit in the other branch.  The commits in
the middle marked with equals signs are the ones that weren't changed.
The upper WIP was replaced with five commits, and the lower one with
four.<p>
I've been planning for a long time to write a tool to help me with
breaking up WIP commits like this, and with branch cleanup in general:
It will write each changed hunk into a file, and then let me separate
the hunk files into several subdirectories, each of which represents
one commit, and then it will create the commits automatically from the
directory contents.  This is still only partly finished, but I think
when it's done it will eliminate the six-color diff printouts.</p><p>
[ Addendum 20120404: Further observation has revealed that I almost
never use <tt>git-commit -a</tt>, even when it would be quicker to do
so.  Instead, I almost always use <tt>git-add -u</tt> and then
<tt>git-commit</tt> the resulting index. This is just an observation,
and not a claim that my practice is either better or worse than using
<tt>git-commit -a</tt>. ]</p><p>
[ Addendum 20120825: There is now <a href=\"http://blog.plover.com/prog/git-vacillation.html\">a followup article about how
to manage rewriting of published history</a>. ]</p><p></p>" nil nil "addb28ecadd04572967491ae66539ded") (103 (20939 63903 509015) "http://blog.plover.com/prog/git-commit-hook.html" "Mark Jason Dominus: How I got four errors into a one-line program" "mjd@plover.com (Mark Dominus)" "Wed, 26 Jun 2013 18:19:00 +0000" "At my current job, each task is assigned a ticket number of the form
<tt>e12345</tt>. The git history is extremely convoluted, and it's
been observed that it's easier to find things if you include the
ticket number at the front of the commit message.  I got tired of
inserting it manually, and thought I would write a <tt>prepare-commit-message</tt> hook to insert
it automatically.<p>
A <tt>prepare-commit-message</tt> hook is a program that you stick in the file
<tt>.git/hooks/prepare-commit-hook</tt>. When you run <tt>git-commit</tt>, git first
writes the commit message to a file, then invokes the <tt>prepare-commit-message</tt> program on
file; the program can modify the contents of the message, or abort the
commit if it wants to. Then git runs the editor on the message, if it
was going to do that, and creates the commit with the edited
message.</p><p>
The hook I wrote was basically a one-liner, and the reason I am
posting this note is because I found three significant programming
errors in it in the first day of use. </p><p>
Here's the first cut:</p><p>
</p><pre>case $2 in
message)
perl -i -lpe \"s/^(e\\d+:\\s+)?/$(cs -): /\" $1
;;
esac
</pre>
This is a shell script, but the main purpose is to run the perl
one-liner. The shell script gets two arguments: <tt>$1</tt> is the
path to the file that contains the proposed commit message.
The <tt>$2</tt> argument is a tag which describes the commit's
context; it's <tt>merge</tt> if the commit is a merge commit, for
example; it's <tt>template</tt> if the commit message is supplied from
a template via <tt>-t</tt> on the command line or the
<tt>commit.template</tt> configuration option.  The default is the
empty string, and <tt>message</tt>, which I have here, means that the
message was supplied with the <tt>-m</tt> command-line option.<p>
The Perl script edits the commit message file, named in <tt>$1</tt>,
in-place, looking for something like <tt>e12345: </tt> at the
beginning of a line, and replacing it with the output of the
<tt>cs -</tt> command, which is a little program I wrote to print
the current ticket number.</p><p> (<tt>cs</tt> is run by the shell, and
its output is inserted into the Perl script before <tt>perl</tt> is
run, so that the program that Perl sees is something like
<tt>s/^(e\\d+:\\s+)?/e12345: /</tt>.)  Simple enough.</p><p>
There is already an error here, although it's a design error, not an
implementation error: the Perl one-liner is only invoked when
<tt>$2</tt> is <tt>message</tt>.  For some reason I decided that I
would want it only when I supplied <tt>git-commit</tt> with the
<tt>-m message</tt> option. This belief lasted exactly until the
first time I ran <tt>git-commit</tt> in default mode it popped up the editor to
edit the commit message, and I had to insert the ticket number
manually.</p><p>
So the first change was to let the hook run in the default case as well
as the <tt>message</tt> case:</p><p>
</p><pre>case $2 in
<span class=\"emph\">\"\"|</span>message)
perl -i -lpe \"s/^(e\\d+:\\s+)?/$(cs -): /\" $1
;;
esac
</pre>
This was wrong because it inserts the ticket number at the start of
each line; I wanted it only at the start of the first line. So that
was programming error number 1:<p>
</p><pre>case $2 in
\"\"|message)
perl -i -lpe \"<span class=\"emph\">$. == 1 && </span>s/^(e\\d+:\\s+)?/$(cs -): /\" $1
;;
esac
</pre>
So far, so good.<p>
Bug #2 appeared the first time I tried a rebase. The <tt>cs</tt>
command infers the ticket number from the name of the current branch.
If it fails, it issues a warning and emits the string <tt>eXXXXX</tt>
instead.  During a rebase, the head is detached and there is no
current branch.  So the four commits I rebased all had their
formerly-correct ticket numbers replaced with the string
<tt>eXXXXX</tt>.</p><p>
There are several ways to fix this. The best way would be to make sure
that the current ticket number was stashed somewhere that <tt>cs</tt>
could always get it.  Instead, I changed the Perl script to recognize
when the commit message already began with a ticket number, and to
leave it alone if so:</p><p>
</p><pre>case $2 in
\"\"|message)
perl -i -lpe \"\\$. == 1 &&<span class=\"emph\"> !/^e\\d+:\\s+/ && s/^/</span>$(cs -): /\" $1
;;
esac
</pre>
It probably would have been a good idea to leave an escape hatch, and
have <tt>cs</tt> emit the value of <tt>$ENV{TICKET_NUMBER}</tt> if
that is set, to allow invocations like <tt>TICKER_NUMBER=e71828 git
commit -m …</tt>, but I didn't do it, yet.<p>
The third bug appeared when I did <tt>git commit --fixup</tt> for the
first time.  With <tt>--fixup</tt> you tell it which commit you are
trying to fix up, and it writes the commit message in a special form
that tells a subsequent <tt>git-rebase --interactive</tt> that this
new commit should be handled specially. (It should be applied
immediately after that other one, and should be marked as a \"fixup\",
which means that it is squashed into the other one and that its log
message is discarded in favor of the other one.)  If you are fixing up
a commit whose message was <tt>Frobulate the veeblefetzers</tt>, the
fixup commit's message is automatically generated as
<tt>fixup! Frobulate the veeblefetzers</tt>. Or it would have
been, if you were not using my <tt>prepare-commit-message</tt> hook, which would rewrite it to
<tt>e12345: fixup! Frobulate the veeblefetzers</tt>. This is not
in the right form, so it's not recognized by <tt>git-rebase
--interactive</tt> for special handling.</p><p>
So the hook became:</p><p>
</p><pre>case $2 in
\"\"|message)
perl -i -lpe \"\\$. == 1 && <span class=\"emph\">!/^(squash|fixup)! / &&</span> !/^e\\d+:\\s+/ && s/^/$(cs -): /\" $1
;;
esac
</pre>
(The exception for <tt>squash</tt> is similar to the one for
<tt>fixup</tt>. I never use <tt>squash</tt>, but it seemed foolish not
to put it in while I was thinking of it.)<p>
This is starting to look a little gross, but in a program this small I
can tolerate a little grossness.</p><p>
I thought it was remarkable that such a small program broke in so many
different ways.  Much of that is because it must interact with git,
which is very large and complicated, and partly it is that it must
interact with <tt>git</tt>, which is in many places not very well
designed.
The first bug, where the ticket number was appended to each line
instead of just the first, is not git's fault.  It was fallout from my
initial bad design decision to apply the script only to messages
supplied with <tt>-m</tt>, which are typically one-liners, so that's
what I was thinking of when I wrote the Perl script.</p><p>
But the other two errors would have been avoided had the interface to
the hook been more uniform. There seems to be no reason that rebasing
(or cherry-picking) and <tt>git-commit --fixup</tt> contexts couldn't
have been communicated to the hook via the same <tt>$2</tt> argument
that communicates other contexts.  Had this been done in a more
uniform way, my program would have worked more correctly.  But it
wasn't done, and it's probably too late to change it now, since such a
change risks breaking many existing <tt>prepare-commit-message</tt> hooks. (\"The enemy of software
is software.)  A well-written hook will of course have a catchall:</p><p>
</p><pre>case $2 in
\"\"|message)
perl -i -lpe \"\\$. == 1 && !/^(squash|fixup)! / && !/^e\\d+:\\s+/ && s/^/$(cs -): /\" $1
;;
<span class=\"emph\">
merge|template|squash|commit)
# do nothing
;;
*)      # wat
echo \"prepare-message-hook: unknown context '$2'\" 1>&2
exit 1;
;;
</span>
esac
</pre>
But mine doesn't and I bet a lot of others don't either.<p></p>" nil nil "0d8910440515212f1d4a64fc269bc053") (102 (20939 63903 477688) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_5883\"></span>, where <span id=\"tex_9577\"></span> is the number of “folds” and <span id=\"tex_2557\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_6540\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "67e0bbe944720f15cd562c1470f7cb5b") (101 (20938 62181 87869) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_9659\"></span>, where <span id=\"tex_5628\"></span> is the number of “folds” and <span id=\"tex_5419\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_4446\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "4c3a21da92e996dd30a3e583f47388d9") (100 (20938 41147 171728) "http://praisecurseandrecurse.blogspot.com/2013/06/the-polar-game-in-haskell-day-1.html" "Paul Potts: The Polar Game in Haskell, Day 1" "noreply@blogger.com (Paul Potts)" "Wed, 26 Jun 2013 00:24:00 +0000" "<p>So if you've been following recent posts, you know I've been messing with the logic for a simple sliding-tile game. In my last post I took some designs refined via a side trip into Dylan and brought them back into Objective-C, making them a little more idiomatic by pruning my tile classes that didn't hold their weight, and compensating for Objective-C's very limited method dispatch options.</p> <p>But in addition to learning Objective-C, and Apple's APIs for writing an app, I'm also trying to further my knowledge of Haskell, which is somewhere just beyond \"utter newbie.\" So I'm going to try to implement the game logic in Haskell, too. Since the game is decidedly stateful, there is a certain impedance mismatch here, at least with respect to the early chapters in most of the tutorials and guides. But I'm told that Haskell also makes a great imperative programming language, so let's give it a shot. And along the way I can try to mold my understanding of stateful versus imperative a little more.</p> <p>For day one, which was a shorter-than-usual day, I did not get into the state monad or how to model mutation of a 2-D array yet. I wanted to consider whether I could model the tile classes the way I could in Dylan, and do something useful in them. It occurred to me that each move of the penguin, and all the subsequent actions including possibly pushing an object, possibly a collision, possibly an object sliding frictionlessly as long as it can and then another collision, actually takes place in a 1-dimensional vector, not a 2-dimensional array. So it might be interesting to handle a penguin move by extracting a vector (in the form of a list) from the array, and replacing it with an updated list.  </p><p>I haven't worked that all out yet but here is the bare beginning of my experimentation. There's a way to represent tiles:</p> <pre>data Tile = Empty | Tree | Mountain | House | Ice_Block | <br />    Bomb | Heart | Edge<br />    deriving (Show)</pre> <p>Part of the confusion of learning Haskell is that, semantically, this isn't quite the equivalent of a set of enumerations, or of a set of class declarations. From what I can tell, this is more like a list of singleton factories -- constructors, where I've also derived them from Show, sort of the equivalent of mixing in a base class. But this is all an approximation, and Haskell is <i>quite</i> different than the other languages I'm most familiar with.</p> <p>My next thought was that I wanted to be able to declare \"base classes\" so that, for example, I could have a Walkable class that comprised Empty and Tree. In Dylan I would do this by using classes, but there is different way: declaring a <b>type-union</b> of singletons. I think that this Haskell solution is more like the <b>type-union</b>. I looked in vain for an explicit type union. Instead I found <b>class</b> (which, in Haskell, does not correspond to a class in the sense that I'm used to, of a template for a run-time object that consists of data members and methods to operate on it, but a <i>typeclass</i>, something I clearly need to study more):  </p><pre>class Walkable a where<br />    walkable :: a -> Bool</pre> <p>And then this: which boils down to, I think, a function to determine whether a Tile is an instance of a Walkable typeclass:</p> <pre>instance Walkable Tile where<br />    walkable Empty = True<br />    walkable Tree = True<br />    walkable _ = False</pre> <p>Now I can write something like this (just a vague thought-in-progress at the moment):</p> <pre>slide :: [Tile] -> [Tile]<br />slide [] = error \"slide empty list!\"<br />slide (t) = error \"single item list!\"<br />slide (Empty:ts) = ts ++ slide ts<br /><br />collide :: [Tile] -> [Tile]<br />collide [] = error \"traverse empty list!\"          <br />collide [Edge] = [Edge]<br />collide (Empty:ts) = ts<br />collide (Bomb:Mountain:ts) = [Empty, Empty] ++ ts          <br />collide (Heart:House:ts) = [Empty, House] ++ ts<br /><br />step :: [Tile] -> Bool<br />step [] = error \"step: empty list!\"<br />step (t:_) = if walkable t then True else False</pre> <p>Then after sticking in a dummy main I can load this into GHCI and interact with it a little:</p> <pre>*Main> :t Tree<br />Tree :: Tile<br />*Main> step [Mountain, Empty, Empty, Tree, Edge]<br />False<br />*Main> step [Tree, Empty, Empty, Tree, Edge]<br />True<br />*Main> collide [Heart, Mountain]<br />*** Exception: arctic-slide.hs:(22,1)-(26,47): Non-exhaustive patterns in function collide<br />(Um, yeah, OK, I have work to do there)<br />*Main> collide [Heart, House]<br />[Empty,House]<br />*Main> slide [Empty, Empty, Empty, Empty, Mountain]<br />*** Exception: single item list!</pre> <p>Anyway, that's not exactly what I want to do -- really, I want the functions to actually return a new list of the same length, so I'll have to build it up as I recurse down the list -- maybe in the List monad? But it's a start on the whole basic concept of matching on the \"types\" of my tiles in a \"vector,\" such as it is. That whole bit with <b>walkable</b> -- which I admit I don't quite understand yet -- seems like far too much conditional logic when I really just want to pattern-match on a type union of Tile. In other words, I want to write something like this (not valid Haskell):</p> <pre>union Walkable = Empty | Tree<br /><br />step (Walkable:_) = True</pre> <p>That's a small example, but I have several other type union classes I need to use to categorize the tiles, so I have an incentive to make that as clear and simple as possible. It seems like I'm still fighting with Haskell's idioms here. Clearly, as they say, more research is needed...</p>" nil nil "754376c0dbbd86fc5dfa8126a20aa78b") (99 (20938 41147 170673) "http://edwinb.wordpress.com/2013/06/25/sequential-decision-problems-dependently-typed-solutions/" "Edwin Brady: Sequential decision problems, dependently typed solutions" nil "Tue, 25 Jun 2013 19:44:01 +0000" "<p>We’ve just shipped the camera ready version of the following paper to <a href=\"http://www.cicm-conference.org/2013/cicm.php?event=plmms\">PLMMS 2013</a>:</p>
<p>
<a href=\"http://eb.host.cs.st-andrews.ac.uk/writings/plmms13.pdf\">Sequential decision problems, dependently typed solutions</a><br />
<a href=\"http://www.pik-potsdam.de/members/botta\">Nicola Botta</a>, <a href=\"http://www.pik-potsdam.de/members/ionescu\">Cezar Ionescu</a>, <a href=\"http://edwinb.wordpress.com/2013/06/25/sequential-decision-problems-dependently-typed-solutions/edwinb.wordpress.com\">Edwin Brady</a>
</p>
<blockquote><p>
We propose a dependently typed formalization for a simple class of sequential decision problems. For this class of problems, we implement a generic version of Bellman’s backwards induction algorithm and a machine checkable proof that the proposed implementation is correct. The formalization is generic. It is presented in Idris, but it can be easily translated to other dependently-typed programming languages. We conclude with an informal discussion of the problems we have faced in extending the formalization to generic monadic sequential decision problems.
</p></blockquote>
<p>You can find the <a href=\"http://eb.host.cs.st-andrews.ac.uk/writings/plmms13.pdf\">full paper here</a>.</p>
<br />  <a href=\"http://feeds.wordpress.com/1.0/gocomments/edwinb.wordpress.com/237/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/edwinb.wordpress.com/237/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=edwinb.wordpress.com&blog=666773&post=237&subd=edwinb&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "9a80ef38fd7c4d60f44ca6b6b0de7d0b") (98 (20938 41147 170050) "http://wadler.blogspot.com/2013/06/come-for-performance-stay-for.html" "Philip Wadler: Come for the performance, stay for the correctness" "noreply@blogger.com (Philip Wadler)" "Tue, 25 Jun 2013 18:34:34 +0000" "<div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://1.bp.blogspot.com/-68rTy8Dc4fM/UcnhdnNkd9I/AAAAAAAACcc/Yj25dAU8tnc/s1600/haskell.jpeg\"><img src=\"http://1.bp.blogspot.com/-68rTy8Dc4fM/UcnhdnNkd9I/AAAAAAAACcc/Yj25dAU8tnc/s400/haskell.jpeg\" height=\"299\" border=\"0\" width=\"400\" /></a></div>An <a href=\"http://www.hpcwire.com/hpcwire/2013-06-24/lustre_founder_spots_haskell_on_hpc_horizon.html?featured=top\">article in HPC Wire</a> lists industrial uses of Haskell, several of which I hadn't heard before. The article profiles Peter Braam, founder of Parallel Scientific. Spotted by Hans Wolfgang Loidl.<br /><br /><blockquote class=\"tr_bq\">Arguably, Google and Facebook have brought more attention to Haskell  in recent years, but there are a number of other notable uses that  highlight Braam’s confidence in the functional language. For instance,  Chicago-based Allston Trading, a high frequency trading company, uses  Haskell in their trading infrastructure. AT&T is using it in their  Network Security group to automate internet abuse complaint processing.  Bank of American is using it in their backend data transformation and  loading system and Credit Suisse’s Global Modeling and Analytics Group  has been using it since 2006 to improve modeler productivity and open  access to those models across the organization.<br /><br />Biotech giant Amgen also uses Haskell for math-heavy models and to  “break developers out of their development rut by giving them a new way  to think about software. According to the company’s David Balaban, “Our  experience is that using functional programming reduces the critical  conceptual distance between thought/algorithms design and code.” But the  real value says Balaban is the level of correctness they’ve been able  to achieve.<br /><br />As Amgen’s Balaban says “we  have been able to develop code quickly and verify--to an applied  mathematician’s satisfaction--the correctness of Haskell code  straightforwardly; we have yet to achieve this with more traditional  mainstream languages.” </blockquote>" nil nil "1f57036b08a8a0bf26b1dd0f3fb340d4") (97 (20938 41147 14671) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_1502\"></span>, where <span id=\"tex_5449\"></span> is the number of “folds” and <span id=\"tex_5552\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_3773\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "0208f6a49f71e95420f6375812b67f67") (96 (20937 54164 18427) "http://parenz.wordpress.com/2013/06/12/ghcjs-build/" "Daniil Frumin: Building GHCJS" nil "Tue, 25 Jun 2013 15:45:34 +0000" "<div id=\"outline-container-sec-1\" class=\"outline-2\">
<h2 id=\"sec-1\"><span class=\"section-number-2\">1</span> Intro</h2>
<div id=\"text-1\" class=\"outline-text-2\">
<p>
In this post I would like to talk about my experience with<br />
bootstrapping <a href=\"http://weblog.luite.com/wordpress/?p=14\">GHCJS</a> using the provided facilities <a href=\"https://github.com/ghcjs/ghcjs-build\">ghcjs-build</a>. I<br />
never used tools like Vagrant or Puppet before so all of this was<br />
kinda new to me.
</p>
</div>
</div>
<div id=\"outline-container-sec-2\" class=\"outline-2\">
<h2 id=\"sec-2\"><span class=\"section-number-2\">2</span> Initial installation</h2>
<div id=\"text-2\" class=\"outline-text-2\">
<p>
GHCJS can’t actually work with vanilla GHC 7.* as it requires to<br />
apply some patches (in order to get JS ffi to work, it adds<br />
<code>JavaScriptFFI</code> language extension among other modifications).
</p>
<p>
<a href=\"https://github.com/ghcjs/ghcjs-build\">ghcjs-build</a> uses <a href=\"http://vagrantup.com\">Vagrant</a> (a tool for automatically building and<br />
running work environments) to mange the work environment, so prior to<br />
running GHCJS you need to install vagrant and <a href=\"http://virtualbox.org\">VirtualBox</a>. It’s actually<br />
a sensible way to tackle a project like that: everyone has similar<br />
work environments, you don’t have to mess with your local GHC<br />
installation. It also make use of <a href=\"http://puppetlabs.com\">Puppet</a> deployment system in<br />
<code>puppetlabs-vcsrepo</code> module for cloning Git repositories.
</p>
<p>
Currently, there are two ways to start up GHCJS using <code>ghcjs-build</code>
</p>
</div>
<div id=\"outline-container-sec-2-1\" class=\"outline-3\">
<h3 id=\"sec-2-1\"><span class=\"section-number-3\">2.1</span> Using the prebuilt version</h3>
<div id=\"text-2-1\" class=\"outline-text-3\">
<div class=\"org-src-container\">
<pre class=\"src src-sh\">git clone https://github.com/ghcjs/ghcjs-build.git
<span style=\"color: #D0D0FF;\">cd</span> ghcjs-build
git checkout prebuilt
vagrant up
</pre>
</div>
<p>
Using this configuration the following procedures are performed:
</p>
<ol class=\"org-ol\">
<li>Vagrant sets up a 32-bit Ubuntu Precise system (/Note: if this is<br />
your first time running Vagrant it downloads the 280Mb<br />
precise32.box file from the Vagrant site/)
</li>
<li>Vagrants does some provisioning using Puppet (downloads and<br />
installs necessary packages)
</li>
<li>A 1.4GB archive with ghcjs and other prebuilt tools are downloaded<br />
and extracted.
</li>
</ol>
</div>
</div>
<div id=\"outline-container-sec-2-2\" class=\"outline-3\">
<h3 id=\"sec-2-2\"><span class=\"section-number-3\">2.2</span> Compiling from source</h3>
<div id=\"text-2-2\" class=\"outline-text-3\">
<div class=\"org-src-container\">
<pre class=\"src src-sh\">git clone https://github.com/ghcjs/ghcjs-build.git
<span style=\"color: #D0D0FF;\">cd</span> ghcjs-build
vagrant up
</pre>
</div>
<p>
Apart from setting up the box this will
</p>
<ol class=\"org-ol\">
<li>Get the GHC sources from Git HEAD and applies the GHCJS <a href=\"http://ghcjs.github.io/patches/ghc-ghcjs.patch\">patch</a>.
</li>
<li>Get all the necessary packages for ghcjs
</li>
<li>Get the latest Cabal from Git HEAD, applies the GHCJS <a href=\"http://ghcjs.github.io/patches/cabal-ghcjs.patch\">patch</a> and<br />
build it.
</li>
<li>Compile the necessary libraries using ghcjs
</li>
<li>Compile <code>ghcjs-examples</code> and its dependencies (it appears that it<br />
can take a lot of time to compile gtk2hs and gtk2hs’s tools)
</li>
</ol>
<p>
Please note, that depending on your computer, you might want to go for<br />
a long walk, enjoy a small book or get a night sleep (assuming you are<br />
not scared by the sound of computer fans).
</p>
<p>
Apart from being slow, the process of compiling everything from<br />
source is error prone. To give you a taste, last night I was not able<br />
to reproduce a working environment myself, because of some recent<br />
changes in GHC HEAD. The prebuilt version on the other hand is<br />
guaranteed to install correctly.
</p>
<p>
Hopefully, the GHCJS patches will be merged upstream before the GHC<br />
7.8 is out. That way you won’t need to partake in building GHC from<br />
the source in order to use GHCJS.
</p>
</div>
</div>
<div id=\"outline-container-sec-2-3\" class=\"outline-3\">
<h3 id=\"sec-2-3\"><span class=\"section-number-3\">2.3</span> Communicating with the VM</h3>
<div id=\"text-2-3\" class=\"outline-text-3\">
<p>
After you’ve finished with the initial setup you should be able just<br />
to
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">vagrant ssh
</pre>
</div>
<p>
in your new vm and start messing around.
</p>
<p>
<code>ghcjs</code> command is available to you and Vagrant kindly forwards the<br />
3000 port on the VM to the local 3030 port, allowing you to run web<br />
servers like <code>warp</code> on the VM and accessing them locally.
</p>
<p>
You can access your local project directory under <code>/vagrant</code> in VM:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">$ ls /vagrant
keys  manifests  modules  outputs  README.rst  Vagrantfile
</pre>
</div>
<p>
However, copying file back-and-forth is not a perfect solution. I<br />
recommend setting up a sshfs filesystem (<i>Note: if you are on OSX,<br />
don’t forget to install fuse4x kernel extension</i>):
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">$ vagrant ssh-config
Host default
HostName 127.0.0.1
User vagrant
Port 2222
UserKnownHostsFile /dev/null
StrictHostKeyChecking no
PasswordAuthentication no
IdentityFile <span style=\"color: #b5bd68;\">\"/Users/dan/.vagrant.d/insecure_private_key\"</span>
IdentitiesOnly yes
LogLevel FATAL
$ sshfs vagrant@localhost:/home/vagrant ../vm -p2222 -oreconnect,defer_permissions,negative_vncache,<span style=\"color: #cc6666;\">volname</span>=ghcjs,<span style=\"color: #cc6666;\">IdentityFile</span>=~/.vagrant.d/insecure_private_key
$ ls ../vm
</pre>
</div>
<p>
When you are done you can just <code>umount ../vm</code>
</p>
</div>
</div>
</div>
<div id=\"outline-container-sec-3\" class=\"outline-2\">
<h2 id=\"sec-3\"><span class=\"section-number-2\">3</span> Compiling other packages</h2>
<div id=\"text-3\" class=\"outline-text-2\">
<p>
Since the <code>diagrams</code> package on Hackage depends on the older version<br />
of base we are going to use the latest version from Git:
</p>
<pre class=\"example\">mkdir dia; cd dia
git clone git://github.com/diagrams/diagrams-core.git
cd diagrams-core && cabal install && cd ..
cabal unpack active
cd active-0.1*
cat >version.patch <<EOF
--- active.cabal        2013-06-12 12:58:40.082914214 +0000
+++ active.cabal.new    2013-06-12 12:58:31.029465815 +0000
@@ -19,7 +19,7 @@
library
exposed-modules:     Data.Active
-  build-depends:       base >= 4.0 && < 4.7,
+  build-depends:       base >= 4.0 && < 4.8,
array >= 0.3 && < 0.5,
semigroups >= 0.1 && < 0.10,
semigroupoids >= 1.2 && < 3.1,
@@ -31,7 +31,7 @@
test-suite active-tests
type:              exitcode-stdio-1.0
main-is:           active-tests.hs
-    build-depends:     base >= 4.0 && < 4.7,
+    build-depends:     base >= 4.0 && < 4.8,
array >= 0.3 && < 0.5,
semigroups >= 0.1 && < 0.10,
semigroupoids >= 1.2 && < 3.1,
EOF
patch active.cabal < version.patch
cabal install
cd ..
git clone git://github.com/diagrams/diagrams-lib.git
cd diagrams-lib && cabal install && cd ..
git clone git://github.com/diagrams/diagrams-svg.git
cd diagrams-svg && cabal install && cd ..
</pre>
<p>
Other packages I had to install already had their Hackage versions<br />
updated.
</p>
<p>
Now you can try to build a test diagram to see that everything works
</p>
<div class=\"org-src-container\">
<pre class=\"src src-haskell\"><span style=\"color: #b294bb;\">module</span> <span style=\"color: #f0c674;\">Main</span> <span style=\"color: #b294bb;\">where</span>
<span style=\"color: #b294bb;\">import</span> <span style=\"color: #f0c674;\">Diagrams.Prelude</span>
<span style=\"color: #b294bb;\">import</span> <span style=\"color: #f0c674;\">Diagrams.Backend.SVG.CmdLine</span>
<span style=\"color: #81a2be;\">d</span> <span style=\"color: #cc6666;\">::</span> <span style=\"color: #f0c674;\">Diagram</span> <span style=\"color: #f0c674;\">SVG</span> <span style=\"color: #f0c674;\">R2</span>
<span style=\"color: #81a2be;\">d</span> <span style=\"color: #cc6666;\">=</span> square 20 <span style=\"color: #cc6666;\">#</span> lw 0<span style=\"color: #cc6666;\">.</span>5
<span style=\"color: #cc6666;\">#</span> fc black
<span style=\"color: #cc6666;\">#</span> lc green
<span style=\"color: #cc6666;\">#</span> dashing [0<span style=\"color: #cc6666;\">.</span>2,0<span style=\"color: #cc6666;\">.</span>2] 0
<span style=\"color: #81a2be;\">main</span> <span style=\"color: #cc6666;\">=</span> defaultMain (pad 1<span style=\"color: #cc6666;\">.</span>1 d)
</pre>
</div>
<p>
then you can compile and run it
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">ghc --make Test.hs
./Test -w 400 -o /vagrant/test.svg
</pre>
</div>
<p><a href=\"http://parenz.files.wordpress.com/2013/06/screen-shot-2013-06-12-at-5-19-03-pm.png\"><img src=\"http://parenz.files.wordpress.com/2013/06/screen-shot-2013-06-12-at-5-19-03-pm.png?w=300&h=289\" alt=\"Screen Shot 2013-06-12 at 5.19.03 PM\" height=\"289\" class=\"alignnone size-medium wp-image-47\" width=\"300\" /></a></p>
<p>
And that’s it!
</p>
</div>
</div>
<div id=\"outline-container-sec-4\" class=\"outline-2\">
<h2 id=\"sec-4\"><span class=\"section-number-2\">4</span> Outro</h2>
<div id=\"text-4\" class=\"outline-text-2\">
<p>
I would also like to note that we are currently polishing the GHCJS<br />
build process. Luite, especially is working on making ghcjs work (and<br />
run tests) with <a href=\"https://travis-ci.org/\">Travis CI</a> (it take quite a bit of time to build ghcjs<br />
and sometimes travis is timeouting) and I am working on tidying up<br />
the build config.
</p>
<p>
Stay tuned for more updates.
</p>
</div>
</div>
<br /> Tagged: <a href=\"http://parenz.wordpress.com/tag/diagrams/\">diagrams</a>, <a href=\"http://parenz.wordpress.com/tag/ghcjs/\">ghcjs</a>, <a href=\"http://parenz.wordpress.com/tag/haskell-2/\">haskell</a>, <a href=\"http://parenz.wordpress.com/tag/soc/\">soc</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/parenz.wordpress.com/49/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/parenz.wordpress.com/49/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=parenz.wordpress.com&blog=26722965&post=49&subd=parenz&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "e53e69d35ed56c72c0d2b1e9ec722a17") (95 (20937 47692 637966) "http://parenz.wordpress.com/2013/06/12/ghcjs-build/" "Daniil Frumin: Building GHCJS" nil "Tue, 25 Jun 2013 15:08:38 +0000" "<div id=\"outline-container-sec-1\" class=\"outline-2\">
<h2 id=\"sec-1\"><span class=\"section-number-2\">1</span> Intro</h2>
<div id=\"text-1\" class=\"outline-text-2\">
<p>
In this post I would like to talk about my experience with<br />
bootstrapping <a href=\"http://weblog.luite.com/wordpress/?p=14\">GHCJS</a> using the provided facilities <a href=\"https://github.com/ghcjs/ghcjs-build\">ghcjs-build</a>. I<br />
never used tools like Vagrant or Puppet before so all of this was<br />
kinda new to me.
</p>
</div>
</div>
<div id=\"outline-container-sec-2\" class=\"outline-2\">
<h2 id=\"sec-2\"><span class=\"section-number-2\">2</span> Initial installation</h2>
<div id=\"text-2\" class=\"outline-text-2\">
<p>
GHCJS can’t actually work with vanilla GHC 7.* as it requires to<br />
apply some patches (in order to get JS ffi to work, it adds<br />
<code>JavaScriptFFI</code> language extension among other modifications).
</p>
<p>
<a href=\"https://github.com/ghcjs/ghcjs-build\">ghcjs-build</a> uses <a href=\"http://vagrantup.com\">Vagrant</a> (a tool for automatically building and<br />
running work environments) to mange the work environment, so prior to<br />
running GHCJS you need to install vagrant and <a href=\"http://virtualbox.org\">VirtualBox</a>. It’s actually<br />
a sensible way to tackle a project like that: everyone has similar<br />
work environments, you don’t have to mess with your local GHC<br />
installation. It also make use of <a href=\"http://puppetlabs.com\">Puppet</a> deployment system in<br />
<code>puppetlabs-vcsrepo</code> module for cloning Git repositories.
</p>
<p>
Currently, there are two ways to start up GHCJS using <code>ghcjs-build</code>
</p>
</div>
<div id=\"outline-container-sec-2-1\" class=\"outline-3\">
<h3 id=\"sec-2-1\"><span class=\"section-number-3\">2.1</span> Using the prebuilt version</h3>
<div id=\"text-2-1\" class=\"outline-text-3\">
<div class=\"org-src-container\">
<pre class=\"src src-sh\">git clone https://github.com/ghcjs/ghcjs-build.git
<span style=\"color: #D0D0FF;\">cd</span> ghcjs-build
git checkout prebuilt
vagrant up
</pre>
</div>
<p>
Using this configuration the following procedures are performed:
</p>
<ol class=\"org-ol\">
<li>Vagrant sets up a 32-bit Ubuntu Precise system (/Note: if this is<br />
your first time running Vagrant it downloads the 280Mb<br />
precise32.box file from the Vagrant site/)
</li>
<li>Vagrants does some provisioning using Puppet (downloads and<br />
installs necessary packages)
</li>
<li>A 1.4GB archive with ghcjs and other prebuilt tools are downloaded<br />
and extracted.
</li>
</ol>
</div>
</div>
<div id=\"outline-container-sec-2-2\" class=\"outline-3\">
<h3 id=\"sec-2-2\"><span class=\"section-number-3\">2.2</span> Compiling from source</h3>
<div id=\"text-2-2\" class=\"outline-text-3\">
<div class=\"org-src-container\">
<pre class=\"src src-sh\">git clone https://github.com/ghcjs/ghcjs-build.git
<span style=\"color: #D0D0FF;\">cd</span> ghcjs-build
vagrant up
</pre>
</div>
<p>
Apart from setting up the box this will
</p>
<ol class=\"org-ol\">
<li>Get the GHC sources from Git HEAD and applies the GHCJS <a href=\"http://ghcjs.github.io/patches/ghc-ghcjs.patch\">patch</a>.
</li>
<li>Get all the necessary packages for ghcjs
</li>
<li>Get the latest Cabal from Git HEAD, applies the GHCJS <a href=\"http://ghcjs.github.io/patches/cabal-ghcjs.patch\">patch</a> and<br />
build it.
</li>
<li>Compile the necessary libraries using ghcjs
</li>
<li>Compile <code>ghcjs-examples</code> and its dependencies (it appears that it<br />
can take a lot of time to compile gtk2hs and gtk2hs’s tools)
</li>
</ol>
<p>
Please note, that depending on your computer, you might want to go for<br />
a long walk, enjoy a small book or get a night sleep (assuming you are<br />
not scared by the sound of computer fans).
</p>
<p>
Apart from being slow, the process of compiling everything from<br />
source is error prone. To give you a taste, last night I was not able<br />
to reproduce a working environment myself, because of some recent<br />
changes in GHC HEAD. The prebuilt version on the other hand is<br />
guaranteed to install correctly.
</p>
<p>
Hopefully, the GHCJS patches will be merged upstream before the GHC<br />
7.8 is out. That way you won’t need to partake in building GHC from<br />
the source in order to use GHCJS.
</p>
</div>
</div>
<div id=\"outline-container-sec-2-3\" class=\"outline-3\">
<h3 id=\"sec-2-3\"><span class=\"section-number-3\">2.3</span> Communicating with the VM</h3>
<div id=\"text-2-3\" class=\"outline-text-3\">
<p>
After you’ve finished with the initial setup you should be able just<br />
to
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">vagrant ssh
</pre>
</div>
<p>
in your new vm and start messing around.
</p>
<p>
<code>ghcjs</code> command is available to you and Vagrant kindly forwards the<br />
3000 port on the VM to the local 3030 port, allowing you to run web<br />
servers like <code>warp</code> on the VM and accessing them locally.
</p>
<p>
You can access your local project directory under <code>/vagrant</code> in VM:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">$ ls /vagrant
keys  manifests  modules  outputs  README.rst  Vagrantfile
</pre>
</div>
<p>
However, copying file back-and-forth is not a perfect solution. I<br />
recommend setting up a sshfs filesystem (<i>Note: if you are on OSX,<br />
don’t forget to install fuse4x kernel extension</i>):
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">$ vagrant ssh-config
Host default
HostName 127.0.0.1
User vagrant
Port 2222
UserKnownHostsFile /dev/null
StrictHostKeyChecking no
PasswordAuthentication no
IdentityFile <span style=\"color: #b5bd68;\">\"/Users/dan/.vagrant.d/insecure_private_key\"</span>
IdentitiesOnly yes
LogLevel FATAL
$ sshfs vagrant@localhost:/home/vagrant ../vm -p2222 -oreconnect,defer_permissions,negative_vncache,<span style=\"color: #cc6666;\">volname</span>=ghcjs,<span style=\"color: #cc6666;\">IdentityFile</span>=~/.vagrant.d/insecure_private_key
$ ls ../vm
</pre>
</div>
<p>
When you are done you can just <code>umount ../vm</code>
</p>
</div>
</div>
</div>
<div id=\"outline-container-sec-3\" class=\"outline-2\">
<h2 id=\"sec-3\"><span class=\"section-number-2\">3</span> Compiling other packages</h2>
<div id=\"text-3\" class=\"outline-text-2\">
<p>
Since the <code>diagrams</code> package on Hackage depends on the older version<br />
of base we are going to use the latest version from Git:
</p>
<pre class=\"example\">mkdir dia; cd dia
git clone git://github.com/diagrams/diagrams-core.git
cd diagrams-core && cabal install && cd ..
cabal unpack active
cd active-0.1*
cat >version.patch <<EOF
--- active.cabal        2013-06-12 12:58:40.082914214 +0000
+++ active.cabal.new    2013-06-12 12:58:31.029465815 +0000
@@ -19,7 +19,7 @@
library
exposed-modules:     Data.Active
-  build-depends:       base >= 4.0 && < 4.7,
+  build-depends:       base >= 4.0 && < 4.8,
array >= 0.3 && < 0.5,
semigroups >= 0.1 && < 0.10,
semigroupoids >= 1.2 && < 3.1,
@@ -31,7 +31,7 @@
test-suite active-tests
type:              exitcode-stdio-1.0
main-is:           active-tests.hs
-    build-depends:     base >= 4.0 && < 4.7,
+    build-depends:     base >= 4.0 && < 4.8,
array >= 0.3 && < 0.5,
semigroups >= 0.1 && < 0.10,
semigroupoids >= 1.2 && < 3.1,
EOF
patch active.cabal < version.patch
cabal install
cd ..
git clone git://github.com/diagrams/diagrams-lib.git
cd diagrams-lib && cabal install && cd ..
git clone git://github.com/diagrams/diagrams-svg.git
cd diagram-svg && cabal install && cd ..
</pre>
<p>
Other packages I had to install already had their Hackage versions<br />
updated.
</p>
<p>
Now you can try to build a test diagram to see that everything works
</p>
<div class=\"org-src-container\">
<pre class=\"src src-haskell\"><span style=\"color: #b294bb;\">module</span> <span style=\"color: #f0c674;\">Main</span> <span style=\"color: #b294bb;\">where</span>
<span style=\"color: #b294bb;\">import</span> <span style=\"color: #f0c674;\">Diagrams.Prelude</span>
<span style=\"color: #b294bb;\">import</span> <span style=\"color: #f0c674;\">Diagrams.Backend.SVG.CmdLine</span>
<span style=\"color: #81a2be;\">d</span> <span style=\"color: #cc6666;\">::</span> <span style=\"color: #f0c674;\">Diagram</span> <span style=\"color: #f0c674;\">SVG</span> <span style=\"color: #f0c674;\">R2</span>
<span style=\"color: #81a2be;\">d</span> <span style=\"color: #cc6666;\">=</span> square 20 <span style=\"color: #cc6666;\">#</span> lw 0<span style=\"color: #cc6666;\">.</span>5
<span style=\"color: #cc6666;\">#</span> fc black
<span style=\"color: #cc6666;\">#</span> lc green
<span style=\"color: #cc6666;\">#</span> dashing [0<span style=\"color: #cc6666;\">.</span>2,0<span style=\"color: #cc6666;\">.</span>2] 0
<span style=\"color: #81a2be;\">main</span> <span style=\"color: #cc6666;\">=</span> defaultMain (pad 1<span style=\"color: #cc6666;\">.</span>1 d)
</pre>
</div>
<p>
then you can compile and run it
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">ghc --make Test.hs
./Test -w 400 -o /vagrant/test.svg
</pre>
</div>
<p><a href=\"http://parenz.files.wordpress.com/2013/06/screen-shot-2013-06-12-at-5-19-03-pm.png\"><img src=\"http://parenz.files.wordpress.com/2013/06/screen-shot-2013-06-12-at-5-19-03-pm.png?w=300&h=289\" alt=\"Screen Shot 2013-06-12 at 5.19.03 PM\" height=\"289\" class=\"alignnone size-medium wp-image-47\" width=\"300\" /></a></p>
<p>
And that’s it!
</p>
</div>
</div>
<div id=\"outline-container-sec-4\" class=\"outline-2\">
<h2 id=\"sec-4\"><span class=\"section-number-2\">4</span> Outro</h2>
<div id=\"text-4\" class=\"outline-text-2\">
<p>
I would also like to note that we are currently polishing the GHCJS<br />
build process. Luite, especially is working on making ghcjs work (and<br />
run tests) with <a href=\"https://travis-ci.org/\">Travis CI</a> (it take quite a bit of time to build ghcjs<br />
and sometimes travis is timeouting) and I am working on tidying up<br />
the build config.
</p>
<p>
Stay tuned for more updates.
</p>
</div>
</div>
<br /> Tagged: <a href=\"http://parenz.wordpress.com/tag/diagrams/\">diagrams</a>, <a href=\"http://parenz.wordpress.com/tag/ghcjs/\">ghcjs</a>, <a href=\"http://parenz.wordpress.com/tag/haskell-2/\">haskell</a>, <a href=\"http://parenz.wordpress.com/tag/soc/\">soc</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/parenz.wordpress.com/49/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/parenz.wordpress.com/49/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=parenz.wordpress.com&blog=26722965&post=49&subd=parenz&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "420579aa4fa57bfef9a6b68bf4b5eb0f") (94 (20937 47692 603706) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_5189\"></span>, where <span id=\"tex_8060\"></span> is the number of “folds” and <span id=\"tex_3022\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_8517\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "26b7e866ae60e2037a2feb2c2feddceb") (93 (20937 23596 981120) "http://feedproxy.google.com/~r/ezyang/~3/qvy2VqDp6Is/" "Edward Z. Yang: (Homotopy) Type Theory: Chapter One" nil "Mon, 24 Jun 2013 22:56:27 +0000" "<div class=\"document\">
<p>In what is old news by now, the folks at the Institute for Advanced Study have released <a href=\"http://homotopytypetheory.org/book/\" class=\"reference external\">Homotopy Type Theory:
Univalent Foundations of Mathematics</a>.  There has been some (meta)commentary (<a href=\"https://plus.google.com/107913314994758123748/posts/VzWAsojiifE\" class=\"reference external\">Dan Piponi</a>, <a href=\"http://existentialtype.wordpress.com/2013/06/22/whats-the-big-deal-with-hott/\" class=\"reference external\">Bob Harper</a>, <a href=\"http://math.andrej.com/2013/06/20/the-hott-book/\" class=\"reference external\">Andrej Bauer</a>, <a href=\"http://dorais.org/archives/1425\" class=\"reference external\">François G. Dorais</a>, <a href=\"http://homotopytypetheory.org/2013/06/20/the-hott-book/\" class=\"reference external\">Steve Awodey</a>, <a href=\"http://www.carloangiuli.com/blog/homotopy-type-theory-univalent-foundations-of-mathematics/\" class=\"reference external\">Carlo Angiuli</a>, <a href=\"http://golem.ph.utexas.edu/category/2013/06/the_hott_book.html\" class=\"reference external\">Mike Shulman</a>, <a href=\"https://plus.google.com/117663015413546257905/posts/cm1sKge8qxX\" class=\"reference external\">John Baez</a>) on the Internet, though, of course, it takes time to read a math textbook, so don’t expect detailed technical commentary from non-authors for a while.</p>
<p>Of course, being a puny grad student, I was, of course, most interested in the book’s contribution of <em>yet another Martin-Löf intuitionistic type theory introduction</em>, e.g. chapter one.  The classic introduction is, of course, the papers that Martin Löf wrote (nota bene: there were many iterations of this paper, so it’s a little hard to find the right one, though it seems Giovanni Sambin’s notes are the easiest to find), but an introduction of type theory for <em>homotopy type theory</em> has to make certain adjustments, and this makes for some novel presentation.  In particular, the chapter’s discussion of <em>identity types</em> is considerably more detailed than I have seen elsewhere (this is not surprising, since identity is of central importance to homotopy type theory). There is also a considerable bit of pedantry/structure in the discussion of the types that make up the theory, reminiscent of the <a href=\"http://existentialtype.wordpress.com/2012/12/03/pfpl-is-out/\" class=\"reference external\">PFPL</a> (though I believe that this particular chapter  was mostly written by others). And, of course, there are many little variations in how the theory is actually put together, expounded upon in some detail in the chapter notes.</p>
<p>In more detail:</p>
<p><strong>Definitional and propositional equality.</strong> The chapter spends a little bit of time carefully distinguishing between definitional equality (a purely syntactic notion up to computation) and propositional equality (which involves evidence), which I appreciated. The difference between connectives which show up inside and outside the deductive system was a major point of confusion for me when I was originally learning logic.</p>
<p><strong>The general pattern of the introduction of a new kind of type.</strong> The modern style for introducing logical connectives is to classify the rules into various kinds, such as introduction rules and elimination rules, and then hew to this regularity in the presentation.  Often, readers are expected to “see it”, but this book makes a helpful remark laying out the style. I found a useful exercise was to take the rules and reorganize them so that, for example, all of the elimination rules are together and compare them.</p>
<p><strong>Recursion and induction.</strong> <a href=\"http://blog.ezyang.com/2013/04/the-difference-between-recursion-induction/\" class=\"reference external\">I’ve written about this subject before</a>, arguing that recursion and induction aren’t the same thing, since induction needs to work over indexed types.  This is true, but there is an important point I did not make: <em>induction is generalized recursion</em>. This is because when you specify your type family <em>P</em> to be the <em>constant type family</em> which ignores its index, the dependence is erased and you have an ordinary recursor.  In fact, this is a <a href=\"http://adam.chlipala.net/cpdt/html/InductiveTypes.html\" class=\"reference external\">CPDT exercise</a>; I think it clarifies things to see this in both Coq and informal mathematics, as the informal presentation makes the dimension of generalization clearer.</p>
<p><strong>Identity types.</strong> I won’t lie: I had a difficult time with this section, and I don’t think I fully understand why path induction works, even after a very long remark at the end of the section.  (Additionally, while the notes point to some prior literature about the subject, I took a look at the papers and I did not see anything that resembled their presentation of path induction.) By default, Coq thinks the inductive principle for equality types should be what is referred to in this book as the indiscernability of identicals:</p>
<pre class=\"literal-block\">> Check eq_rect.
eq_rect
: forall (A : Type) (x : A) (P : A -> Type),
P x -> forall y : A, x = y -> P y
</pre>
<p>(As a tangent, the use of family <em>C</em> is confusingly overloaded; when discussing the generalization of the previous principlem the reader is required to imagine <tt class=\"docutils literal\">C(x) <span class=\"pre\">-></span> C(y)  ===  C(x, y)</tt>—the C’s of course being distinct.) Path induction asks for more:</p>
<pre class=\"literal-block\">eq_ind
: forall (A : Type), forall (C : forall (x y : A), x = y -> Type),
(forall (x : A), C x x (eq_refl x)) -> forall (x y : A), forall (p : x = y), C x y p
</pre>
<p>This is perhaps not too surprising, since this machinery is principally motivated by homotopy type theory. Additionally, the inductive principle follows the same pattern as the other inductive principles defined for the other types. The trouble is a frustrating discussion of why this inductive principle valid, even when you might expect, in a HoTT setting, that not all equality was proven using reflexivity. My understanding of the matter is that is has to do with the placement of the <tt class=\"docutils literal\">forall (x : A)</tt> quantifier. It is permissible to move one of the x's to the top level (based path induction), but not <em>both</em>. (This is somewhat obscured by the reuse of variable names.) There is also a geometric intuition, which is that when both or one endpoints of the path are free (inner-quantification), then I can contract the path into nothingness. But I have a difficult time mapping this onto any sort of rigorous argument. Perhaps you can help me out.</p>
<blockquote>
As an aside, I have some general remarks about learning type theory from a functional programming background.  I have noticed that it is not too hard to use Coq without knowing much type theory, and even easier to miss the point of why the type theory might be helpful.  But in the end, it is really useful to understand what is going on, and so it’s well worth studying <em>why</em> dependent products and sums generalize the way they do.  It also seems that people find the pi and sigma notation confusing: it helps if you realize that they are algebraic puns. Don’t skip the definition of the inductive principles.</blockquote>
<p>I apologize if any of this post has been inaccurate or misleadingly skewed. My overall impression is that this first chapter is a very crisp introduction to type theory, but that the segments on identity types may be a little difficult to understand. Now, onwards to chapter two!</p>
</div>
<img src=\"http://feeds.feedburner.com/~r/ezyang/~4/qvy2VqDp6Is\" height=\"1\" width=\"1\" />" nil nil "ba71d6fdc9ef485db95c3ce3a2197f73") (92 (20937 23596 978954) "http://praisecurseandrecurse.blogspot.com/2013/06/objective-c-day-6-back-from-dylan-land.html" "Paul Potts: Objective-C, Day 6 (Back from Dylan-land)" "noreply@blogger.com (Paul Potts)" "Mon, 24 Jun 2013 22:53:00 +0000" "<p>I've been a little sick -- maybe something in our water, because our tap water started tasting like hose water -- but it seems to be clearing up. There's nothing like having flu-like symptoms to celebrate the first couple of days of summer! But I'm more-or-less back on my feet, although still a little queasy. Yesterday the weather station closest to our home in Saginaw hit 93, \"feels like 100\" with the humidity. I know that's nothing compared to some of the folks out west, but it came on us pretty fast, and I'd happily trade 100 in the low-humidity desert for 90 in Saginaw. I've got the A/C unit set up in the home office, since we finally need it, and I'm pressing on with my re-engineering of the old Mac Polar game.</p> <p>The Dylan implementation I discussed last time helped focus my thinking about, if not the optimal, at least a fairly clear model for implementing game piece behavior. It also clarified what I should do with game objects in Objective-C, and that is \"nothing.\" The \"model\" class still deserves to live, but the tile pieces just don't derive any benefit from being classes. The two main reasons are (1) Objective-C doesn't really support static methods in the sense that C++ does, and (2) Objective-C's dispatch mechanism isn't sophisticated enough to help us significantly save on \"code to find code.\" So the tiles will be represented by plain old data, and we'll dispatch on their \"types\" with plain old logic.</p> <p>The Dylan code has a small infrastructure of helper functions for accessing, filling, and logging the board state. I won't include all of it, because most of what it does is pretty clear from the function name, but there are functions like this:</p> <pre>define method getTileAtPos( model :: <model>, pos :: <pos-or-false> ) =><br />    ( tile :: <tile> )<br />    if ( pos )<br />        getTileAtXY( model, pos.y-idx, pos.x-idx );<br />    else<br />        $the-edge;<br />    end if;<br />end;<br /><br />define function getAdjacentPos( pos :: <pos>, dir :: <dir> )<br />    => ( pos-or-false :: <pos-or-false> )<br />    let y-offset :: <integer> = 0;<br />    let x-offset :: <integer> = 0;<br />    if ( dir == #\"east\" )<br />        x-offset := 1;<br />    elseif ( dir == #\"south\" )<br />        y-offset := 1;<br />    elseif ( dir == #\"west\" )<br />        x-offset := -1;<br />    elseif ( dir == #\"north\" )<br />        y-offset := -1;<br />    end if;<br />    let new-y-idx :: <integer> = pos.y-idx + y-offset;<br />    let new-x-idx :: <integer> = pos.x-idx + x-offset;<br />    if ( ( ( new-y-idx >= 0 ) & ( new-y-idx < $board-dim-y ) ) & <br />         ( ( new-x-idx >= 0 ) & ( new-x-idx < $board-dim-x ) ) )<br />        make( <pos>, y-idx: new-y-idx, x-idx: new-x-idx );<br />    else<br />        #f<br />    end if;<br />end;<br /><br />define method penguinPush( model :: <model> )<br />    => ( result :: <boolean> )<br />    let target-pos :: <pos-or-false> = <br />        getAdjacentPos( model.penguin-pos, model.penguin-dir );<br />    let target-tile = getTileAtPos( model, target-pos );<br />    pushTile( model, model.penguin-dir, target-pos, target-tile );<br />end;<br /><br />define method penguinMove( model :: <model>, dir :: <dir> )<br />    if ( model.penguin-dir ~= dir )<br />        model.penguin-dir := dir;<br />        format-out( \"Penguin changed dir to %S\\n\", dir );<br />        force-output( *standard-output* );<br />    else<br />        if ( penguinPush( model ) )<br />            format-out ( \"Penguin moved to %d, %d\\n\",<br />                model.penguin-pos.y-idx, model.penguin-pos.x-idx );<br />            force-output( *standard-output* );<br />        end if;<br />        if ( model.heart-count == 0 )<br />            format-out( \"Heart count reached zero, level cleared!\\n\" );<br />            force-output( *standard-output* );<br />        end if;<br />    end if;<br />end;<br /><br />define method penguinMoveTimes( model :: <model>, dir :: <dir>,<br />    times :: <integer> )<br />    for ( count from 1 to times )<br />        penguinMove( model, dir );<br />    end for;<br />end;<br /><br />define method describe-tile( tile :: <tile> ) => ( str :: <string> )<br />    case<br />        ( tile == $the-empty     ) => \"___ \";<br />        ( tile == $the-tree      ) => \"tre \";<br />        ( tile == $the-mountain  ) => \"mtn \";<br />        ( tile == $the-house     ) => \"hou \";<br />        ( tile == $the-ice-block ) => \"ice \";<br />        ( tile == $the-heart     ) => \"hea \";<br />        ( tile == $the-bomb      ) => \"bom \";<br />        otherwise                  => \"??? \";<br />    end case;<br />end method;<br /><br />define method describe-board( model :: <model> )<br />    for ( y-idx from 0 below $board-dim-y )<br />        for ( x-idx from 0 below $board-dim-x )<br />            format-out( \"%S\", <br />                describe-tile( model.board[ y-idx, x-idx ]  ) );<br />        end for;<br />        format-out( \"\\n\" );<br />    end for;<br />    force-output( *standard-output* );<br />end;</pre> <p>In Objective-C, I'm going to get rid of the singletons and tile classes altogether. They will live on in the comments, to clarify what the pseudo-object-dispatch is doing, and vestigially in the code. The board will have the same internal representation as the raw strings of data taken from the original Polar game resources. I'll keep my three main methods from the Dylan code -- pushing a tile, colliding, and sliding -- but these will be single Objective-C methods rather than multi-methods. The tiles are just chars:</p> <pre>#define POLAR_DATA_LEN_Y 4               // 4x24 grid<br />#define POLAR_DATA_LEN_X 24<br />#define POLAR_DATA_NUM_LEVELS 6          // In the original game<br /><br />typedef char tile_t;<br /><br />enum {<br />    polar_tile_empty = '0',<br />    polar_tile_tree,<br />    polar_tile_mountain,<br />    polar_tile_house,<br />    polar_tile_ice_block,<br />    polar_tile_heart,<br />    polar_tile_bomb,<br />    polar_tile_last = polar_tile_bomb<br />};<br /><br />/*<br />    Not part of the level data; an extra flag value representing<br />    edge of board<br />*/<br />#define polar_tile_edge 'X'<br /><br />typedef const char polar_level_array_t[POLAR_DATA_NUM_LEVELS]<br />                                      [POLAR_DATA_LEN_Y]<br />                                      [POLAR_DATA_LEN_X];<br /><br />typedef char polar_board_array_t[POLAR_DATA_LEN_Y]<br />                                [POLAR_DATA_LEN_X];<br /><br />extern polar_level_array_t polar_levels;</pre> <p>Why use <b>#define</b> for array indices and our tile pieces instead of <b>const int</b> and <b>const char?</b> Because using a const integral variable (yeah... a \"const variable...\") to dimension an array, or represent a case value for a switch statement, is <a href=\"http://stackoverflow.com/questions/3988122/static-const-int-not-good-enough-for-array-size\">still not standard C</a> everywhere, although it is a common extension to allow the compiler to treat it as so in contexts like this. Enum works fine with characters. Oddly, I have a build issue when using enum values to define the array boundaries. I haven't figured out quite what that is all about -- I think it may be a Clang bug. But I'll worry about that later.</p> <p>In the implementation file:</p> <pre>polar_level_array_t polar_levels =<br />{<br />    {<br />        \"100000000000000100000400\"<br />        \"106020545000000000100100\"<br />        \"100000000000000050002300\"<br />        \"110000100000000000000000\"<br />    },<br />    // Etc., for the other five levels<br />}</pre> <p>The model class gets one as a member:</p> <pre>@interface ArcticSlideModel : NSObject<br />{<br />    polar_level_array_t board;<br />    pos_t penguinPos;<br />    dir_e penguinDir;<br />    int heartCount;<br />}</pre> <p>We'll work ourselves down from the external API to the associated implementation:</p> <pre><br />// The external API<br />- (void)penguinMoveDue:(dir_e)dir;<br />- (void)penguinMoveNTimes:(int)n<br />                      due:(dir_e)dir;</pre> <p><b>penguinMoveNTimes:due:</b> calls <b>penguinMoveDue:</b> which calls <b>penguinPushDue:</b>. In Dylan:</p> <pre>define method penguinPush( model :: <model> )<br />    => ( result :: <boolean> )<br />    let target-pos :: <pos-or-false> = <br />        getAdjacentPos( model.penguin-pos, model.penguin-dir );<br />    let target-tile = getTileAtPos( model, target-pos );<br />    pushTile( model, model.penguin-dir, target-pos, target-tile );<br />end;</pre> <p>That's not strictly translatable to C, since we're taking advantage of a <b>type-union</b> to retrieve the position or <b>#f</b> with <b>getAdjacentPos</b>. This usage extends to the lower levels of the implementation, though, so for now we're going to continue to allow getAdjacentPos to return position values that are invalid, and explicitly check for them so we don't read or write at non-existent array indices.</p> <pre>pos_t getAdjacentPos( pos_t original_pos, dir_e dir )<br />{<br />    pos_t updated_pos = original_pos;<br />    int y_offset = 0;<br />    int x_offset = 0;<br />    switch ( dir )<br />    {<br />        case dir_east:<br />            x_offset = 1;<br />            break;<br />        case dir_south:<br />            y_offset = 1;<br />            break;<br />        case dir_west:<br />            x_offset = -1;<br />            break;<br />        case dir_north:<br />            y_offset = -1;<br />            break;<br />        default:<br />            NSLog( @\"getAdjacentPos: invalid dir %d\", dir );<br />    }<br />    updated_pos.y_idx += y_offset;<br />    updated_pos.x_idx += x_offset;;<br />    return updated_pos;<br />}</pre> <p>We rely on posValid to explicitly check for invalid tile cases:</p> <pre>BOOL posValid( pos_t pos )<br />{<br />    return ( ( ( pos.y_idx >= 0 ) &&<br />               ( pos.y_idx < POLAR_DATA_LEN_Y  ) ) &&<br />             ( ( pos.x_idx >= 0 ) &&<br />               ( pos.x_idx < POLAR_DATA_LEN_X ) ) );<br />}</pre> <p>That should be pretty non-controversial. Note that BOOL in Objective-C is not a real type; it's just a #define and a typedef based on char_t. So don't get a <a href=\"http://blog.bignerdranch.com/564-bools-sharp-corners/\">false sense of security</a> -- it has the same problems that fake bool types always have, and always will have, in straight C.</p> <p>Anyway, we can now implement our pushTile function. Here is the Dylan:</p> <pre><br />define generic pushTile( model :: <model>, dir :: <dir>,<br />    pos :: <pos-or-false>, target-tile :: <tile> );<br /><br />// Handle walkable (empty or tree tile). The penguin<br />// is allowed to move onto this tile (indicated by<br />// returning #t).<br />define method pushTile( model :: <model>, dir :: <dir>,<br />    target-pos :: <pos>, target-tile :: <walkable> )<br />    => ( result :: <boolean> )<br />    model.penguin-pos := target-pos;<br />    #t;<br />end;<br /><br />// Handle movable (bomb, heart, ice block) -- call<br />// collide which specializes in various combinations.<br />define method pushTile( model :: <model>, dir :: <dir>,<br />    target-pos :: <pos>, target-tile :: <movable> )<br />    => ( result :: <boolean> )<br />    let next-pos :: <pos-or-false>  = <br />        getAdjacentPos( target-pos, dir );<br />    let next-tile = getTileAtPos ( model, next-pos );<br />    collide( model, dir, target-pos, target-tile,<br />        next-pos, next-tile );<br />    #f;<br />end;<br /><br />// Handle fixed (house, mountain, edge) -- do nothing.<br />// The GUI might play a \"fail\" beep.<br />define method pushTile( model :: <model>, dir :: <dir>,<br />    target-pos :: <pos-or-false>, target-tile :: <fixed> )<br />    => ( result :: <boolean> )<br />    #f;<br />end;<br /></pre> <p>Doing all our own dispatch logic, here is a single method in Objective-C:</p> <pre>- (BOOL)pushTile:(tile_t)target_tile<br />             due:(dir_e)dir<br />              at:(pos_t)target_pos<br />{<br />    switch ( target_tile )<br />    {<br />        /*<br />            Handle the \"walkable\" cases. The penguin is allowed to move<br />            onto these tiles, indicated by returning YES<br />        */<br />        case polar_tile_empty: /* FALL THROUGH */<br />        case polar_tile_tree:<br />            NSLog( @\"pushTile: walkable\\n\" );<br />            self->penguinPos = target_pos;<br />            return YES;<br /><br />        /*<br />            Handle \"movable\" cases. Call collide which specializes in<br />            various combinations.<br />        */<br />        case polar_tile_bomb:      /* FALL THROUGH */<br />        case polar_tile_heart:     /* FALL THROUGH */<br />        case polar_tile_ice_block:<br />            NSLog( @\"pushTile: movable\\n\" );<br />            {<br />                pos_t next_pos = getAdjacentPos( target_pos, dir );<br />                /*<br />                    Note that next-pos can be invalid, which results<br />                    in the special \"edge\" tile value.<br />                */<br />                tile_t next_tile = [ self getTileAtPos:next_pos ];<br />                [ self collideTile:target_tile atPos:target_pos<br />                    due:dir withTile:next_tile<br />                    atSecondPos:next_pos ];<br />            }<br />            return NO;<br /><br />        /*<br />            Handle \"fixed\" cases. Do nothing; the GUI might play<br />            a \"fail\" beep.<br />        */<br />        case polar_tile_mountain:   /* FALL THROUGH */<br />        case polar_tile_house:<br />            NSLog( @\"pushTile: fixed\\n\" );<br />            return NO;<br /><br />        default:<br />            NSLog( @\"pushTile: unexpected tile value %d\\n\",<br />                   target_tile );<br />            return NO;<br />    }<br />}</pre> <p>And as in the Dylan version, for interesting interactions this method defers to another method:</p> <pre>- (void)collideTile:(tile_t)first_tile<br />              atPos:(pos_t)first_pos<br />                due:(dir_e)dir<br />           withTile:(tile_t)second_tile<br />        atSecondPos:(pos_t)second_pos<br />{<br />    BOOL empty = ( second_tile == polar_tile_empty );<br />    /* Blocking includes the special edge tile value */<br />    BOOL blocking = ( second_tile != polar_tile_empty );<br />    BOOL mountain = ( second_tile == polar_tile_mountain );<br />    BOOL house = ( second_tile == polar_tile_house );<br /><br />    BOOL ice_block = ( first_tile == polar_tile_ice_block );<br />    BOOL bomb = ( first_tile == polar_tile_bomb );<br />    BOOL heart = ( first_tile == polar_tile_heart );<br />    BOOL movable = ( ice_block || bomb || heart );<br /><br />    if ( bomb && mountain )<br />    {<br />        /*<br />            When a bomb meets a mountain, both bomb and mountain blow up<br />        */<br />        NSLog( @\"collideTile: bomb / mountain\\n\" );<br />        [ self setTile:polar_tile_empty AtPos:first_pos ];<br />        [ self setTile:polar_tile_empty AtPos:second_pos ];<br />    }<br />    else if ( heart && house )<br />    {<br />        /*<br />            When a bomb heart meets a house, we are closer to winning<br />        */<br />        NSLog( @\"collideTile: heart / house\\n\" );<br />        [ self setTile:polar_tile_empty AtPos:first_pos ];<br />        [ self decrementHeartCount ];<br />    }<br />    else if ( ice_block && blocking )<br />    {<br />        /*<br />            When an ice block is pushed directly against any<br />            blocking tile (including the board edge), it is destroyed.<br />        */<br />        NSLog( @\"collideTile: ice block / blocking\\n\" );<br />        [ self setTile:polar_tile_empty AtPos:first_pos ];<br />    }<br />    else if ( movable )<br />    {<br />        if ( empty )<br />        {<br />            /*<br />                A movable tile pushed onto an empty tile will slide<br />            */<br />            NSLog( @\"collideTile: movable / empty: start slide\\n\" );<br />            [ self slideTile:first_tile atPos:first_pos due:dir<br />                   toTile:second_tile atSecondPos:second_pos ];<br />        }<br />        else if ( blocking )<br />        {<br />            /*<br />                When a generic movable piece meets any other<br />                blocking pieces not handled by a special case<br />                above, nothig happens; it stops. Maybe play<br />                a \"fail\" beep.<br />            */<br />            NSLog( @\"collideTile: movable / blocking\\n\" );<br />        }<br />    }<br />}</pre> <p>This could have been written with a bunch of ugly, redundant-looking <b>switch</b> statements, but the duplicated cases and defaults just don't seem as clear to me as making flags that precisely describe the nature of the \"double dispatch\" going on. In this program, having to spell out the logic (using code to find code) is not really onerous. But the problem comes, of course, in code where we keep having to add special cases. I could refactor this method to call some smaller methods but that doesn't seem like a real win. In the Dylan implementation if I wanted to add another special interaction, it might only require adding another generic function. That's assuming my whole class hierarchy didn't change.</p> <p>Finally, the slide method:</p> <pre>- (void)slideTile:(tile_t)first_tile<br />            atPos:(pos_t)first_pos<br />              due:(dir_e)dir<br />           toTile:(tile_t)second_tile<br />      atSecondPos:(pos_t)second_pos<br />{<br />    BOOL empty = ( second_tile == polar_tile_empty );<br />    /* Blocking includes the special edge tile value */<br />    BOOL blocking = ( second_tile != polar_tile_empty );<br />    <br />    BOOL ice_block = ( first_tile == polar_tile_ice_block );<br />    BOOL movable = ( ice_block ||<br />                     first_tile == polar_tile_bomb ||<br />                     first_tile == polar_tile_heart );<br /><br />    if ( ice_block && blocking )<br />    {<br />        // A specific movable tile, ice-block, meets a<br />        // blocking tile; don't call collide since the behavior<br />        // of a sliding ice block is different than a pushed ice<br />        // block. It just stops and doesn't break.<br />        NSLog( @\"slideTile: ice block / blocking\\n\" );       <br />    }<br />    else if ( movable && empty )<br />    {<br />        // A movable tile interacting with an empty tile --<br />        // move forward on the board and call slide again.<br />        NSLog( @\"slideTile: movable / empty\\n\" );<br />        pos_t third_pos = getAdjacentPos( second_pos, dir );<br />        tile_t third_tile = [ self getTileAtPos:third_pos ];<br />        [ self setTile:polar_tile_empty AtPos:first_pos ];<br />        [ self setTile:first_tile AtPos:second_pos ];<br />        [ self slideTile:first_tile atPos:second_pos due:dir<br />                  toTile:third_tile atSecondPos:third_pos ];<br />    }<br />    else if ( movable && blocking )<br />    {<br />        // A movable tile meets a blocking tile: call collide to<br />        // handle heart/house, bomb/mountain, edge of world, etc.<br />        NSLog( @\"slideTile: movable / blocking\\n\" );<br />        [ self collideTile:first_tile atPos:first_pos due:dir<br />                  withTile:second_tile atSecondPos:second_pos ];<br />    }<br />}</pre> <p>That's the bulk of it. Here's an excerpt from the log as it finishes up the first level:</p> <pre>ArcticSlide[2279:c07] penguinPush: tile at 2, 5 pushed<br />ArcticSlide[2279:c07] pushTile: walkable<br />ArcticSlide[2279:c07] Penguin moved to: 2, 5<br />ArcticSlide[2279:c07] Penguin direction changed to EAST<br />ArcticSlide[2279:c07] Penguin moving EAST<br />ArcticSlide[2279:c07] penguinPush: tile at 2, 6 pushed<br />ArcticSlide[2279:c07] pushTile: movable<br />ArcticSlide[2279:c07] collideTile: movable / empty: start slide<br />ArcticSlide[2279:c07] slideTile: movable / empty<br />ArcticSlide[2279:c07] collideTile: heart / house<br />ArcticSlide[2279:c07] Heart count reached zero, level cleared!<br />ArcticSlide[2279:c07] ArcticSlideModel board state:<br />tre__________________________________________treice_____________________<br />tre_________mtn_______________________________________tre______tre______<br />tre____________________________________________________________hou______<br />tretre____________treice________________________________________________<br /></pre> <p>I'll put in logic to play the remaining levels soon, as additional test cases.</p> <p>Note that I kept the recursive call to slideTile. It's not an idiom commonly used in C and Objective-C. We only recurse when the moving tile traverses more than one empty tile, and so never more than 23 times. I like to write algorithms recursively when possible while sketching out code. If direct recursion like that is <i>verboten</i>, it can be removed. I don't think my compiler is optimizing it out. But the termination logic now starts to look redundant:</p> <pre>else if ( movable && empty )<br />    {<br />        while ( NO == blocking )<br />        {<br />            pos_t third_pos = getAdjacentPos( second_pos, dir );<br />            tile_t third_tile = [ self getTileAtPos:third_pos ];<br />            [ self setTile:polar_tile_empty AtPos:first_pos ];<br />            [ self setTile:first_tile AtPos:second_pos ];<br />            first_pos = second_pos;<br />            second_pos = third_pos;<br />            second_tile = third_tile;<br />            blocking = ( third_tile != polar_tile_empty );<br />        }<br />        if ( ice_block )<br />        {<br />            NSLog( @\"slideTile: ice block / blocking\\n\" );<br />        }<br />        else<br />        {<br />            [ self collideTile:first_tile atPos:first_pos due:dir<br />                      withTile:second_tile atSecondPos:second_pos ];<br />        }<br />    }</pre> <p>And if I don't want to call back into methods in my own call chain at all -- that is, if I have to give up calling <b>collideTile</b>, well, I could do that but it would involve putting copying of the logic from collideTile into this method, and by that point this method will be badly breaking the \"DRY\" (Don't Repeat Yourself) axiom, so it might be clearer to turn <b>collideTile</b> and <b>slideTile</b> into one method.</p> <p>Anyway, the heat is building up in my office and it is about dinnertime. I think it's time to move on to some user interface, so the app can actually be played on an untethered iOS device. I also am still struggling a bit to get going on a Haskell implementation. I know it can be done -- people describe Haskell as a good imperative language too, for modeling state as safely as possible -- but let's just say that the chapters and examples I'm reading haven't quite \"gelled\" in my brain. I still feel like someone studying a foreign language who can read it and understand it when spoken, but not speak it yet -- especially the Monadic dialects. But I'm still working on that.</p> <p>UPDATE: I have put the source on GitHub, such as it is -- for now, ignore the license text; I need to pick an actual license. See: <a href=\"https://github.com/paulrpotts/arctic-slide-ios\">https://github.com/paulrpotts/arctic-slide-ios</a></p>" nil nil "4dd23d4b203effde8a79f8efa9e9a827") (91 (20937 23596 864736) "http://feedproxy.google.com/~r/FpComplete/~3/F6zWN-sWxgw/fp-haskell-center-video-blog" "FP Complete: FP Haskell Center Video Blog" nil "Mon, 24 Jun 2013 14:42:00 +0000" "<p>FP Haskell Center is approaching its beta release date for an on-time delivery, and I wanted to share with you some of the details of our product in a short video blog. You can find a link to the video below:</p><p><a href=\"http://youtu.be/3lPFg-tQaLY\">FP Haskell Center Video Blog</a></p><p>Remember, there is still plenty of time to sign-up for the <a href=\"https://www.fpcomplete.com/business/haskell-center\">FP Haskell Center beta.</a></p><div class=\"feedflare\">
<a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=F6zWN-sWxgw:3yiTnUAVPzw:yIl2AUoC8zA\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=yIl2AUoC8zA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=F6zWN-sWxgw:3yiTnUAVPzw:V_sGLiPBpWU\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=F6zWN-sWxgw:3yiTnUAVPzw:V_sGLiPBpWU\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=F6zWN-sWxgw:3yiTnUAVPzw:qj6IDK7rITs\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=qj6IDK7rITs\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=F6zWN-sWxgw:3yiTnUAVPzw:gIN9vFwOqvQ\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=F6zWN-sWxgw:3yiTnUAVPzw:gIN9vFwOqvQ\" border=\"0\" /></a>
</div><img src=\"http://feeds.feedburner.com/~r/FpComplete/~4/F6zWN-sWxgw\" height=\"1\" width=\"1\" />" nil nil "53b0840df6197ac5ba254f7bfca9c978") (90 (20937 23596 853594) "http://praisecurseandrecurse.blogspot.com/2013/06/dispatch-for-polar-game-in-dylan.html" "Paul Potts: Dispatch for the Polar Game in Dylan" "noreply@blogger.com (Paul Potts)" "Thu, 20 Jun 2013 04:44:00 +0000" "<p>So with some assistance from the folks on the Dylan Hackers mailing list I got enough clues to press on and get my Dylan implementation of the Polar game working, at least up through the end of the first board. I haven't verified that every possible tile interaction works yet, but it's a start. This seems like a silly problem, but it interests me because of several problems. Dispatch (or simulated dispatch) is \"double dispatch,\" based on the types of two different objects interacting. The breakdown of how to categorize the classes of objects isn't 100% clear -- there is some overlap that I can't seem to eliminate, and the compiler has to decide what methods constitute the most specific match. And finally, the logic does not seem easily fixed in either classes representing the tiles, or a single class representing the board.</p> <p>If I wrote it in C, the tile classes pretty much wouldn't exist; they'd exist only as flag enumerations in an array of tiles, and the code would consist mostly of <b>switch</b> or <b>if-else</b> logic that did the \"double dispatch\" in a fixed, predictable order, without relying on the compiler very much. Objective-C, again mostly C with a thin layer for representing classes, doesn't really give these classes enough features to make them worthwhile, so I will probably just keep the board (the model in the model/view/controller) and treat the tiles like I would in plain old C. But in Dylan they have an interesting life in terms of how they can be used to organize the code -- using generic functions -- so that I'm doing less writing of \"code to find code\" -- that is, code to look at run-time identity of objects and \"manually\" dispatch on it.</p> <p>Here are the tile classes:</p> <pre>define abstract class <tile> ( <object> ) end;<br />define abstract class <blocking> ( <tile> ) end;<br />define abstract class <walkable> ( <tile> ) end;<br />define abstract class <movable> ( <blocking> ) end;<br />define abstract class <fixed> ( <blocking> ) end;<br />define class <bomb> ( <movable> ) end;<br />define class <heart> ( <movable> ) end;<br />define class <ice-block> ( <movable> ) end;<br />define class <house> ( <fixed> ) end;<br />define class <mountain> ( <fixed> ) end;<br />define class <edge> ( <fixed> ) end;<br />define class <tree> ( <blocking>, <walkable> ) end;<br />define class <empty> ( <walkable> ) end;</pre> <p>Oy, is that a pain to replace all the angle brackets with HTML entities... there must be a better way in Blogger! Anyway, these tile classes have no state -- in Dylan, no slots -- and are used in my program solely for their types. Edge does not actually appear on the board, but is used internally when the penguin or another moving object attempts to interact with the edge of the board. We treat this just like another blocking object, as if the board was surrounded by immovable, inert objects.</p> <p>Diagramatically, like so:</p> <a href=\"http://4.bp.blogspot.com/-edliQJKZWbs/UcJyojJiJ_I/AAAAAAAADGU/HrdQeMbN914/s1600/tile-classes-v2-75-percent.png\"><img src=\"http://4.bp.blogspot.com/-edliQJKZWbs/UcJyojJiJ_I/AAAAAAAADGU/HrdQeMbN914/s1600/tile-classes-v2-75-percent.png\" border=\"0\" /></a> <p>There did not seem to be one absolute best way to represent these classes. I want to organize their abstract base classes by behavior, but their behavior does not break down with complete consistency -- for example, tiles with trees are \"blocking\" with respect to sliding objects, except for the penguin. The ice block is \"blocking\" except for the case where the penguin pushes it and it is not adjacent to an empty tile -- then it is crushed. Bombs and hearts seem to have the same interactions with mountains and houses whether they traverse an empty tile by sliding first across one or more empty tiles, while ice blocks behave differently -- if they slide first and then collide with a blocking object, they are not destroyed, they just stop. So the groupings of the concrete classes isn't going to be able to coherently divide up all their possible behaviors.</p> <p>The scheme I settled on for object interactions involves three layers, in the form of three generic functions. The first represents interactions of the player's \"avatar,\" the penguin, with tiles:</p> <pre>define generic pushTile( model :: <model>, dir :: <dir>,<br />    pos :: <pos-or-false>, target-tile :: <tile> );<br /><br />define method pushTile( model :: <model>, dir :: <dir>,<br />    target-pos :: <pos>, target-tile :: <walkable> )<br />    => ( result :: <boolean> )<br />    model.penguin-pos := target-pos;<br />    #t;<br />end;<br /><br />define method pushTile( model :: <model>, dir :: <dir>,<br />    target-pos :: <pos>, target-tile :: <movable> )<br />    => ( result :: <boolean> )<br />    let next-pos :: <pos-or-false>  = <br />        getAdjacentPos( target-pos, dir );<br />    let next-tile = getTileAtPos ( model, next-pos );<br />    collide( model, dir, target-pos, target-tile,<br />        next-pos, next-tile );<br />    #f;<br />end;<br /><br />define method pushTile( model :: <model>, dir :: <dir>,<br />    target-pos :: <pos-or-false>, target-tile :: <fixed> )<br />    => ( result :: <boolean> )<br />    #f;<br />end;</pre> <p>Dylan doesn't strictly require that I define the generic function before defining methods for it; if I just start writing methods with the same name, it will assume that I mean them to be associated with a generic function. But defining the generic function first has a benefit -- the compiler will tell me whether my methods make sense, in that their parameters are all strictly the same type or a more specific subclass of the types mentioned in the <b>define generic</b> statement. Note that <b><pos-or-false></b> is a type union of a simple <b><pos></b> class with singleton( #f ). The generic uses that type union, but one of the methods are more specific: they require an actual <b><pos></b> instance and will not accept #f.</p> <p>The first method handles the case where the penguin is pushing a <b><walkable></b> tile, and returns false to indicate that the penguin position can be updated. The pos must not be <b>#f</b>. The second method handles pushing any <b><movable></b> tiles. And the third handles the <b><fixed></b> tiles. Between the three methods, you might notice that they cover all the leaf classes (all the instantiable classes) in the graph above, in 3 separate groups with no overlapping. You could shade in the leaf nodes covered by the three different methods with three different colors, going from the abstract classes mentioned downward, and all the leaves would all be colored and none would be colored more than once:</p> <a href=\"http://1.bp.blogspot.com/-7hB-6vXpCqc/UcJ6yt9HtyI/AAAAAAAADGk/KywbId2KW4k/s1600/tile-classes-v2-color-1-75-percent.png\"><img src=\"http://1.bp.blogspot.com/-7hB-6vXpCqc/UcJ6yt9HtyI/AAAAAAAADGk/KywbId2KW4k/s1600/tile-classes-v2-color-1-75-percent.png\" border=\"0\" /></a> <p>So on the tile parameter, the coverage of the concrete classes is complete and the dispatch algorithm should not have any difficulty. Combined with the position parameter, though, the situation is slightly trickier. At runtime, a caller could call <b>pushTile</b> with <b>#f</b> for <b>pos</b> and <b><empty></b>; or <b><bomb></b> for <b>tile</b> and the dispatcher would, correctly, throw up its hands at this point and say that there was no applicable method. I could have defined a more general method to handle this case, but I didn't -- there shouldn't ever be an empty or bomb tile without a corresponding valid position, since they are real tiles on the board, and I want the runtime to help me catch that case if it ever happens. Similarly, I could have defined a method that handled <b><blocking></b> or <b><tile></b> as part of this generic function but the whole point is that I don't know what to do with those more general classes here.</p> <p>So, you may notice that the middle <b>pushTile</b> method calls <b>collide</b> with a second tile and position, adjacent to the first in a specified direction. That generic function looks like this:</p> <pre>define generic collide( model :: <model>, dir :: <dir>,<br />    tile-1-pos :: <pos>, tile-1 :: <movable>,<br />    tile-2-pos :: <pos-or-false>, tile-2 :: <blocking-or-empty> );<br /><br />define method collide( model :: <model>, dir :: <dir>,<br />    movable-pos :: <pos>, movable-tile :: <movable>,<br />    next-pos :: <pos>, next-tile :: <empty> )<br />    slide ( model, dir, movable-pos, movable-tile,<br />            next-pos, next-tile );<br />end;<br /><br />define method collide( model :: <model>, dir :: <dir>,<br />    ice-block-pos :: <pos>, ice-block-tile :: <ice-block>,<br />    icebreaking-pos :: <pos-or-false>,<br />    ice-breaking-tile :: <blocking> )<br />    setTileAtPos( model, ice-block-pos, $the-empty );<br />end;<br /><br />define method collide( model :: <model>, dir :: <dir>,<br />    heart-pos :: <pos>, heart-tile :: <heart>,<br />    house-pos :: <pos>, house-tile :: <house> )<br />    setTileAtPos( model, heart-pos, $the-empty );<br />    decrementHeartCount( model );<br />end;<br /><br />define method collide( model :: <model>, dir :: <dir>,<br />    bomb-pos :: <pos>, bomb-tile :: <bomb>,<br />    mountain-pos :: <pos>, mountain-tile :: <mountain> )<br />    setTileAtPos( model, bomb-pos, $the-empty );<br />    setTileAtPos( model, mountain-pos, $the-empty );<br />end;<br /><br />define method collide( model :: <model>, dir :: <dir>,<br />    movable-pos :: <pos>, movable-tile :: <movable>,<br />    blocking-pos :: <pos-or-false>, blocking-tile :: <blocking> )<br />end;</pre> <p>You might notice that before long you hit yet another method call you haven't seen before -- slide. This is, as you might guess, yet another generic function. (Doesn't this program every get around to <i>doing</i> anything? In fact it does, but this is the often-paradoxical-seeming logic of object-oriented design -- individual methods that seem too small and simple to get anything done can actually get a lot done together, especially when aided by a smart dispatcher that eliminates most of the need to write \"code to find code.\"</p> <p>The type-union <b><blocking-or-empty></b> allows us to specify, for our generic function, as tight a class as possible out of two otherwise disjoint sections of our class diagram. We don't have to loosen the type specification needlessly by using <b><tile></b>, which would allow <b><walkable></b> as a valid class for this parameter. Meanwhile, we can loosen <b>tile-2-pos</b> so that we make our intention to allow <b>#f</b> explicit here.</p> <p>The methods break down as follows. The first one handles any movable tile that is moving onto an empty tile, by calling a slide method to be defined later. The second one is a special case to handle the crushable <b><ice-block></b> class -- if it is pushed into the world edge, or any other object, it is destroyed (replaced with <b>$the-empty</b> class instance). The third and fourth methods handle specific interactions between hearts and houses, and bombs and mountains. And finally, to handle the case where the penguin pushes a heart against a mountain, or a bomb against the edge of the world, we have a less specific method that dispatches on <b><movable></b> and <b><blocking></b>. This prevents the runtime from generating an error in this case, but also gives us a place where we could generate some kind of feedback to the user, like a special sound to indicate failure.</p> <p>The breakdown of instantiable tile classes here is much more complex, especially given that we are dispatching on two class parameters drawn from the same hierarchy. We could try coloring them by using two copies of the diagram:</p> <div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://1.bp.blogspot.com/-d-ajjIIutjI/UcM8kBSlaWI/AAAAAAAADHM/UQ5mauDpXKA/s1600/tile-classes-v2-double-dispatch-2-75-percent.png\"><img src=\"http://1.bp.blogspot.com/-d-ajjIIutjI/UcM8kBSlaWI/AAAAAAAADHM/UQ5mauDpXKA/s1600/tile-classes-v2-double-dispatch-2-75-percent.png\" border=\"0\" /></a></div> <p>Err, that's pretty, but is it helpful? I'm using colors and borders to indicate that classes are handled by specific methods, but the main thing I hope I'm illustrating is that, unlike with the first generic function, in this one there is significant overlap between the classes handled by the different methods. This is where the dispatch mechanism really has to shine. There is an ordering that makes sense from my point of view, and that is one in which the most specific matching method will be called. However, as you can see, quantifying \"most specific\" may be slightly complex when dispatching on more than one class parameter, throwing in type-unions for fun. Fortunately this code is now working, but while I was developing it I became familiar with a warning message in Open Dylan that says something like \"the method dispatch handling this set of classes is determined by arbitrary and capricious rules\" -- indicating that the dispatch logic is still considered a work in progress. I was concerned that the current version of the Open Dylan compiler wasn't quite solid enough to make this work, but it does seem to work. The backup plan was to dispatch entirely on type-unions made up of different sets of singletons, but that is longer and obscures what is meant by the abstract classes.</p> <p>I won't go to the trouble to do the same diagram on my slide method, but that code looks like this:</p> <pre>define generic slide( model :: <model>, dir :: <dir>,<br />    movable-pos :: <pos>, movable-tile :: <movable>,<br />    next-pos :: <pos-or-false>, next-tile :: <blocking-or-empty> );<br /><br />define method slide( model :: <model>, dir :: <dir>,<br />    movable-pos :: <pos>, movable-tile :: <movable>,<br />    next-pos :: <pos>, next-tile :: <empty> )<br />    let next-next-pos :: <pos-or-false> =<br />        getAdjacentPos( next-pos, dir );<br />    let next-next-tile = getTileAtPos( model, next-next-pos );<br />    setTileAtPos( model, next-pos, movable-tile );<br />    setTileAtPos( model, movable-pos, $the-empty );<br />    slide( model, dir, next-pos, movable-tile ),<br />           next-next-pos, next-next-tile );<br />end;<br /><br />define method slide( model :: <model>, dir :: <dir>,<br />    movable-pos :: <pos>, movable-tile :: <movable>,<br />    next-pos :: <pos-or-false>, next-tile :: <blocking> )<br />    collide( model, dir, movable-pos, movable-tile,<br />              next-pos, next-tile );<br />end;<br /><br />define method slide( model :: <model>, dir :: <dir>,<br />    ice-block-pos :: <pos>, ice-block-tile :: <ice-block>,<br />    next-pos :: <pos-or-false>, next-tile :: <blocking> )<br />end;</pre> <p>Aaaand that's pretty much the whole of the logic for handling interaction between the penguin and the various tiles. Note that we call ourselves recursively. It looks kind of like we have no termination condition! Except note that the method isn't calling itself, it's doing the same method dispatch that found it in the first place. When we come to a termination condition for our recursions, we'll actually call a different method of the same generic function -- most likely the third one, where a sliding object encounters a blocking object. That condition can include hitting the edge of the board. And fortunately -- we already have logic for that, mostly -- in our collide generic function! So sliding hearts and bombs are handled just the same as if they were pushed instead of ending a slide.</p> <p>There's a slightly tricky part where we want to bind up the next tile beyond the two tiles we were dispatched on, then perform two set operations to move the currently sliding tile, then dispatch on the starting tile at its moved position. To figure that out I had to draw some bits of the game board with circles and arrows (but not a paragraph on the back of each one to be used as evidence against me). (If you don't get that reference, either you're too young or I'm too old!)</p> <p>This is not the whole program, obviously, but these are the key methods for encoding the collisions between tiles. If you'd like to play with the whole program, you might come and join the <a href=\"https://lists.opendylan.org/mailman/listinfo/hackers\">Dylan Hackers mailing list</a>, or leave me a note. If there is interest I'll publish it, here or elsewhere. I am now curious as to how a similar set of overlapping dispatches -- via pattern matching, perhaps? -- might look in Haskell. I might try to write that next. If you've got an idea about the clearest and most idiomatic way to do it, I welcome your comments.</p> <p>UPDATE: the code, such as it is, is on GitHub. Ignore the license for now; I have to decide on an actual license. See: <a href=\"https://github.com/paulrpotts/arctic-slide-dylan\">https://github.com/paulrpotts/arctic-slide-dylan</a></p>" nil nil "5d28564e67c8c62e90a6d534a489b240") (89 (20937 23596 830637) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_7721\"></span>, where <span id=\"tex_5519\"></span> is the number of “folds” and <span id=\"tex_2185\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_8441\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "32b8eea390b767f20e5b34c3f41c86a9") (88 (20936 19053 419988) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_2337\"></span>, where <span id=\"tex_3142\"></span> is the number of “folds” and <span id=\"tex_9560\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_7654\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "d91f496ef4dd96b3024a151682efa29c") (87 (20936 8556 647559) "http://kenta.blogspot.com/2013/06/kiwzoxbe-deep-maybe.html" "Ken T Takusagawa: [kiwzoxbe] Deep maybe" "noreply@blogger.com (Ken)" "Mon, 24 Jun 2013 08:50:00 +0000" "<p dir=\"ltr\">Given a Haskell record data type, transform it so that each of its fields becomes a Maybe type, and do this recursively into subrecords, including the top level.</p><p dir=\"ltr\">data Foo = Foo Int String ; data Bar = Bar Foo Float</p><p dir=\"ltr\">data FooM = FooM (Maybe Int) (Maybe String) ; type MFoo = Maybe FooM ; data BarM = BarM MFoo (Maybe Float) ; type MBar = Maybe BarM</p><p dir=\"ltr\">Next, transform a function that operates on the original non-Maybe type to work on the new type, inserting Nothing when there is missing needed data.  This is very similar to liftM except deep.  Simple example:</p><p dir=\"ltr\">f :: (Foo -> Bar) -> (MFoo -> MBar)</p><p dir=\"ltr\">This has some feel of reifying laziness: where Foo had a bottom value, MFoo can have a Nothing.</p><p dir=\"ltr\">Given a Nothing in one of the fields of the output, get a trace of which operation in the function, and which Nothing in the input, caused it.</p><p dir=\"ltr\">Generalize to any MonadPlus.</p><p dir=\"ltr\">Avoid confusion between Maybes inserted by this transformation and Maybes that which were present in the original data type.  Perhaps it should be a different Maybe.</p><p dir=\"ltr\">Somewhat inspired by databases which permit \"undefined\" in any field.</p><p dir=\"ltr\">No actual application in mind for this, yet.</p>" nil nil "d8755ee462a2d5e8dd1e6796f5a0eaba") (86 (20935 65032 470491) "http://theorylunch.wordpress.com/2013/05/30/when-does-an-endofunctor-derive-from-an-adjunction/" "Theory Lunch (Institute of Cybernetics, Tallinn): When does an endofunctor derive from an adjunction?" nil "Sun, 23 Jun 2013 15:23:28 +0000" "<p>This is the first of two talks based on Andrea Schalk’s very good introduction to monads, which can be retrieved <a href=\"http://www.cs.man.ac.uk/~schalk/notes/monads.pdf\" target=\"_blank\" title=\"http://www.cs.man.ac.uk/~schalk/notes/monads.pdf‎\">HERE</a></p>
<p>In the following, if <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> is a category, we indicate by <img src=\"http://s0.wp.com/latex.php?latex=%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"|\\mathcal{C}|\" class=\"latex\" title=\"|\\mathcal{C}|\" /> the collection of objects of <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" />, and by <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D%28A%2CB%29&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}(A,B)\" class=\"latex\" title=\"\\mathcal{C}(A,B)\" /> the collection of morphisms in <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> from <img src=\"http://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=333333&s=0\" alt=\"A\" class=\"latex\" title=\"A\" /> to <img src=\"http://s0.wp.com/latex.php?latex=B&bg=ffffff&fg=333333&s=0\" alt=\"B\" class=\"latex\" title=\"B\" />.</p>
<p>As we know, there are two basic ways of defining an adjunction: <span id=\"more-768\"></span></p>
<p><strong>Definition 1.</strong> Let <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{D}\" class=\"latex\" title=\"\\mathcal{D}\" /> be categories; let <img src=\"http://s0.wp.com/latex.php?latex=F+%3A+%5Cmathcal%7BC%7D+%5Cto+%5Cmathcal%7BD%7D&bg=ffffff&fg=333333&s=0\" alt=\"F : \\mathcal{C} \\to \\mathcal{D}\" class=\"latex\" title=\"F : \\mathcal{C} \\to \\mathcal{D}\" /> and <img src=\"http://s0.wp.com/latex.php?latex=G+%3A+%5Cmathcal%7BD%7D+%5Cto+%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"G : \\mathcal{D} \\to \\mathcal{C}\" class=\"latex\" title=\"G : \\mathcal{D} \\to \\mathcal{C}\" /> be functors. An <em>adjunction</em> from <img src=\"http://s0.wp.com/latex.php?latex=F&bg=ffffff&fg=333333&s=0\" alt=\"F\" class=\"latex\" title=\"F\" /> to <img src=\"http://s0.wp.com/latex.php?latex=G&bg=ffffff&fg=333333&s=0\" alt=\"G\" class=\"latex\" title=\"G\" />, written <img src=\"http://s0.wp.com/latex.php?latex=F+%5Cdashv+G&bg=ffffff&fg=333333&s=0\" alt=\"F \\dashv G\" class=\"latex\" title=\"F \\dashv G\" />, is a quadruple <img src=\"http://s0.wp.com/latex.php?latex=%28F%2CG%2C%5Ceta%2C%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F,G,\\eta,\\varepsilon)\" class=\"latex\" title=\"(F,G,\\eta,\\varepsilon)\" /> where <img src=\"http://s0.wp.com/latex.php?latex=%5Ceta%3A+%5Cmathrm%7BId%7D_%5Cmathcal%7BC%7D+%5Cto+GF&bg=ffffff&fg=333333&s=0\" alt=\"\\eta: \\mathrm{Id}_\\mathcal{C} \\to GF\" class=\"latex\" title=\"\\eta: \\mathrm{Id}_\\mathcal{C} \\to GF\" /> (the <em>unit</em> of the adjunction) and <img src=\"http://s0.wp.com/latex.php?latex=%5Cvarepsilon%3A+FG+%5Cto+%5Cmathrm%7BId%7D_%5Cmathcal%7BD%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\varepsilon: FG \\to \\mathrm{Id}_\\mathcal{D}\" class=\"latex\" title=\"\\varepsilon: FG \\to \\mathrm{Id}_\\mathcal{D}\" /> (the <em>counit</em>) are natural transformations such that , for every <img src=\"http://s0.wp.com/latex.php?latex=A+%5Cin+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"A \\in |\\mathcal{C}|\" class=\"latex\" title=\"A \\in |\\mathcal{C}|\" /> and <img src=\"http://s0.wp.com/latex.php?latex=S+%5Cin+%7C%5Cmathcal%7BD%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"S \\in |\\mathcal{D}|\" class=\"latex\" title=\"S \\in |\\mathcal{D}|\" />, <img src=\"http://s0.wp.com/latex.php?latex=G%5Cvarepsilon_S+%5Ccirc+%5Ceta_%7BGS%7D+%3D+%5Cmathrm%7Bid%7D_%7BGS%7D&bg=ffffff&fg=333333&s=0\" alt=\"G\\varepsilon_S \\circ \\eta_{GS} = \\mathrm{id}_{GS}\" class=\"latex\" title=\"G\\varepsilon_S \\circ \\eta_{GS} = \\mathrm{id}_{GS}\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cvarepsilon_%7BFA%7D+%5Ccirc+F%5Ceta_%7BA%7D+%3D+%5Cmathrm%7Bid%7D_%7BFA%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\varepsilon_{FA} \\circ F\\eta_{A} = \\mathrm{id}_{FA}\" class=\"latex\" title=\"\\varepsilon_{FA} \\circ F\\eta_{A} = \\mathrm{id}_{FA}\" />.</p>
<p><strong>Definition 2.</strong> Let <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{D}\" class=\"latex\" title=\"\\mathcal{D}\" /> be categories. We call <em>adjunction quadruple</em> a quadruple <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Csharp%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, (\\cdot)^\\sharp)\" class=\"latex\" title=\"(F, G, \\eta, (\\cdot)^\\sharp)\" /> such that:</p>
<ol>
<li><img src=\"http://s0.wp.com/latex.php?latex=G+%3A+%5Cmathcal%7BD%7D+%5Cto+%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"G : \\mathcal{D} \\to \\mathcal{C}\" class=\"latex\" title=\"G : \\mathcal{D} \\to \\mathcal{C}\" /> is a functor,</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=F+%3A+%7C%5Cmathcal%7BC%7D%7C+%5Cto+%7C%5Cmathcal%7BD%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"F : |\\mathcal{C}| \\to |\\mathcal{D}|\" class=\"latex\" title=\"F : |\\mathcal{C}| \\to |\\mathcal{D}|\" /> is a mapping, and</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%5Ceta&bg=ffffff&fg=333333&s=0\" alt=\"\\eta\" class=\"latex\" title=\"\\eta\" /> associates to every object <img src=\"http://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=333333&s=0\" alt=\"A\" class=\"latex\" title=\"A\" /> a morphism <img src=\"http://s0.wp.com/latex.php?latex=%5Ceta_A+%3A+A+%5Cto+GFA&bg=ffffff&fg=333333&s=0\" alt=\"\\eta_A : A \\to GFA\" class=\"latex\" title=\"\\eta_A : A \\to GFA\" /> so that</li>
<li>for every <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+A+%5Cto+GS&bg=ffffff&fg=333333&s=0\" alt=\"f : A \\to GS\" class=\"latex\" title=\"f : A \\to GS\" /> there exists a unique <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Csharp+%3A+FA+%5Cto+S&bg=ffffff&fg=333333&s=0\" alt=\"f^\\sharp : FA \\to S\" class=\"latex\" title=\"f^\\sharp : FA \\to S\" /> such that <img src=\"http://s0.wp.com/latex.php?latex=Gf%5E%5Csharp+%5Ccirc+%5Ceta_A+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"Gf^\\sharp \\circ \\eta_A = f\" class=\"latex\" title=\"Gf^\\sharp \\circ \\eta_A = f\" />.</li>
</ol>
<p>The two definitions above are equivalent in the following sense. If <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> is an adjunction according to Definition 1, and <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Csharp+%3D+%5Cvarepsilon_S+%5Ccirc+Ff&bg=ffffff&fg=333333&s=0\" alt=\"f^\\sharp = \\varepsilon_S \\circ Ff\" class=\"latex\" title=\"f^\\sharp = \\varepsilon_S \\circ Ff\" />, then <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Csharp%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, (\\cdot)^\\sharp)\" class=\"latex\" title=\"(F, G, \\eta, (\\cdot)^\\sharp)\" /> is an adjunction quadruple according to Definition 2. On the other hand, if <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Cast%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, (\\cdot)^\\ast)\" class=\"latex\" title=\"(F, G, \\eta, (\\cdot)^\\ast)\" /> is an adjunction quadruple according to Definition 2, and <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ccdot%29_%5Cflat&bg=ffffff&fg=333333&s=0\" alt=\"(\\cdot)_\\flat\" class=\"latex\" title=\"(\\cdot)_\\flat\" /> is the inverse operation of <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ccdot%29%5E%5Csharp&bg=ffffff&fg=333333&s=0\" alt=\"(\\cdot)^\\sharp\" class=\"latex\" title=\"(\\cdot)^\\sharp\" />—that is, <img src=\"http://s0.wp.com/latex.php?latex=g_%5Cflat+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"g_\\flat = f\" class=\"latex\" title=\"g_\\flat = f\" /> if and only if <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Csharp+%3D+g&bg=ffffff&fg=333333&s=0\" alt=\"f^\\sharp = g\" class=\"latex\" title=\"f^\\sharp = g\" />—then necessarily <img src=\"http://s0.wp.com/latex.php?latex=%5Ceta_A+%3D+%28%5Cmathrm%7Bid%7D_%7BFA%7D%29_%5Cflat&bg=ffffff&fg=333333&s=0\" alt=\"\\eta_A = (\\mathrm{id}_{FA})_\\flat\" class=\"latex\" title=\"\\eta_A = (\\mathrm{id}_{FA})_\\flat\" />, and by putting <img src=\"http://s0.wp.com/latex.php?latex=Ff+%3D+%28%5Ceta_B+%5Ccirc+f%29%5E%5Csharp&bg=ffffff&fg=333333&s=0\" alt=\"Ff = (\\eta_B \\circ f)^\\sharp\" class=\"latex\" title=\"Ff = (\\eta_B \\circ f)^\\sharp\" /> for <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D%28A%2CB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}(A,B)\" class=\"latex\" title=\"f \\in \\mathcal{C}(A,B)\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cvarepsilon_S+%3D+%28%5Cmathrm%7Bid%7D_%7BGS%7D%29%5E%5Csharp&bg=ffffff&fg=333333&s=0\" alt=\"\\varepsilon_S = (\\mathrm{id}_{GS})^\\sharp\" class=\"latex\" title=\"\\varepsilon_S = (\\mathrm{id}_{GS})^\\sharp\" /> for <img src=\"http://s0.wp.com/latex.php?latex=S+%5Cin+%7C%5Cmathcal%7BD%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"S \\in |\\mathcal{D}|\" class=\"latex\" title=\"S \\in |\\mathcal{D}|\" /> we define an adjunction according to Definition 1.</p>
<p>If <img src=\"http://s0.wp.com/latex.php?latex=%28F%2CG%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F,G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F,G, \\eta, \\varepsilon)\" /> is an adjunction, then <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+GF+%3A+%5Cmathcal%7BC%7D+%5Cto+%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"T = GF : \\mathcal{C} \\to \\mathcal{C}\" class=\"latex\" title=\"T = GF : \\mathcal{C} \\to \\mathcal{C}\" /> is an endofunctor.The first question that comes to our mind is:</p>
<p style=\"text-align: center;\"><em>when does an endofunctor derive from an adjunction?</em></p>
<p>Let us check some basic properties such an endofunctor must satisfy. First of all, <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu+%3A+T%5E2+%5Cto+T&bg=ffffff&fg=333333&s=0\" alt=\"\\mu : T^2 \\to T\" class=\"latex\" title=\"\\mu : T^2 \\to T\" /> defined by <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%3D+G%5Cvarepsilon_%7BFA%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A = G\\varepsilon_{FA}\" class=\"latex\" title=\"\\mu_A = G\\varepsilon_{FA}\" /> is a natural transformation and satisfies</p>
<p style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%5Ccirc+T%5Ceta_A+%3D+%5Cmu_A+%5Ccirc+%5Ceta_%7BTA%7D+%3D+%5Cmathrm%7Bid%7D_%7BTA%7D+%5C%3B%5C%3B+%5Cforall+A+%5Cin+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A \\circ T\\eta_A = \\mu_A \\circ \\eta_{TA} = \\mathrm{id}_{TA} \\;\\; \\forall A \\in |\\mathcal{C}|\" class=\"latex\" title=\"\\mu_A \\circ T\\eta_A = \\mu_A \\circ \\eta_{TA} = \\mathrm{id}_{TA} \\;\\; \\forall A \\in |\\mathcal{C}|\" /></p>
<p style=\"text-align: left;\">Moreover, as <img src=\"http://s0.wp.com/latex.php?latex=%5Cvarepsilon+%3A+FG+%5Cto+%5Cmathrm%7BId%7D_%7B%5Cmathcal%7BD%7D%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\varepsilon : FG \\to \\mathrm{Id}_{\\mathcal{D}}\" class=\"latex\" title=\"\\varepsilon : FG \\to \\mathrm{Id}_{\\mathcal{D}}\" /> is a natural transformation, by choosing <img src=\"http://s0.wp.com/latex.php?latex=f+%3D+%5Cvarepsilon_%7BFA%7D&bg=ffffff&fg=333333&s=0\" alt=\"f = \\varepsilon_{FA}\" class=\"latex\" title=\"f = \\varepsilon_{FA}\" /> we get <img src=\"http://s0.wp.com/latex.php?latex=%5Cvarepsilon_%7BFA%7D+%5Ccirc+%5Cvarepsilon_%7BFGFA%7D+%3D+%5Cvarepsilon_%7BFA%7D+%5Ccirc+FG%5Cvarepsilon_%7BFA%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\varepsilon_{FA} \\circ \\varepsilon_{FGFA} = \\varepsilon_{FA} \\circ FG\\varepsilon_{FA}\" class=\"latex\" title=\"\\varepsilon_{FA} \\circ \\varepsilon_{FGFA} = \\varepsilon_{FA} \\circ FG\\varepsilon_{FA}\" />, which after an application of <img src=\"http://s0.wp.com/latex.php?latex=G&bg=ffffff&fg=333333&s=0\" alt=\"G\" class=\"latex\" title=\"G\" /> yields</p>
<p style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%5Ccirc+%5Cmu_%7BTA%7D+%3D+%5Cmu_A+%5Ccirc+T%5Cmu_A+%5C%3B%5C%3B+%5Cforall+A+%5Cin+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A \\circ \\mu_{TA} = \\mu_A \\circ T\\mu_A \\;\\; \\forall A \\in |\\mathcal{C}|\" class=\"latex\" title=\"\\mu_A \\circ \\mu_{TA} = \\mu_A \\circ T\\mu_A \\;\\; \\forall A \\in |\\mathcal{C}|\" /></p>
<p style=\"text-align: left;\">It will turn out that these two properties are precisely what we need.</p>
<p style=\"text-align: left;\"><strong>Definition 3.</strong> A <em>monad</em> on a category <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> is a triple <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+%28T%2C+%5Ceta%2C+%5Cmu%29&bg=ffffff&fg=333333&s=0\" alt=\"T = (T, \\eta, \\mu)\" class=\"latex\" title=\"T = (T, \\eta, \\mu)\" /> where:</p>
<ol>
<li><img src=\"http://s0.wp.com/latex.php?latex=T+%3A+%5Cmathcal%7BC%7D+%5Cto+%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"T : \\mathcal{C} \\to \\mathcal{C}\" class=\"latex\" title=\"T : \\mathcal{C} \\to \\mathcal{C}\" /> is an endofunctor,</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%5Ceta+%3A+%5Cmathrm%7BId%7D_%5Cmathcal%7BC%7D+%5Cto+T&bg=ffffff&fg=333333&s=0\" alt=\"\\eta : \\mathrm{Id}_\\mathcal{C} \\to T\" class=\"latex\" title=\"\\eta : \\mathrm{Id}_\\mathcal{C} \\to T\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu%3A+T%5E2+%5Cto+T&bg=ffffff&fg=333333&s=0\" alt=\"\\mu: T^2 \\to T\" class=\"latex\" title=\"\\mu: T^2 \\to T\" /> are natural transformations, and</li>
<li>for every <img src=\"http://s0.wp.com/latex.php?latex=A+%5Cin+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"A \\in |\\mathcal{C}|\" class=\"latex\" title=\"A \\in |\\mathcal{C}|\" /> we have <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%5Ccirc+%5Ceta_%7BTA%7D+%3D+%5Cmu_A+%5Ccirc+T%5Ceta_A+%3D+%5Cmathrm%7Bid%7D_%7BTA%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A \\circ \\eta_{TA} = \\mu_A \\circ T\\eta_A = \\mathrm{id}_{TA}\" class=\"latex\" title=\"\\mu_A \\circ \\eta_{TA} = \\mu_A \\circ T\\eta_A = \\mathrm{id}_{TA}\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%5Ccirc+%5Cmu_%7BTA%7D+%3D+%5Cmu_A+%5Ccirc+T%5Cmu_A&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A \\circ \\mu_{TA} = \\mu_A \\circ T\\mu_A\" class=\"latex\" title=\"\\mu_A \\circ \\mu_{TA} = \\mu_A \\circ T\\mu_A\" />,</li>
</ol>
<p>As a very basic example, the <em>free monoid</em> construction is a monad on <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathbf%7BSet%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathbf{Set}\" class=\"latex\" title=\"\\mathbf{Set}\" />, where <img src=\"http://s0.wp.com/latex.php?latex=TA+%3D+A%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"TA = A^\\ast\" class=\"latex\" title=\"TA = A^\\ast\" />, <img src=\"http://s0.wp.com/latex.php?latex=Tf%28s%29+%3D+%5Bf%28a%29+%5C%3B+%5Cmathtt%7Bfor%7D+%5C%3B+a+%5C%3B+%5Cmathtt%7Bin%7D+%5C%3B+s%5D&bg=ffffff&fg=333333&s=0\" alt=\"Tf(s) = [f(a) \\; \\mathtt{for} \\; a \\; \\mathtt{in} \\; s]\" class=\"latex\" title=\"Tf(s) = [f(a) \\; \\mathtt{for} \\; a \\; \\mathtt{in} \\; s]\" />, <img src=\"http://s0.wp.com/latex.php?latex=%5Ceta_A%28a%29+%3D+%5Ba%5D&bg=ffffff&fg=333333&s=0\" alt=\"\\eta_A(a) = [a]\" class=\"latex\" title=\"\\eta_A(a) = [a]\" />, and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A%28%5B%5Ba%5E1_1%2C+%5Cldots%2C+a%5E1_%7Bn_1%7D%5D%2C+%5Cldots%2C+%5Ba%5Em_1%2C+%5Cldots%2C+a%5Em_%7Bn_m%7D%5D%5D+%3D+%5Ba%5E1_1%2C+%5Cldots%2C+a%5E1_%7Bn_1%7D%2C+%5Cldots%2C+a%5Em_1%2C+%5Cldots%2C+a%5Em_%7Bn_m%7D%5D&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A([[a^1_1, \\ldots, a^1_{n_1}], \\ldots, [a^m_1, \\ldots, a^m_{n_m}]] = [a^1_1, \\ldots, a^1_{n_1}, \\ldots, a^m_1, \\ldots, a^m_{n_m}]\" class=\"latex\" title=\"\\mu_A([[a^1_1, \\ldots, a^1_{n_1}], \\ldots, [a^m_1, \\ldots, a^m_{n_m}]] = [a^1_1, \\ldots, a^1_{n_1}, \\ldots, a^m_1, \\ldots, a^m_{n_m}]\" />.</p>
<p>As a less basic example, suppose <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D+%3D+%28S%2C+%5Cleq%29&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C} = (S, \\leq)\" class=\"latex\" title=\"\\mathcal{C} = (S, \\leq)\" /> is a poset: what is a monad on <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" />? First of all, an endofunctor on a poset is a monotone function; next, if there is <img src=\"http://s0.wp.com/latex.php?latex=%5Ceta_A+%3A+A+%5Cto+TA&bg=ffffff&fg=333333&s=0\" alt=\"\\eta_A : A \\to TA\" class=\"latex\" title=\"\\eta_A : A \\to TA\" />, then <img src=\"http://s0.wp.com/latex.php?latex=A+%5Cleq+TA&bg=ffffff&fg=333333&s=0\" alt=\"A \\leq TA\" class=\"latex\" title=\"A \\leq TA\" />; finally, if there is <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%3A+T%5E2A+%5Cto+TA&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A : T^2A \\to TA\" class=\"latex\" title=\"\\mu_A : T^2A \\to TA\" />, then <img src=\"http://s0.wp.com/latex.php?latex=T%5E2A+%5Cleq+TA&bg=ffffff&fg=333333&s=0\" alt=\"T^2A \\leq TA\" class=\"latex\" title=\"T^2A \\leq TA\" />, which together with the previous inequality yields <img src=\"http://s0.wp.com/latex.php?latex=T%5E2A+%3D+TA&bg=ffffff&fg=333333&s=0\" alt=\"T^2A = TA\" class=\"latex\" title=\"T^2A = TA\" />. On the other hand, any nondecreasing idempotent is the endofunctor component of a monad: the monad equations are actually ensured by <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> being a poset, so that any two maps with same domain and same codomain are equal.</p>
<p>We then restate our original problem as follows:</p>
<p style=\"text-align: center;\"><em>given a monad <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+%28T%2C+%5Ceta%2C+%5Cmu%29&bg=ffffff&fg=333333&s=0\" alt=\"T = (T, \\eta, \\mu)\" class=\"latex\" title=\"T = (T, \\eta, \\mu)\" />, find an adjunction <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> such that <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+GF&bg=ffffff&fg=333333&s=0\" alt=\"T = GF\" class=\"latex\" title=\"T = GF\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu+%3D+G+%5Cvarepsilon_F&bg=ffffff&fg=333333&s=0\" alt=\"\\mu = G \\varepsilon_F\" class=\"latex\" title=\"\\mu = G \\varepsilon_F\" /></em></p>
<p>If the adjunction <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> solves the problem above, we say that it <em>generates</em> the monad <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />.</p>
<p>The first solution to this problem was given by the Swiss mathematician Heinrich Kleisli, and is based on an alternative way of defining monads, as it is the case with adjunctions. Let us suppose <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+GF&bg=ffffff&fg=333333&s=0\" alt=\"T = GF\" class=\"latex\" title=\"T = GF\" /> with <img src=\"http://s0.wp.com/latex.php?latex=F+%5Cdashv+G&bg=ffffff&fg=333333&s=0\" alt=\"F \\dashv G\" class=\"latex\" title=\"F \\dashv G\" />. If <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+A+%5Cto+TB+%3D+G%28FB%29&bg=ffffff&fg=333333&s=0\" alt=\"f : A \\to TB = G(FB)\" class=\"latex\" title=\"f : A \\to TB = G(FB)\" />, then <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Csharp+%3A+FA+%5Cto+FB&bg=ffffff&fg=333333&s=0\" alt=\"f^\\sharp : FA \\to FB\" class=\"latex\" title=\"f^\\sharp : FA \\to FB\" />, so that <img src=\"http://s0.wp.com/latex.php?latex=Gf%5E%5Csharp+%3A+TA+%5Cto+TB&bg=ffffff&fg=333333&s=0\" alt=\"Gf^\\sharp : TA \\to TB\" class=\"latex\" title=\"Gf^\\sharp : TA \\to TB\" />: and we know from the definition of monad that <img src=\"http://s0.wp.com/latex.php?latex=Gf%5E%5Csharp+%5Ccirc+%5Ceta_A+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"Gf^\\sharp \\circ \\eta_A = f\" class=\"latex\" title=\"Gf^\\sharp \\circ \\eta_A = f\" />. We can thus define an operator <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ccdot%29%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"(\\cdot)^\\ast\" class=\"latex\" title=\"(\\cdot)^\\ast\" /> that takes <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D%28A%2CTB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}(A,TB)\" class=\"latex\" title=\"f \\in \\mathcal{C}(A,TB)\" /> into <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Cast+%5Cin+%5Cmathcal%7BC%7D%28TA%2CTB%29&bg=ffffff&fg=333333&s=0\" alt=\"f^\\ast \\in \\mathcal{C}(TA,TB)\" class=\"latex\" title=\"f^\\ast \\in \\mathcal{C}(TA,TB)\" /> in a way such that <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Cast+%5Ccirc+%5Ceta_A+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"f^\\ast \\circ \\eta_A = f\" class=\"latex\" title=\"f^\\ast \\circ \\eta_A = f\" /> whatever <img src=\"http://s0.wp.com/latex.php?latex=f&bg=ffffff&fg=333333&s=0\" alt=\"f\" class=\"latex\" title=\"f\" /> is. The simplest example is <img src=\"http://s0.wp.com/latex.php?latex=f+%3D+%5Ceta_A&bg=ffffff&fg=333333&s=0\" alt=\"f = \\eta_A\" class=\"latex\" title=\"f = \\eta_A\" /> itself, so that <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ceta_A%29%5E%5Cast+%5Ccirc+%5Ceta_A+%3D+%5Ceta_A&bg=ffffff&fg=333333&s=0\" alt=\"(\\eta_A)^\\ast \\circ \\eta_A = \\eta_A\" class=\"latex\" title=\"(\\eta_A)^\\ast \\circ \\eta_A = \\eta_A\" />, and <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ceta_A%29%5E%5Cast+%3D+%5Cmathrm%7Bid%7D_%7BTA%7D&bg=ffffff&fg=333333&s=0\" alt=\"(\\eta_A)^\\ast = \\mathrm{id}_{TA}\" class=\"latex\" title=\"(\\eta_A)^\\ast = \\mathrm{id}_{TA}\" /> by uniqueness in the definition of adjunction quadruple. Moreover, if <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+A+%5Cto+TB&bg=ffffff&fg=333333&s=0\" alt=\"f : A \\to TB\" class=\"latex\" title=\"f : A \\to TB\" /> and <img src=\"http://s0.wp.com/latex.php?latex=g+%3A+B+%5Cto+TC&bg=ffffff&fg=333333&s=0\" alt=\"g : B \\to TC\" class=\"latex\" title=\"g : B \\to TC\" />, then</p>
<p style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=g%5E%5Cast+%5Ccirc+f+%3D+Gg%5E%5Csharp+%5Ccirc+%28Gf%5E%5Csharp+%5Ccirc+%5Ceta_A%29+%3D+%28g%5E%5Cast+%5Ccirc+f%5E%5Cast%29+%5Ccirc+%5Ceta_A+%5C%3B%2C&bg=ffffff&fg=333333&s=0\" alt=\"g^\\ast \\circ f = Gg^\\sharp \\circ (Gf^\\sharp \\circ \\eta_A) = (g^\\ast \\circ f^\\ast) \\circ \\eta_A \\;,\" class=\"latex\" title=\"g^\\ast \\circ f = Gg^\\sharp \\circ (Gf^\\sharp \\circ \\eta_A) = (g^\\ast \\circ f^\\ast) \\circ \\eta_A \\;,\" /></p>
<p style=\"text-align: left;\">which implies <img src=\"http://s0.wp.com/latex.php?latex=%28g%5E%5Cast+%5Ccirc+f%29%5E%5Cast+%3D+g%5E%5Cast+%5Ccirc+f%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"(g^\\ast \\circ f)^\\ast = g^\\ast \\circ f^\\ast\" class=\"latex\" title=\"(g^\\ast \\circ f)^\\ast = g^\\ast \\circ f^\\ast\" /> by uniqueness.</p>
<p>This is the base of Kleisli’s solution to our problem, which we will discuss in a future talk.</p>
<br />  <a href=\"http://feeds.wordpress.com/1.0/gocomments/theorylunch.wordpress.com/768/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/theorylunch.wordpress.com/768/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=theorylunch.wordpress.com&blog=43735749&post=768&subd=theorylunch&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "4973b705109d4425d10f598efdefdd61") (85 (20935 65032 467399) "http://www.yesodweb.com/blog/2013/06/first-11-chapters" "Yesod Web Framework: First 11 chapters are Yesod 1.2-compliant" nil "Sun, 23 Jun 2013 13:00:00 +0000" "<p>It's been a while since I've written a post. Besides being <a href=\"https://www.fpcomplete.com/blog/2013/06/beta-sign-up\">very busy at
work</a>, a lot of my time
has gone into getting the Yesod book up-to-date with Yesod version 1.2. And
today, I'm happy to report that the first 11 chapters, comprising the \"basics\"
section of the book, have been converted.</p><p>You can view the new content <a href=\"http://www.yesodweb.com/book-1.2\">at the 1.2
URL</a>. Once the entire book is converted, I'll
switch the URLs, but will continue hosting the 1.1 version of the book <a href=\"http://www.yesodweb.com/book-1.1\">at its
own URL</a>. I intend to continue this pattern
for any future releases as well.</p><p>I intend to continue the conversion process, but I also intend to augment the
book. In particular, I have a number of new examples to add. My current plans
are:</p><ul><li>JSON serving</li><li>Client-side development with Fay</li><li>An updated subsite example based on 1.2 features</li><li>Easy generation of streaming data</li><li>How to store some initialized data in the foundation</li><li>Getting configuration from environment variables</li><li>Writing your own Template Haskell code</li></ul><p>If anyone has suggestions for changes to this list, let me know.</p><p>As for the newly converted content: comments and pull requests are, as always,
welcome!</p>" nil nil "3c795352087b11fdabc0a4bccc2ce241") (84 (20935 65032 466886) "http://neilmitchell.blogspot.com/2013/06/building-llvm-using-shake.html" "Neil Mitchell: Building LLVM using Shake" "noreply@blogger.com (Neil Mitchell)" "Sun, 23 Jun 2013 09:33:08 +0000" "<i>Summary: You can now build LLVM using Shake, and a rebuild with nothing to do goes massively faster than make (0.8s vs 199s) and fractionally faster than Ninja (0.8s vs 0.9s).</i><br /><br />As of <a href=\"https://github.com/ndmitchell/shake\">Shake</a> 0.10.4 the <tt>shake</tt> tool can execute <a href=\"http://martine.github.io/ninja/\">Ninja</a> build files. <a href=\"http://llvm.org/\">LLVM</a> can be built with <a href=\"http://www.cmake.org/\">CMake</a>, and CMake can generate a Ninja build file, so you can compile LLVM with Shake. I've included the full steps I followed at the end of this post.<br /><br />The main thing I wanted to test was how fast a rebuild with nothing to do was using Shake vs Ninja, as Ninja prides itself on having \"a focus on speed\". When compiling LLVM on Windows with GCC, a nothing to do build using make takes 199s, Shake takes 0.8s and Ninja takes 0.9s. The CMake generator does not use one of the latest Ninja build features (the deps keyword), but if it did, Shake would be about 0.1s faster and Ninja would be at least 0.1s faster.<br /><br />Full builds with Shake and Ninja both take about the same time, but with anything higher than 2 CPUs the linker phase ends up contending heavily and the machine thrashes the disk, making robust measurements impossible. The solution would be to use <a href=\"http://neilmitchell.blogspot.co.uk/2013/02/summary-management-of-finite-resources.html\">finite resources</a> on the linkers, something that needs implementing in the CMake Ninja generator, and would then allow more CPUs to be used.<br /><br />Other than speed, why would you use Shake to compile LLVM?<br /><br /><ul><li>If you build with <tt>--report</tt> the file <tt>report.html</tt> will be generated. Open that report file and you can see numerous details about the build - how good the parallel utilisation was, what changed to cause what to rebuild, summary statistics, a dependency graph and more. See the Help page in any generated report for more details.</li><li>If you build with <tt>--progress</tt> the console titlebar will display a predicted completion time, how many seconds until your build completes. The predicted time will be fairly inaccurate the first time round, but future runs are influenced by recorded timings, and can produce useful guesses.</li><li>If your CPU has a preference for functional languages it will make the registers happier.</li></ul><br />Existing Ninja users may also be interested in <a href=\"https://github.com/ndmitchell/shake/blob/master/docs/Ninja.md\">a guide to running Ninja builds with Shake</a>, which gives a few more details on using Shake like Ninja.<br /><br /><b>Compiling LLVM with Shake</b><br /><br />These instructions are how I compiled LLVM with Shake, on Windows, with GCC. I didn't run into any significant problems, but there were two minor niggles I had to work though (both listed below). I compiled LLVM with make, then Ninja, then Shake, to check each phase as I went - but only the final Shake compile is actually necessary.<br /><br /><ul><li>Install Shake with <tt>cabal update && cabal install shake --global</tt>, if you are new to Haskell package installation, see <a href=\"https://github.com/ndmitchell/shake/blob/master/docs/Ninja.md#installing-shake\">here</a>.</li><li>Get LLVM and compile it with make, I followed the instructions at <tt>http://bencode.net/clangonwindows</tt>, which has disappeared in the last few days (I have emailed the web master to see where it went).</li><li>Install <a href=\"http://martine.github.io/ninja/\">Ninja</a>.</li><li>Run CMake over LLVM <a href=\"http://llvm.org/docs/CMake.html\">like this</a>, configuring with <tt>-G Ninja</tt>.</li><li>To build with Ninja I had to edit <tt>build.ninja</tt> line 17697 to delete <tt>lib/clang/3.4/lib/windows/libclang_rt.i386.a,</tt> which won't build on my system and isn't built at all by the make system - I suspect this is a tip/mingw issue. At this stage you can compile LLVM with Ninja.</li><li>Type <tt>touch tools/clang/lib/Basic/CMakeFiles/clang_revision_tag</tt> to create a dummy file. There is a Ninja rule to create such a file, but the rule is wrong since it doesn't actually produce the file, and Shake's sanity checking spots that.</li><li>Run <tt>shake -j2</tt> in the build directory. Come back later and you will have a build.</li><li>Run <tt>shake -j2</tt> again to enjoy the fast nothing to do build.</li></ul>" nil nil "4cfea6738477b821a9fd9630d728cda4") (83 (20935 65032 463950) "http://existentialtype.wordpress.com/2013/06/22/whats-the-big-deal-with-hott/" "Robert Harper: =?utf-8?Q?What=E2=80=99s?= the big deal with HoTT?" nil "Sun, 23 Jun 2013 00:25:39 +0000" "<p>Now that the <a href=\"http://homotopytypetheory.org/book\" target=\"_blank\" title=\"Homotopy Type Theory Book\">Homotopy Type Theory</a> book is out, a lot of people are asking “What’s the big deal?”.  The full answer lies within the book itself (or, at any rate, the fullest answer to date), but I am sure that many of us who were involved in its creation will be fielding this question in our own ways to help explain why we are so excited by it.  In fact what I think is really fascinating about HoTT is precisely that there are so many different ways to think about it, according to one’s interests and backgrounds.  For example, one might say it’s a nice way to phrase arguments in homotopy theory that avoids some of the technicalities in the classical proofs by treating spaces and paths synthetically, rather than analytically.  Or one might say that it’s a good language for mechanization of mathematics that provides for the concise formulation of proofs in a form that can be verified by a computer.  Or one might say that it points the way towards a vast extension of the concept of computation that enables us to compute with abstract geometric objects such as spheres or toruses.  Or one might say that it’s a new foundation for mathematics that subsumes set theory by generalizing types from mere sets to arbitrary infinity groupoids,  sets being but particularly simple types (those with no non-trivial higher-dimensional structure).</p>
<p>But what is it about HoTT that makes all these interpretations and applications possible?  What is the key idea that separates HoTT from other approaches that seek to achieve similar ends?  What makes HoTT so special?</p>
<p>In a word the answer is <em>constructivity.</em>  The distinctive feature of HoTT is that it is based on Per Martin-Löf’s Intuitionistic Theory of Types, which was formulated as a foundation for <em>intuitionistic mathematics</em> as originally put forth by Brouwer in the 1930′s, and further developed by Bishop, Gentzen, Heyting, Kolmogorov, Kleene, Lawvere, and Scott, among many others.  Briefly put, the idea of type theory is to codify and systematize the concept of a <em>mathematical construction</em> by characterizing the abstract properties, rather than the concrete realizations, of the objects used in everyday mathematics.  Brouwer’s key insight, which lies at the heart of HoTT, is that <em>proofs are a form of construction</em> no different in kind or character from numbers, geometric figures, spaces, mappings, groups, algebras, or any other mathematical structure.  <a href=\"http://existentialtype.wordpress.com/2012/08/11/extensionality-intensionality-and-brouwers-dictum/\" target=\"_blank\" title=\"Extensionality, Intensionality, and Brouwer’s Dictum\">Brouwer’s dictum</a>, which distinguished his approach from competing alternatives, is that <em>logic is a part of mathematics</em>, rather than <em>mathematics is an application of logic</em>.  Because for him the concept of a construction, including the concept of a proof, is prior to any other form of mathematical activity, including the study of proofs themselves (<em>i.e.</em>, logic).</p>
<p>So under Martin-Löf’s influence HoTT starts with the notion of <em>type</em> as a classification of the notion of <em>construction</em>, and builds upwards from that foundation.  Unlike competing approaches to foundations, <em>proofs are mathematical objects</em> that play a central role in the theory.  This conception is <em>central</em> to the homotopy-theoretic interpretation of type theory, which enriches types to encompass spaces with higher-dimensional structure.  Specifically, the type <img src=\"http://s0.wp.com/latex.php?latex=%5Ctextsf%7BId%7D_A%28M%2CN%29&bg=ffffff&fg=333333&s=0\" alt=\"\\textsf{Id}_A(M,N)\" class=\"latex\" title=\"\\textsf{Id}_A(M,N)\" /> is the type of <em>identifications</em> of <img src=\"http://s0.wp.com/latex.php?latex=M&bg=ffffff&fg=333333&s=0\" alt=\"M\" class=\"latex\" title=\"M\" /> and <img src=\"http://s0.wp.com/latex.php?latex=N&bg=ffffff&fg=333333&s=0\" alt=\"N\" class=\"latex\" title=\"N\" /> within the space <img src=\"http://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=333333&s=0\" alt=\"A\" class=\"latex\" title=\"A\" />.  Identifications may be thought of as <em>proofs</em> that <img src=\"http://s0.wp.com/latex.php?latex=M&bg=ffffff&fg=333333&s=0\" alt=\"M\" class=\"latex\" title=\"M\" /> and <img src=\"http://s0.wp.com/latex.php?latex=N&bg=ffffff&fg=333333&s=0\" alt=\"N\" class=\"latex\" title=\"N\" /> are <em>equal</em> as elements of $A$, or, equivalently, as <em>paths</em> in the space <img src=\"http://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=333333&s=0\" alt=\"A\" class=\"latex\" title=\"A\" /> between points <img src=\"http://s0.wp.com/latex.php?latex=M&bg=ffffff&fg=333333&s=0\" alt=\"M\" class=\"latex\" title=\"M\" /> and <img src=\"http://s0.wp.com/latex.php?latex=N&bg=ffffff&fg=333333&s=0\" alt=\"N\" class=\"latex\" title=\"N\" />.  The fundamental principles of abstraction at the heart of type theory ensure that <em>all constructs of the theory respect these identifications</em>, so that we may treat them as proofs of equality of two elements.  There are three main sources of identifications in HoTT:</p>
<ol>
<li>Reflexivity, stating that everything is equal to itself.</li>
<li>Higher inductive types, defining a type by giving its points, paths, paths between paths, and so on to any dimension.</li>
<li>Univalence, which states that an equivalence between types determines a path between them.</li>
</ol>
<p>I will not attempt here to explain each of these in any detail; everything you need to know is in the HoTT book.  But I will say a few things about their consequences, just to give a flavor of what these new principles give us.</p>
<p>Perhaps the most important conceptual point is that mathematics in HoTT emphasizes the <em>structure of proofs</em> rather than their mere existence.  Rather than settle for a mere logical equivalence between two types (mappings back and forth stating that each implies the other), one instead tends to examine the <em>entire space</em> of proofs of a proposition and how it relates to others.  For example, the univalence axiom itself does not merely state that every equivalence between types gives rise to a path between them, but rather that there is an <em>equivalence</em> between the type of equivalences between two types and the type of paths between them.  Familiar patterns such as “<img src=\"http://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=333333&s=0\" alt=\"A\" class=\"latex\" title=\"A\" /> iff <img src=\"http://s0.wp.com/latex.php?latex=B&bg=ffffff&fg=333333&s=0\" alt=\"B\" class=\"latex\" title=\"B\" />” tend to become “<img src=\"http://s0.wp.com/latex.php?latex=A%5Csimeq+B&bg=ffffff&fg=333333&s=0\" alt=\"A\\simeq B\" class=\"latex\" title=\"A\\simeq B\" />“, stating that the proofs of <img src=\"http://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=333333&s=0\" alt=\"A\" class=\"latex\" title=\"A\" /> and the proofs of <img src=\"http://s0.wp.com/latex.php?latex=B&bg=ffffff&fg=333333&s=0\" alt=\"B\" class=\"latex\" title=\"B\" /> are equivalent.  Of course one may <em>choose </em>neglect this additional information, stating only weaker forms of it using, say, truncation to suppress higher-dimensional information in a type, but the tendency is to <em>embrace</em> the structure and characterize the space of proofs as fully as possible.</p>
<p>A close second in importance is the <em>axiomatic freedom</em> afforded by constructive foundations.  This point has been made many times by many authors in many different settings, but has particular bite in HoTT.   The theory does not commit to (nor does it refute) the infamous <em>Law of the Excluded Middle</em> for arbitrary types: the type <img src=\"http://s0.wp.com/latex.php?latex=A%2B%28A%5Cto+%5Ctextbf%7B0%7D%29&bg=ffffff&fg=333333&s=0\" alt=\"A+(A\\to \\textbf{0})\" class=\"latex\" title=\"A+(A\\to \\textbf{0})\" /> need not always be inhabited.  This property of HoTT is absolutely essential to its expressive power.  Not only does it admit a wider range of interpretations than are possible with the Law included, but it also allows for the <em>selective imposition</em> of the Law where it is needed to recover a classical argument, or where it is important to distinguish the implications of decidability in a given situation.  (Here again I defer to the book itself for full details.)  Similar considerations arise in connection with the many forms of Choice that can be expressed in HoTT, some of which are outright provable, others of which are independent as they are in axiomatic set theory.</p>
<p>Thus, what makes HoTT so special is that it is a<em> constructive</em> theory of mathematics.  Historically, this has meant that it has a <em>computational</em> interpretation, expressed most vividly by the <a href=\"http://existentialtype.wordpress.com/2011/03/27/the-holy-trinity/\" target=\"_blank\" title=\"The Holy Trinity\"><em>propositions as types</em></a> principle.  And yet, for all of its promise, what HoTT currently lacks is a computational interpretation!  What, exactly, does it mean to <em>compute</em> with higher-dimensional objects?  At the moment it is difficult to say for sure, though there seem to be clear intuitions in at least some cases of how to “implement” such a rich type theory.  Alternatively, one may ask whether the term “constructive”, when construed in such a general setting, must inevitably involve a notion of computation.  While it seems obvious on computational grounds that the Law of the Excluded Middle should not be considered universally valid, it becomes less clear why it is so important to omit this Law (and, essentially, no other) in order to obtain the richness of HoTT when no computational interpretation is extant.  From my point of view understanding the <em>computational </em>meaning of higher-dimensional type theory is of paramount importance, because, for me, type theory is and always has been a <em>theory of computation</em> on which the entire edifice of mathematics ought to be built.</p>
<br />Filed under: <a href=\"http://existentialtype.wordpress.com/category/research/\">Research</a> Tagged: <a href=\"http://existentialtype.wordpress.com/tag/homotopy-theory/\">homotopy theory</a>, <a href=\"http://existentialtype.wordpress.com/tag/type-theory/\">type theory</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/existentialtype.wordpress.com/819/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/existentialtype.wordpress.com/819/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=existentialtype.wordpress.com&blog=2157150&post=819&subd=existentialtype&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "802b8f1e1f327b5f631f2d746645663c") (82 (20935 65032 462214) "http://neilmitchell.blogspot.com/2013/05/three-types-of-build-system-dependency.html" "Neil Mitchell: Three types of build-system dependency" "noreply@blogger.com (Neil Mitchell)" "Sat, 22 Jun 2013 21:05:27 +0000" "<i>Summary: There are three types of dependencies you might want to express in a build system, all of which are supported by Shake.</i><br /><br />A build system, at its heart, is a system which runs commands in an order satisfying user-specified dependencies. But what kind of dependencies can be expressed? This post describes three different types of dependency, only one of which is available in Make, but all of which are available in both <a href=\"https://github.com/ndmitchell/shake#readme\">Shake</a> and <a href=\"http://martine.github.io/ninja/\">Ninja</a>.<br /><br /><b>Feature 1: Static dependencies (available in every build system)</b><br /><br />The most basic form of dependency is a static dependency, where a rule produces an output from some inputs:<br /><br /><pre>-- In Make --<br />result.tar : file1 file2<br />    tar -cf result.tar file1 file2<br /><br />-- In Shake --<br />\"result.tar\" *> \\out -> do<br />    let deps = [\"file1\",\"file2\"]<br />    need deps<br />    cmd \"tar -cf\" [out] deps<br /></pre><br />This rule says that the file <tt>result.tar</tt> depends on the inputs <tt>file1</tt> and <tt>file2</tt>, and provides a command to build <tt>result.tar</tt>. Whenever <tt>file1</tt> or <tt>file2</tt> change, the command will be run, and <tt>result.tar</tt> will be built.<br /><br />Static dependencies occur in almost every build rule, and are supported by all build tools, including Make and Shake.<br /><br /><b>Feature 2: Dynamic dependencies (available in Shake, Ninja, Redo and tup)</b><br /><br />A more advanced dependency is where the list of dependencies itself depends on the results of previous dependencies. Imagine we want to build <tt>result.tar</tt> from the list of files stored in <tt>list.txt</tt>. The dependencies of <tt>result.tar</tt> cannot be specified statically, but depend on <i>the contents</i> of <tt>list.txt</tt>. In Shake we can write:<br /><br /><pre>\"result.tar\" *> \\out -> do<br />    need [\"list.txt\"]<br />    contents <- readFileLines \"list.txt\"<br />    need contents<br />    cmd \"tar -cf\" [out] contents<br /></pre><br />This rule describes how to build <tt>result.tar</tt>. We depend on (<tt>need</tt>) the file <tt>list.txt</tt>. We read each line from <tt>list.txt</tt> into the variable <tt>contents</tt> - being a list of the files that should go into <tt>result.tar</tt>. Next, we depend on all the files in <tt>contents</tt>, and finally call the <tt>tar</tt> program. If either <tt>list.txt</tt> changes, or any of the files listed by <tt>list.txt</tt> change, then <tt>result.tar</tt> will be rebuilt.<br /><br />This feature is necessary in almost every build system, yet is shockingly lacking from most build tools - I am only aware of it being available in <a href=\"https://github.com/ndmitchell/shake#readme\">Shake</a>, <a href=\"http://martine.github.io/ninja/\">Ninja</a>, <a href=\"https://github.com/apenwarr/redo#readme\">Redo</a> and <a href=\"http://gittup.org/tup/\">tup</a>. As a common example, in Make you might write:<br /><br /><pre>result.o : result.c result_header1.h result_header2.h<br />    gcc ...<br /></pre><br />The file <tt>result.o</tt> depends on both the C source file <tt>result.c</tt> and all headers that file includes. But listing the headers both in <tt>result.c</tt> with <tt>#include</tt> directives, and in the Makefile, is a brittle form of duplication. A better approach is for the build system to run <tt>gcc -M result.c</tt> and extract the includes from there. In Shake we can write:<br /><br /><pre>\"result.o\" *> \\out -> do<br />    let src = \"result.c\"<br />    Stdout stdout <- cmd \"gcc -MM\" [src]<br />    need $ src : drop 2 (words stdout)<br />    cmd \"gcc -o\" [out] \"-c\" [src]<br /></pre><br />My experience is that about a quarter of rules require some kind of additional dependency based on previous dependencies. While you can hack round some of the issues in Make, and people have become disturbingly adept at doing so, the result often only approximates the dependencies - building either too much or too little.<br /><br /><b>Feature 3: Multiple outputs from one rule (available in Shake and Ninja)</b><br /><br />The final feature is producing multiple outputs from one command, and is used far more rarely (perhaps one or two rules in a complex build system) - but when needed, is essential. Some programs, such as GHC, can produce two outputs with one command - compiling <tt>Foo.hs</tt> produces both <tt>Foo.o</tt> and <tt>Foo.hi</tt>. As a first approximation, the <tt>.o</tt> file depends on the entire contents of the source file, while the <tt>.hi</tt> file depends only on the type signatures. A single <tt>ghc</tt> invocation needs to do all the work to produce both, but often the <tt>.hi</tt> file will be left unchanged. In Shake we can write:<br /><br /><pre>[\"Foo.hi\",\"Foo.o\"] *>> \\_ -> do<br />    need [\"Foo.hs\"]<br />    cmd \"gcc -c Foo.hs\"<br /></pre><br />While it is often possible to construct a series of dependencies to approximate a single rule producing multiple outputs, it only works in some cases, and is brittle. The only build systems I am aware of which support multiple outputs are <a href=\"https://github.com/ndmitchell/shake#readme\">Shake</a> and <a href=\"http://martine.github.io/ninja/\">Ninja</a>.<br /><br /><b>Essential features</b><br /><br />My standard advice when people ask about writing a build system is \"don't\". If some existing build system (e.g. ghc --make or Cabal) is capable of building your project, use that instead. Custom build systems are necessary for many complex projects, but many projects are not complex. If you have decided your project is complex, you should use a build tool that can express complex dependencies, both for writing the initial system and to provide the flexibility to make the inevitable changes required.<br /><br />Looking only at dependency features, I would consider it unwise to start a complex build system using a tool other than Shake or Ninja, or perhaps either Redo or tup (if you accept the absence of multiple outputs from one rule).<br /><br />Weak dependency specification in build tools, particularly Make, has left its mark on many programs. I recently talked to some OCaml hackers complaining that their tools were not \"Make friendly\" because they produced multiple output files. I wonder what lengths other tools have gone to in order to cope with weak dependency specification...<br /><br /><b>Update:</b> The relative power of tup was reported as a comment, and it appears to have the necessary power, but I haven't yet checked. Following further research into Ninja I suspect it may not be as powerful as originally stated and may not have Feature 2, but am not yet sure." nil nil "172b752395a399a74033dcef53ac2e3f") (81 (20935 65032 460717) "http://twanvl.nl/blog/agda/subst-from-cong" "Twan van Laarhoven: Substitution from congruence in univalent OTT" nil "Sat, 22 Jun 2013 14:51:00 +0000" "<p>In this post I will show that in an univalence style observational type theory, it is enough to take congruence as a primitive, rather than the more complicated substitution or J axioms. This post is literate Agda, so here are some boring import declarations
</p><pre class=\"agda\"><span class=\"keyword\">module</span> <span class=\"varid\">subst-from-cong</span> <span class=\"keyword\">where</span>
<div class=\"empty-line\"></div>
<span class=\"keyword\">open</span> <span class=\"keyword\">import</span> <span class=\"conid\">Level</span>
<span class=\"keyword\">open</span> <span class=\"keyword\">import</span> <span class=\"conid\">Function</span>
<span class=\"keyword\">open</span> <span class=\"keyword\">import</span> <span class=\"conid\">Data.Unit</span>
<span class=\"keyword\">open</span> <span class=\"keyword\">import</span> <span class=\"conid\">Data.Bool</span>
<span class=\"keyword\">open</span> <span class=\"keyword\">import</span> <span class=\"conid\">Data.Empty</span>
<span class=\"keyword\">open</span> <span class=\"keyword\">import</span> <span class=\"conid\">Data.Product</span>
</pre><p>I will be using the standard propositional equality as a meta equality,
</p><pre class=\"agda\"><span class=\"keyword\">open</span> <span class=\"keyword\">import</span> <span class=\"conid\">Relation.Binary.PropositionalEquality</span> <span class=\"varid\">as</span> <span class=\"conid\">Meta</span> <span class=\"varid\">using</span> (<span class=\"keyglyph\">_</span><span class=\"varop\">≡</span><span class=\"keyglyph\">_</span>)
</pre><p>while postulating a path type (equality type) and its computation rules for me to prove things about,
</p><pre class=\"agda\"><span class=\"keyword\">postulate</span> <span class=\"conid\">Path</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span>} <span class=\"keyglyph\">→</span> (<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>
<span class=\"keyword\">postulate</span> <span class=\"varid\">refl</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span>} <span class=\"keyglyph\">→</span> (<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>) <span class=\"keyglyph\">→</span> (<span class=\"varid\">x</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">x</span>
</pre><p>The idea of Observational Type Theory (OTT) is that <tt><span class=\"conid\">Path</span></tt> is actually defined by case analysis on the structure of the argument type. For the finite types this is simple, there is a path if and only if the values are the same,
</p><pre class=\"agda\"><span class=\"keyword\">postulate</span> <span class=\"conid\">Path-⊤</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> ⊤ <span class=\"varid\">tt</span> <span class=\"varid\">tt</span> <span class=\"varop\">≡</span> ⊤
<div class=\"empty-line\"></div>
<span class=\"keyword\">postulate</span> <span class=\"conid\">Path-Bool00</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">Bool</span> <span class=\"varid\">false</span> <span class=\"varid\">false</span> <span class=\"varop\">≡</span> ⊤
<span class=\"keyword\">postulate</span> <span class=\"conid\">Path-Bool01</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">Bool</span> <span class=\"varid\">false</span> <span class=\"varid\">true</span> <span class=\"varop\">≡</span> ⊥
<span class=\"keyword\">postulate</span> <span class=\"conid\">Path-Bool10</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">Bool</span> <span class=\"varid\">true</span> <span class=\"varid\">false</span> <span class=\"varop\">≡</span> ⊥
<span class=\"keyword\">postulate</span> <span class=\"conid\">Path-Bool11</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">Bool</span> <span class=\"varid\">true</span> <span class=\"varid\">true</span> <span class=\"varop\">≡</span> ⊤
</pre><p>A path for functions is a function to paths, which also means that we have functional extensionality.
</p><pre class=\"agda\"><span class=\"conid\">Π</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} (<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>) (<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> (<span class=\"varid\">a</span> ⊔ <span class=\"varid\">b</span>)
<span class=\"conid\">Π</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span> <span class=\"keyglyph\">=</span> (<span class=\"varid\">x</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span> <span class=\"varid\">x</span>
<div class=\"empty-line\"></div>
<span class=\"keyword\">postulate</span> <span class=\"conid\">Path-Π</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>} (<span class=\"varid\">f</span> <span class=\"varid\">g</span> <span class=\"varop\">:</span> <span class=\"conid\">Π</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>)
<span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">Π</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>) <span class=\"varid\">f</span> <span class=\"varid\">g</span> <span class=\"varop\">≡</span> ((<span class=\"varid\">x</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">B</span> <span class=\"varid\">x</span>) (<span class=\"varid\">f</span> <span class=\"varid\">x</span>) (<span class=\"varid\">g</span> <span class=\"varid\">x</span>))
</pre><p>In their <a href=\"http://www.cs.nott.ac.uk/~txa/publ/obseqnow.pdf\">original OTT paper</a>, Alternkirch et.al. defined equality for types also by structure matching. I.e. Π types are equal to Π types with equal arguments, Σ types are equal to Σ types, etc.
But this is incompatible with the univalence axiom from Homotopy Type Theory. That axiom states that equivalent or isomorphic types are equal. So, what happens if we take isomorphism as our definition of equality between types?
</p><pre class=\"agda\"><span class=\"conid\">Iso</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span>} <span class=\"keyglyph\">→</span> (<span class=\"conid\">A</span> <span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>
<span class=\"conid\">Iso</span> {<span class=\"varid\">a</span>} <span class=\"conid\">A</span> <span class=\"conid\">B</span>
<span class=\"keyglyph\">=</span> <span class=\"conid\">Σ</span> (<span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>) <span class=\"keyglyph\">\\</span><span class=\"varid\">fw</span> <span class=\"keyglyph\">→</span>
<span class=\"conid\">Σ</span> (<span class=\"conid\">B</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">A</span>) <span class=\"keyglyph\">\\</span><span class=\"varid\">bw</span> <span class=\"keyglyph\">→</span>
(<span class=\"keyglyph\">∀</span> <span class=\"varid\">x</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> (<span class=\"varid\">bw</span> (<span class=\"varid\">fw</span> <span class=\"varid\">x</span>)) <span class=\"varid\">x</span>) ×
(<span class=\"keyglyph\">∀</span> <span class=\"varid\">y</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">B</span> (<span class=\"varid\">fw</span> (<span class=\"varid\">bw</span> <span class=\"varid\">y</span>)) <span class=\"varid\">y</span>)
<div class=\"empty-line\"></div>
<span class=\"varid\">id-Iso</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span>} <span class=\"keyglyph\">→</span> (<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">Iso</span> <span class=\"conid\">A</span> <span class=\"conid\">A</span>
<span class=\"varid\">id-Iso</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">=</span> (<span class=\"varid\">id</span> , <span class=\"varid\">id</span> , <span class=\"varid\">refl</span> <span class=\"conid\">A</span> , <span class=\"varid\">refl</span> <span class=\"conid\">A</span>)
<div class=\"empty-line\"></div>
<span class=\"keyword\">postulate</span> <span class=\"conid\">Path-Type</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span>} (<span class=\"conid\">A</span> <span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>)
<span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">Set</span> <span class=\"varid\">a</span>) <span class=\"conid\">A</span> <span class=\"conid\">B</span> <span class=\"varop\">≡</span> <span class=\"conid\">Lift</span> {<span class=\"varid\">a</span>} {<span class=\"varid\">suc</span> <span class=\"varid\">a</span>} (<span class=\"conid\">Iso</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>)
</pre><p>Now suppose that we have a congruence, i.e. that all functions preserve paths. So from a path between <tt><span class=\"varid\">x</span></tt> and <tt><span class=\"varid\">y</span></tt>, we can construct a path between <tt class=\"complex\"><span class=\"varid\">f</span> <span class=\"varid\">x</span></tt> and <tt class=\"complex\"><span class=\"varid\">f</span> <span class=\"varid\">y</span></tt> for any function <tt><span class=\"varid\">f</span></tt>.
</p><pre class=\"agda\"><span class=\"comment\">-- we have congruence for non-dependent functions</span>
<span class=\"keyword\">postulate</span> <span class=\"varid\">cong</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>}
<span class=\"keyglyph\">→</span> (<span class=\"varid\">f</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>) <span class=\"keyglyph\">→</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">x</span> <span class=\"varid\">y</span>} <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">B</span> (<span class=\"varid\">f</span> <span class=\"varid\">x</span>) (<span class=\"varid\">f</span> <span class=\"varid\">y</span>)
</pre><p>Then this is enough to define substitution, since the paths for a type <tt class=\"complex\"><span class=\"conid\">B</span> <span class=\"varid\">x</span></tt> are isomorphisms, and we can apply these in the forward direction
</p><pre class=\"agda\"><span class=\"varid\">subst</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} (<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>) {<span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>} <span class=\"keyglyph\">→</span> (<span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span> <span class=\"varid\">x</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span> <span class=\"varid\">y</span>
<span class=\"varid\">subst</span> <span class=\"conid\">B</span> {<span class=\"varid\">x</span>} {<span class=\"varid\">y</span>} <span class=\"varid\">p</span> <span class=\"varid\">with</span> <span class=\"varid\">Meta.subst</span> <span class=\"varid\">id</span> (<span class=\"conid\">Path-Type</span> (<span class=\"conid\">B</span> <span class=\"varid\">x</span>) (<span class=\"conid\">B</span> <span class=\"varid\">y</span>)) (<span class=\"varid\">cong</span> <span class=\"conid\">B</span> <span class=\"varid\">p</span>)
<span class=\"varop\">...</span> <span class=\"keyglyph\">|</span> <span class=\"varid\">lift</span> (<span class=\"varid\">fw</span> , <span class=\"varid\">bw</span> , <span class=\"keyglyph\">_</span> , <span class=\"keyglyph\">_</span>) <span class=\"keyglyph\">=</span> <span class=\"varid\">fw</span>
</pre><p>With substitution we can now finally define what paths are for dependent Σ types.
A path between pairs is a pair of paths,
</p><pre class=\"agda\"><span class=\"keyword\">postulate</span> <span class=\"conid\">Path-Σ</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>} (<span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">Σ</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>)
<span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">Σ</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>) <span class=\"varid\">x</span> <span class=\"varid\">y</span>
<span class=\"varop\">≡</span> <span class=\"conid\">Σ</span> (<span class=\"conid\">Path</span> <span class=\"conid\">A</span> (<span class=\"varid\">proj₁</span> <span class=\"varid\">x</span>) (<span class=\"varid\">proj₁</span> <span class=\"varid\">y</span>))
(<span class=\"keyglyph\">\\</span><span class=\"varid\">pa</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">B</span> (<span class=\"varid\">proj₁</span> <span class=\"varid\">y</span>)) (<span class=\"varid\">subst</span> <span class=\"conid\">B</span> <span class=\"varid\">pa</span> (<span class=\"varid\">proj₂</span> <span class=\"varid\">x</span>)) (<span class=\"varid\">proj₂</span> <span class=\"varid\">y</span>))
</pre><p>Substitution is not the most general eliminator for paths.
It is not enough to prove properties about paths. For that we need the general induction principle for paths, often called J
</p><pre class=\"agda\"><span class=\"conid\">J</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"varid\">x</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>} <span class=\"keyglyph\">→</span> (<span class=\"conid\">B</span> <span class=\"varop\">:</span> (<span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>)
<span class=\"keyglyph\">→</span> {<span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>} <span class=\"keyglyph\">→</span> (<span class=\"varid\">p</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span> <span class=\"varid\">x</span> (<span class=\"varid\">refl</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span> <span class=\"varid\">y</span> <span class=\"varid\">p</span>
</pre><p>Unfortunately, I was unable to prove J from just congruence. For that I needed an additional lemma,
</p><pre class=\"agda\"><span class=\"keyword\">postulate</span> <span class=\"varid\">subst-refl</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>} <span class=\"keyglyph\">→</span> (<span class=\"varid\">p</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span>)
<span class=\"keyglyph\">→</span> <span class=\"varid\">p</span> <span class=\"varop\">≡</span> <span class=\"varid\">subst</span> (<span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span>) <span class=\"varid\">p</span> (<span class=\"varid\">refl</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span>)
</pre><p>Since <tt class=\"complex\"><span class=\"conid\">Path</span> <span class=\"conid\">A</span></tt> is inductively defined, I believe that <tt class=\"complex\"><span class=\"varid\">subst-refl</span></tt> should be provable by case analysis on <tt><span class=\"conid\">A</span></tt>, but I have not yet done so. We can now implement J by using <tt><span class=\"varid\">subst</span></tt> with a dependent pair.
Note that here I have to manually apply the comptuation rules for <tt class=\"complex\"><span class=\"conid\">Path</span> (<span class=\"conid\">Σ</span> <span class=\"keyglyph\">_</span> <span class=\"keyglyph\">_</span>)</tt> and use the <tt class=\"complex\"><span class=\"varid\">subst-refl</span></tt> lemma.
</p><pre class=\"agda\"><span class=\"conid\">J</span> {<span class=\"conid\">A</span> <span class=\"keyglyph\">=</span> <span class=\"conid\">A</span>} {<span class=\"varid\">x</span> <span class=\"keyglyph\">=</span> <span class=\"varid\">x</span>} <span class=\"conid\">B</span> {<span class=\"varid\">y</span>} <span class=\"varid\">p</span>
<span class=\"keyglyph\">=</span> <span class=\"varid\">subst</span> (<span class=\"varid\">uncurry</span> <span class=\"conid\">B</span>)
(<span class=\"varid\">Meta.subst</span> <span class=\"varid\">id</span> (<span class=\"varid\">Meta.sym</span> <span class=\"varop\">$</span> <span class=\"conid\">Path-Σ</span> (<span class=\"varid\">x</span> , <span class=\"varid\">refl</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span>) (<span class=\"varid\">y</span> , <span class=\"varid\">p</span>)) <span class=\"varop\">$</span>
(<span class=\"varid\">p</span> , <span class=\"varid\">Meta.subst</span> (<span class=\"keyglyph\">\\</span><span class=\"varid\">q</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span>) <span class=\"varid\">q</span> <span class=\"varid\">p</span>) (<span class=\"varid\">subst-refl</span> <span class=\"varid\">p</span>)
(<span class=\"varid\">refl</span> (<span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span>) <span class=\"varid\">p</span>)))
</pre><h2><a name=\"does-it-compute\"></a>Does it compute </h2>
<p>An important question to ask is whether this style of OTT is actually implementable.
We can certainly implement the definitions, but would they allow us to compute?
</p><p>The type <tt class=\"complex\"><span class=\"conid\">Path</span> <span class=\"conid\">A</span></tt> certainly reduces, by definition. Similarly, it is not hard to implemenent <tt><span class=\"varid\">refl</span></tt>.
The hard part is defining what <tt><span class=\"varid\">cong</span></tt> means for various functions, and then proving <tt class=\"complex\"><span class=\"varid\">subst-refl</span></tt>.
Somewhere in there we should put the fact that paths are transitive and symmetric, since we have not used that property so far. For what I have done up till now I could equally well have taken <tt class=\"complex\"><span class=\"conid\">Iso</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span> <span class=\"keyglyph\">=</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span></tt>.
</p><p>Here are the implementations of <tt><span class=\"varid\">refl</span></tt>,
</p><pre class=\"agda\"><span class=\"keyglyph\">_</span><span class=\"varop\">≡[</span><span class=\"keyglyph\">_</span><span class=\"varop\">]≡</span><span class=\"keyglyph\">_</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span>} {<span class=\"conid\">A</span> <span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} <span class=\"keyglyph\">→</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">A</span> <span class=\"varop\">≡</span> <span class=\"conid\">B</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>
<span class=\"varid\">a</span> <span class=\"varop\">≡[</span> <span class=\"varid\">p</span> <span class=\"varop\">]≡</span> <span class=\"varid\">b</span> <span class=\"keyglyph\">=</span> <span class=\"varid\">Meta.subst</span> <span class=\"varid\">id</span> <span class=\"varid\">p</span> <span class=\"varid\">a</span> <span class=\"varop\">≡</span> <span class=\"varid\">b</span>
<div class=\"empty-line\"></div>
<span class=\"keyword\">postulate</span>
<span class=\"varid\">refl-⊤</span>     <span class=\"varop\">:</span> <span class=\"varid\">refl</span> ⊤ <span class=\"varid\">tt</span> <span class=\"varop\">≡[</span> <span class=\"conid\">Path-⊤</span> <span class=\"varop\">]≡</span> <span class=\"varid\">tt</span>
<span class=\"varid\">refl-Bool0</span> <span class=\"varop\">:</span> <span class=\"varid\">refl</span> <span class=\"conid\">Bool</span> <span class=\"varid\">false</span> <span class=\"varop\">≡[</span> <span class=\"conid\">Path-Bool00</span> <span class=\"varop\">]≡</span> <span class=\"varid\">tt</span>
<span class=\"varid\">refl-Bool1</span> <span class=\"varop\">:</span> <span class=\"varid\">refl</span> <span class=\"conid\">Bool</span> <span class=\"varid\">true</span>  <span class=\"varop\">≡[</span> <span class=\"conid\">Path-Bool11</span> <span class=\"varop\">]≡</span> <span class=\"varid\">tt</span>
<span class=\"varid\">refl-Π</span>     <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>} (<span class=\"varid\">f</span> <span class=\"varop\">:</span> <span class=\"conid\">Π</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>)
<span class=\"keyglyph\">→</span> <span class=\"varid\">refl</span> (<span class=\"conid\">Π</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>) <span class=\"varid\">f</span> <span class=\"varop\">≡[</span> <span class=\"conid\">Path-Π</span> <span class=\"varid\">f</span> <span class=\"varid\">f</span> <span class=\"varop\">]≡</span> (<span class=\"keyglyph\">\\</span><span class=\"varid\">x</span> <span class=\"keyglyph\">→</span> <span class=\"varid\">refl</span> (<span class=\"conid\">B</span> <span class=\"varid\">x</span>) (<span class=\"varid\">f</span> <span class=\"varid\">x</span>))
<span class=\"varid\">refl-Type</span>  <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span>} (<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>)
<span class=\"keyglyph\">→</span> <span class=\"varid\">refl</span> (<span class=\"conid\">Set</span> <span class=\"varid\">a</span>) <span class=\"conid\">A</span> <span class=\"varop\">≡[</span> <span class=\"conid\">Path-Type</span> <span class=\"conid\">A</span> <span class=\"conid\">A</span> <span class=\"varop\">]≡</span> <span class=\"varid\">lift</span> (<span class=\"varid\">id-Iso</span> <span class=\"conid\">A</span>)
</pre><p>For <tt class=\"complex\"><span class=\"varid\">refl</span> (<span class=\"conid\">Σ</span> <span class=\"keyglyph\">_</span> <span class=\"keyglyph\">_</span>)</tt> we need yet another lemma, which is a bit a dual to <tt class=\"complex\"><span class=\"varid\">subst-refl₁</span></tt>, allowing <tt><span class=\"varid\">refl</span></tt> in the second argument instead of the third.
</p><pre class=\"agda\"><span class=\"keyword\">postulate</span>
<span class=\"varid\">subst-refl₁</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>} {<span class=\"varid\">x</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>} {<span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">B</span> <span class=\"varid\">x</span>}
<span class=\"keyglyph\">→</span> <span class=\"varid\">y</span> <span class=\"varop\">≡</span> <span class=\"varid\">subst</span> <span class=\"conid\">B</span> (<span class=\"varid\">refl</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span>) <span class=\"varid\">y</span>
<div class=\"empty-line\"></div>
<span class=\"varid\">refl-Σ</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>} (<span class=\"varid\">x</span> <span class=\"varop\">:</span> <span class=\"conid\">Σ</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>)
<span class=\"keyglyph\">→</span> <span class=\"varid\">refl</span> (<span class=\"conid\">Σ</span> <span class=\"conid\">A</span> <span class=\"conid\">B</span>) <span class=\"varid\">x</span> <span class=\"varop\">≡[</span> <span class=\"conid\">Path-Σ</span> <span class=\"varid\">x</span> <span class=\"varid\">x</span> <span class=\"varop\">]≡</span>
(<span class=\"varid\">refl</span> <span class=\"conid\">A</span> (<span class=\"varid\">proj₁</span> <span class=\"varid\">x</span>) ,
<span class=\"varid\">Meta.subst</span> (<span class=\"keyglyph\">\\</span><span class=\"varid\">x1</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Path</span> (<span class=\"conid\">B</span> (<span class=\"varid\">proj₁</span> <span class=\"varid\">x</span>)) <span class=\"varid\">x1</span> (<span class=\"varid\">proj₂</span> <span class=\"varid\">x</span>))
(<span class=\"varid\">subst-refl₁</span> {<span class=\"conid\">B</span> <span class=\"keyglyph\">=</span> <span class=\"conid\">B</span>} {<span class=\"varid\">y</span> <span class=\"keyglyph\">=</span> <span class=\"varid\">proj₂</span> <span class=\"varid\">x</span>})
(<span class=\"varid\">refl</span> (<span class=\"conid\">B</span> (<span class=\"varid\">proj₁</span> <span class=\"varid\">x</span>)) (<span class=\"varid\">proj₂</span> <span class=\"varid\">x</span>)))
</pre><p>And here is a start of the implementation of <tt><span class=\"varid\">cong</span></tt>,
</p><pre class=\"agda\"><span class=\"keyword\">postulate</span>
<span class=\"varid\">cong-const</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>} {<span class=\"varid\">x</span> <span class=\"varid\">x'</span>} {<span class=\"varid\">y</span>} {<span class=\"varid\">p</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">x'</span>}
<span class=\"keyglyph\">→</span> <span class=\"varid\">cong</span> (<span class=\"keyglyph\">\\</span><span class=\"varid\">x</span> <span class=\"keyglyph\">→</span> <span class=\"varid\">y</span>) <span class=\"varid\">p</span> <span class=\"varop\">≡</span> <span class=\"varid\">refl</span> <span class=\"conid\">B</span> <span class=\"varid\">y</span>
<span class=\"varid\">cong-id</span>    <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"varid\">x</span> <span class=\"varid\">x'</span>} {<span class=\"varid\">p</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">x'</span>}
<span class=\"keyglyph\">→</span> <span class=\"varid\">cong</span> (<span class=\"keyglyph\">\\</span><span class=\"varid\">x</span> <span class=\"keyglyph\">→</span> <span class=\"varid\">x</span>) <span class=\"varid\">p</span> <span class=\"varop\">≡</span> <span class=\"varid\">p</span>
<span class=\"varid\">cong-∘</span>     <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span> <span class=\"varid\">c</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} {<span class=\"varid\">x</span> <span class=\"varid\">x'</span>} {<span class=\"varid\">p</span> <span class=\"varop\">:</span> <span class=\"conid\">Path</span> <span class=\"conid\">A</span> <span class=\"varid\">x</span> <span class=\"varid\">x'</span>}
{<span class=\"conid\">B</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">b</span>} {<span class=\"conid\">C</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">c</span>} {<span class=\"varid\">f</span> <span class=\"varop\">:</span> <span class=\"conid\">B</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">C</span>} {<span class=\"varid\">g</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span>}
<span class=\"keyglyph\">→</span> <span class=\"varid\">cong</span> (<span class=\"keyglyph\">\\</span><span class=\"varid\">x</span> <span class=\"keyglyph\">→</span> <span class=\"varid\">f</span> (<span class=\"varid\">g</span> <span class=\"varid\">x</span>)) <span class=\"varid\">p</span> <span class=\"varop\">≡</span> <span class=\"varid\">cong</span> <span class=\"varid\">f</span> (<span class=\"varid\">cong</span> <span class=\"varid\">g</span> <span class=\"varid\">p</span>)
<span class=\"comment\">-- etc.</span>
</pre><p>At some point I think you will also need a dependent <tt><span class=\"varid\">cong</span></tt>.
</p><p>But this is enough postulating for one day.
</p>" nil nil "e2662c32c877bd411c4416097504839b") (80 (20935 65032 456426) "http://wadler.blogspot.com/2013/06/a-perverted-view-of-impact.html" "Philip Wadler: A perverted view of \"impact\"" "noreply@blogger.com (Philip Wadler)" "Fri, 21 Jun 2013 16:34:31 +0000" "<div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://3.bp.blogspot.com/-5sYTh32tOSQ/UcR-z3Eze2I/AAAAAAAACcI/9AUvZRJBo-M/s1600/impact1.jpg\"><img src=\"http://3.bp.blogspot.com/-5sYTh32tOSQ/UcR-z3Eze2I/AAAAAAAACcI/9AUvZRJBo-M/s320/impact1.jpg\" height=\"160\" border=\"0\" width=\"320\" /></a></div>I think the emphasis on impact in UK research can be counterproductive. Jeremy Gibbons alerted me to this <a href=\"http://www.sciencemag.org/content/340/6138/1265.full\">op-ed by Marc Kirschner</a> in Science, pointing out that the situation is even more severe in the US biomedical community, where the search for \"impact\" leads to focus on human medicine, to the detriment of fundamental studies.<br /><blockquote class=\"tr_bq\">One may be able to recognize good science as it happens, but significant science can only be viewed in the rearview mirror. To pretend otherwise distorts science. DNA restriction enzymes, once the province of obscure microbiological investigation, ultimately enabled the entire recombinant DNA revolution. Measurement of the ratios of heavy and light isotopes of oxygen, once a limited area of geochemistry, eventually allowed the interpretation of prior climate change. What is now promoted as high-impact science is usually a narrow extension of existing experimental designs in a program focused on a set of feasible goals. Fuzzy new directions that might fail, but could open up major new questions, are often dismissed as too speculative and considered low-impact. And in biomedical science, there is an increasing tendency to equate significance to any form of medical relevance. This causes biochemical investigations and research on nonmammalian systems to be treated as intrinsically less valuable than studies on human cells. As a result, biomedicine is losing the historically productive cross-fertilization between model systems and human biology.</blockquote><div><br /></div>" nil nil "2fd3c9e589f7201098555aecb62338a7") (79 (20935 65032 455899) "http://www.joachim-breitner.de/blog/archives/599-Haskell-and-Debian-talk-at-HaL8.html" "Joachim Breitner: Haskell and Debian talk at HaL8" "mail@joachim-breitner.de (nomeata)" "Fri, 21 Jun 2013 16:04:45 +0000" "<p>I just finished my “Haskell und Debian” talk at the Haskell-Workshop <a href=\"http://www.bioinf.uni-leipzig.de/conference-registration/13haskell/de/Start.html\">HaL8 in Leipzig</a>. Unfortunately I was thrown a off track by time constraints and since there were much less beginners and interested visitors in the audience than I had anticipated, so I skipped some parts and improvised others somewhat chaotically, so the presentation was not up to the standards that I expect from my talks. If you have attended (or if you have not) I recommend you have a look <a href=\"http://www.bioinf.uni-leipzig.de/conference-registration/13haskell/papers/paper_1.pdf\">at the extended abstract</a> (in German), which contains what I skipped and is much clearer than what I said.</p>" nil nil "90f4249df1875a89be340aa1d5866258") (78 (20935 65032 455249) "http://lambdacube3d.wordpress.com/2013/06/21/a-few-thoughts-on-geometry-shaders/" "LambdaCube: A few thoughts on geometry shaders" nil "Fri, 21 Jun 2013 08:34:03 +0000" "<p>We just added a new example to the LambdaCube repository, which shows off <a href=\"https://github.com/csabahruska/lc-dsl/tree/master/samples/cubemap\" title=\"LambdaCube cube mapping example\">cube map based reflections</a>. Reflections are rendered by sampling a cube map, which is created by rendering the world from the centre of the reflecting object in six directions. This is done in a single pass, using a geometry shader to replicate every incoming triangle six times. Here is the final result:</p>
<div style=\"width: 640px;\" id=\"attachment_334\" class=\"wp-caption aligncenter\"><a href=\"http://lambdacube3d.files.wordpress.com/2013/06/cubemap-example1.png\"><img src=\"http://lambdacube3d.files.wordpress.com/2013/06/cubemap-example1.png?w=630&h=354\" alt=\"Reflecting surface simulated with cube mapping\" height=\"354\" class=\"size-full wp-image-334\" width=\"630\" /></a><p class=\"wp-caption-text\">Reflecting surface simulated with cube mapping</p></div>
<p>While the main focus of this blog is language and API design, we need to describe the pipeline structure of the example to put the rest of the discussion into context. The high-level structure corresponds to the following data-flow graph:</p>
<div style=\"width: 640px;\" id=\"attachment_340\" class=\"wp-caption aligncenter\"><a href=\"http://lambdacube3d.files.wordpress.com/2013/06/cubemap-example-pipeline1.png\"><img src=\"http://lambdacube3d.files.wordpress.com/2013/06/cubemap-example-pipeline1.png?w=630&h=261\" alt=\"Pipeline structure for the cube map example\" height=\"261\" class=\"size-full wp-image-340\" width=\"630\" /></a><p class=\"wp-caption-text\">Pipeline structure for the cube map example</p></div>
<p>The most important observation is that several pieces of this graph are reused multiple times. For instance, all geometry goes through the model-view transformation, but sometimes this is performed in a vertex shader (VS), sometimes in a geometry shader (GS). Also, the same lighting equation is used when creating the reflection map as well as the non-reflective parts of the final rendering, so the corresponding fragment shader (FS) is shared.</p>
<h2>The Good</h2>
<p>For us, the most important result of writing this example was that we could express all the above mentioned instances of shared logic in a straightforward way. The high-level graph structure is captured by the top declarations in <strong>sceneRender</strong>’s definition:</p>
<pre style=\"padding-bottom: 0;\"><span style=\"color: #0000ff;\">sceneRender</span> <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">Accumulate</span> accCtx <span style=\"color: #228b22;\">PassAll</span> reflectFrag (<span style=\"color: #228b22;\">Rasterize</span> rastCtx reflectPrims) directRender
<span style=\"color: #a020f0;\">where</span>
directRender <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">Accumulate</span> accCtx <span style=\"color: #228b22;\">PassAll</span> frag (<span style=\"color: #228b22;\">Rasterize</span> rastCtx directPrims) clearBuf
cubeMapRender <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">Accumulate</span> accCtx <span style=\"color: #228b22;\">PassAll</span> frag (<span style=\"color: #228b22;\">Rasterize</span> rastCtx cubePrims) clearBuf6
accCtx <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">AccumulationContext</span> <span style=\"color: #228b22;\">Nothing</span> (<span style=\"color: #228b22;\">DepthOp</span> <span style=\"color: #228b22;\">Less</span> <span style=\"color: #228b22;\">True</span> <span style=\"color: #228b22;\">:.</span> <span style=\"color: #228b22;\">ColorOp</span> <span style=\"color: #228b22;\">NoBlending</span> (one' <span style=\"color: #a0522d;\">::</span> <span style=\"color: #228b22;\">V4B</span>) <span style=\"color: #228b22;\">:.</span> <span style=\"color: #228b22;\">ZT</span>)
rastCtx <span style=\"color: #a0522d;\">=</span> triangleCtx { ctxCullMode <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">CullFront</span> <span style=\"color: #228b22;\">CCW</span> }
clearBuf <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">FrameBuffer</span> (<span style=\"color: #228b22;\">DepthImage</span> n1 1000 <span style=\"color: #228b22;\">:.</span> <span style=\"color: #228b22;\">ColorImage</span> n1 (<span style=\"color: #228b22;\">V4</span> 0<span style=\"color: #a0522d;\">.</span>1 0<span style=\"color: #a0522d;\">.</span>2 0<span style=\"color: #a0522d;\">.</span>6 1) <span style=\"color: #228b22;\">:.</span> <span style=\"color: #228b22;\">ZT</span>)
clearBuf6 <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">FrameBuffer</span> (<span style=\"color: #228b22;\">DepthImage</span> n6 1000 <span style=\"color: #228b22;\">:.</span> <span style=\"color: #228b22;\">ColorImage</span> n6 (<span style=\"color: #228b22;\">V4</span> 0<span style=\"color: #a0522d;\">.</span>05 0<span style=\"color: #a0522d;\">.</span>1 0<span style=\"color: #a0522d;\">.</span>3 1) <span style=\"color: #228b22;\">:.</span> <span style=\"color: #228b22;\">ZT</span>)
worldInput <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">Fetch</span> <span style=\"color: #8b2252;\">\"geometrySlot\"</span> <span style=\"color: #228b22;\">Triangles</span> (<span style=\"color: #228b22;\">IV3F</span> <span style=\"color: #8b2252;\">\"position\"</span>, <span style=\"color: #228b22;\">IV3F</span> <span style=\"color: #8b2252;\">\"normal\"</span>)
reflectInput <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">Fetch</span> <span style=\"color: #8b2252;\">\"reflectSlot\"</span> <span style=\"color: #228b22;\">Triangles</span> (<span style=\"color: #228b22;\">IV3F</span> <span style=\"color: #8b2252;\">\"position\"</span>, <span style=\"color: #228b22;\">IV3F</span> <span style=\"color: #8b2252;\">\"normal\"</span>)
directPrims <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">Transform</span> directVert worldInput
cubePrims <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">Reassemble</span> geom (<span style=\"color: #228b22;\">Transform</span> cubeMapVert worldInput)
reflectPrims <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">Transform</span> directVert reflectInput</pre>
<p>The top-level definition describes the last pass, which draws the reflective capsule – whose geometry is carried by the primitive stream <strong>reflectPrims</strong> – on top of the image emitted by a previous pass called <strong>directRender</strong>. The two preceding passes render the scene without the capsule (<strong>worldInput</strong>) on a screen-sized framebuffer as well as the cube map. We can see that the pipeline section generating the cube map has a <strong>reassemble</strong> phase, which corresponds to the geometry shader. Note that these two passes have no data dependencies between each other, so they can be executed in any order by the back-end.</p>
<p>It’s clear to see how the same fragment shader is used in the first two passes. The more interesting story is finding a way to express the model-view transformation in one place and use it both in <strong>directVert</strong> and <strong>geom</strong>. As it turns out, we can simply extract the common functionality and give it a name. The function we get this way is frequency agnostic, which is reflected in its type:</p>
<pre style=\"padding-bottom: 0;\">    transformGeometry <span style=\"color: #a0522d;\">::</span> <span style=\"color: #228b22;\">Exp</span> f <span style=\"color: #228b22;\">V4F</span> <span style=\"color: #a0522d;\">-></span> <span style=\"color: #228b22;\">Exp</span> f <span style=\"color: #228b22;\">V3F</span> <span style=\"color: #a0522d;\">-></span> <span style=\"color: #228b22;\">Exp</span> f <span style=\"color: #228b22;\">M44F</span> <span style=\"color: #a0522d;\">-></span> (<span style=\"color: #228b22;\">Exp</span> f <span style=\"color: #228b22;\">V4F</span>, <span style=\"color: #228b22;\">Exp</span> f <span style=\"color: #228b22;\">V4F</span>, <span style=\"color: #228b22;\">Exp</span> f <span style=\"color: #228b22;\">V3F</span>)
transformGeometry localPos localNormal viewMatrix <span style=\"color: #a0522d;\">=</span> (viewPos, worldPos, worldNormal)
<span style=\"color: #a020f0;\">where</span>
worldPos <span style=\"color: #a0522d;\">=</span> modelMatrix <span style=\"color: #a0522d;\">@*.</span> localPos
viewPos <span style=\"color: #a0522d;\">=</span> viewMatrix <span style=\"color: #a0522d;\">@*.</span> worldPos
worldNormal <span style=\"color: #a0522d;\">=</span> normalize' (v4v3 (modelMatrix <span style=\"color: #a0522d;\">@*.</span> n3v4 localNormal))</pre>
<p>The simpler use case is <strong>directVert</strong>, which simply wraps the above functionality in a vertex shader:</p>
<pre style=\"padding-bottom: 0;\">    directVert <span style=\"color: #a0522d;\">::</span> <span style=\"color: #228b22;\">Exp</span> <span style=\"color: #228b22;\">V</span> (<span style=\"color: #228b22;\">V3F</span>, <span style=\"color: #228b22;\">V3F</span>) <span style=\"color: #a0522d;\">-></span> <span style=\"color: #228b22;\">VertexOut</span> <span style=\"color: #228b22;\">()</span> (<span style=\"color: #228b22;\">V3F</span>, <span style=\"color: #228b22;\">V3F</span>, <span style=\"color: #228b22;\">V3F</span>)
directVert attr <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">VertexOut</span> viewPos (floatV 1) <span style=\"color: #228b22;\">ZT</span> (<span style=\"color: #228b22;\">Smooth</span> (v4v3 worldPos) <span style=\"color: #228b22;\">:.</span> <span style=\"color: #228b22;\">Smooth</span> worldNormal <span style=\"color: #228b22;\">:.</span> <span style=\"color: #228b22;\">Flat</span> viewCameraPosition <span style=\"color: #228b22;\">:.</span> <span style=\"color: #228b22;\">ZT</span>)
<span style=\"color: #a020f0;\">where</span>
(localPos, localNormal) <span style=\"color: #a0522d;\">=</span> untup2 attr
(viewPos, worldPos, worldNormal) <span style=\"color: #a0522d;\">=</span> transformGeometry (v3v4 localPos) localNormal viewCameraMatrix</pre>
<p>As for the geometry shader…</p>
<h2>The Bad</h2>
<p>… we already mentioned in <a href=\"http://lambdacube3d.wordpress.com/2012/09/07/the-lambdacube-3d-pipeline-model/\" title=\"The LambdaCube 3D pipeline model\">the introduction of our functional pipeline model</a> that we aren’t happy with the current way of expressing geometry shaders. The current approach is a very direct mapping of two nested for loops as an initialisation function and two state transformers – essentially <em>unfold</em> kernels. The outer loop is responsible for one primitive per iteration, while the inner loop emits the individual vertices. Without further ado, here’s the geometry shader needed by the example:</p>
<pre style=\"padding-bottom: 0;\">    geom <span style=\"color: #a0522d;\">::</span> <span style=\"color: #228b22;\">GeometryShader</span> <span style=\"color: #228b22;\">Triangle</span> <span style=\"color: #228b22;\">Triangle</span> <span style=\"color: #228b22;\">()</span> <span style=\"color: #228b22;\">()</span> 6 <span style=\"color: #228b22;\">V3F</span> (<span style=\"color: #228b22;\">V3F</span>, <span style=\"color: #228b22;\">V3F</span>, <span style=\"color: #228b22;\">V3F</span>)
geom <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">GeometryShader</span> n6 <span style=\"color: #228b22;\">TrianglesOutput</span> 18 init prim vert
<span style=\"color: #a020f0;\">where</span>
init attr <span style=\"color: #a0522d;\">=</span> tup2 (primInit, intG 6)
<span style=\"color: #a020f0;\">where</span>
primInit <span style=\"color: #a0522d;\">=</span> tup2 (intG 0, attr)
prim primState <span style=\"color: #a0522d;\">=</span> tup5 (layer, layer, primState', vertInit, intG 3)
<span style=\"color: #a020f0;\">where</span>
(layer, attr) <span style=\"color: #a0522d;\">=</span> untup2 primState
primState' <span style=\"color: #a0522d;\">=</span> tup2 (layer <span style=\"color: #a0522d;\">@+</span> intG 1, attr)
vertInit <span style=\"color: #a0522d;\">=</span> tup3 (intG 0, viewMatrix, attr)
viewMatrix <span style=\"color: #a0522d;\">=</span> indexG (map cubeCameraMatrix [1<span style=\"color: #a0522d;\">..</span>6]) layer
vert vertState <span style=\"color: #a0522d;\">=</span> <span style=\"color: #228b22;\">GeometryOut</span> vertState' viewPos pointSize <span style=\"color: #228b22;\">ZT</span> (<span style=\"color: #228b22;\">Smooth</span> (v4v3 worldPos) <span style=\"color: #228b22;\">:.</span> <span style=\"color: #228b22;\">Smooth</span> worldNormal <span style=\"color: #228b22;\">:.</span> <span style=\"color: #228b22;\">Flat</span> cubeCameraPosition <span style=\"color: #228b22;\">:.</span> <span style=\"color: #228b22;\">ZT</span>)
<span style=\"color: #a020f0;\">where</span>
(index, viewMatrix, attr) <span style=\"color: #a0522d;\">=</span> untup3 vertState
vertState' <span style=\"color: #a0522d;\">=</span> tup3 (index <span style=\"color: #a0522d;\">@+</span> intG 1, viewMatrix, attr)
(attr0, attr1, attr2) <span style=\"color: #a0522d;\">=</span> untup3 attr
(localPos, pointSize, <span style=\"color: #a020f0;\">_</span>, localNormal) <span style=\"color: #a0522d;\">=</span> untup4 (indexG [attr0, attr1, attr2] index)
(viewPos, worldPos, worldNormal) <span style=\"color: #a0522d;\">=</span> transformGeometry localPos localNormal viewMatrix</pre>
<p>The <strong>init</strong> function’s sole job is to define the initial state and iteration count of the outer loop. The initial state is just a loop counter set to zero plus the input of the shader in a single tuple called <strong>attr</strong>, while the iteration count is <strong>6</strong>. The <strong>prim</strong> function takes care of increasing this counter, specifying the layer for the primitive (equal to the counter), and picking the appropriate view matrix from one of six uniforms. It defines the iteration count (<strong>3</strong>, since we’re drawing triangles) and the initial state of the inner loop, which contains another counter set at zero, the chosen view matrix, and the attribute tuple. Finally, the <strong>vert</strong> function calculates the output attributes using <strong>transformGeometry</strong>, and also its next state, which only differs from the current one in having the counter incremented.</p>
<p>On one hand, we had success in reusing the common logic between different shader stages by simply extracting it as a pure function. On the other, it is obvious at this point that directly mapping imperative loops results in really awkward code. At least it does the job!</p>
<p><span style=\"text-align: center; display: block;\" class=\"embed-youtube\"><iframe class=\"youtube-player\" frameborder=\"0\" height=\"385\" src=\"http://www.youtube.com/embed/9f5oSv1SZiE?version=3&amp;rel=1&amp;fs=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent\" type=\"text/html\" width=\"630\"></iframe></span></p>
<h2>The Next Step?</h2>
<p>We’ve been thinking about alternative ways to model geometry shaders that would allow a more convenient and ‘natural’ manner of expressing our intent. One option we’ve considered lately would be to have the shader yield a list of lists. This would allow us to use scoping to access attributes in the inner loop instead of having to pass them around explicitly, not to mention doing away with explicit loop counters altogether. We could use existing techniques to generate imperative code, e.g. stream fusion. However, it is an open question how we could introduce lists or some similar structure in the language without disrupting other parts, keeping the use of the new feature appropriately constrained. One thing is clear: there has to be a better way.</p>
<br />  <img src=\"http://stats.wordpress.com/b.gif?host=lambdacube3d.wordpress.com&blog=39087425&post=331&subd=lambdacube3d&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "269a550dc6a9df0b7995ff5b17756672") (77 (20935 65032 452859) "http://existentialtype.wordpress.com/2013/06/20/the-homotopy-type-theory-book-is-out/" "Robert Harper: The Homotopy Type Theory Book is out!" nil "Thu, 20 Jun 2013 19:49:08 +0000" "<p>By now many of you have heard of the development of Homotopy Type Theory (HoTT), an extension of intuitionistic type theory that provides a natural foundation for doing synthetic homotopy theory.  Last year the <a href=\"http://ias.edu\" target=\"_blank\" title=\"Institute for Advanced Study\">Institute for Advanced Study at Princeton</a> sponsored a program on the <a href=\"http://uf-ias-2012.wikispaces.com/\" target=\"_blank\" title=\"Univalent Foundations Program\">Univalent Foundations of Mathematics</a>, which was concerned with developing these ideas.  One important outcome of the year-long program is a full-scale book presenting the main ideas of Homotopy Type Theory itself and showing how to apply them to various branches of mathematics, including homotopy theory, category theory, set theory, and constructive analysis.  The book is the product of a joint effort by dozens of participants in the program, and is intended to document the state of the art as it is known today, and to encourage its further development by the participation of others interested in the topic (i.e., you!).  Among the many directions in which one may take these ideas, the most important (to me) is to develop a constructive (computational) interpretation of HoTT.  Some partial results in this direction have already been obtained, including fascinating work by Thierry Coquand on developing a constructive version of Kan complexes in ITT, by Mike Shulman on proving homotopy canonicity for the natural numbers in a two-dimensional version of HoTT, and by Dan Licata and me on a weak definitional canonicity theorem for a similar two-dimensional theory.  Much work remains to be done to arrive at a fully satisfactory constructive interpretation, which is essential for application of these ideas to computer science.  Meanwhile, though, great progress has been made on using HoTT to formulate and formalize significant pieces of mathematics in a new, and strikingly beautiful, style, that are well-documented in the book.</p>
<p>The book is <a href=\"http://homotopytypetheory.org/book\" target=\"_blank\" title=\"Homotopy Type Theory Book\">freely available on the web</a> in various formats, including a PDF version with active references, an ebook version suitable for your reading device, and may be purchased in hard- or soft-cover from Lulu.  The book itself is open source, and is available at the <a href=\"http://github.com/hott/book\" target=\"_blank\" title=\"HoTT Book Git Hub\">Hott Book Git Hub</a>.  The book is under the Creative Commons  <a href=\"http://creativecommons.org/licenses/by-sa/3.0/\" title=\"Creative Common License\">CC BY-SA</a> license, and will be freely available in perpetuity.</p>
<p>Readers may also be interested in the posts on <a href=\"http://www.homotopytypetheory.org/2013/06/20/the-hott-book/\" target=\"_blank\" title=\"Homotopy Type Theory Book Announcement\">Homotopy Type Theory</a>, the <a href=\"http://golem.ph.utexas.edu/category/2013/06/the_hott_book.html\" title=\"n-Category Cafe Hott Book\">n-Category Cafe</a>, and <a href=\"http://math.andrej.com/2013/06/20/the-hott-book/\" title=\"Mathematics and Computation HoTT Book\">Mathematics and Computation</a> which describe more about the book and the process of its creation.</p>
<br />Filed under: <a href=\"http://existentialtype.wordpress.com/category/research/\">Research</a> Tagged: <a href=\"http://existentialtype.wordpress.com/tag/category-theory/\">category theory</a>, <a href=\"http://existentialtype.wordpress.com/tag/homotopy-theory/\">homotopy theory</a>, <a href=\"http://existentialtype.wordpress.com/tag/type-theory/\">type theory</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/existentialtype.wordpress.com/806/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/existentialtype.wordpress.com/806/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=existentialtype.wordpress.com&blog=2157150&post=806&subd=existentialtype&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "ae76362f1f9620a714075ba7c384177c") (76 (20935 65032 446274) "http://blog.moertel.com/posts/2013-06-12-recursion-to-iteration-4-trampolines.html" "Tom Moertel: Tricks of the trade: Recursion to Iteration, Part 4: The Trampoline" nil "Wed, 12 Jun 2013 00:00:00 +0000" "<div class=\"info byline\">Posted by <span><span>Tom Moertel<span></span></span></span></div>
<div class=\"info\">Posted on <time datetime=\"2013-06-12\" itemprop=\"datePublished\">June 12, 2013</time></div>
<div class=\"tags\">Tags: <span><a href=\"http://blog.moertel.com/tags/programming.html\">programming</a>, <a href=\"http://blog.moertel.com/tags/recursion.html\">recursion</a>, <a href=\"http://blog.moertel.com/tags/iteration.html\">iteration</a>, <a href=\"http://blog.moertel.com/tags/python.html\">python</a>, <a href=\"http://blog.moertel.com/tags/recursion-to-iteration series.html\">recursion-to-iteration series</a>, <a href=\"http://blog.moertel.com/tags/tail calls.html\">tail calls</a>, <a href=\"http://blog.moertel.com/tags/data structures.html\">data structures</a>, <a href=\"http://blog.moertel.com/tags/trampolines.html\">trampolines</a></span></div>
<div>
<p>This is the fourth article in <a href=\"http://blog.moertel.com/tags/recursion-to-iteration%20series.html\">a series on converting recursive algorithms into iterative algorithms</a>. If you haven’t read the earlier articles first, you may want to do so before continuing.</p>
<p>In <a href=\"http://blog.moertel.com/posts/2013-05-11-recursive-to-iterative.html\">the first article of our series</a>, we showed that if you can convert an algorithm’s recursive calls into tail calls, you can eliminate those tail calls to create an iterative version of the algorithm using The Simple Method. In this article, we’ll look at another way to eliminate tail calls: the <em>trampoline</em>.</p>
<p>The idea behind the trampoline is this: before making a tail call, manually remove the current execution frame from the stack, eliminating stack build-up.</p>
<h3 id=\"execution-frames-and-the-stack\">Execution frames and the stack</h3>
<p>To understand why we might want to manually remove an execution frame, let’s think about what happens when we call a function. The language runtime needs some place to store housekeeping information and any local variables the function may use, so it allocates a new execution frame on the stack. Then it turns control over to the function. When the function is done, it executes a <code>return</code> statement. This statement tells the runtime to remove the execution frame from the stack and to give control (and any result) back to the caller.</p>
<p>But what if the function doesn’t return right away? What if it makes another function call instead? In that case, the runtime must create a new execution frame for <em>that</em> call and push it onto the stack, on top of the current frame. If the function ends up calling itself many times recursively, each call will add another frame to the stack, and pretty soon we will have eaten up a lot of stack space.</p>
<h3 id=\"eliminating-stack-build-up\">Eliminating stack build-up</h3>
<p>To avoid this problem, some programming languages guarantee that they will recycle the current execution frame whenever a function makes a tail call. That is, if the function calls some other function (or itself recursively) and just returns that function’s result verbatim, that’s a tail call. In that case, the runtime will recycle the current function’s execution frame before transferring control to the other function, making it so that the other function will return its result directly to the original function’s caller. This process is called <em>tail-call elimination</em>.</p>
<p>But in languages like Python that don’t offer tail-call elimination, every call, even if it’s a tail call, pushes a new frame onto the stack. So if we want to prevent stack build-up, we must somehow eliminate the current frame from the stack ourselves, before making a tail call.</p>
<p>But how? The only obvious way to eliminate the current frame is to <code>return</code> to our caller. If we’re to make this work, then, the caller must be willing to help us out. That’s where the trampoline comes in. It’s our co-conspirator in the plot to eliminate stack build-up.</p>
<h3 id=\"the-trampoline\">The trampoline</h3>
<p>Here’s what the trampoline does:</p>
<ol style=\"\">
<li>It calls our function <code>f</code>, making itself the current caller.</li>
<li>When <code>f</code> wants to make a recursive tail call to itself, it returns the instruction <code>call(f)(*args, **kwds)</code>. The language runtime dutifully removes the current execution frame from the stack and returns control to the trampoline, passing it the instruction.</li>
<li>The trampoline interprets the instruction and calls <code>f</code> back, giving it the supplied arguments, and again making itself the caller.</li>
<li>This process repeats until <code>f</code> wants to return a final result <code>z</code>; then it returns the new instruction <code>result(z)</code> instead. As before, the runtime removes the current execution frame from the stack and returns control to the trampoline.</li>
<li>But now when the trampoline interprets the new instruction it will return <code>z</code> to <em>its</em> caller, ending the trampoline dance.</li>
</ol>
<p>Now you can see how the trampoline got its name. When our function uses a <code>return</code> statement to remove its own execution frame from the stack, the trampoline bounces control back to it with new arguments.</p>
<p>Here’s a simple implementation. First, we will encode our instructions to the trampoline as triples. We’ll let <code>call(f)(*args, **kwds)</code> be the triple <code>(f, args, kwds)</code>, and <code>result(z)</code> be the triple <code>(None, z, None)</code>:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> call(f):
<span class=\"co\">\"\"\"Instruct trampoline to call f with the args that follow.\"\"\"</span>
<span class=\"kw\">def</span> g(*args, **kwds):
<span class=\"kw\">return</span> f, args, kwds
<span class=\"kw\">return</span> g
<span class=\"kw\">def</span> result(value):
<span class=\"co\">\"\"\"Instruct trampoline to stop iterating and return a value.\"\"\"</span>
<span class=\"kw\">return</span> <span class=\"ot\">None</span>, value, <span class=\"ot\">None</span></code></pre>
<p>Now we’ll create a decorator to wrap a function with a trampoline that will interpret the instructions that the function returns:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"ch\">import</span> functools
<span class=\"kw\">def</span> with_trampoline(f):
<span class=\"co\">\"\"\"Wrap a trampoline around a function that expects a trampoline.\"\"\"</span>
<span class=\"ot\">@functools.wraps</span>(f)
<span class=\"kw\">def</span> g(*args, **kwds):
h = f
<span class=\"co\"># the trampoline</span>
<span class=\"kw\">while</span> h is not <span class=\"ot\">None</span>:
h, args, kwds = h(*args, **kwds)
<span class=\"kw\">return</span> args
<span class=\"kw\">return</span> g</code></pre>
<p>Note that the trampoline boils down to three lines:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">while</span> h is not <span class=\"ot\">None</span>:
h, args, kwds = h(*args, **kwds)
<span class=\"kw\">return</span> args</code></pre>
<p>Basically, the trampoline keeps calling whatever function is in <code>h</code> until that function returns a <code>result(z)</code> instruction, at which time the loop exits and <code>z</code> is returned. The original recursive tail calls have been boiled down to a <code>while</code> loop. Recursion has become iteration.</p>
<h3 id=\"example-factorial\">Example: factorial</h3>
<p>To see how we might use this implementation, let’s return to the factorial example from <a href=\"http://blog.moertel.com/posts/2013-05-11-recursive-to-iterative.html\">the first article in our series</a>:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> factorial(n):
<span class=\"kw\">if</span> n < <span class=\"dv\">2</span>:
<span class=\"kw\">return</span> <span class=\"dv\">1</span>
<span class=\"kw\">return</span> n * factorial(n - <span class=\"dv\">1</span>)</code></pre>
<p>Step one, as before, is to tail-convert the lone recursive call:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"> <span class=\"kw\">def</span> factorial(n, acc=<span class=\"dv\">1</span>):
<span class=\"kw\">if</span> n < <span class=\"dv\">2</span>:
<span class=\"kw\">return</span> acc
<span class=\"kw\">return</span> factorial(n - <span class=\"dv\">1</span>, acc * n)</code></pre>
<p>Now we can create an equivalent function that uses trampoline idioms:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> trampoline_factorial(n, acc=<span class=\"dv\">1</span>):
<span class=\"kw\">if</span> n < <span class=\"dv\">2</span>:
<span class=\"kw\">return</span> result(acc)
<span class=\"kw\">return</span> call(trampoline_factorial)(n - <span class=\"dv\">1</span>, n * acc)</code></pre>
<p>Note how the <code>return</code> statements have been transformed.</p>
<p>Finally, we can wrap this function with a trampoline to get a callable version that we can use just like the original:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\">factorial = with_trampoline(trampoline_factorial)</code></pre>
<p>Let’s take it for a spin:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\">>>> factorial(<span class=\"dv\">5</span>)
<span class=\"dv\">120</span></code></pre>
<p>To really see what’s going on, be sure to use the Online Python Tutor’s visualizer to step through the original, tail-recursive, and trampoline versions of the function. Just open this link: <a href=\"http://www.pythontutor.com/visualize.html#code=%23+our+trampoline+library%0A%0Aimport+functools%0A%0Adef+call(f)%3A%0A++++%22%22%22Instruct+trampoline+to+call+f+with+the+args+that+follow.%22%22%22%0A++++def+g(*args,+**kwds)%3A%0A++++++++return+f,+args,+kwds%0A++++return+g%0A%0Adef+result(value)%3A%0A++++%22%22%22Instruct+trampoline+to+stop+iterating+and+return+a+value.%22%22%22%0A++++return+None,+value,+None%0A%0Adef+with_trampoline(f)%3A%0A++++%22%22%22Wrap+a+trampoline+around+a+function+that+expects+a+trampoline.%22%22%22%0A++++%40functools.wraps(f)%0A++++def+g(*args,+**kwds)%3A%0A++++++++h+%3D+f%0A++++++++%23+the+trampoline%0A++++++++while+h+is+not+None%3A%0A++++++++++++h,+args,+kwds+%3D+h(*args,+**kwds)%0A++++++++return+args%0A++++return+g%0A%0A%0A%23+original+recursive+version+of+factorial+function%0A%0Adef+factorial(n)%3A%0A++++if+n+%3C+2%3A%0A++++++++return+1%0A++++return+n+*+factorial(n+-+1)%0A%0Aprint+factorial(5)%0A%0A%0A%23+tail-call+recursive+version%0A%0Adef+factorial(n,+acc%3D1)%3A%0A+++++if+n+%3C+2%3A%0A+++++++++return+acc%0A+++++return+factorial(n+-+1,+acc+*+n)%0A%0Aprint+factorial(5)%0A%0A%0A%23+trampoline-based+tail-call+version+(%3D+iterative)%0A%0Adef+trampoline_factorial(n,+acc%3D1)%3A%0A++++if+n+%3C+2%3A%0A++++++++return+result(acc)%0A++++return+call(trampoline_factorial)(n+-+1,+n+*+acc)%0A%0Afactorial+%3D+with_trampoline(trampoline_factorial)%0A%0Aprint+factorial(5)%0A&mode=display&cumulative=false&heapPrimitives=false&drawParentPointers=false&textReferences=false&showOnlyOutputs=false&py=2&curInstr=0\">Visualize the execution</a>. (ProTip: use a new tab.)</p>
<h3 id=\"why-use-the-trampoline\">Why use the trampoline?</h3>
<p>As I mentioned at the beginning of this article, if you can convert a function’s recursive calls into tail calls – which you must do to use a trampoline – you can also use the Simple Method on the function. For example, here’s what the Simple Method does to our original <code>factorial</code> function:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> factorial(n, acc=<span class=\"dv\">1</span>):
<span class=\"kw\">while</span> n > <span class=\"dv\">1</span>:
(n, acc) = (n - <span class=\"dv\">1</span>, acc * n)
<span class=\"kw\">return</span> acc</code></pre>
<p>This version is simpler and more efficient than the trampoline version. So why not use the Simple Method always?</p>
<p>The answer is that the Simple Method is tricky to apply to functions that make tail calls from within loops. Recall that it introduces a loop around a function’s body and replaces recursive tail calls with <code>continue</code> statements. But if the function already has its own loops, replacing a tail call within one of them with a <code>continue</code> statement will restart that inner loop instead of the whole-body loop, as desired. In that case, you must add condition flags to make sure the right loop gets restarted, and that gets old fast. Then, using a trampoline may be a win.</p>
<p>That said, I almost never use trampolines. Getting a function into tail-call form is nine tenths of the battle. If I’ve gone that far already, I’ll usually go the rest of the way to get a tight, iterative version.</p>
<p>Why, then, did we make this effort to understand the trampoline? Two reasons. First, it’s semi-common in programming lore, so it’s best to know about it. Second, it’s a stepping stone to a more-general, more-powerful technique: <em>continuation-passing-style expressions</em>. That’s our subject for next time.</p>
<p>In the meantime, if you want another take on trampolines in Python, Kyle Miller wrote a nice article on the subject: <a href=\"http://web.mit.edu/kmill/www/programming/tailcall.html\">Tail call recursion in Python</a>.</p>
<p>Thanks for reading! As always, if you have questions or comments, please leave a comment on the blog or hit me at <a href=\"https://twitter.com/tmoertel\">@tmoertel</a>.</p>
</div>" nil nil "0fbd60248f2323644ee5e1cf092bd561") (75 (20935 65032 322111) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_4888\"></span>, where <span id=\"tex_3959\"></span> is the number of “folds” and <span id=\"tex_1924\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_3966\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "04aa072f5f828ce911818ea0a1e6b4f9") (74 (20935 65032 320764) "http://blog.moertel.com/posts/2013-06-03-recursion-to-iteration-3.html" "Tom Moertel: Tricks of the trade: Recursion to Iteration, Part 3: Recursive Data Structures" nil "Mon, 03 Jun 2013 00:00:00 +0000" "<div class=\"info byline\">Posted by <span><span>Tom Moertel<span></span></span></span></div>
<div class=\"info\">Posted on <time datetime=\"2013-06-03\" itemprop=\"datePublished\">June  3, 2013</time></div>
<div class=\"tags\">Tags: <span><a href=\"http://blog.moertel.com/tags/programming.html\">programming</a>, <a href=\"http://blog.moertel.com/tags/recursion.html\">recursion</a>, <a href=\"http://blog.moertel.com/tags/iteration.html\">iteration</a>, <a href=\"http://blog.moertel.com/tags/python.html\">python</a>, <a href=\"http://blog.moertel.com/tags/recursion-to-iteration series.html\">recursion-to-iteration series</a>, <a href=\"http://blog.moertel.com/tags/tail calls.html\">tail calls</a>, <a href=\"http://blog.moertel.com/tags/data structures.html\">data structures</a></span></div>
<div>
<p>This is the third article in <a href=\"http://blog.moertel.com/tags/recursion-to-iteration%20series.html\">a series on converting recursive algorithms into iterative algorithms</a>. If any of what follows seems confusing, you may want to read the earlier articles first.</p>
<p>This is an extra article that I hadn’t planned. I’m writing it because in a comment on the previous article a reader asked me to show a less mathematical example and suggested tree traversal. So that’s the subject of this article: We’ll take a binary tree and flatten it into a list, first recursively, then iteratively.</p>
<h3 id=\"the-challenge\">The challenge</h3>
<p>First, let’s define a binary tree to be either empty or given by a node having three parts: (1) a value, (2) a left subtree, and (3) a right subtree, where both of the subtrees are themselves binary trees. In Haskell, we might define it like so:</p>
<pre class=\"sourceCode haskell\"><code class=\"sourceCode haskell\"><span class=\"kw\">data</span> <span class=\"dt\">BinaryTree</span> a <span class=\"fu\">=</span> <span class=\"dt\">Empty</span> <span class=\"fu\">|</span> <span class=\"dt\">Node</span> a (<span class=\"dt\">BinaryTree</span> a) (<span class=\"dt\">BinaryTree</span> a)</code></pre>
<p>In Python, which we’ll use for the rest of this article, we’ll say that <code>None</code> represents an empty tree and that the following class represents a node:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"ch\">import</span> collections
Node = collections.namedtuple(<span class=\"st\">'Node'</span>, <span class=\"st\">'val left right'</span>)
<span class=\"co\"># some sample trees having various node counts</span>
tree0 = <span class=\"ot\">None</span>  <span class=\"co\"># empty tree</span>
tree1 = Node(<span class=\"dv\">5</span>, <span class=\"ot\">None</span>, <span class=\"ot\">None</span>)
tree2 = Node(<span class=\"dv\">7</span>, tree1, <span class=\"ot\">None</span>)
tree3 = Node(<span class=\"dv\">7</span>, tree1, Node(<span class=\"dv\">9</span>, <span class=\"ot\">None</span>, <span class=\"ot\">None</span>))
tree4 = Node(<span class=\"dv\">2</span>, <span class=\"ot\">None</span>, tree3)
tree5 = Node(<span class=\"dv\">2</span>, Node(<span class=\"dv\">1</span>, <span class=\"ot\">None</span>, <span class=\"ot\">None</span>), tree3)</code></pre>
<p>Let us now define a function to flatten a tree using an <a href=\"http://en.wikipedia.org/wiki/Tree_traversal#In-order\">in-order traversal</a>. The recursive definition is absurdly simple, the data type having only two cases to consider:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> flatten(bst):
<span class=\"co\"># empty case</span>
<span class=\"kw\">if</span> bst is <span class=\"ot\">None</span>:
<span class=\"kw\">return</span> []
<span class=\"co\"># node case</span>
<span class=\"kw\">return</span> flatten(bst.left) + [bst.val] + flatten(bst.right)</code></pre>
<p>A few tests to check that it does what we expect:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> check_flattener(f):
<span class=\"kw\">assert</span> f(tree0) == []
<span class=\"kw\">assert</span> f(tree1) == [<span class=\"dv\">5</span>]
<span class=\"kw\">assert</span> f(tree2) == [<span class=\"dv\">5</span>, <span class=\"dv\">7</span>]
<span class=\"kw\">assert</span> f(tree3) == [<span class=\"dv\">5</span>, <span class=\"dv\">7</span>, <span class=\"dv\">9</span>]
<span class=\"kw\">assert</span> f(tree4) == [<span class=\"dv\">2</span>, <span class=\"dv\">5</span>, <span class=\"dv\">7</span>, <span class=\"dv\">9</span>]
<span class=\"kw\">assert</span> f(tree5) == [<span class=\"dv\">1</span>, <span class=\"dv\">2</span>, <span class=\"dv\">5</span>, <span class=\"dv\">7</span>, <span class=\"dv\">9</span>]
<span class=\"kw\">print</span> <span class=\"st\">'ok'</span>
check_flattener(flatten)  <span class=\"co\"># ok</span></code></pre>
<p>Our challenge for today is to convert <code>flatten</code> into an iterative version. Other than a new trick – partial evaluation – the transformation is straightforward, so I’ll move quickly.</p>
<p>Let’s do this!</p>
<h3 id=\"eliminating-the-first-recursive-call\">Eliminating the first recursive call</h3>
<p>First, let’s separate the base case from the incremental work:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(bst):
<span class=\"kw\">return</span> flatten(bst.left) + [bst.val] + flatten(bst.right)
<span class=\"kw\">def</span> flatten(bst):
<span class=\"kw\">if</span> bst is <span class=\"ot\">None</span>:
<span class=\"kw\">return</span> []
<span class=\"kw\">return</span> step(bst)</code></pre>
<p>And let’s break the incremental work into smaller pieces to see what’s going on.</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(bst):
left = flatten(bst.left)
left.append(bst.val)
right = flatten(bst.right)
left.extend(right)
<span class=\"kw\">return</span> left
<span class=\"kw\">def</span> flatten(bst):
<span class=\"kw\">if</span> bst is <span class=\"ot\">None</span>:
<span class=\"kw\">return</span> []
<span class=\"kw\">return</span> step(bst)</code></pre>
<p>Let’s try to get rid of the first recursive call by assuming that somebody has passed us its result via a secret argument <code>left</code>:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(bst, left=<span class=\"ot\">None</span>):
<span class=\"kw\">if</span> left is <span class=\"ot\">None</span>:
left = flatten(bst.left)
left.append(bst.val)
right = flatten(bst.right)
left.extend(right)
<span class=\"kw\">return</span> left
<span class=\"kw\">def</span> flatten(bst):
<span class=\"kw\">if</span> bst is <span class=\"ot\">None</span>:
<span class=\"kw\">return</span> []
<span class=\"kw\">return</span> step(bst)</code></pre>
<p>And now we’ll make <code>step</code> return values that parallel its input arguments:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(bst, left=<span class=\"ot\">None</span>):
<span class=\"kw\">if</span> left is <span class=\"ot\">None</span>:
left = flatten(bst.left)
left.append(bst.val)
right = flatten(bst.right)
left.extend(right)
<span class=\"kw\">return</span> bst, left  <span class=\"co\"># <-- add bst</span>
<span class=\"kw\">def</span> flatten(bst):
<span class=\"kw\">if</span> bst is <span class=\"ot\">None</span>:
<span class=\"kw\">return</span> []
<span class=\"kw\">return</span> step(bst)[-<span class=\"dv\">1</span>]  <span class=\"co\"># <-- note [-1]</span></code></pre>
<p>In the first recursive call, the transformation applied to <code>bst</code> is <code>.left</code>, so we want to apply the opposite transformation to <code>bst</code> in the returned values. And what’s the opposite of descending to a node’s left subtree? It’s ascending to the node’s parent. So we want something like this:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"co\"># this code does not work!</span>
<span class=\"kw\">def</span> step(bst, left=<span class=\"ot\">None</span>):
<span class=\"kw\">if</span> left is <span class=\"ot\">None</span>:
left = flatten(bst.left)
left.append(bst.val)
right = flatten(bst.right)
left.extend(right)
<span class=\"kw\">return</span> get_parent(bst), left  <span class=\"co\"># <-- need get_parent</span></code></pre>
<p>But we’re stuck. We can’t define <code>get_parent</code> because our tree data structure doesn’t keep track of parents, only children.</p>
<p>New plan: Maybe we can assume that someone has <em>passed us</em> the node’s parent and go from there?</p>
<p>But this plan hits the same brick wall: If we add a new argument to accept the parent, we must for parallelism add a new return value to emit the transformed parent, which is the parent of the parent. But we can’t compute the parent of the parent because, as before, we have no way of implementing <code>get_parent</code>.</p>
<p>So we do what mathematicians do when their assumptions hit a brick wall: we strengthen our assumption! Now we assume that someone has passed us <em>all of the parents</em>, right up to the tree’s root. And that assumption gives us what we need:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(bst, parents, left=<span class=\"ot\">None</span>):
<span class=\"kw\">if</span> left is <span class=\"ot\">None</span>:
left = flatten(bst.left)
left.append(bst.val)
right = flatten(bst.right)
left.extend(right)
<span class=\"kw\">return</span> parents[-<span class=\"dv\">1</span>], parents[:-<span class=\"dv\">1</span>], left</code></pre>
<p>Note that we’re using the Python stack convention for <code>parents</code>; thus the immediate parent of <code>bst</code> is given by the final element <code>parents[-1]</code>.</p>
<p>As a simplification, we can eliminate the <code>bst</code> argument by considering it the final parent pushed onto the stack:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(parents, left=<span class=\"ot\">None</span>):
bst = parents.pop()  <span class=\"co\"># <-- bst = top of parents stack</span>
<span class=\"kw\">if</span> left is <span class=\"ot\">None</span>:
left = flatten(bst.left)
left.append(bst.val)
right = flatten(bst.right)
left.extend(right)
<span class=\"kw\">return</span> parents, left</code></pre>
<p>Now that <code>step</code> requires the <code>parents</code> stack as an argument, the base function must provide it:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> flatten(bst):
<span class=\"kw\">if</span> bst is <span class=\"ot\">None</span>:
<span class=\"kw\">return</span> []
parents = [bst]
<span class=\"kw\">return</span> step(parents)[-<span class=\"dv\">1</span>]</code></pre>
<p>But we still haven’t eliminated the first recursive call. To do that, we’ll need to pass the <code>step</code> function a value for its <code>left</code> argument, which will cause the recursive call to be skipped.</p>
<p>But we only know what that value should be for one case, the base case, when <code>bst</code> is <code>None</code>; then <code>left</code> must be <code>[]</code>. To get to that case from the tree’s root, where <code>bst</code> is definitely not <code>None</code>, we must iteratively replicate the normal recursive calls on <code>bst.left</code> until we hit the leftmost leaf node. And then, to compute the desired result, we must reverse the trip, iterating the <code>step</code> function until we have returned to the tree’s root, where the <code>parents</code> stack must be empty:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> flatten(bst):
<span class=\"co\"># find initial conditions for secret-feature \"left\"</span>
left = []
parents = []
<span class=\"kw\">while</span> bst is not <span class=\"ot\">None</span>:
parents.append(bst)
bst = bst.left
<span class=\"co\"># iterate to compute the result</span>
<span class=\"kw\">while</span> parents:
parents, left = step(parents, left)
<span class=\"kw\">return</span> left</code></pre>
<p>And just like that, one of the recursive calls has been transformed into iteration. We’re halfway to the finish line!</p>
<h3 id=\"eliminating-the-second-recursive-call\">Eliminating the second recursive call</h3>
<p>But we still have to eliminate that final recursive call to <code>flatten</code>, now sequestered in <code>step</code>. Let’s take a closer look at that function after we make its <code>left</code> argument required since it always gets called with a value now:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(parents, left):
bst = parents.pop()
left.append(bst.val)
right = flatten(bst.right)
left.extend(right)
<span class=\"kw\">return</span> parents, left</code></pre>
<p>To get rid of the recursive call to <code>flatten</code>, we’re going to use a new trick: partial evaluation. Basically, we’re going to replace the call to <code>flatten</code> with the function body of <code>flatten</code>, after we rename all its variables to prevent conflicts. So let’s make a copy of <code>flatten</code> and suffix all its variables with <code>1</code>:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> flatten1(bst1):
left1 = []
parents1 = []
<span class=\"kw\">while</span> bst1 is not <span class=\"ot\">None</span>:
parents1.append(bst1)
bst1 = bst1.left
<span class=\"kw\">while</span> parents1:
parents1, left1 = step(parents1, left1)
<span class=\"kw\">return</span> left1</code></pre>
<p>And then let’s make its arguments and return values explicit:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\">    (bst1, ) = ARGUMENTS
left1 = []
parents1 = []
<span class=\"kw\">while</span> bst1 is not <span class=\"ot\">None</span>:
parents1.append(bst1)
bst1 = bst1.left
<span class=\"kw\">while</span> parents1:
parents1, left1 = step(parents1, left1)
RETURNS = (left1, )</code></pre>
<p>And then we’ll drop this expansion into <code>step</code>:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(parents, left):
bst = parents.pop()
left.append(bst.val)
<span class=\"co\"># -- begin partial evaluation --</span>
(bst1, ) = (bst.right, )
left1 = []
parents1 = []
<span class=\"kw\">while</span> bst1 is not <span class=\"ot\">None</span>:
parents1.append(bst1)
bst1 = bst1.left
<span class=\"kw\">while</span> parents1:
parents1, left1 = step(parents1, left1)
(right, ) = (left1, )
<span class=\"co\"># -- end partial evaluation --</span>
left.extend(right)
<span class=\"kw\">return</span> parents, left</code></pre>
<p>Now we can eliminate code by fusion across the partial-evaluation boundary.</p>
<p>First up: <code>left1</code>. We can now see that this variable accumulates values that, in the end, get appended to <code>left</code> (via the return variable <code>right</code>). But we can just as well append those values to <code>left</code> directly, eliminating <code>left1</code> within the boundary and the call to <code>left.extend(right)</code> without:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(parents, left):
bst = parents.pop()
left.append(bst.val)
<span class=\"co\"># -- begin partial evaluation --</span>
(bst1, ) = (bst.right, )
<span class=\"co\"># left1 = []  # <-- eliminate and use left instead</span>
parents1 = []
<span class=\"kw\">while</span> bst1 is not <span class=\"ot\">None</span>:
parents1.append(bst1)
bst1 = bst1.left
<span class=\"kw\">while</span> parents1:
parents1, left = step(parents1, left)
<span class=\"co\"># (right, ) = (left, )  # <-- eliminated</span>
<span class=\"co\"># -- end partial evaluation --</span>
<span class=\"co\"># left.extend(right)  # <-- eliminated</span>
<span class=\"kw\">return</span> parents, left</code></pre>
<p>For this next fusion, we’re going to need to recall our base function to get the necessary outside scope:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(parents, left):
bst = parents.pop()
left.append(bst.val)
<span class=\"co\"># -- begin partial evaluation --</span>
(bst1, ) = (bst.right, )
parents1 = []
<span class=\"kw\">while</span> bst1 is not <span class=\"ot\">None</span>:
parents1.append(bst1)
bst1 = bst1.left
<span class=\"kw\">while</span> parents1:
parents1, left = step(parents1, left)
<span class=\"co\"># -- end partial evaluation --</span>
<span class=\"kw\">return</span> parents, left
<span class=\"kw\">def</span> flatten(bst):
left = []
parents = []
<span class=\"kw\">while</span> bst is not <span class=\"ot\">None</span>:
parents.append(bst)
bst = bst.left
<span class=\"kw\">while</span> parents:
parents, left = step(parents, left)
<span class=\"kw\">return</span> left</code></pre>
<p>When <code>flatten</code> calls <code>step</code> and the code within the partially evaluated region executes, it builds up a stack of nodes <code>parents1</code> and then calls <code>step</code> iteratively to pop values off of that stack and process them. When it’s finished, control returns to <code>step</code> proper, which then returns to its caller, <code>flatten</code>, with the values (<code>parents</code>, <code>left</code>). But look at what <code>flatten</code> then does with <code>parents</code>: it calls <code>step</code> iteratively to pop values off of that stack and process them in exactly the same way.</p>
<p>So we can eliminate the <code>while</code> loop in <code>step</code> – and the recursive call! – by returning not <code>parents</code> but <code>parents + parents1</code>, which will make the <code>while</code> loop in <code>flatten</code> do the exact same work.</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(parents, left):
bst = parents.pop()
left.append(bst.val)
<span class=\"co\"># -- begin partial evaluation --</span>
(bst1, ) = (bst.right, )
parents1 = []
<span class=\"kw\">while</span> bst1 is not <span class=\"ot\">None</span>:
parents1.append(bst1)
bst1 = bst1.left
<span class=\"co\"># while parents1:                            # <-- eliminated</span>
<span class=\"co\">#     parents1, left = step(parents1, left)  #</span>
<span class=\"co\"># -- end partial evaluation --</span>
<span class=\"kw\">return</span> parents + parents1, left  <span class=\"co\"># parents -> parents + parents1</span></code></pre>
<p>And then we can eliminate <code>parents1</code> completely by taking the values we would have appended to it and appending them directly to <code>parents</code>:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(parents, left):
bst = parents.pop()
left.append(bst.val)
<span class=\"co\"># -- begin partial evaluation --</span>
(bst1, ) = (bst.right, )
<span class=\"co\"># parents1 = []  # <-- eliminated</span>
<span class=\"kw\">while</span> bst1 is not <span class=\"ot\">None</span>:
parents.append(bst1)  <span class=\"co\"># parents1 -> parents</span>
bst1 = bst1.left
<span class=\"co\"># -- end partial evaluation --</span>
<span class=\"kw\">return</span> parents, left  <span class=\"co\"># parents + parents1 -> parents</span></code></pre>
<p>And now, once we remove our partial-evaluation scaffolding, our <code>step</code> function is looking simple again:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(parents, left):
bst = parents.pop()
left.append(bst.val)
bst1 = bst.right
<span class=\"kw\">while</span> bst1 is not <span class=\"ot\">None</span>:
parents.append(bst1)
bst1 = bst1.left
<span class=\"kw\">return</span> parents, left</code></pre>
<p>For the final leg of our journey – simplification – let’s inline the <code>step</code> logic back into the base function:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> flatten(bst):
left = []
parents = []
<span class=\"kw\">while</span> bst is not <span class=\"ot\">None</span>:
parents.append(bst)
bst = bst.left
<span class=\"kw\">while</span> parents:
parents, left = parents, left
bst = parents.pop()
left.append(bst.val)
bst1 = bst.right
<span class=\"kw\">while</span> bst1 is not <span class=\"ot\">None</span>:
parents.append(bst1)
bst1 = bst1.left
parents, left = parents, left
<span class=\"kw\">return</span> left</code></pre>
<p>Let’s eliminate the trivial argument-binding and return-value assignments:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> flatten(bst):
left = []
parents = []
<span class=\"kw\">while</span> bst is not <span class=\"ot\">None</span>:
parents.append(bst)
bst = bst.left
<span class=\"kw\">while</span> parents:
<span class=\"co\"># parents, left = parents, left  # = no-op</span>
bst = parents.pop()
left.append(bst.val)
bst1 = bst.right
<span class=\"kw\">while</span> bst1 is not <span class=\"ot\">None</span>:
parents.append(bst1)
bst1 = bst1.left
<span class=\"co\"># parents, left = parents, left  # = no-op</span>
<span class=\"kw\">return</span> left</code></pre>
<p>And, finally, factor out the duplicated <code>while</code> loop into a local function:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> flatten(bst):
left = []
parents = []
<span class=\"kw\">def</span> descend_left(bst):
<span class=\"kw\">while</span> bst is not <span class=\"ot\">None</span>:
parents.append(bst)
bst = bst.left
descend_left(bst)
<span class=\"kw\">while</span> parents:
bst = parents.pop()
left.append(bst.val)
descend_left(bst.right)
<span class=\"kw\">return</span> left</code></pre>
<p>And that’s it! We now have a tight, efficient, and iterative version of our original function. Further, the code is close to idiomatic.</p>
<p>That’s it for this time. If you have any questions or comments, just hit me at <a href=\"https://twitter.com/tmoertel\">@tmoertel</a> or use the comment form below.</p>
<p>Thanks for reading!</p>
</div>" nil nil "e430c69f5361c2bfd98d3a7979ea7cdf") (73 (20935 65032 307805) "http://blog.moertel.com/posts/2013-05-26-python-lazy-merge.html" "Tom Moertel: Lazy merging in Python using streams" nil "Sun, 26 May 2013 00:00:00 +0000" "<div class=\"info byline\">Posted by <span><span>Tom Moertel<span></span></span></span></div>
<div class=\"info\">Posted on <time datetime=\"2013-05-26\" itemprop=\"datePublished\">May 26, 2013</time></div>
<div class=\"tags\">Tags: <span><a href=\"http://blog.moertel.com/tags/programming.html\">programming</a>, <a href=\"http://blog.moertel.com/tags/python.html\">python</a>, <a href=\"http://blog.moertel.com/tags/iterators.html\">iterators</a>, <a href=\"http://blog.moertel.com/tags/streams.html\">streams</a>, <a href=\"http://blog.moertel.com/tags/SICP.html\">SICP</a>, <a href=\"http://blog.moertel.com/tags/functional programming.html\">functional programming</a></span></div>
<div>
<p>Recently while solving a programming puzzle in Python, I needed to merge a series of <em>N</em> iterators, each yielding values in sorted order, into a single iterator over the sorted values. The trick is that, when asked for a value from the merged series, to determine which iterator should contribute that value, you must extract all <em>N</em> iterators’ next values. And then, of course, you can emit only one. So what do you do with the remaining <em>N</em> – 1 values you’ve extracted?</p>
<p>Rather than think about that question too hard, I just converted the iterators into an equivalent form in which the next value was always exposed and hence available for making decisions <em>before</em> extraction. This form is basically the <a href=\"http://mitpress.mit.edu/sicp/full-text/sicp/book/node69.html\"><em>stream</em> of SICP fame</a>.</p>
<p>The idea is to convert each <a href=\"http://www.python.org/dev/peps/pep-0234/\">Python iterator</a> into either <code>None</code> (representing an empty stream) or a pair containing the iterator’s next value and the iterator itself:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> iterator_to_stream(iterator):
<span class=\"co\">\"\"\"Convert an iterator into a stream (None if the iterator is empty).\"\"\"</span>
<span class=\"kw\">try</span>:
<span class=\"kw\">return</span> iterator.<span class=\"dt\">next</span>(), iterator
<span class=\"kw\">except</span> <span class=\"ot\">StopIteration</span>:
<span class=\"kw\">return</span> <span class=\"ot\">None</span></code></pre>
<p>Then to extract values from the stream, you just apply <code>stream_next</code> to it, and it will hand you back the next value and the updated state of the stream:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> stream_next(stream):
<span class=\"co\">\"\"\"Get (next_value, next_stream) from a stream.\"\"\"</span>
val, iterator = stream
<span class=\"kw\">return</span> val, iterator_to_stream(iterator)</code></pre>
<p>Since streams expose their next value, they can be ordered by that value. And for my task that was the property that made all the difference:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"ch\">import</span> heapq
<span class=\"kw\">def</span> merge(iterators):
<span class=\"co\">\"\"\"Make a lazy sorted iterator that merges lazy sorted iterators.\"\"\"</span>
streams = <span class=\"dt\">map</span>(iterator_to_stream, <span class=\"dt\">map</span>(<span class=\"dt\">iter</span>, iterators))
heapq.heapify(streams)
<span class=\"kw\">while</span> streams:
stream = heapq.heappop(streams)
<span class=\"kw\">if</span> stream is not <span class=\"ot\">None</span>:
val, stream = stream_next(stream)
heapq.heappush(streams, stream)
<span class=\"kw\">yield</span> val</code></pre>
<p>An example use:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\">>>> xs = merge([<span class=\"dt\">xrange</span>(<span class=\"dv\">3</span>), <span class=\"dt\">xrange</span>(<span class=\"dv\">2</span>, <span class=\"dv\">9</span>), <span class=\"dt\">xrange</span>(<span class=\"dv\">5</span>)])
>>> xs
<generator <span class=\"dt\">object</span> merge at <span class=\"bn\">0x7fea07c9d320</span>>
>>> <span class=\"dt\">list</span>(xs)
[<span class=\"dv\">0</span>, <span class=\"dv\">0</span>, <span class=\"dv\">1</span>, <span class=\"dv\">1</span>, <span class=\"dv\">2</span>, <span class=\"dv\">2</span>, <span class=\"dv\">2</span>, <span class=\"dv\">3</span>, <span class=\"dv\">3</span>, <span class=\"dv\">4</span>, <span class=\"dv\">4</span>, <span class=\"dv\">5</span>, <span class=\"dv\">6</span>, <span class=\"dv\">7</span>, <span class=\"dv\">8</span>]</code></pre>
</div>" nil nil "1db31a35ebfdd9189112b89fb68fe903") (72 (20935 65032 305863) "http://twanvl.nl/blog/agda/sorting" "Twan van Laarhoven: The complete correctness of sorting" nil "Thu, 23 May 2013 12:43:33 +0000" "<p>A while ago I set out to prove the correctness of <a href=\"http://en.wikipedia.org/wiki/Merge_sort\">merge sort</a> in Agda.
Of course this has been done before.
But <a href=\"http://mazzo.li/posts/AgdaSort.html\">most</a> <a href=\"http://www.iis.sinica.edu.tw/~scm/2007/agda-exercise-proving-that-mergesort-returns-ordered-list/\">proofs</a> you find are far from complete.
All they prove is a lemma such as
</p><pre class=\"agda\"><span class=\"varid\">is-sorted</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> (<span class=\"varid\">xs</span> <span class=\"varop\">:</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">IsSortedList</span> (<span class=\"varid\">sort</span> <span class=\"varid\">xs</span>)
</pre><p>Maybe even restricted to lists of natural numbers.
While it is nice that a sort function indeed produces a sorted output, that is only half of the story.
Consider this function:
</p><pre class=\"agda\"><span class=\"varid\">cheat-sort</span> <span class=\"varop\">:</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span>
<span class=\"varid\">cheat-sort</span> <span class=\"keyglyph\">_</span> <span class=\"keyglyph\">=</span> <span class=\"varop\">[]</span>
</pre><p>Clearly the empty list is sorted. So we are done.
What is missing is the second half of correctness of sorting: that the output is a permutation of the input.
You want something like:
</p><pre class=\"agda\"><span class=\"varid\">sort</span> <span class=\"varop\">:</span> (<span class=\"varid\">xs</span> <span class=\"varop\">:</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">Sorted'</span> <span class=\"conid\">A</span>
<span class=\"keyword\">record</span> <span class=\"conid\">Sorted'</span> (<span class=\"varid\">xs</span> <span class=\"varop\">:</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span>) <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"keyword\">where</span>
<span class=\"keyword\">field</span>
<span class=\"varid\">ys</span>       <span class=\"varop\">:</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span>
<span class=\"varid\">isSorted</span> <span class=\"varop\">:</span> <span class=\"conid\">IsSorted</span> <span class=\"varid\">ys</span>
<span class=\"varid\">isPerm</span>   <span class=\"varop\">:</span> <span class=\"conid\">IsPermutation</span> <span class=\"varid\">ys</span> <span class=\"varid\">xs</span>
</pre><p>While I was at it, I decided to add the third half of correctness: a bound on the runtime or computational complexity.
In the end I was able to define:
</p><pre class=\"agda\"><span class=\"varid\">insertion-sort</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> <span class=\"varid\">xs</span> <span class=\"keyglyph\">→</span> (<span class=\"conid\">Sorted</span> <span class=\"varid\">xs</span>) <span class=\"varop\">in-time</span> (<span class=\"varid\">length</span> <span class=\"varid\">xs</span> <span class=\"varop\">*</span> <span class=\"varid\">length</span> <span class=\"varid\">xs</span>)
<span class=\"varid\">selection-sort</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> <span class=\"varid\">xs</span> <span class=\"keyglyph\">→</span> (<span class=\"conid\">Sorted</span> <span class=\"varid\">xs</span>) <span class=\"varop\">in-time</span> (<span class=\"varid\">length</span> <span class=\"varid\">xs</span> <span class=\"varop\">*</span> <span class=\"varid\">length</span> <span class=\"varid\">xs</span>)
<span class=\"varid\">merge-sort</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> <span class=\"varid\">xs</span> <span class=\"keyglyph\">→</span> (<span class=\"conid\">Sorted</span> <span class=\"varid\">xs</span>) <span class=\"varop\">in-time</span> (<span class=\"varid\">length</span> <span class=\"varid\">xs</span> <span class=\"varop\">*</span> <span class=\"varop\">⌈log₂</span> <span class=\"varid\">length</span> <span class=\"varid\">xs</span> <span class=\"varop\">⌉</span>)
</pre><p>This was not as easy as I would have hoped.
In this post I will not bore you with all the details, I'll just go over some of the highlights. The <a href=\"https://gist.github.com/twanvl/5635740\">full code is on github</a>.
</p><h2><a name=\"what-it-means-to-be-sorted\"></a>What it means to be sorted </h2>
<p>There are roughly two ways to define sorted lists that I know of:
</p><ol><li> Parametrize the sorted list by a lower bound on the values it contains. For a cons cell the head should be smaller than the lower bound, and the tail should be larger than the head. This requires the type to have a smallest element, but you can adjoin -∞ with a new datatype.</li>
<li> Parametrize the sorted list by a list of all values in it. For a cons cell require that the head is smaller than all the values in the tail.</li>
</ol><p>Since I already need to parametrize by all values in the list to show that the sorted list contains a permutation of them, I went with the second approach:
</p><pre class=\"agda\"><span class=\"comment\">-- A proof that x is less than all values in xs</span>
<span class=\"keyword\">data</span> <span class=\"keyglyph\">_</span><span class=\"varop\">≤*</span><span class=\"keyglyph\">_</span> (<span class=\"varid\">x</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>) <span class=\"varop\">:</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"keyword\">where</span>
<span class=\"varop\">[]</span>  <span class=\"varop\">:</span> <span class=\"varid\">x</span> <span class=\"varop\">≤*</span> <span class=\"varop\">[]</span>
<span class=\"keyglyph\">_</span>∷<span class=\"keyglyph\">_</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">y</span> <span class=\"varid\">ys</span>} <span class=\"keyglyph\">→</span> (<span class=\"varid\">x</span> <span class=\"varop\">≤</span> <span class=\"varid\">y</span>) <span class=\"keyglyph\">→</span> <span class=\"varid\">x</span> <span class=\"varop\">≤*</span> <span class=\"varid\">ys</span> <span class=\"keyglyph\">→</span> <span class=\"varid\">x</span> <span class=\"varop\">≤*</span> (<span class=\"varid\">y</span> ∷ <span class=\"varid\">ys</span>)
<div class=\"empty-line\"></div>
<span class=\"comment\">-- Proof that a list is sorted</span>
<span class=\"keyword\">data</span> <span class=\"conid\">IsSorted</span> <span class=\"varop\">:</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"keyword\">where</span>
<span class=\"varop\">[]</span>  <span class=\"varop\">:</span> <span class=\"conid\">IsSorted</span> <span class=\"varop\">[]</span>
<span class=\"keyglyph\">_</span>∷<span class=\"keyglyph\">_</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">x</span> <span class=\"varid\">xs</span>} <span class=\"keyglyph\">→</span> <span class=\"varid\">x</span> <span class=\"varop\">≤*</span> <span class=\"varid\">xs</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">IsSorted</span> <span class=\"varid\">xs</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">IsSorted</span> (<span class=\"varid\">x</span> ∷ <span class=\"varid\">xs</span>)
</pre><h2><a name=\"what-it-means-to-be-a-permutation\"></a>What it means to be a permutation </h2>
<p>To show that one list is a permutation of another I again used two data types.
Suppose that we know that <tt><span class=\"varid\">xs</span></tt> is a permutation of <tt><span class=\"varid\">ys</span></tt>. Then when is <tt class=\"complex\"><span class=\"varid\">x</span> ∷ <span class=\"varid\">xs</span></tt> a permutation of some list <tt><span class=\"varid\">xys</span></tt>? Well, we can permute <tt><span class=\"varid\">xs</span></tt> to <tt><span class=\"varid\">ys</span></tt>, and insert <tt><span class=\"varid\">x</span></tt> anywhere. I used <tt class=\"complex\"><span class=\"varop\">◂</span></tt> to denote this insertion,
</p><pre class=\"agda\"><span class=\"comment\">-- x ◂ xs ≡ xys means that xys is equal to xs with x inserted somewhere</span>
<span class=\"keyword\">data</span> <span class=\"keyglyph\">_</span><span class=\"varop\">◂</span><span class=\"keyglyph\">_</span><span class=\"varop\">≡</span><span class=\"keyglyph\">_</span> (<span class=\"varid\">x</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>) <span class=\"varop\">:</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span> <span class=\"keyword\">where</span>
<span class=\"varid\">here</span>  <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">xs</span>}           <span class=\"keyglyph\">→</span> <span class=\"varid\">x</span> <span class=\"varop\">◂</span> <span class=\"varid\">xs</span> <span class=\"varop\">≡</span> (<span class=\"varid\">x</span> ∷ <span class=\"varid\">xs</span>)
<span class=\"varid\">there</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">y</span>} {<span class=\"varid\">xs</span>} {<span class=\"varid\">xys</span>} <span class=\"keyglyph\">→</span> (<span class=\"varid\">p</span> <span class=\"varop\">:</span> <span class=\"varid\">x</span> <span class=\"varop\">◂</span> <span class=\"varid\">xs</span> <span class=\"varop\">≡</span> <span class=\"varid\">xys</span>) <span class=\"keyglyph\">→</span> <span class=\"varid\">x</span> <span class=\"varop\">◂</span> (<span class=\"varid\">y</span> ∷ <span class=\"varid\">xs</span>) <span class=\"varop\">≡</span> (<span class=\"varid\">y</span> ∷ <span class=\"varid\">xys</span>)
</pre><pre class=\"agda\"><span class=\"comment\">-- Proof that a list is a permutation of another one</span>
<span class=\"keyword\">data</span> <span class=\"conid\">IsPermutation</span> <span class=\"varop\">:</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span> <span class=\"keyword\">where</span>
<span class=\"varop\">[]</span>  <span class=\"varop\">:</span> <span class=\"conid\">IsPermutation</span> <span class=\"varop\">[]</span> <span class=\"varop\">[]</span>
<span class=\"keyglyph\">_</span>∷<span class=\"keyglyph\">_</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">x</span> <span class=\"varid\">xs</span> <span class=\"varid\">ys</span> <span class=\"varid\">xys</span>}
<span class=\"keyglyph\">→</span> (<span class=\"varid\">p</span> <span class=\"varop\">:</span> <span class=\"varid\">x</span> <span class=\"varop\">◂</span> <span class=\"varid\">ys</span> <span class=\"varop\">≡</span> <span class=\"varid\">xys</span>)
<span class=\"keyglyph\">→</span> (<span class=\"varid\">ps</span> <span class=\"varop\">:</span> <span class=\"conid\">IsPermutation</span> <span class=\"varid\">xs</span> <span class=\"varid\">ys</span>)
<span class=\"keyglyph\">→</span> <span class=\"conid\">IsPermutation</span> (<span class=\"varid\">x</span> ∷ <span class=\"varid\">xs</span>) <span class=\"varid\">xys</span>
</pre><p>Now the <tt><span class=\"conid\">Sorted</span></tt> data type has three components: the sorted list, a proof that it is sorted, and a proof that it is a permutation of the input. These parts are either all <tt class=\"complex\"><span class=\"varop\">[]</span></tt>, or they are all <tt class=\"complex\"><span class=\"keyglyph\">_</span>∷<span class=\"keyglyph\">_</span></tt>.
It turns out to be much nicer to combine the parts together,
</p><pre class=\"agda\"><span class=\"comment\">-- Sorted permutations of a list</span>
<span class=\"keyword\">data</span> <span class=\"conid\">Sorted</span> <span class=\"varop\">:</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span>  <span class=\"keyword\">where</span>
<span class=\"varop\">[]</span>   <span class=\"varop\">:</span> <span class=\"conid\">Sorted</span> <span class=\"varop\">[]</span>
<span class=\"varid\">cons</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> <span class=\"varid\">x</span> {<span class=\"varid\">xs</span> <span class=\"varid\">xxs</span>}
<span class=\"keyglyph\">→</span> (<span class=\"varid\">p</span> <span class=\"varop\">:</span> <span class=\"varid\">x</span> <span class=\"varop\">◂</span> <span class=\"varid\">xs</span> <span class=\"varop\">≡</span> <span class=\"varid\">xxs</span>) <span class=\"comment\">-- inserting x somewhere into xs gives xxs</span>
<span class=\"keyglyph\">→</span> (<span class=\"varid\">least</span> <span class=\"varop\">:</span> <span class=\"varid\">x</span> <span class=\"varop\">≤*</span> <span class=\"varid\">xs</span>)  <span class=\"comment\">-- x is the smallest element of the list</span>
<span class=\"keyglyph\">→</span> (<span class=\"varid\">rest</span> <span class=\"varop\">:</span> <span class=\"conid\">Sorted</span> <span class=\"varid\">xs</span>) <span class=\"comment\">-- and we have also sorted xs</span>
<span class=\"keyglyph\">→</span> <span class=\"conid\">Sorted</span> <span class=\"varid\">xxs</span>
</pre><p>Of course <tt><span class=\"conid\">Sorted</span></tt> and <tt class=\"complex\"><span class=\"conid\">Sorted'</span></tt> are equivalent.
</p><p>As an aside, these are all the ingredients necessary for proving
</p><pre class=\"agda\"><span class=\"varid\">sorted-unique</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">xs</span>} <span class=\"keyglyph\">→</span> (<span class=\"varid\">ys</span> <span class=\"varid\">zs</span> <span class=\"varop\">:</span> <span class=\"conid\">Sorted</span> <span class=\"varid\">xs</span>)
<span class=\"keyglyph\">→</span> <span class=\"varid\">sorted-to-List</span> <span class=\"varid\">ys</span> <span class=\"varop\">≡</span> <span class=\"varid\">sorted-to-List</span> <span class=\"varid\">zs</span>
</pre><h2><a name=\"a-monad-for-keeping-track-of-the-runtime\"></a>A monad for keeping track of the runtime </h2>
<p>To be able to reason about the runtime, as measured in the number of comparisons performed, I decided to use a monad. The type is simply
</p><pre class=\"agda\"><span class=\"keyword\">data</span> <span class=\"keyglyph\">_</span><span class=\"varop\">in-time</span><span class=\"keyglyph\">_</span> (<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span>) (<span class=\"varid\">n</span> <span class=\"varop\">:</span> <span class=\"conop\">ℕ</span>) <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span> <span class=\"keyword\">where</span>
<span class=\"varid\">box</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">C</span> <span class=\"conid\">A</span> <span class=\"varid\">n</span>
</pre><p>the constructor <tt><span class=\"varid\">box</span></tt> is private, and it can only be accessed through the standard monad operations,
</p><pre class=\"agda\"><span class=\"varid\">return</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"conid\">A</span> <span class=\"varid\">n</span>} <span class=\"keyglyph\">→</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">A</span> <span class=\"varop\">in-time</span> <span class=\"varid\">n</span>
<div class=\"empty-line\"></div>
<span class=\"keyglyph\">_</span><span class=\"varop\">>>=</span><span class=\"keyglyph\">_</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"conid\">A</span> <span class=\"conid\">B</span>} {<span class=\"varid\">m</span> <span class=\"varid\">n</span>} <span class=\"keyglyph\">→</span> <span class=\"conid\">A</span> <span class=\"varop\">in-time</span> <span class=\"varid\">n</span> <span class=\"keyglyph\">→</span> (<span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span> <span class=\"varop\">in-time</span> <span class=\"varid\">m</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span> <span class=\"varop\">in-time</span> (<span class=\"varid\">n</span> <span class=\"varop\">+</span> <span class=\"varid\">m</span>)
</pre><p>Then the sorting functions will be parametrized by a function that for some partial order decides between <tt class=\"complex\"><span class=\"varid\">x</span> <span class=\"varop\">≤</span> <span class=\"varid\">y</span></tt> and <tt class=\"complex\"><span class=\"varid\">y</span> <span class=\"varop\">≤</span> <span class=\"varid\">x</span></tt> in one step, using the monad we defined above:
</p><pre class=\"agda\"><span class=\"keyword\">module</span> <span class=\"conid\">Sorting</span>
{<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span>} {<span class=\"varid\">l</span>} {<span class=\"keyglyph\">_</span><span class=\"varop\">≤</span><span class=\"keyglyph\">_</span> <span class=\"varop\">:</span> <span class=\"conid\">Rel</span> <span class=\"conid\">A</span> <span class=\"varid\">l</span>}
(<span class=\"varid\">isPartialOrder</span> <span class=\"varop\">:</span> <span class=\"conid\">IsPartialOrder</span> <span class=\"keyglyph\">_</span><span class=\"varop\">≡</span><span class=\"keyglyph\">_</span> <span class=\"keyglyph\">_</span><span class=\"varop\">≤</span><span class=\"keyglyph\">_</span>)
(<span class=\"keyglyph\">_</span><span class=\"varop\">≤?</span><span class=\"keyglyph\">_</span> <span class=\"varop\">:</span> (<span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span>) <span class=\"keyglyph\">→</span> (<span class=\"varid\">x</span> <span class=\"varop\">≤</span> <span class=\"varid\">y</span> <span class=\"conop\">⊎</span> <span class=\"varid\">y</span> <span class=\"varop\">≤</span> <span class=\"varid\">x</span>) <span class=\"varop\">in-time</span> <span class=\"num\">1</span>)
<span class=\"keyword\">where</span> <span class=\"varop\">...</span>
</pre><p>Note that I specify that <tt class=\"complex\"><span class=\"keyglyph\">_</span><span class=\"varop\">≤</span><span class=\"keyglyph\">_</span></tt> is a <em>partial</em> order,
because the Agda standard library definition of a total order actually comes with a function
</p><pre class=\"agda\"><span class=\"varid\">total</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"keyglyph\">→</span> (<span class=\"varid\">x</span> <span class=\"varop\">≤</span> <span class=\"varid\">y</span>) <span class=\"conop\">⊎</span> (<span class=\"varid\">y</span> <span class=\"varop\">≤</span> <span class=\"varid\">x</span>)
</pre><p>which would defeat the whole prupose of <tt class=\"complex\"><span class=\"keyglyph\">_</span><span class=\"varop\">≤?</span><span class=\"keyglyph\">_</span></tt>.
In fact, the standard <tt><span class=\"conid\">TotalOrder</span></tt>s are decidable up to base equality, and if the base equality is propositional equality, then they are decidable. I.e.
</p><pre class=\"agda\"><span class=\"varid\">total-decidable</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">r</span>} {<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} <span class=\"keyglyph\">→</span> (<span class=\"keyglyph\">_</span><span class=\"varop\">≤</span><span class=\"keyglyph\">_</span> <span class=\"varop\">:</span> <span class=\"conid\">Rel</span> <span class=\"conid\">A</span> <span class=\"varid\">r</span>)
<span class=\"keyglyph\">→</span> <span class=\"conid\">IsTotalOrder</span> <span class=\"keyglyph\">_</span><span class=\"varop\">≡</span><span class=\"keyglyph\">_</span> <span class=\"keyglyph\">_</span><span class=\"varop\">≤</span><span class=\"keyglyph\">_</span>
<span class=\"keyglyph\">→</span> <span class=\"conid\">IsDecTotalOrder</span> <span class=\"keyglyph\">_</span><span class=\"varop\">≡</span><span class=\"keyglyph\">_</span> <span class=\"keyglyph\">_</span><span class=\"varop\">≤</span><span class=\"keyglyph\">_</span>
</pre><p>See the source for the proof of this side theorem. It relies on a trick to show that <tt class=\"complex\"><span class=\"varid\">total</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span></tt> can only be different from <tt class=\"complex\"><span class=\"varid\">total</span> <span class=\"varid\">y</span> <span class=\"varid\">x</span></tt> if <tt class=\"complex\"><span class=\"varid\">x</span> <span class=\"varop\">≢</span> <span class=\"varid\">y</span></tt>. Which holds for propositional equality, but not in general.
</p><h2><a name=\"logarithms\"></a>Logarithms </h2>
<p>To be able to complete the specification of merge sort, we still need to add some missing functions on natural numbers. In particular, we need a logarithm.
This logarithm turns out to be surprisingly tricky to define in Agda.
Why? Because the usual definition uses non-structural recursion. In haskell you would write
</p><pre class=\"haskell\"><span class=\"comment\">-- @log n@ calculates ⌊log₂ (n+1)⌋</span>
<span class=\"varid\">log</span> <span class=\"num\">0</span> <span class=\"keyglyph\">=</span> <span class=\"num\">0</span>
<span class=\"varid\">log</span> <span class=\"varid\">n</span> <span class=\"keyglyph\">=</span> <span class=\"num\">1</span> <span class=\"varop\">+</span> <span class=\"varid\">log</span> (<span class=\"varid\">n</span> `<span class=\"varid\">div`</span> <span class=\"num\">2</span>)
</pre><p>But Agda is not able to see that <tt class=\"complex\"><span class=\"varid\">n</span> `<span class=\"varid\">div`</span> <span class=\"num\">2</span></tt> (or in agda notation, <tt class=\"complex\"><span class=\"varop\">⌊</span> <span class=\"varid\">n</span> <span class=\"varop\">/2⌋</span></tt>) is smaller than <tt><span class=\"varid\">n</span></tt>.
There are two approaches to circumvent this problem:
</p><ol><li> Use a different algorithm: Convert <tt><span class=\"varid\">n</span></tt> to a binary representation, and count the number of digits.</li>
<li> Use well-founded recursion, manually supplying a proof that <tt class=\"complex\"><span class=\"varop\">⌊</span> <span class=\"varid\">n</span> <span class=\"varop\">/2⌋</span> <span class=\"varop\"><</span> <span class=\"varid\">n</span></tt>.</li>
</ol><p>I went with the second option, because I will also be using the same shape of recursion inside merge sort itself.
The standard way to use well-founded recursion is through the function <tt class=\"complex\"><span class=\"keyglyph\"><-</span><span class=\"varid\">rec</span></tt>, which works a bit like <tt><span class=\"varid\">fix</span></tt> in haskell, except that you need to pass in a proof that the argument is smaller. The code would look like this:
</p><pre class=\"agda\"><span class=\"varid\">log</span> <span class=\"keyglyph\">=</span> <span class=\"keyglyph\"><-</span><span class=\"varid\">rec</span> <span class=\"varid\">log'</span>
<span class=\"keyword\">where</span>
<span class=\"varid\">log′</span> <span class=\"varid\">self</span> <span class=\"num\">0</span> <span class=\"keyglyph\">=</span> <span class=\"num\">0</span>
<span class=\"varid\">log′</span> <span class=\"varid\">self</span> (<span class=\"varid\">suc</span> <span class=\"varid\">n</span>) <span class=\"keyglyph\">=</span> <span class=\"num\">1</span> <span class=\"varop\">+</span> <span class=\"varid\">self</span> <span class=\"varop\">⌊</span> <span class=\"varid\">suc</span> <span class=\"varid\">n</span> <span class=\"varop\">/2⌋</span> (<span class=\"comment\">{-proof ommitted-}</span>)
</pre><p>But this leads to a problem as soon as you want to prove a property of logarithms. For example, you would think that <tt class=\"complex\"><span class=\"varid\">log</span> (<span class=\"varid\">suc</span> <span class=\"varid\">n</span>) <span class=\"varop\">≡</span> <span class=\"num\">1</span> <span class=\"varop\">+</span> (<span class=\"varid\">log</span> <span class=\"varop\">⌊</span> <span class=\"varid\">suc</span> <span class=\"varid\">n</span> <span class=\"varop\">/2⌋</span>)</tt>. But that is not definitionally true, since one <tt class=\"complex\"><span class=\"keyglyph\"><-</span><span class=\"varid\">rec</span></tt> is not like another. I found that the well-founded recursion library was in general a pain to work with, especially because it uses so many type synonyms. My solution was to use the slightly lower level accessibility relation. A value of type <tt class=\"complex\"><span class=\"conid\">Acc</span> <span class=\"keyglyph\">_</span><span class=\"varop\"><′</span><span class=\"keyglyph\">_</span> <span class=\"varid\">n</span></tt> allows you to do recursion with any <tt class=\"complex\"><span class=\"varid\">m</span> <span class=\"varop\"><′</span> <span class=\"varid\">n</span></tt>. Now I can use actual recursion:
</p><pre class=\"agda\"><span class=\"varid\">log-acc</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> <span class=\"varid\">n</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Acc</span> <span class=\"keyglyph\">_</span><span class=\"varop\"><′</span><span class=\"keyglyph\">_</span> <span class=\"varid\">n</span> <span class=\"keyglyph\">→</span> <span class=\"conop\">ℕ</span>
<span class=\"varid\">log-acc</span> <span class=\"num\">0</span> <span class=\"keyglyph\">_</span> <span class=\"keyglyph\">=</span> <span class=\"num\">0</span>
<span class=\"varid\">log-acc</span> (<span class=\"varid\">suc</span> <span class=\"varid\">n</span>) (<span class=\"varid\">acc</span> <span class=\"varid\">more</span>) <span class=\"keyglyph\">=</span> <span class=\"num\">1</span> <span class=\"varop\">+</span> <span class=\"varid\">log-acc</span> <span class=\"varop\">⌊</span> <span class=\"varid\">suc</span> <span class=\"varid\">n</span> <span class=\"varop\">/2⌋</span> (<span class=\"varid\">more</span> <span class=\"keyglyph\">_</span> <span class=\"comment\">{-proof ommitted-}</span>)
</pre><p>And use the well-foundedness of ℕ to get an <tt><span class=\"conid\">Acc</span></tt> for any number:
</p><pre class=\"agda\"><span class=\"varid\">log</span> <span class=\"varop\">:</span> <span class=\"conop\">ℕ</span> <span class=\"keyglyph\">→</span> <span class=\"conop\">ℕ</span>
<span class=\"varid\">log</span> <span class=\"varid\">n</span> <span class=\"keyglyph\">=</span> <span class=\"varid\">log-acc</span> <span class=\"varid\">n</span> (<span class=\"keyglyph\"><-</span><span class=\"varid\">well-founded</span> <span class=\"varid\">n</span>)
<div class=\"empty-line\"></div>
<span class=\"varop\">⌈log₂</span><span class=\"keyglyph\">_</span><span class=\"varop\">⌉</span> <span class=\"varop\">:</span> <span class=\"conop\">ℕ</span> <span class=\"keyglyph\">→</span> <span class=\"conop\">ℕ</span>
<span class=\"varop\">⌈log₂</span> <span class=\"varid\">n</span> <span class=\"varop\">⌉</span> <span class=\"keyglyph\">=</span> <span class=\"varid\">log</span> (<span class=\"varid\">pred</span> <span class=\"varid\">n</span>)
</pre><p>There is still a snag when proving properties of <tt><span class=\"varid\">log</span></tt> or <tt class=\"complex\"><span class=\"varid\">log-acc</span></tt>, namely that you need to prove that <tt class=\"complex\">(<span class=\"varid\">more</span> <span class=\"varid\">n</span> <span class=\"varop\">...</span>) <span class=\"varop\">≡</span> <span class=\"keyglyph\"><-</span><span class=\"varid\">well-founded</span> <span class=\"varid\">n</span></tt>. But the accessibility relation doesn't actually matter for the computation, so I decided to just postulate
</p><pre class=\"agda\"><span class=\"keyword\">postulate</span> <span class=\"varid\">acc-irrelevance</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">n</span> <span class=\"varop\">:</span> <span class=\"conop\">ℕ</span>} <span class=\"keyglyph\">→</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span> <span class=\"varop\">:</span> <span class=\"conid\">Acc</span> <span class=\"keyglyph\">_</span><span class=\"varop\"><′</span><span class=\"keyglyph\">_</span> <span class=\"varid\">n</span>} <span class=\"keyglyph\">→</span> <span class=\"varid\">a</span> <span class=\"varop\">≡</span> <span class=\"varid\">b</span>
<span class=\"comment\">-- this also follows from function extensionality</span>
</pre><p>If anyone knows a better way to prove properties of functions defined with well-founded recursion, I am open to suggestions.
</p><h2><a name=\"vectors-versus-lists\"></a>Vectors versus lists </h2>
<p>While working on the proofs I had to choose: Do I use fixed length <tt><span class=\"conid\">Vec</span></tt>s or variable length <tt><span class=\"conid\">List</span></tt>s? Both have their pros and cons.
</p><p>On the one hand, the sorting functions with vectors look a bit nicer, because we can use <tt><span class=\"varid\">n</span></tt> instead of <tt class=\"complex\"><span class=\"varid\">length</span> <span class=\"varid\">xs</span></tt>:
</p><pre class=\"agda\"><span class=\"varid\">merge-sort</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">n</span>} (<span class=\"varid\">xs</span> <span class=\"varop\">:</span> <span class=\"conid\">Vec</span> <span class=\"conid\">A</span> <span class=\"varid\">n</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">Sorted</span> <span class=\"varid\">xs</span> <span class=\"varop\">in-time</span> (<span class=\"varid\">n</span> <span class=\"varop\">*</span> <span class=\"varop\">⌈log₂</span> <span class=\"varid\">n</span> <span class=\"varop\">⌉</span>)
</pre><p>Additionally, with lists we can only do recursion on the input list, with vectors we can do recursion on the length of the list. The former works fine for insertion sort, where in each step you do something with the head element of the list; but it fails for selection and merge sort.
</p><p>On the other hand, with vectors you sometimes can't even <em>state</em> the property that one vector is equal to another.
For the term <tt class=\"complex\"><span class=\"varid\">xs</span> <span class=\"varop\">≡</span> <span class=\"varid\">ys</span> <span class=\"varop\">++</span> <span class=\"varid\">zs</span></tt> to be well-typed, <tt><span class=\"varid\">xs</span></tt> must have the type <tt class=\"complex\"><span class=\"conid\">Vec</span> <span class=\"conid\">A</span> (<span class=\"varid\">m</span> <span class=\"varop\">+</span> <span class=\"varid\">n</span>)</tt>.
</p><p>I went back and forth a couple of times between vectors and lists.
In the end I settled for using vectors only when needed, and specifying properties in terms of lists.
For example the split function for merge sort has the type
</p><pre class=\"agda\"><span class=\"varid\">splitHalf</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">n</span>} <span class=\"keyglyph\">→</span> (<span class=\"varid\">xs</span> <span class=\"varop\">:</span> <span class=\"conid\">Vec</span> <span class=\"conid\">A</span> <span class=\"varid\">n</span>)
<span class=\"keyglyph\">→</span> ∃₂ <span class=\"keyglyph\">\\</span>(<span class=\"varid\">ys</span> <span class=\"varop\">:</span> <span class=\"conid\">Vec</span> <span class=\"conid\">A</span> <span class=\"varop\">⌈</span> <span class=\"varid\">n</span> <span class=\"varop\">/2⌉</span>) (<span class=\"varid\">zs</span> <span class=\"varop\">:</span> <span class=\"conid\">Vec</span> <span class=\"conid\">A</span> <span class=\"varop\">⌊</span> <span class=\"varid\">n</span> <span class=\"varop\">/2⌋</span>)
<span class=\"keyglyph\">→</span> <span class=\"varid\">toList</span> <span class=\"varid\">ys</span> <span class=\"varop\">++</span> <span class=\"varid\">toList</span> <span class=\"varid\">zs</span> <span class=\"varop\">≡</span> <span class=\"varid\">toList</span> <span class=\"varid\">xs</span>
</pre><p>So instead of using <tt class=\"complex\">Vec<span class=\"varop\">.</span><span class=\"keyglyph\">_</span><span class=\"varop\">++</span><span class=\"keyglyph\">_</span></tt>, I use <tt class=\"complex\">List<span class=\"varop\">.</span><span class=\"keyglyph\">_</span><span class=\"varop\">++</span><span class=\"keyglyph\">_</span></tt>.
In this style 'select' from selection sort looks like
</p><pre class=\"agda\"><span class=\"varid\">select</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">n</span>} (<span class=\"varid\">xs</span> <span class=\"varop\">:</span> <span class=\"conid\">Vec</span> <span class=\"conid\">A</span> (<span class=\"varid\">suc</span> <span class=\"varid\">n</span>))
<span class=\"keyglyph\">→</span> (∃₂ <span class=\"keyglyph\">\\</span><span class=\"varid\">y</span> <span class=\"varid\">ys</span> <span class=\"keyglyph\">→</span> (<span class=\"varid\">y</span> <span class=\"varop\">◂</span> <span class=\"varid\">toList</span> <span class=\"varid\">ys</span> <span class=\"varop\">≡</span> <span class=\"varid\">toList</span> <span class=\"varid\">xs</span>) × (<span class=\"varid\">y</span> <span class=\"varop\">≤*</span> <span class=\"varid\">toList</span> <span class=\"varid\">ys</span>)) <span class=\"varop\">in-time</span> <span class=\"varid\">n</span>
</pre><p>I.e. given a <em>vector</em> <tt><span class=\"varid\">xs</span></tt> with <tt class=\"complex\"><span class=\"varid\">n+1</span></tt> elements, return a vector <tt><span class=\"varid\">ys</span></tt> with <tt><span class=\"varid\">n</span></tt> elements, such that inserting <tt><span class=\"varid\">y</span></tt> into it gives us back <tt><span class=\"varid\">xs</span></tt>. And this item <tt><span class=\"varid\">y</span></tt> should be the smallest one.
</p><h2><a name=\"extension-expected-runtime\"></a>Extension: expected runtime </h2>
<p>An extension of this post would be to look at randomized sorting algorithms. In particular, quick sort with a randomly chosen pivot has expected runtime <tt class=\"complex\"><span class=\"conid\">O</span>(<span class=\"varid\">n</span> <span class=\"varop\">*</span> <span class=\"varid\">log</span> <span class=\"varid\">n</span>)</tt>. At first I thought that all that would be needed is a function
</p><pre class=\"agda\"><span class=\"varid\">expected</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"conid\">P</span>}
<span class=\"keyglyph\">→</span> (<span class=\"varid\">ns</span> <span class=\"varop\">:</span> <span class=\"conid\">List</span> <span class=\"conop\">ℕ</span>)             <span class=\"comment\">-- A list of numbers</span>
<span class=\"keyglyph\">→</span> <span class=\"conid\">All</span> (<span class=\"keyglyph\">\\</span><span class=\"varid\">n</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">P</span> <span class=\"varop\">in-time</span> <span class=\"varid\">n</span>) <span class=\"varid\">ns</span> <span class=\"comment\">-- for each n we have P in-time n</span>
<span class=\"keyglyph\">→</span> <span class=\"conid\">P</span> <span class=\"varop\">in-time</span> <span class=\"varop\">⌈mean</span> <span class=\"varid\">ns</span> <span class=\"varop\">⌉</span>      <span class=\"comment\">-- then expect time is mean of ns</span>
</pre><p>But that is not quite right, since if we actually knew the runtimes <tt><span class=\"varid\">ns</span></tt> we could just pick the fastest one.
With the randomized quicksort you will end up in a situation where you have two or more computations to choose from, and you know that some are faster than the others, but you don't yet know which one. That sounds a bit classical. A second idea is to return the runtimes at a later time, something like
</p><pre class=\"agda\"><span class=\"varid\">expected</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"conid\">P</span>} {<span class=\"varid\">long-time</span>}
<span class=\"keyglyph\">→</span> (<span class=\"varid\">xs</span> <span class=\"varop\">:</span> <span class=\"conid\">List</span> (<span class=\"keyglyph\">\\</span><span class=\"varid\">ex</span> <span class=\"varid\">n</span> <span class=\"conid\">P</span> <span class=\"varop\">in-time</span> <span class=\"varid\">n</span>) <span class=\"varop\">in-time</span> <span class=\"varid\">long-time</span>)
<span class=\"keyglyph\">→</span> <span class=\"conid\">P</span> <span class=\"varop\">in-time</span> <span class=\"varop\">⌈mean</span> <span class=\"varid\">map</span> <span class=\"varid\">proj1</span> <span class=\"varid\">xs</span> <span class=\"varop\">⌉</span>
</pre><p>But this is not quite right either, since after <tt class=\"complex\"><span class=\"varid\">long-time</span></tt> computing <tt><span class=\"conid\">P</span></tt> (i.e. a sorting) can be done in 0 time.
Rather, we need to decouple the proof about the runtime from the computation.
This is not possible with the <tt class=\"complex\"><span class=\"keyglyph\">_</span><span class=\"varop\">in-time</span><span class=\"keyglyph\">_</span></tt> monad. We would need to get rid of the runtime from the type, and store it as a value instead.
</p><p>I have tried redoing the proofs in this post with the monad
</p><pre class=\"agda\"><span class=\"keyword\">data</span> <span class=\"conid\">Timed</span> (<span class=\"conid\">A</span> <span class=\"varop\">:</span> <span class=\"conid\">Set</span>) <span class=\"varop\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span> <span class=\"keyword\">where</span>
<span class=\"keyglyph\">_</span><span class=\"varop\">in-time</span><span class=\"keyglyph\">_</span> <span class=\"varop\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conop\">ℕ</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Timed</span> <span class=\"conid\">A</span>
<span class=\"varid\">runtime</span> <span class=\"varop\">:</span> <span class=\"conid\">Timed</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conop\">ℕ</span>
</pre><p>But I didn't succeed; I ended up with the baffling error message
</p><pre class=\"agda\"><span class=\"varid\">runtime</span> (<span class=\"varid\">big-lambda-term</span> (<span class=\"varid\">unbox</span> (<span class=\"varid\">x</span> <span class=\"varop\">≤?</span> <span class=\"varid\">u</span>)))
<span class=\"varop\">!=</span>
<span class=\"varid\">runtime</span> (<span class=\"varid\">big-lambda-term</span> (<span class=\"varid\">unbox</span> (<span class=\"varid\">x</span> <span class=\"varop\">≤?</span> <span class=\"varid\">u</span>)))
</pre><h2><a name=\"another-extension-lower-bound-on-runtime\"></a>Another extension: lower bound on runtime </h2>
<p>So far I have proved that you can sort a list in time <tt class=\"complex\"><span class=\"varid\">n</span> <span class=\"varop\">*</span> <span class=\"varid\">log</span> <span class=\"varid\">n</span></tt>.
It would also be interesting to look at the well known <a href=\"http://planetmath.org/LowerBoundForSorting\">lower bound on the runtime of sorting</a>, and prove a theorem such as
</p><pre class=\"agda\"><span class=\"varid\">can't-sort-in-linear-time</span> <span class=\"varop\">:</span> ¬ ∃ <span class=\"keyglyph\">\\</span><span class=\"varid\">k</span> <span class=\"keyglyph\">→</span> <span class=\"keyglyph\">∀</span> <span class=\"varid\">xs</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Sorted</span> <span class=\"varid\">xs</span> <span class=\"varop\">in-time</span> <span class=\"varid\">k</span> <span class=\"varop\">*</span> <span class=\"varid\">length</span> <span class=\"varid\">xs</span>
</pre><p>unfortunately this statement is not actually true for all types. For finite sets you actually <em>can</em> sort in linear time with counting sort.
It also fails if we happen to have some decidable total order for that type lying around. But it might be possible to prove
</p><pre class=\"agda\"><span class=\"varid\">can't-sort-in-linear-time</span>
<span class=\"varop\">:</span> (<span class=\"varid\">no-fast-compare</span> <span class=\"varop\">:</span> <span class=\"keyglyph\">∀</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"keyglyph\">→</span> (<span class=\"varid\">x</span> <span class=\"varop\">≤</span> <span class=\"varid\">y</span> <span class=\"conop\">⊎</span> <span class=\"varid\">y</span> <span class=\"varop\">≤</span> <span class=\"varid\">x</span>) <span class=\"varop\">in-time</span> <span class=\"num\">0</span> <span class=\"keyglyph\">→</span> <span class=\"varid\">x</span> <span class=\"varop\">≡</span> <span class=\"varid\">y</span>)
<span class=\"keyglyph\">→</span> ¬ ∃ <span class=\"keyglyph\">\\</span><span class=\"varid\">k</span> <span class=\"keyglyph\">→</span> <span class=\"keyglyph\">∀</span> <span class=\"varid\">xs</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Sorted</span> <span class=\"varid\">xs</span> <span class=\"varop\">in-time</span> <span class=\"varid\">k</span> <span class=\"varop\">*</span> <span class=\"varid\">length</span> <span class=\"varid\">xs</span>
</pre><p>But you have to be really careful with a term like <tt class=\"complex\"><span class=\"varid\">no-fast-compare</span></tt>, because inside the runtime monad we do have values of type <tt class=\"complex\">(<span class=\"varid\">x</span> <span class=\"varop\">≤</span> <span class=\"varid\">y</span> <span class=\"conop\">⊎</span> <span class=\"varid\">y</span> <span class=\"varop\">≤</span> <span class=\"varid\">x</span>)</tt>. And so you can derive <tt class=\"complex\"><span class=\"keyglyph\">∀</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"keyglyph\">→</span> <span class=\"varid\">x</span> <span class=\"varop\">≡</span> <span class=\"varid\">y</span> <span class=\"varop\">in-time</span> <span class=\"num\">1</span></tt>, and therefore also <tt class=\"complex\">⊥ <span class=\"varop\">in-time</span> <span class=\"num\">1</span></tt> for non trivial types. Which certainly looks wrong to me.
</p><p>I don't know a way around this problem, but it might be related to the same issue as expected runtime.
I.e. the problem is that all information about the runtime is bundled together with the return value.
The lower bound proof essentially asks to sort a 'random' list, and by a counting argument shows that at least a certain number of comparisons are needed to be able to produce all outputs.
</p>" nil nil "d60485021a474624a737a1ff17f5f98a") (71 (20931 19033 40279) "http://praisecurseandrecurse.blogspot.com/2013/06/dispatch-for-polar-game-in-dylan.html" "Paul Potts: Dispatch for the Polar Game in Dylan" "noreply@blogger.com (Paul Potts)" "Thu, 20 Jun 2013 04:44:00 +0000" "<p>So with some assistance from the folks on the Dylan Hackers mailing list I got enough clues to press on and get my Dylan implementation of the Polar game working, at least up through the end of the first board. I haven't verified that every possible tile interaction works yet, but it's a start. This seems like a silly problem, but it interests me because of several problems. Dispatch (or simulated dispatch) is \"double dispatch,\" based on the types of two different objects interacting. The breakdown of how to categorize the classes of objects isn't 100% clear -- there is some overlap that I can't seem to eliminate, and the compiler has to decide what methods constitute the most specific match. And finally, the logic does not seem easily fixed in either classes representing the tiles, or a single class representing the board.</p> <p>If I wrote it in C, the tile classes pretty much wouldn't exist; they'd exist only as flag enumerations in an array of tiles, and the code would consist mostly of <b>switch</b> or <b>if-else</b> logic that did the \"double dispatch\" in a fixed, predictable order, without relying on the compiler very much. Objective-C, again mostly C with a thin layer for representing classes, doesn't really give these classes enough features to make them worthwhile, so I will probably just keep the board (the model in the model/view/controller) and treat the tiles like I would in plain old C. But in Dylan they have an interesting life in terms of how they can be used to organize the code -- using generic functions -- so that I'm doing less writing of \"code to find code\" -- that is, code to look at run-time identity of objects and \"manually\" dispatch on it.</p> <p>Here are the tile classes:</p> <pre>define abstract class <tile> ( <object> ) end;<br />define abstract class <blocking> ( <tile> ) end;<br />define abstract class <walkable> ( <tile> ) end;<br />define abstract class <movable> ( <blocking> ) end;<br />define abstract class <fixed> ( <blocking> ) end;<br />define class <bomb> ( <movable> ) end;<br />define class <heart> ( <movable> ) end;<br />define class <ice-block> ( <movable> ) end;<br />define class <house> ( <fixed> ) end;<br />define class <mountain> ( <fixed> ) end;<br />define class <edge> ( <fixed> ) end;<br />define class <tree> ( <blocking>, <walkable> ) end;<br />define class <empty> ( <walkable> ) end;</pre> <p>Oy, is that a pain to replace all the angle brackets with HTML entities... there must be a better way in Blogger! Anyway, these tile classes have no state -- in Dylan, no slots -- and are used in my program solely for their types. Edge does not actually appear on the board, but is used internally when the penguin or another moving object attempts to interact with the edge of the board. We treat this just like another blocking object, as if the board was surrounded by immovable, inert objects.</p> <p>Diagramatically, like so:</p> <a href=\"http://4.bp.blogspot.com/-edliQJKZWbs/UcJyojJiJ_I/AAAAAAAADGU/HrdQeMbN914/s1600/tile-classes-v2-75-percent.png\"><img src=\"http://4.bp.blogspot.com/-edliQJKZWbs/UcJyojJiJ_I/AAAAAAAADGU/HrdQeMbN914/s1600/tile-classes-v2-75-percent.png\" border=\"0\" /></a> <p>There did not seem to be one absolute best way to represent these classes. I want to organize their abstract base classes by behavior, but their behavior does not break down with complete consistency -- for example, tiles with trees are \"blocking\" with respect to sliding objects, except for the penguin. The ice block is \"blocking\" except for the case where the penguin pushes it and it is not adjacent to an empty tile -- then it is crushed. Bombs and hearts seem to have the same interactions with mountains and houses whether they traverse an empty tile by sliding first across one or more empty tiles, while ice blocks behave differently -- if they slide first and then collide with a blocking object, they are not destroyed, they just stop. So the groupings of the concrete classes isn't going to be able to coherently divide up all their possible behaviors.</p> <p>The scheme I settled on for object interactions involves three layers, in the form of three generic functions. The first represents interactions of the player's \"avatar,\" the penguin, with tiles:</p> <pre>define generic pushTile( model :: <model>, dir :: <dir>,<br />    pos :: <pos-or-false>, target-tile :: <tile> );<br /><br />define method pushTile( model :: <model>, dir :: <dir>,<br />    target-pos :: <pos>, target-tile :: <walkable> )<br />    => ( result :: <boolean> )<br />    model.penguin-pos := target-pos;<br />    #t;<br />end;<br /><br />define method pushTile( model :: <model>, dir :: <dir>,<br />    target-pos :: <pos>, target-tile :: <movable> )<br />    => ( result :: <boolean> )<br />    let next-pos :: <pos-or-false>  = <br />        getAdjacentPos( target-pos, dir );<br />    let next-tile = getTileAtPos ( model, next-pos );<br />    collide( model, dir, target-pos, target-tile,<br />        next-pos, next-tile );<br />    #f;<br />end;<br /><br />define method pushTile( model :: <model>, dir :: <dir>,<br />    target-pos :: <pos-or-false>, target-tile :: <fixed> )<br />    => ( result :: <boolean> )<br />    #f;<br />end;</pre> <p>Dylan doesn't strictly require that I define the generic function before defining methods for it; if I just start writing methods with the same name, it will assume that I mean them to be associated with a generic function. But defining the generic function first has a benefit -- the compiler will tell me whether my methods make sense, in that their parameters are all strictly the same type or a more specific subclass of the types mentioned in the <b>define generic</b> statement. Note that <b><pos-or-false></b> is a type union of a simple <b><pos></b> class with singleton( #f ). The generic uses that type union, but one of the methods are more specific: they require an actual <b><pos></b> instance and will not accept #f.</p> <p>The first method handles the case where the penguin is pushing a <b><walkable></b> tile, and returns false to indicate that the penguin position can be updated. The pos must not be <b>#f</b>. The second method handles pushing any <b><movable></b> tiles. And the third handles the <b><fixed></b> tiles. Between the three methods, you might notice that they cover all the leaf classes (all the instantiable classes) in the graph above, in 3 separate groups with no overlapping. You could shade in the leaf nodes covered by the three different methods with three different colors, going from the abstract classes mentioned downward, and all the leaves would all be colored and none would be colored more than once:</p> <a href=\"http://1.bp.blogspot.com/-7hB-6vXpCqc/UcJ6yt9HtyI/AAAAAAAADGk/KywbId2KW4k/s1600/tile-classes-v2-color-1-75-percent.png\"><img src=\"http://1.bp.blogspot.com/-7hB-6vXpCqc/UcJ6yt9HtyI/AAAAAAAADGk/KywbId2KW4k/s1600/tile-classes-v2-color-1-75-percent.png\" border=\"0\" /></a> <p>So on the tile parameter, the coverage of the concrete classes is complete and the dispatch algorithm should not have any difficulty. Combined with the position parameter, though, the situation is slightly trickier. At runtime, a caller could call <b>pushTile</b> with <b>#f</b> for <b>pos</b> and <b><empty></b>; or <b><bomb></b> for <b>tile</b> and the dispatcher would, correctly, throw up its hands at this point and say that there was no applicable method. I could have defined a more general method to handle this case, but I didn't -- there shouldn't ever be an empty or bomb tile without a corresponding valid position, since they are real tiles on the board, and I want the runtime to help me catch that case if it ever happens. Similarly, I could have defined a method that handled <b><blocking></b> or <b><tile></b> as part of this generic function but the whole point is that I don't know what to do with those more general classes here.</p> <p>So, you may notice that the middle <b>pushTile</b> method calls <b>collide</b> with a second tile and position, adjacent to the first in a specified direction. That generic function looks like this:</p> <pre>define generic collide( model :: <model>, dir :: <dir>,<br />    tile-1-pos :: <pos>, tile-1 :: <movable>,<br />    tile-2-pos :: <pos-or-false>, tile-2 :: <blocking-or-empty> );<br /><br />define method collide( model :: <model>, dir :: <dir>,<br />    movable-pos :: <pos>, movable-tile :: <movable>,<br />    next-pos :: <pos>, next-tile :: <empty> )<br />    slide ( model, dir, movable-pos, movable-tile,<br />            next-pos, next-tile );<br />end;<br /><br />define method collide( model :: <model>, dir :: <dir>,<br />    ice-block-pos :: <pos>, ice-block-tile :: <ice-block>,<br />    icebreaking-pos :: <pos-or-false>,<br />    ice-breaking-tile :: <blocking> )<br />    setTileAtPos( model, ice-block-pos, $the-empty );<br />end;<br /><br />define method collide( model :: <model>, dir :: <dir>,<br />    heart-pos :: <pos>, heart-tile :: <heart>,<br />    house-pos :: <pos>, house-tile :: <house> )<br />    setTileAtPos( model, heart-pos, $the-empty );<br />    decrementHeartCount( model );<br />end;<br /><br />define method collide( model :: <model>, dir :: <dir>,<br />    bomb-pos :: <pos>, bomb-tile :: <bomb>,<br />    mountain-pos :: <pos>, mountain-tile :: <mountain> )<br />    setTileAtPos( model, bomb-pos, $the-empty );<br />    setTileAtPos( model, mountain-pos, $the-empty );<br />end;<br /><br />define method collide( model :: <model>, dir :: <dir>,<br />    movable-pos :: <pos>, movable-tile :: <movable>,<br />    blocking-pos :: <pos-or-false>, blocking-tile :: <blocking> )<br />end;</pre> <p>You might notice that before long you hit yet another method call you haven't seen before -- slide. This is, as you might guess, yet another generic function. (Doesn't this program every get around to <i>doing</i> anything? In fact it does, but this is the often-paradoxical-seeming logic of object-oriented design -- individual methods that seem too small and simple to get anything done can actually get a lot done together, especially when aided by a smart dispatcher that eliminates most of the need to write \"code to find code.\"</p> <p>The type-union <b><blocking-or-empty></b> allows us to specify, for our generic function, as tight a class as possible out of two otherwise disjoint sections of our class diagram. We don't have to loosen the type specification needlessly by using <b><tile></b>, which would allow <b><walkable></b> as a valid class for this parameter. Meanwhile, we can loosen <b>tile-2-pos</b> so that we make our intention to allow <b>#f</b> explicit here.</p> <p>The methods break down as follows. The first one handles any movable tile that is moving onto an empty tile, by calling a slide method to be defined later. The second one is a special case to handle the crushable <b><ice-block></b> class -- if it is pushed into the world edge, or any other object, it is destroyed (replaced with <b>$the-empty</b> class instance). The third and fourth methods handle specific interactions between hearts and houses, and bombs and mountains. And finally, to handle the case where the penguin pushes a heart against a mountain, or a bomb against the edge of the world, we have a less specific method that dispatches on <b><movable></b> and <b><blocking></b>. This prevents the runtime from generating an error in this case, but also gives us a place where we could generate some kind of feedback to the user, like a special sound to indicate failure.</p> <p>The breakdown of instantiable tile classes here is much more complex, especially given that we are dispatching on two class parameters drawn from the same hierarchy. We could try coloring them by using two copies of the diagram:</p> <div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://1.bp.blogspot.com/-d-ajjIIutjI/UcM8kBSlaWI/AAAAAAAADHM/UQ5mauDpXKA/s1600/tile-classes-v2-double-dispatch-2-75-percent.png\"><img src=\"http://1.bp.blogspot.com/-d-ajjIIutjI/UcM8kBSlaWI/AAAAAAAADHM/UQ5mauDpXKA/s1600/tile-classes-v2-double-dispatch-2-75-percent.png\" border=\"0\" /></a></div> <p>Err, that's pretty, but is it helpful? I'm using colors and borders to indicate that classes are handled by specific methods, but the main thing I hope I'm illustrating is that, unlike with the first generic function, in this one there is significant overlap between the classes handled by the different methods. This is where the dispatch mechanism really has to shine. There is an ordering that makes sense from my point of view, and that is one in which the most specific matching method will be called. However, as you can see, quantifying \"most specific\" may be slightly complex when dispatching on more than one class parameter, throwing in type-unions for fun. Fortunately this code is now working, but while I was developing it I became familiar with a warning message in Open Dylan that says something like \"the method dispatch handling this set of classes is determined by arbitrary and capricious rules\" -- indicating that the dispatch logic is still considered a work in progress. I was concerned that the current version of the Open Dylan compiler wasn't quite solid enough to make this work, but it does seem to work. The backup plan was to dispatch entirely on type-unions made up of different sets of singletons, but that is longer and obscures what is meant by the abstract classes.</p> <p>I won't go to the trouble to do the same diagram on my slide method, but that code looks like this:</p> <pre>define generic slide( model :: <model>, dir :: <dir>,<br />    movable-pos :: <pos>, movable-tile :: <movable>,<br />    next-pos :: <pos-or-false>, next-tile :: <blocking-or-empty> );<br /><br />define method slide( model :: <model>, dir :: <dir>,<br />    movable-pos :: <pos>, movable-tile :: <movable>,<br />    next-pos :: <pos>, next-tile :: <empty> )<br />    let next-next-pos :: <pos-or-false> =<br />        getAdjacentPos( next-pos, dir );<br />    let next-next-tile = getTileAtPos( model, next-next-pos );<br />    setTileAtPos( model, next-pos, movable-tile );<br />    setTileAtPos( model, movable-pos, $the-empty );<br />    slide( model, dir, next-pos, getTileAtPos( model, next-pos ),<br />           next-next-pos, next-next-tile );<br />end;<br /><br />define method slide( model :: <model>, dir :: <dir>,<br />    movable-pos :: <pos>, movable-tile :: <movable>,<br />    next-pos :: <pos-or-false>, next-tile :: <blocking> )<br />    collide( model, dir, movable-pos, movable-tile,<br />              next-pos, next-tile );<br />end;<br /><br />define method slide( model :: <model>, dir :: <dir>,<br />    ice-block-pos :: <pos>, ice-block-tile :: <ice-block>,<br />    next-pos :: <pos-or-false>, next-tile :: <blocking> )<br />end;</pre> <p>Aaaand that's pretty much the whole of the logic for handling interaction between the penguin and the various tiles. Note that we call ourselves recursively. It looks kind of like we have no termination condition! Except note that the method isn't calling itself, it's doing the same method dispatch that found it in the first place. When we come to a termination condition for our recursions, we'll actually call a different method of the same generic function -- most likely the third one, where a sliding object encounters a blocking object. That condition can include hitting the edge of the board. And fortunately -- we already have logic for that, mostly -- in our collide generic function! So sliding hearts and bombs are handled just the same as if they were pushed instead of ending a slide.</p> <p>There's a slightly tricky part where we want to bind up the next tile beyond the two tiles we were dispatched on, then perform two set operations to move the currently sliding tile, then dispatch on the new second and third tiles we've set, rather than the original incoming second tile and the new third one. That required drawing a few little diagrams when I wrote it, but it works just fine.</p> <p>This is not the whole program, obviously, but these are the key methods for encoding the collisions between tiles. If you'd like to play with the whole program, you might come and join the <a href=\"https://lists.opendylan.org/mailman/listinfo/hackers\">Dylan Hackers mailing list</a>, or leave me a note. If there is interest I'll publish it, here or elsewhere. I am now curious as to how a similar set of overlapping dispatches -- via pattern matching, perhaps? -- might look in Haskell. I might try to write that next. If you've got an idea about the clearest and most idiomatic way to do it, I welcome your comments.</p>" nil nil "2fa9a721affc32d924d7825e2d0c26e1") (70 (20931 1847 380202) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_5229\"></span>, where <span id=\"tex_6636\"></span> is the number of “folds” and <span id=\"tex_2370\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_1643\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "d0221aaf10a18cf04f56ca656a15aa70") (69 (20930 47228 365799) "http://praisecurseandrecurse.blogspot.com/2013/06/dispatch-for-polar-game-in-dylan.html" "Paul Potts: Dispatch for the Polar Game in Dylan" "noreply@blogger.com (Paul Potts)" "Thu, 20 Jun 2013 04:44:00 +0000" "<p>So with some assistance from the folks on the Dylan Hackers mailing list I got enough clues to press on and get my Dylan implementation of the Polar game working, at least up through the end of the first board. I haven't verified that every possible tile interaction works yet, but it's a start. This seems like a silly problem, but it interests me because of several problems. Dispatch (or simulated dispatch) is \"double dispatch,\" based on the types of two different objects interacting. The breakdown of how to categorize the classes of objects isn't 100% clear -- there is some overlap that I can't seem to eliminate, and the compiler has to decide what methods constitute the most specific match. And finally, the logic does not seem easily fixed in either classes representing the tiles, or a single class representing the board.</p> <p>If I wrote it in C, the tile classes pretty much wouldn't exist; they'd exist only as flag enumerations in an array of tiles, and the code would consist mostly of <b>switch</b> or <b>if-else</b> logic that did the \"double dispatch\" in a fixed, predictable order, without relying on the compiler very much. Objective-C, again mostly C with a thin layer for representing classes, doesn't really give these classes enough features to make them worthwhile, so I will probably just keep the board (the model in the model/view/controller) and treat the tiles like I would in plain old C. But in Dylan they have an interesting life in terms of how they can be used to organize the code -- methods into generic functions -- so that I'm doing less writing of \"code to find code\" -- that is, code to look at run-time identity of objects and \"manually\" dispatch on it.</p> <p>Here are the tile classes:</p> <pre>define abstract class <tile> ( <object> ) end;<br />define abstract class <blocking> ( <tile> ) end;<br />define abstract class <walkable> ( <tile> ) end;<br />define abstract class <movable> ( <blocking> ) end;<br />define abstract class <fixed> ( <blocking> ) end;<br />define class <bomb> ( <movable> ) end;<br />define class <heart> ( <movable> ) end;<br />define class <ice-block> ( <movable> ) end;<br />define class <house> ( <fixed> ) end;<br />define class <mountain> ( <fixed> ) end;<br />define class <edge> ( <fixed> ) end;<br />define class <tree> ( <blocking>, <walkable> ) end;<br />define class <empty> ( <walkable> ) end;</pre> <p>Oy, is that a pain to replace all the angle brackets with HTML entities... there must be a better way in Blogger! Anyway, these tile classes have no state -- in Dylan, no slots -- and are used in my program solely for their types. Edge does not actually appear on the board, but is used internally when the penguin or another moving object attempts to interact with the edge of the board. We treat this just like another blocking object, as if the board was surrounded by immovable, inert objects.</p> <p>Diagramatically, like so:</p> <a href=\"http://4.bp.blogspot.com/-edliQJKZWbs/UcJyojJiJ_I/AAAAAAAADGU/HrdQeMbN914/s1600/tile-classes-v2-75-percent.png\"><img src=\"http://4.bp.blogspot.com/-edliQJKZWbs/UcJyojJiJ_I/AAAAAAAADGU/HrdQeMbN914/s1600/tile-classes-v2-75-percent.png\" border=\"0\" /></a> <p>There did not seem to be one absolute best way to represent these classes. I want to organize their abstract base classes by behavior, but their behavior does not break down with complete consistency -- for example, tiles with trees are \"blocking\" with respect to sliding objects, except for the penguin. The ice block is \"blocking\" except for the case where the penguin pushes it and it is not adjacent to an empty tile -- then it is crushed. Bombs and hearts seem to have the same interactions with mountains and houses whether they traverse an empty tile by sliding first across one or more empty tiles, while ice blocks behave differently -- if they slide first and then collide with a blocking object, they are not destroyed, they just stop. So the groupings of the concrete classes isn't going to be able to coherently divide up all their possible behaviors.</p> <p>The scheme I settled on for object interactions involves three layers, in the form of three generic functions. The first represents interactions of the player's \"avatar,\" the penguin, with tiles:</p> <pre>define generic pushTile( model :: <model>, dir :: <dir>,<br />    pos :: <pos-or-false>, target-tile :: <tile> );<br /><br />define method pushTile( model :: <model>, dir :: <dir>,<br />    target-pos :: <pos>, target-tile :: <walkable> )<br />    => ( result :: <boolean> )<br />    model.penguin-pos := target-pos;<br />    #t;<br />end;<br /><br />define method pushTile( model :: <model>, dir :: <dir>,<br />    target-pos :: <pos>, target-tile :: <movable> )<br />    => ( result :: <boolean> )<br />    let next-pos :: <pos-or-false>  = <br />        getAdjacentPos( target-pos, dir );<br />    let next-tile = getTileAtPos ( model, next-pos );<br />    collide( model, dir, target-pos, target-tile,<br />        next-pos, next-tile );<br />    #f;<br />end;<br /><br />define method pushTile( model :: <model>, dir :: <dir>,<br />    target-pos :: <pos-or-false>, target-tile :: <fixed> )<br />    => ( result :: <boolean> )<br />    #f;<br />end;</pre> <p>Dylan doesn't strictly require that I define the generic function before defining methods for it; if I just start writing methods with the same name, it will assume that I mean them to be associated with a generic function. But defining the generic function first has a benefit -- the compiler will tell me whether my methods make sense, in that their parameters are all strictly the same type or a more specific subclass of the types mentioned in the <b>define generic</b> statement. Note that <b><pos-or-false></b> is a type union of a simple <b><pos></b> class with singleton( #f ). The generic uses that type union, but one of the methods are more specific: they require an actual <b><pos></b> instance and will not accept #f.</p> <p>The first method handles the case where the penguin is pushing a <b><walkable></b> tile, and returns false to indicate that the penguin position can be updated. The pos must not be <b>#f</b>. The second method handles pushing any <b><movable></b> tiles. And the third handles the <b><fixed></b> tiles. Between the three methods, you might notice that they cover all the leaf classes (all the instantiable classes) in the graph above, in 3 separate groups with no overlapping. You could shade in the leaf nodes covered by the three different methods with three different colors, going from the abstract classes mentioned downward, and all the leaves would all be colored and none would be left un-colored:</p> <a href=\"http://1.bp.blogspot.com/-7hB-6vXpCqc/UcJ6yt9HtyI/AAAAAAAADGk/KywbId2KW4k/s1600/tile-classes-v2-color-1-75-percent.png\"><img src=\"http://1.bp.blogspot.com/-7hB-6vXpCqc/UcJ6yt9HtyI/AAAAAAAADGk/KywbId2KW4k/s1600/tile-classes-v2-color-1-75-percent.png\" border=\"0\" /></a> <p>So on the tile parameter, the coverage is complete and the dispatch algorithm should not have any difficulty. Combined with the position parameter, though, the situation is slightly trickier. At runtime, a caller could call <b>pushTile</b> with <b>#f</b> for <b>pos</b> and <b><empty></b>; or <b><bomb></b> for <b>tile</b> and the dispatcher would, correctly, throw up its hands at this point and say that there was no applicable method. I could have defined a more general method to handle this case, but I didn't -- there shouldn't ever be an empty or bomb tile without a corresponding valid position, since they are real tiles on the board, and I wanted the runtime to consider that a failure if it ever happened. Similarly, I could have defined a method that handled <b><blocking></b> or <b><tile></b> as part of this generic function but the whole point is that I don't know what to do with those more general classes here.</p> <p>So, you may notice that the middle <b>pushTile</b> method calls <b>collide</b> with a second tile and position, adjacent to the first in a specified direction. That generic function looks like this:</p> <pre>define generic collide( model :: <model>, dir :: <dir>,<br />    tile-1-pos :: <pos>, tile-1 :: <movable>,<br />    tile-2-pos :: <pos-or-false>, tile-2 :: <blocking-or-empty> );<br /><br />define method collide( model :: <model>, dir :: <dir>,<br />    movable-pos :: <pos>, movable-tile :: <movable>,<br />    next-pos :: <pos>, next-tile :: <empty> )<br />    slide ( model, dir, movable-pos, movable-tile,<br />            next-pos, next-tile );<br />end;<br /><br />define method collide( model :: <model>, dir :: <dir>,<br />    ice-block-pos :: <pos>, ice-block-tile :: <ice-block>,<br />    icebreaking-pos :: <pos-or-false>,<br />    ice-breaking-tile :: <blocking> )<br />    setTileAtPos( model, ice-block-pos, $the-empty );<br />end;<br /><br />define method collide( model :: <model>, dir :: <dir>,<br />    heart-pos :: <pos>, heart-tile :: <heart>,<br />    house-pos :: <pos>, house-tile :: <house> )<br />    setTileAtPos( model, heart-pos, $the-empty );<br />    decrementHeartCount( model );<br />end;<br /><br />define method collide( model :: <model>, dir :: <dir>,<br />    bomb-pos :: <pos>, bomb-tile :: <bomb>,<br />    mountain-pos :: <pos>, mountain-tile :: <mountain> )<br />    setTileAtPos( model, bomb-pos, $the-empty );<br />    setTileAtPos( model, mountain-pos, $the-empty );<br />end;<br /><br />define method collide( model :: <model>, dir :: <dir>,<br />    movable-pos :: <pos>, movable-tile :: <movable>,<br />    blocking-pos :: <pos-or-false>, blocking-tile :: <blocking> )<br />end;</pre> <p>You might notice that before long you hit yet another method call you haven't seen before -- slide. This is, as you might guess, yet another generic function. (Doesn't this program every get around to <i>doing</i> anything? In fact it does, but this is the often-paradoxical-seeming logic of object-oriented design -- individual methods that seem too small and simple to get anything done can actually get a lot done together, especially when aided by a smart dispatcher that eliminates most of the need to write \"code to find code.\"</p> <p>The type-union <b><blocking-or-empty></b> allows us to specify, for our generic function, as tight a class as possible out of two otherwise disjoint sections of our class diagram. We don't have to loosen the type specification needlessly by using <b><tile></b>, which would allow <b><tree></b> as a valid class for this parameter. Meanwhile, we can loosen <b>tile-2-pos</b> so that we make our intention to allow <b>#f</b> explicit here.</p> <p>The methods break down as follows. The first one handles any movable tile that is moving onto an empty tile, by calling a slide method to be defined later. The second one is a special case to handle the crushable <b><ice-block></b> class -- if it is pushed into the world edge, or any other object, it is destroyed (replaced with <b>$the-empty</b> class instance). The third and fourth methods handle specific interactions between hearts and houses, and bombs and mountains. And finally, to handle the case where the penguin pushes a heart against a mountain, or a bomb against the edge of the world, we have a less specific method that dispatches on <b><movable></b> and <b>>blocking></b>. This prevents the runtime from generating an error in this case, but also gives us a place where we could generate some kind of feedback to the user, like a special sound to indicate failure.</p> <p>The breakdown of instantiable tile classes here is much more complex, especially given that we are dispatching on two class parameters drawn from the same hierarchy. We could try coloring them by using two copies of the diagram:</p> <a href=\"http://1.bp.blogspot.com/-3R6WI_O9ZlE/UcKC6aKUpHI/AAAAAAAADG8/-SF4ddZ9rSo/s1600/tile-classes-v2-double-dispatch-2.png\"><img src=\"http://1.bp.blogspot.com/-3R6WI_O9ZlE/UcKC6aKUpHI/AAAAAAAADG8/-SF4ddZ9rSo/s1600/tile-classes-v2-double-dispatch-2.png\" border=\"0\" /></a> <p>Err, that's pretty, but is it helpful? I'm using colors and borders to indicate that classes are handled by specific methods, but the main thing I hope I'm illustrating is that, unlike with the first generic function, in this one there is significant overlap between the classes handled by the different methods. This is where the dispatch mechanism really has to shine. There is an ordering that makes sense from my point of view, and that is one in which the most specific matching method will be called. However, as you can see, quantifying \"most specific\" may be slightly complex when dispatching on more than one class parameter, throwing in type-unions for fun. Fortunately this code is now working, but while I was developing it I became familiar with a warning message in Open Dylan that says something like \"the method dispatch handling this set of classes is determined by arbitrary and capricious rules\" -- indicating that the dispatch logic is still considered a work in progress. I was concerned that the current version of the Open Dylan compiler wasn't quite solid enough to make this work, but it does seem to work. The backup plan was to dispatch entirely on type-unions made up of different sets of singletons, but that is longer and obscures what is meant by the abstract classes.</p> <p>I won't go to the trouble to do the same diagram on my slide method, but that code looks like this:</p> <pre>define generic slide( model :: <model>, dir :: <dir>,<br />    movable-pos :: <pos>, movable-tile :: <movable>,<br />    next-pos :: <pos-or-false>, next-tile :: <blocking-or-empty> );<br /><br />define method slide( model :: <model>, dir :: <dir>,<br />    movable-pos :: <pos>, movable-tile :: <movable>,<br />    next-pos :: <pos>, next-tile :: <empty> )<br />    let next-next-pos :: <pos-or-false> =<br />        getAdjacentPos( next-pos, dir );<br />    let next-next-tile = getTileAtPos( model, next-next-pos );<br />    setTileAtPos( model, next-pos, movable-tile );<br />    setTileAtPos( model, movable-pos, $the-empty );<br />    slide( model, dir, next-pos, getTileAtPos( model, next-pos ),<br />           next-next-pos, next-next-tile );<br />end;<br /><br />define method slide( model :: <model>, dir :: <dir>,<br />    movable-pos :: <pos>, movable-tile :: <movable>,<br />    next-pos :: <pos-or-false>, next-tile :: <blocking> )<br />    collide( model, dir, movable-pos, movable-tile,<br />              next-pos, next-tile );<br />end;<br /><br />define method slide( model :: <model>, dir :: <dir>,<br />    ice-block-pos :: <pos>, ice-block-tile :: <ice-block>,<br />    next-pos :: <pos-or-false>, next-tile :: <blocking> )<br />end;</pre> <p>Aaaand that's pretty much the whole of the logic for handling interaction between the penguin and the various tiles. Note that we call ourselves recursively. It looks kind of like we have no termination condition! Except note that the method isn't calling itself, it's doing the same method dispatch that found it in the first place. When we come to a termination condition for our recursions, we'll actually call a different method of the same generic function -- most likely the third one, where a sliding object encounters a blocking object. That condition can include hitting the edge of the board. There's a slightly tricky part where we want to bind up the next tile beyond the two tiles we were dispatched on, then perform two set operations to move the currently sliding tile, then dispatch on the new second and third tiles we've set, rather than the original incoming second tile and the new third one. That required drawing a few little diagrams when I wrote it, but it works just fine.</p> <p>This is not the whole program, obviously, but these are the key methods for encoding the collisions between tiles. If you'd like to play with the whole program, you might come and join the <a href=\"https://lists.opendylan.org/mailman/listinfo/hackers\">Dylan Hackers mailing list</a>, or leave me a note. If there is interest I'll publish it, here or elsewhere. I am now curious as to how a similar set of overlapping dispatches -- via pattern matching, perhaps? -- might look in Haskell. I might try to write that next. If you've got an idea about the best and most idiomatic way to do it, I welcome your comments.</p>" nil nil "d89319ed504813740a02f2dd6c3a9ce2") (68 (20930 47228 218771) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_1154\"></span>, where <span id=\"tex_5820\"></span> is the number of “folds” and <span id=\"tex_510\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_6562\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "e79874e777906d15718aef9a3e26e79f") (67 (20929 34232 569356) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_7479\"></span>, where <span id=\"tex_3881\"></span> is the number of “folds” and <span id=\"tex_4131\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_1491\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "445ab0d961e9d1fe1c3ac00f67ae9041") (66 (20929 26150 86717) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_4521\"></span>, where <span id=\"tex_6707\"></span> is the number of “folds” and <span id=\"tex_7456\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_9435\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "91848bbb4998fede065141f372e9acdd") (65 (20928 39045 928766) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_3888\"></span>, where <span id=\"tex_7057\"></span> is the number of “folds” and <span id=\"tex_9970\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_2530\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "fde7b9cf0f2e97c4e97ce09b0e5f73c5") (64 (20928 31806 522965) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_4982\"></span>, where <span id=\"tex_7154\"></span> is the number of “folds” and <span id=\"tex_4863\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_361\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "8918c7a9ba85201de96c6bddf7ebe466") (63 (20928 25599 231659) "http://functionaljobs.com/jobs/154-senior-software-developer-functional-programmer-at-vector-fabrics" "Functional Jobs: Senior software developer/Functional programmer at Vector Fabrics (Full-time)" nil "Tue, 18 Jun 2013 12:44:48 +0000" "<p>Vector Fabrics is hiring: we are looking for a top-notch programmer to extend our program-analysis and parallelization products. You design and implement algorithms to assist the programmer to create a parallel design from a sequential C or C++ program. You work with our international team of world-class computer scientists and experts in the Haskell / OCaml functional programming languages.</p>
<p>Your work is at the forefront of technology, giving you the opportunity to publish your work in major conferences and directly cooperate with processor design companies and domain-specific application vendors.</p>
<p>As we are a startup company, you will quickly have a major impact on our products and get to know all aspects of product creation. You will be part of a strongly committed development team and contribute to our agile development process and automated test suites. Interested? Send your CV, GitHub account or other proof of what you can do to <span class=\"spam-protect\"><span class=\"user\">jobs</span> [at] <span class=\"host\">vectorfabrics [dot] com</span></span>.</p>
<h3>Responsibilities</h3>
<ul>
<li>Design and implement software
optimization (e.g. parallelization)
algorithms for CPUs and GPUs;</li>
<li>Thoroughly test your code, create
automated test suites;</li>
<li>Contribute to our agile development
planning and process;</li>
<li>Analyze complex customer applications
for optimization opportunities and
translate this to new analysis
algorithms.</li>
</ul>
<h3>Profile</h3>
<ul>
<li>Your friends and colleagues describe
you as a superb programmer; your
programming ability is way above
average;</li>
<li>Demonstrable experience in design and
implementation of complex software
applications; prior experience in
functional programming languages is
preferred;</li>
<li>You continuously surprise us with
your creative yet pragmatic solutions
for complex software problems;</li>
<li>You are strongly committed to deliver
working software as early as
possible;</li>
<li>You work against very high quality
standards. Refactoring is your bread
and butter, pair-programming is how
you prefer to review your code;</li>
<li>Whatever technologies, languages, or
development environments you've been
using, we expect you have mastered
them in depth, and we expect that you
will be able to master any
technology, language, or development
environment that we need in the
future;</li>
<li>Excellent command of written and
spoken English.</li>
</ul>
<h3>Education</h3>
<p>MSc, MEng or PhD in Computer Science or significant relevant experience.</p>
<h3>About Vector Fabrics</h3>
<p>Vector Fabrics is a high-tech software company, developing tools for embedded multicore programming. Its technology and expertise is getting widespread recognition in the industry as being innovative and unique in their ability to address heterogeneous multicore application-specific silicon platforms. Due to the advanced nature of its tools, Vector Fabrics operates at the forefront of the next generation of embedded platforms for diverse markets ranging from supercomputers to automotive to cell phones.</p>
<p>Vector Fabrics puts absolute priority on hiring top class individuals in key positions. Vector Fabrics’ team profile is exceptional and its ambition is to hire only individuals that match or surpass that profile. The company pays top salary and offers a challenging, engaging and stimulating work environment with a high degree of responsibility.</p>
<p>Get information on <a href=\"http://functionaljobs.com/jobs/154-senior-software-developer-functional-programmer-at-vector-fabrics\">how to apply</a> for this position.</p>" nil nil "ac7959e4e864069a84c92bb6ccf120f4") (62 (20928 25599 88477) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_3351\"></span>, where <span id=\"tex_5054\"></span> is the number of “folds” and <span id=\"tex_5672\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_4270\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "ed76cce3976710dfc5817371da90a533") (61 (20928 15494 157269) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_9344\"></span>, where <span id=\"tex_487\"></span> is the number of “folds” and <span id=\"tex_4228\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_4829\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "308f77fdbe934750b58a084421010d6d") (60 (20928 8813 828404) "http://feedproxy.google.com/~r/FpComplete/~3/o-o2AKSmDZc/beta-sign-up" "FP Complete: FP Haskell Center Beta Sign-Up" nil "Mon, 17 Jun 2013 14:42:00 +0000" "<h4>Beta sign-up Blog</h4><p>It’s almost here!  After months of hard work by our engineers, I am pleased to announce that we’ve opened up sign-up for <a href=\"http://feeds.feedburner.com/business/designer-ide\">beta of FP Haskell Center</a>, the world's first commercial Haskell IDE and deployment platform.  The beta will be released by the end of the month, and we are eager to have your active testing and feedback so we can deliver a great product that the market needs in early September.  As an appreciation and reward for being in the beta program, we will offer special incentives to the finished product when available.  Details of the offer will be announced in late July/early August.</p><p>The IDE includes a Haskell compiler and a continually updated set of vetted, tested and supported libraries and code templates.  There is no need to run Cabal or other installers.  The FP Haskell Application Server is used to deploy and run Haskell applications directly in the cloud with no additional effort.  A free shared instance is included with every account. Larger and dedicated instances are available for active project deployments at a reasonable monthly charge.</p><h4>FP Haskell Center’s key features and benefits are:</h4><ul><li>Simplifies the writing and deploying of Haskell applications from a single online dashboard.</li><li>Cloud-based development frees you to move among multiple devices without needing your own functioning Haskell environment.</li><li>Integrated deployment frees you from needing to run a specific OS to match build and production environments.</li><li>A hierarchical module tree for:</li><li>convenient management (renaming, moving, deleting modules or whole trees)</li><li>navigation (much easier to read, expand/collapse)</li><li>Regular, automatic parsing and type checking as feedback inside the editor and unobtrusive error output below.</li><li>Type and documentation inspection of names.</li><li>Integrated access to sample code, School of Haskell tutorials, Haddock documentation service, and Hoogle resource database.</li></ul><p>Sign-up for <a href=\"http://feeds.feedburner.com/business/haskell-center\">beta of FP Haskell Center</a>.</p><div class=\"feedflare\">
<a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=o-o2AKSmDZc:zpOQ0FhJErU:yIl2AUoC8zA\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=yIl2AUoC8zA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=o-o2AKSmDZc:zpOQ0FhJErU:V_sGLiPBpWU\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=o-o2AKSmDZc:zpOQ0FhJErU:V_sGLiPBpWU\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=o-o2AKSmDZc:zpOQ0FhJErU:qj6IDK7rITs\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=qj6IDK7rITs\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=o-o2AKSmDZc:zpOQ0FhJErU:gIN9vFwOqvQ\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=o-o2AKSmDZc:zpOQ0FhJErU:gIN9vFwOqvQ\" border=\"0\" /></a>
</div><img src=\"http://feeds.feedburner.com/~r/FpComplete/~4/o-o2AKSmDZc\" height=\"1\" width=\"1\" />" nil nil "a9a3b01db0317af1d0dbfe3b2234c283") (59 (20928 8813 827819) "http://feedproxy.google.com/~r/FpComplete/~3/YGZb2pYnjPw/interim-web-site" "FP Complete: Interim Web Site" nil "Mon, 17 Jun 2013 12:42:00 +0000" "<h4>Interim Site blog</h4><p>Welcome to our updated website! FP Complete is evolving into a full-fledged commercial developer of Haskell tools and services, as called for in our original plans.  The previous site showcased the School of Haskell. We have been delighted to see it used by thousands of Haskell learners and teachers, including some authors who’ve taken advantage of its unique Active Code features to help people learn.  Now that we are about to release the FP Haskell Center beta, the School remains an integral part of our offering as a place to teach and learn, but we are even more excited by the new full-powered commercial features.</p><p>This site is an interim redesign, and will be completed when we release FP Haskell Center, the world’s first commercial Haskell IDE and deployment platform, in early September.  The site, and our strategy, are based on 3 pillars:</p><ol><li>We must produce products and services needed by developers who are already using Haskell tools in their work. This is our base.</li><li>At the same time, we need to promote Haskell to the vastly larger non-Haskeller market which on the whole is unaware of Haskell’s existence.  This is a long-term effort that’s absolutely necessary if Haskell is going to have meaningful adoption in the mainstream market.  That’s why you see us putting a lot of effort into high-level discussions and information about what Haskell is, its feature advantages and strategic benefits.  The target audience is business management, engineering management and developers who need to be converted into Haskell supporters and users.  </li><li>In all our efforts, we are always working with the Haskell community.  FP Complete was started in 2012 with the help of some of the leaders of the community and is committed to continue working with the entire community to advance the technology and expand Haskell adoption in the commercial market.  This follows a well-proven model of success for companies commercializing open-source technologies starting with Red Hat.</li></ol><p>In the coming months, we will be continually adding more content to fulfill our goal to be a major resource for all things Haskell.  Things like more whitepapers, case studies, video testimonials, tutorials and sample codes.  If you have any suggestions or things to contribute, be sure to let us know.  As always, we welcome constructive comments from the community.</p><div class=\"feedflare\">
<a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=YGZb2pYnjPw:Cjpscs1vI9g:yIl2AUoC8zA\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=yIl2AUoC8zA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=YGZb2pYnjPw:Cjpscs1vI9g:V_sGLiPBpWU\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=YGZb2pYnjPw:Cjpscs1vI9g:V_sGLiPBpWU\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=YGZb2pYnjPw:Cjpscs1vI9g:qj6IDK7rITs\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=qj6IDK7rITs\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=YGZb2pYnjPw:Cjpscs1vI9g:gIN9vFwOqvQ\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=YGZb2pYnjPw:Cjpscs1vI9g:gIN9vFwOqvQ\" border=\"0\" /></a>
</div><img src=\"http://feeds.feedburner.com/~r/FpComplete/~4/YGZb2pYnjPw\" height=\"1\" width=\"1\" />" nil nil "3f18d89ca1e9a92fcb26aaa7bfc6a4d3") (58 (20928 8813 827057) "http://logicaltypes.blogspot.com/2013/06/thoughts-on-kleisli-arrows-in-java-wip.html" "Douglas M. Auclair (geophf): Thoughts on Kleisli Arrows in Java (WIP)" "noreply@blogger.com (geophf)" "Mon, 17 Jun 2013 12:39:32 +0000" "Here are some ramblings as I puzzle my way through on how to represent Kleisli arrows in Java (and why I would want to do that, anyway). This is very much a work in progress, so no solid conclusions from this posting.<br /><br /><br />Categories are abstractions. They have objects and morphisms. The thing of Category theory is that the objects can be anything, as they are atomic, and the morphisms aren't necessarily functions. So, the objects can be numbers, not that we care, or they could be arrows (another term for morphisms), or they could be categories themselves, so the morphisms become morphisms between categories. Or if the objects are arrows then the morphisms are higher-order functions.<br /><br />Neat-o!<br /><br />So, John Baez did some wonderful pieces on higher-order categories in the direction of physical math: topologies and groups and such, and this was replicated in Edward Kmett's work with ... what are they called? Ah, yes: semigroupoids (how could I forget), where the monoids have no zero bases and so identity functions aren't necessary, I suppose.<br /><br />Interesting! Half-monoids!<br /><br />But if we look at Categories as simply that: objects and morphisms, and we look at morphisms as simply arrows from a to b, then does that simplify my implementation of my categories library?<br /><br />Monads no longer are generically typeful but now use inheritance to describe the type families:<br /><br />Monad<a> is the interface and Maybe<a> extends Monad<a> instead of<br /><br />Monad<M extends Monad, a> being the interface as Maybe<a> extends Monad<Maybe, a>.<br /><br />The problem is in the generic functions, how does one grab the 'm' in the monadic type? Or is it as simple as using inheritance and forgetting the thorny problem of genericity, or passing that problem off to the inheritance structure?<br /><br />Same thing for Arrow ...<br /><br />instead of Arrow<a, b, c><br /><br />we have Arrow<b, c><br /><br />and then the Kleisli arrow becomes more simple, perhaps? Because<br /><br />KleisliArrow<m, b, c> extends Arrow<b, m c><br /><br />... but how does that work? Can it work? I don't see how that works.<br /><br />for first :: a b c -> a (b, d) (c, d)<br /><br />how does that work for the KleisliArrow, and for chaining the monadic computation?<br /><br />It appears further research is necessary for me to get a solid grasp of this to be able to implement this properly in Java (as opposed to writing a haskell parser on top of Java, which is also a viable way of going about it, except for the fact that there is political resistance to learning a domain-specific language from devs brought on to code 'only' in language-of-choice X).<br /><br />So that's my problem, because in my 'Monads in Java' article I concluded with a:<br /><br />So you see we can now do the following:<br /><br />f.apply(m).bind(g).bind(h)<br /><br />and I now know that f.apply(m) is a weakness in coding. This should all be strung together with Kleisli arrows and the resulting morphism be run through the Kleisli computer.<br /><br />\"The (explicit) use of apply considered harmful\"?<br /><br />I mean, Gah! How bold! How daring! How so against the grain!<br /><br />And it isn't even really 'harmful' either. More like obtuse or obnoxious. And not even that, more like: inelegant. That's the word: inelegant. And we're not even 'using' apply in the above computation. I mean, we are, but we are always using apply. It's so inherent that now just juxtaposition is now apply, so it's not the '(explicit) use' of apply, it's the '(explicit) call' or '(explicit) invocation' of apply that's inelegant.<br /><br />I mean, when I see the above formulation, I now shudder, whereas before I might've said, with a pause so slight it didn't even register, 'What do we do here? Oh, use apply!' knowing, at the back of my mind, that this didn't sit perfectly right, but what else was there to do?<br /><br />Well, with Kleisli composition, there is nothing to do at all, but just do it<br /><br />runKleisli (f <+> g <+> h) m<br /><br />and we're done.<br /><br />Now, how to represent that in Java, ... well, I do have a KleisliArrow type that does return the underlying arrow, but what about composition ... it probably has that, too:<br /><br />f >>> g >>> h<br /><br />But the gnawing problem there is that KleisliArrow is not related to Arrow, because, properly, it isn't: KleisliArrow on a specific monadic type m IS related to Arrow.<br /><br />And I don't know how to represent that in Java.<br /><br />Yet.<br />" nil nil "b3a90bbcae05b6f71b74fb61a566d254") (57 (20928 8813 826103) "http://hyperq.github.io/blog/trading-a-hacker-approach.html" "hyperq: Trading: a hacker approach?" nil "Mon, 17 Jun 2013 08:19:00 +0000" "<blockquote>
<p>
You are startled by the sound of an alarm. It is followed by an urgent voice
which warns that the Arcada has been boarded by unknown intruders. It ends
abruptly. <br />
> <br />
<a href=\"http://sarien.net/spacequest#anotherhallway\">start of Space Quest I</a>
</p>
</blockquote>
<p>
Most hackers involved in the world of trading enter from the technology side
of the business. And there's two main gateways are via trader enhancement or
trader replacement. Making traders smarter and faster using technology is one
well worn road. There's lots of room to streamline the human trading process:
automation of regular tasks, expansion of back-testing capabilities and easy
gains to be had in better trader dashboards to get information when and where
needed.
</p>
<p>
Trader replacement is a little harder but also hackable. There's plenty of
tricks out there to shave a few msecs of computation and execution time, and
bringing bigdata testing and conversion of a sometimes fuzzy human rule-set
into a more rigorous computational exercise.
</p>
<p>
Either way, a trading runtime ends up paving the cow-paths of institutional
finance which look somewhat like this:
</p>
<img src=\"http://hyperq.github.io/assets/ats_features_diagram.png\" alt=\"design\" width=\"100%\" />
<p>
Over at <a href=\"http://hyperq.github.io\">hyperq</a>, we've been thinking about the above diagram and how to get
together a decent trading runtime. Now when a wildly ambitious objective meets
a meager resource base you have two options:
</p>
<ul class=\"org-ul\">
<li>go on a <a href=\"http://hyperq.github.io/../blog/trading-a-hacker-approach/ENOxd.jpg\">kamikaze</a> death march
</li>
<li>take the team on a <a href=\"http://www.qt.com.au/news/abolish-fringe-benefits-tax-bring-back-long-lunch-/1895360/\">long lunch</a> and redefine
</li>
</ul>
<p>
Since this is all open source, our long lunch redefinitional musings led us to
computer sciencing the bejesus out of the trading problem domain.
</p>
<p>
Here's the alternative design specification document we wrote on one of the
drink coasters:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-haskell\"><span class=\"org-function-name\">trade</span> <span class=\"org-variable-name\">::</span> [<span class=\"org-type\">MarketData</span> a] <span class=\"org-variable-name\">-></span> <span class=\"org-type\">Book</span> b <span class=\"org-variable-name\">-></span> <span class=\"org-type\">IO</span> [<span class=\"org-type\">Order</span> b]
<span class=\"org-function-name\">main</span> <span class=\"org-variable-name\">=</span> forever <span class=\"org-variable-name\">.</span> <span class=\"org-keyword\">do</span> <span class=\"org-variable-name\">.</span> trade
</pre>
</div>
<p>
Having just cut 3 months out of our critical path we even had time for some
Zork:
</p>
<blockquote>
<p>
You are in an open field west of a big white house with a boarded
front door.
There is a small mailbox here.<br />
> <br />
<a href=\"http://thcnet.net/error/index.php\">Zork</a>
</p>
</blockquote>
<p>
Long lunch over and the new specs still seem sweet. Some immediate ideas:
</p>
<ul class=\"org-ul\">
<li>the concept of market data becomes naturally abstractable.  Data can
include multiple sources, news flow or whatever universe observation you
can think of. Do you need the Market prefix?
</li>
<li>there is an immediate reminder of real world interaction with the IO monad.
</li>
<li>subsequent functions scan more easily and can be categorized - often as a
matter of taste.  For example, a complex event process (CEP), a fashionable
big deal in trading system circles, seems logically to have this type:
<div class=\"org-src-container\">
<pre class=\"src src-haskell\"><span class=\"org-function-name\">cep</span> <span class=\"org-variable-name\">::</span> [<span class=\"org-type\">MarketData</span> a] <span class=\"org-variable-name\">-></span> <span class=\"org-type\">MarketData</span> a
</pre>
</div>
<p>
Whether to put this prior to or inside the trade function then becomes a
matter of taste.
</p>
</li>
<li>Should the input be [Maybe MarketData a]? This puts the real world
likelihood of the data feed being down front and center, rather than
designing a system assuming an idealized world and then panicking when
something breaks.
</li>
</ul>
<p>
More generally, a more hacker approach leads you away from bigdata phd
solutions that dominate hft and algorithmic trading and towards the important,
small and obvious stuff (that may not lend themselves to a phd dissertation).
The market is closed (unexpectedly) - I better not try and trade, or I had
better try and trade elsewhere given the sorry state of Book a. Gee, there's a
lot of volatility out and about today - is it a big news day? The last news
piece of note was a facebook announcement. Wow, facebook really tanked but but
zygna didn't - what gives there? Someone must have forgot to turn the market
feed on. etc etc
</p>
<p>
And I suspect this approach leads further to a big, big gap in the market.
Imagine on a busy day in the market you could slow down time. The e-mini
suddenly drops by 1% in the space of a few heartbeats. What just happened?
Rewind the video tape and look more carefully at the last few minutes. Look
back at the news-flow over the last 10 minutes and look for keywords. Check
other markets - are they all tanking or is it just a local event? Or did some
human just enter an extra zero or three again?
</p>
<p>
If you can do all of that in a few seconds your process is way ahead of the
competition. The HFT guys have already panicked and run away to hide behind
their statistical order flow models. Algorithmic trades are pinging their stop
loss instructions blindly creating what may be a forecastable trend.
Meanwhile, discretionary day traders have just noticed a small section of one
of their screen is flashing red…
</p>
<p>
In this zone, a hacker trader with a hacker-like trading process can find all
sorts of edges and market tells.
</p>
<p>
So do we want our trading process to look and feel like a big finance
organizational structure? Or should for hyperq to have a Roger Wilco attitude:
</p>
<blockquote>
<p>
Anyway, I aborted the launch and jetted out of there in an escape pod. I
crawled into the sleep chamber, and the next thing I knew, I woke up in a
trash freighter! Yeah, things didn't look too good, but I blasted out of the
freighter in an old jalopy I resurrected from the rubble.
~ <a href=\"http://spacequest.wikia.com/wiki/Roger's_Dialogue\">Roger Wilco</a>
</p>
</blockquote>
<p>
Much more fun than a death march to pave the cow-paths.
</p>" nil nil "cea78f3aad7d936f75cfe8d1504da9b8") (56 (20928 8813 824998) "http://justtesting.org/post/53175916852" "Manuel M T Chakravarty: Data Flow Fusion with Series Expressions in Haskell" nil "Mon, 17 Jun 2013 05:39:34 +0000" "<p>We are currently exploring <em>flow fusion</em>, a new fusion method for purely functional array code that overcomes the main limitation of stream fusion, namely stream fusion’s inability to fuse branching streams. Our current flow-fusion prototype in the Glasgow Haskell Compiler manages to achieve a twofold speedup over stream fusion for computing convex hulls of 2D points using the <a href=\"http://en.wikipedia.org/wiki/QuickHull\">QuickHull</a> algorithm. In fact, the code generated by flow fusion is only a few percent points away from hand-written C code. We have summarised all the details in a draft paper <a href=\"http://www.cse.unsw.edu.au/~chak/papers/BCKR13.html\">Data Flow Fusion with Series Expressions in Haskell</a>.</p>" nil nil "864c81abdaf0011c73371c118ba4fa69") (55 (20928 8813 824459) "http://praisecurseandrecurse.blogspot.com/2013/06/objective-dylan-or-perhaps-subjective-c.html" "Paul Potts: Objective-Dylan, or Perhaps Subjective-C?" "noreply@blogger.com (Paul Potts)" "Mon, 17 Jun 2013 01:09:00 +0000" "<p>Yesterday my wife took the kids with her on an overnight trip to Ann Arbor so I've had a bit of extra quiet time. How am I making use of this bounty? Getting on with some minor home repairs? Cleaning my office from top to bottom? Er, no... porting the game logic I've written so far in Objective-C back to Dylan, so that I can do some more thinking about it.</p> <p>So after a phone job interview yesterday (which went well, I thought -- I'm optimistic about this possibility!) I started working on this task, and then about twelve hours later, around 2 a.m., I had the basic setup and population of the game board working. It's embarrassing to admit how long it took. I started on my Mac, and when I began encountering constant runtime errors switched over to my Ubuntu box, thinking that the Mac version of Open Dylan might just be broken (it isn't; I got the identical behavior on the Linux build). I finally figured out workarounds -- it's funny how taking a break clears my head far better than pressing on ever does -- then read a little Gene Wolfe (I'm working my way through <i>In Green's Jungles</i>, one of his books I've repeatedly tried and failed to finish), and fell asleep with no children in the bed to kick or otherwise interfere with a good night's sleep. I'm back up this morning, had a bath, and I'm drinking a large coffee with soy creamer and stevia and trying to hold off on a lunch break until I have some more done. It's about 10 a.m. and I'm expecting my family back in about six hours, so the race is on!</p> <p>This has taken far longer than I hoped; I lost quite a bit of time stumbling across things in Open Dylan that still seem just plain broken. I had to start working on a smaller and smaller program to figure out exactly what was broken. These things I've flagged in comments, as places where, basically, I wish Dylan worked a certain way, and it doesn't. I may just be asking for something that doesn't quite match the original spec or isn't quite possible, but I'll share those with the Dylan Hackers team and see if it seems like I can help with them. The biggest thing that was broken, though, was me -- my brain, that is -- since it's been a long time since I've worked with Dylan's <b>type-union</b> and <b>singleton</b> pseudo-classes and I had forgotten the details. The compiler was not a big help with this, since it is such a <i>dynamic</i> language and leaves an awful lot of things to the runtime to figure out, which it does by throwing an error message that may or may not help much. The documentation is a bit scanty, but it does contain everything you need to know, if you re-read and squint at the scanty examples that are out there hard enough.</p> <p>The good news is that the port is working and I'd like to share it. Dylan is still up there with Scheme (and now Haskell) as one of my favorite languages for <i>designing</i> programs -- yes, even though Dylan is quite old as languages go. I like to see what it can do especially with generic functions and its sophisticated model for object-oriented <i>dispatch</i>. I've been a little stymied as to how to express the design best in Objective-C. If it was a complicated game design, I wouldn't feel bad about having a program that looked complex. But it's really an elegantly simple game, and so I feel like the implementation should reflect that. My Objective-C implementation has been feeling more and more bloated and pointlessly complex, although it works, so my thought was to get it down to a simple implementation that takes full advantage of Dylan's object-oriented programming features, largely borrowed from CLOS, and then port that back to Objective-C, adding whatever minimalist support is needed to fake up some of the features that Dylan gives me that Objective-C doesn't have. This might be by way of also writing a Haskell or Scala implementation later, for yet more learning and language comparison, although really what I should focus on is getting the iOS GUI up and working so that I have something to show people.</p> <p>Anyway, I've got a Dylan program that plays the Polar game, using singletons to represent tile types, and methods dispatched on singletons to handle specific kinds of collisions. The classes -- which are empty, pretty much used <i>only</i> for their usefulness as types, for driving dispatch -- are like so:</p> <div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://2.bp.blogspot.com/-PiK8rgZXxVo/Ubx_P2ZZKtI/AAAAAAAADGA/N3msDgs2kPQ/s1600/tile-classes-75-percent.png\"><img src=\"http://2.bp.blogspot.com/-PiK8rgZXxVo/Ubx_P2ZZKtI/AAAAAAAADGA/N3msDgs2kPQ/s1600/tile-classes-75-percent.png\" border=\"0\" /></a></div> <p>In Dylan you can create some instances, and create something called a <b>type-union</b>, which is something that is a type, I think, but not a class. You can use it to define a slot type or a parameter type. But you can't make one:</p> <pre>define constant $the-bomb = make(<bomb>);<br />define constant $the-empty = make(<empty>);<br />define constant $the-heart = make(<heart>);<br />define constant $the-house = make(<house>);<br />define constant $the-ice-block = make(<ice-block>);<br />define constant $the-mountain = make(<mountain>);<br />define constant $the-tree = make(<tree>);<br /><br />define constant <tile-or-false> = type-union(<br />    singleton( $the-bomb ), singleton( $the-empty ),<br />    singleton( $the-heart ), singleton( $the-house ),<br />    singleton( $the-ice-block ), singleton( $the-mountain ),<br />    singleton( $the-tree ), singleton( #f ) );</pre> <p>And eventually dispatch on singletons -- meaning that a given method will be called with it is called with references to the exact objects that you specify:</p> <pre>define method collide( model :: <model>, dir :: <dir>,<br />    heart-pos :: <pos>, heart-tile == $the-heart,<br />    house-pos :: <pos>, house-tile == $the-house )<br />    format-out( \"collide: $the-heart / $the-house\\n\" );<br />    setTileAtPos( model, heart-pos, $the-empty );<br />    model.decrementHeartCount();<br />end;</pre> <p>That gives you an idea of how some of the code in the Dylan program is organized. I have it mostly working, however, I'm not going to present the full code quite yet because I have a crashing bug, and I haven't yet been able to figure out if it is a dumb mistake on my part or a compiler or runtime bug in Open Dylan. I've also asked the Dylan hackers to take a look at my design and see what they think -- if they can find, as I put it, \"a simpler design struggling to get out.\" Which is always the challenge, when trying to write not just functional, but <i>model</i> code, isn't it?</p>" nil nil "ad22292acb04a9ab92001802cff43d97") (54 (20928 8813 823309) "http://gentoohaskell.wordpress.com/2013/06/16/call-for-help-wiki-gentoo-org-documentation/" "The Gentoo Haskell Team: Call for help: wiki.gentoo.org documentation" nil "Sun, 16 Jun 2013 19:30:25 +0000" "<p>I’d like to ask gentoo-haskell community for help. We have a nice <a href=\"http://wiki.gentoo.org\">wiki</a> and our project page have moved <a href=\"http://wiki.gentoo.org/wiki/Project:Haskell\">there</a>. But it seems that we don’t have enough documentation quality for end-user application. As a developers we support proper builds and tests for that packages but we are not expert users for many of them. So I’d like to ask community to add some docs and tips for applications you use. This basically means installation, advanced config (examples), interesting use cases, links to external resources (blog posts/documentation) and so on. It can help a lot for new Gentoo users.</p>
<p>The most interesting projects are:</p>
<ul>
<li><a href=\"http://wiki.gentoo.org/wiki/Pandoc\">pandoc</a></li>
<li><a href=\"http://wiki.gentoo.org/wiki/Git-annex\">git-annex</a></li>
<li><a href=\"http://wiki.gentoo.org/wiki/Gitit\">gitit</a></li>
<li><a href=\"http://wiki.gentoo.org/wiki/yi\">yi</a></li>
<li><a href=\"http://wiki.gentoo.org/wiki/Xmonad\">xmonad</a></li>
</ul>
<p>Thanks!</p>
<br />  <a href=\"http://feeds.wordpress.com/1.0/gocomments/gentoohaskell.wordpress.com/86/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/gentoohaskell.wordpress.com/86/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=gentoohaskell.wordpress.com&blog=7667502&post=86&subd=gentoohaskell&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "ec6ce914662995bca5ac9daad6770581") (53 (20928 8813 822818) "http://lambda.jstolarek.com/2013/06/getting-friendly-with-stg/" "Jan Stolarek: Getting friendly with STG" nil "Thu, 13 Jun 2013 20:45:46 +0000" "<p style=\"text-align: justify;\">I’ve been spending last months on developing GHC. No rocket science so far, just a bit of hacking here and there. The biggest thing I am working on is <a href=\"http://hackage.haskell.org/trac/ghc/ticket/6135\">ticket #6135</a>, which is about changing some of the existing <a href=\"http://hackage.haskell.org/trac/ghc/wiki/Commentary/PrimOps\">PrimOps</a> to return unboxed <code>Int#</code> instead of <code>Bool</code>. This means that the result of comparing two unboxed values will be either an unboxed <code>0#</code> or unboxed <code>1#</code>, instead of a tagged pointer to statically allocated object representing <code>True</code> or <code>False</code>. This modification will allow to write branchless algorithms in Haskell. I promise to write about this one day, but today I want to blog about a different topic.</p>
<p style=\"text-align: justify;\">It so happens that things I’ve been doing in GHC require me to make changes in the code generator. This is a bit challenging for me, because the code generator is something that didn’t interest me much when I started to learn about compilers. Probably the main reason for this is that code generation means dealing with assembly. I’ve been programming for about 16 years and only two languages caused me problems when I tried to learn them. Assembly is one of them<sup><a title=\" In case you’re interested, the other one is Io\" href=\"http://lambda.jstolarek.com/2013/06/getting-friendly-with-stg/#footnote_0_1210\" id=\"identifier_0_1210\" class=\"footnote-link footnote-identifier-link\">1</a></sup>. I have been learning it for one year during my studies and, although I had no problems with understanding the idea behind assembly and writing short snippets of code, writing a larger piece of code always ended up in a headache.</p>
<p style=\"text-align: justify;\">It looks that the time has come to overcome my fear. During last months I’ve been reading a lot of assembly generated by GHC and I even made some attempts at writing assembly code by myself (well, using intrinsics, but I guess that counts). But between Haskell source code and the generated executable there are many intermediate steps. From my observations it seems that many Haskellers have basic knowledge of Core – GHC’s intermediate language. Most have also heard about other two intermediate representations used by GHC – STG and Cmm – but it seems that few people know them, unless they hack the compiler. And since I’m hacking the compiler I should probably have more knowledge about these two representations, right?</p>
<p style=\"text-align: justify;\">There’s a classic paper by Simon Peyton-Jones “Implementing lazy functional languages on stock hardware: the Spineless Tagless G-machine”. It is quite long – 87 pages total – and, being published in 1992, it is mostly out of date. These two things kept me from reading it, although I think that being out of date was only a pretext for me to avoid reading almost 90 pages of text. But, since I need to learn about STG, I finally decided to give it a shot. Reading the paper took my four days. Paper is very well written and in general is an easy read. I was afraid that I might not understand formal description of operational semantics of STG, but it turned out to be well explained so I had no problem with that. The major problem turned out to be the amount of knowledge I had to learn while reading. This resulted in problems with fully understanding last sections of the paper. Not because they are more difficult than the initial ones, but because I didn’t fully remember all the details that were discussed earlier. An important question is which information is not up to date. I’m not yet familiar with the existing implementation, but it seems that many things have changed: the Spineless Tagless G-machine is not tagless any more since the introduction of pointer tagging; curried function are now evaluated using eval/apply convention, while the paper describes push/enter; the paper discusses only compilation to C, while currently C back-end is becoming deprecated in favour of native code generator and LLVM; and finally the layout of closures is now slightly different than the one presented in the paper. I am almost certain that garbage collection is also performed differently. These are the differences that I noticed, which means that really a lot has changed since the publication over 20 years ago. Surprisingly, this doesn’t seem like a big problem, because the most important thing is that the paper presents an idea of how STG works, while the mentioned changes are only not so important details.</p>
<p style=\"text-align: justify;\">So, now that I have a basic idea of how STG works, what comes next? There are a few follow up papers:</p>
<ul>
<li style=\"text-align: justify;\">“The STG runtime system (revised)” – an updated description of STG written in 1999 by Simon Peyton Jones and Simon Marlow. I guess it’s also outdated, but still probably worth reading. It has only 65 pages :)</li>
<li style=\"text-align: justify;\">“Making a Fast Curry. Push-Enter vs. Eval-Apply for Higher-order Languages” – this described the mentioned eval/apply and push/enter strategies. Already read this one.</li>
<li style=\"text-align: justify;\">“Faster Laziness Using Dynamic Pointer Tagging” – this will tell you why STG is not tagless. Read this one also.</li>
</ul>
<p>And once I’ll deal with STG I’ll have to learn about Cmm.</p>
<ol class=\"footnotes\"><li id=\"footnote_0_1210\" class=\"footnote\"> In case you’re interested, the other one is <a href=\"http://iolanguage.org/\">Io</a></li></ol>" nil nil "803bc25112ad69a512cffafe934a7851") (52 (20928 8813 702665) "http://parenz.wordpress.com/2013/06/12/ghcjs-build/" "Daniil Frumin: Building GHCJS" nil "Thu, 13 Jun 2013 06:05:11 +0000" "<div id=\"outline-container-sec-1\" class=\"outline-2\">
<h2 id=\"sec-1\"><span class=\"section-number-2\">1</span> Intro</h2>
<div id=\"text-1\" class=\"outline-text-2\">
<p>
In this post I would like to talk about my experience with<br />
bootstrapping <a href=\"http://weblog.luite.com/wordpress/?p=14\">GHCJS</a> using the provided facilities <a href=\"https://github.com/ghcjs/ghcjs-build\">ghcjs-build</a>. I<br />
never used tools like Vagrant or Puppet before so all of this was<br />
kinda new to me.
</p>
</div>
</div>
<div id=\"outline-container-sec-2\" class=\"outline-2\">
<h2 id=\"sec-2\"><span class=\"section-number-2\">2</span> Initial installation</h2>
<div id=\"text-2\" class=\"outline-text-2\">
<p>
GHCJS can’t actually work with vanilla GHC 7.* as it requires to<br />
apply some patches (in order to get JS ffi to work, it adds<br />
<code>JavaScriptFFI</code> language extension among other modifications).
</p>
<p>
<a href=\"https://github.com/ghcjs/ghcjs-build\">ghcjs-build</a> uses <a href=\"http://vagrantup.com\">Vagrant</a> (a tool for automatically building and<br />
running work environments) to mange the work environment, so prior to<br />
running GHCJS you need to install vagrant and <a href=\"http://virtualbox.org\">VirtualBox</a>. It’s actually<br />
a sensible way to tackle a project like that: everyone has similar<br />
work environments, you don’t have to mess with your local GHC<br />
installation. It also make use of <a href=\"http://puppetlabs.com\">Puppet</a> deployment system in<br />
<code>puppetlabs-vcsrepo</code> module for cloning Git repositories.
</p>
<p>
Currently, there are two ways to start up GHCJS using <code>ghcjs-build</code>
</p>
</div>
<div id=\"outline-container-sec-2-1\" class=\"outline-3\">
<h3 id=\"sec-2-1\"><span class=\"section-number-3\">2.1</span> Using the prebuilt version</h3>
<div id=\"text-2-1\" class=\"outline-text-3\">
<div class=\"org-src-container\">
<pre class=\"src src-sh\">git clone https://github.com/ghcjs/ghcjs-build.git
<span style=\"color: #D0D0FF;\">cd</span> ghcjs-build
git checkout prebuilt
vagrant up
</pre>
</div>
<p>
Using this configuration the following procedures are performed:
</p>
<ol class=\"org-ol\">
<li>Vagrant sets up a 32-bit Ubuntu Precise system (/Note: if this is<br />
your first time running Vagrant it downloads the 280Mb<br />
precise32.box file from the Vagrant site/)
</li>
<li>Vagrants does some provisioning using Puppet (downloads and<br />
installs necessary packages)
</li>
<li>A 1.4GB archive with ghcjs and other prebuilt tools are downloaded<br />
and extracted.
</li>
</ol>
</div>
</div>
<div id=\"outline-container-sec-2-2\" class=\"outline-3\">
<h3 id=\"sec-2-2\"><span class=\"section-number-3\">2.2</span> Compiling from source</h3>
<div id=\"text-2-2\" class=\"outline-text-3\">
<div class=\"org-src-container\">
<pre class=\"src src-sh\">git clone https://github.com/ghcjs/ghcjs-build.git
<span style=\"color: #D0D0FF;\">cd</span> ghcjs-build
vagrant up
</pre>
</div>
<p>
Apart from setting up the box this will
</p>
<ol class=\"org-ol\">
<li>Get the GHC sources from Git HEAD and applies the GHCJS <a href=\"http://ghcjs.github.io/patches/ghc-ghcjs.patch\">patch</a>.
</li>
<li>Get all the necessary packages for ghcjs
</li>
<li>Get the latest Cabal from Git HEAD, applies the GHCJS <a href=\"http://ghcjs.github.io/patches/cabal-ghcjs.patch\">patch</a> and<br />
build it.
</li>
<li>Compile the necessary libraries using ghcjs
</li>
<li>Compile <code>ghcjs-examples</code> and its dependencies (it appears that it<br />
can take a lot of time to compile gtk2hs and gtk2hs’s tools)
</li>
</ol>
<p>
Please note, that depending on your computer, you might want to go for<br />
a long walk, enjoy a small book or get a night sleep (assuming you are<br />
not scared by the sound of computer fans).
</p>
<p>
Apart from being slow, the process of compiling everything from<br />
source is error prone. To give you a taste, last night I was not able<br />
to reproduce a working environment myself, because of some recent<br />
changes in GHC HEAD. The prebuilt version on the other hand is<br />
guaranteed to install correctly.
</p>
<p>
Hopefully, the GHCJS patches will be merged upstream before the GHC<br />
7.8 is out. That way you won’t need to partake in building GHC from<br />
the source in order to use GHCJS.
</p>
</div>
</div>
<div id=\"outline-container-sec-2-3\" class=\"outline-3\">
<h3 id=\"sec-2-3\"><span class=\"section-number-3\">2.3</span> Communicating with the VM</h3>
<div id=\"text-2-3\" class=\"outline-text-3\">
<p>
After you’ve finished with the initial setup you should be able just<br />
to
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">vagrant ssh
</pre>
</div>
<p>
in your new vm and start messing around.
</p>
<p>
<code>ghcjs</code> command is available to you and Vagrant kindly forwards the<br />
3000 port on the VM to the local 3030 port, allowing you to run web<br />
servers like <code>warp</code> on the VM and accessing them locally.
</p>
<p>
You can access your local project directory under <code>/vagrant</code> in VM:
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">$ ls /vagrant
keys  manifests  modules  outputs  README.rst  Vagrantfile
</pre>
</div>
<p>
However, copying file back-and-forth is not a perfect solution. I<br />
recommend setting up a sshfs filesystem (<i>Note: if you are on OSX,<br />
don’t forget to install fuse4x kernel extension</i>):
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">$ vagrant ssh-config
Host default
HostName 127.0.0.1
User vagrant
Port 2222
UserKnownHostsFile /dev/null
StrictHostKeyChecking no
PasswordAuthentication no
IdentityFile <span style=\"color: #b5bd68;\">\"/Users/dan/.vagrant.d/insecure_private_key\"</span>
IdentitiesOnly yes
LogLevel FATAL
$ sshfs vagrant@localhost:/home/vagrant ../vm -p2222 -oreconnect,defer_permissions,negative_vncache,<span style=\"color: #cc6666;\">volname</span>=ghcjs,<span style=\"color: #cc6666;\">IdentityFile</span>=~/.vagrant.d/insecure_private_key
$ ls ../vm
</pre>
</div>
<p>
When you are done you can just <code>umount ../vm</code>
</p>
</div>
</div>
</div>
<div id=\"outline-container-sec-3\" class=\"outline-2\">
<h2 id=\"sec-3\"><span class=\"section-number-2\">3</span> Compiling other packages</h2>
<div id=\"text-3\" class=\"outline-text-2\">
<p>
Since the <code>diagrams</code> package on Hackage depends on the older version<br />
of base we are going to use the latest version from Git:
</p>
<pre class=\"example\">mkdir dia; cd dia
git clone git://github.com/diagrams/diagrams-core.git
cd diagram-core && cabal install && cd ..
cabal unpack active
cd active-0.1*
cat >version.patch <<EOF
--- active.cabal        2013-06-12 12:58:40.082914214 +0000
+++ active.cabal.new    2013-06-12 12:58:31.029465815 +0000
@@ -19,7 +19,7 @@
library
exposed-modules:     Data.Active
-  build-depends:       base >= 4.0 && < 4.7,
+  build-depends:       base >= 4.0 && < 4.8,
array >= 0.3 && < 0.5,
semigroups >= 0.1 && < 0.10,
semigroupoids >= 1.2 && < 3.1,
@@ -31,7 +31,7 @@
test-suite active-tests
type:              exitcode-stdio-1.0
main-is:           active-tests.hs
-    build-depends:     base >= 4.0 && < 4.7,
+    build-depends:     base >= 4.0 && < 4.8,
array >= 0.3 && < 0.5,
semigroups >= 0.1 && < 0.10,
semigroupoids >= 1.2 && < 3.1,
EOF
patch active.cabal < version.patch
cabal install
cd ..
git clone git://github.com/diagrams/diagrams-lib.git
cd diagrams-lib && cabal install && cd ..
git clone git://github.com/diagrams/diagrams-svg.git
cd diagram-svg && cabal install && cd ..
</pre>
<p>
Other packages I had to install already had their Hackage versions<br />
updated.
</p>
<p>
Now you can try to build a test diagram to see that everything works
</p>
<div class=\"org-src-container\">
<pre class=\"src src-haskell\"><span style=\"color: #b294bb;\">module</span> <span style=\"color: #f0c674;\">Main</span> <span style=\"color: #b294bb;\">where</span>
<span style=\"color: #b294bb;\">import</span> <span style=\"color: #f0c674;\">Diagrams.Prelude</span>
<span style=\"color: #b294bb;\">import</span> <span style=\"color: #f0c674;\">Diagrams.Backend.SVG.CmdLine</span>
<span style=\"color: #81a2be;\">d</span> <span style=\"color: #cc6666;\">::</span> <span style=\"color: #f0c674;\">Diagram</span> <span style=\"color: #f0c674;\">SVG</span> <span style=\"color: #f0c674;\">R2</span>
<span style=\"color: #81a2be;\">d</span> <span style=\"color: #cc6666;\">=</span> square 20 <span style=\"color: #cc6666;\">#</span> lw 0<span style=\"color: #cc6666;\">.</span>5
<span style=\"color: #cc6666;\">#</span> fc black
<span style=\"color: #cc6666;\">#</span> lc green
<span style=\"color: #cc6666;\">#</span> dashing [0<span style=\"color: #cc6666;\">.</span>2,0<span style=\"color: #cc6666;\">.</span>2] 0
<span style=\"color: #81a2be;\">main</span> <span style=\"color: #cc6666;\">=</span> defaultMain (pad 1<span style=\"color: #cc6666;\">.</span>1 d)
</pre>
</div>
<p>
then you can compile and run it
</p>
<div class=\"org-src-container\">
<pre class=\"src src-sh\">ghc --make Test.hs
./Test -w 400 -o /vagrant/test.svg
</pre>
</div>
<p><a href=\"http://parenz.files.wordpress.com/2013/06/screen-shot-2013-06-12-at-5-19-03-pm.png\"><img src=\"http://parenz.files.wordpress.com/2013/06/screen-shot-2013-06-12-at-5-19-03-pm.png?w=300&h=289\" alt=\"Screen Shot 2013-06-12 at 5.19.03 PM\" height=\"289\" class=\"alignnone size-medium wp-image-47\" width=\"300\" /></a></p>
<p>
And that’s it!
</p>
</div>
</div>
<div id=\"outline-container-sec-4\" class=\"outline-2\">
<h2 id=\"sec-4\"><span class=\"section-number-2\">4</span> Outro</h2>
<div id=\"text-4\" class=\"outline-text-2\">
<p>
I would also like to note that we are currently polishing the GHCJS<br />
build process. Luite, especially is working on making ghcjs work (and<br />
run tests) with <a href=\"https://travis-ci.org/\">Travis CI</a> (it take quite a bit of time to build ghcjs<br />
and sometimes travis is timeouting) and I am working on tidying up<br />
the build config.
</p>
<p>
Stay tuned for more updates.
</p>
</div>
</div>
<br /> Tagged: <a href=\"http://parenz.wordpress.com/tag/diagrams/\">diagrams</a>, <a href=\"http://parenz.wordpress.com/tag/ghcjs/\">ghcjs</a>, <a href=\"http://parenz.wordpress.com/tag/haskell-2/\">haskell</a>, <a href=\"http://parenz.wordpress.com/tag/soc/\">soc</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/parenz.wordpress.com/49/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/parenz.wordpress.com/49/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=parenz.wordpress.com&blog=26722965&post=49&subd=parenz&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "fbb67a5fcb9b5d5721283c237da01f6c") (51 (20928 8813 701006) "http://parenz.wordpress.com/2013/06/10/soc-2013/" "Daniil Frumin: Summer of Code" nil "Wed, 12 Jun 2013 14:17:57 +0000" "<p>Hello, everyone!</p>
<p>I’ve decided to reinstate this blog since I’ve got accepted to this year’s Google Summer of Code program. I’ll blog about my updates, stuff that I’ve been working on and bottlenecks and problems I’ve encountered.</p>
<p>My project is a pastebin site using diagrams and <a href=\"http://weblog.luite.com/wordpress/?p=14\">GHCJS</a> to generate embeddable interactive widgets and static images/text in case when the pasted code does not require additional interaction. My mentor is Luite Stegeman, and Brent Yorgey and other nice people from the diagrams community has agreed to help.</p>
<p>I am very excited about this and happy that I’ve got a whole bunch of smart people to help me with this.</p>
<p>Unfortunately, as we haven’t sorted out a completely safe way to evaluate code coming from 3rd parties, there is no public version hosted anywhere yet. Meanwhile, there is a <a href=\"https://github.com/co-dan/interactive-diagrams\">project on GitHub</a>.</p>
<p>Hopefully, soon I’ll be able to publish a post about my experience with bootstrapping GHCJS.<br />
Until then, stay tuned!</p>
<br /> Tagged: <a href=\"http://parenz.wordpress.com/tag/diagrams/\">diagrams</a>, <a href=\"http://parenz.wordpress.com/tag/ghcjs/\">ghcjs</a>, <a href=\"http://parenz.wordpress.com/tag/haskell-2/\">haskell</a>, <a href=\"http://parenz.wordpress.com/tag/interactive-diagrams/\">interactive-diagrams</a>, <a href=\"http://parenz.wordpress.com/tag/soc/\">soc</a> <a href=\"http://feeds.wordpress.com/1.0/gocomments/parenz.wordpress.com/42/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/parenz.wordpress.com/42/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=parenz.wordpress.com&blog=26722965&post=42&subd=parenz&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "433a0620a71d0a3cfa284d636f3e6bc1") (50 (20928 8813 700321) "http://blog.moertel.com/posts/2013-06-12-recursion-to-iteration-4-trampolines.html" "Tom Moertel: Tricks of the trade: Recursion to Iteration, Part 4: The Trampoline" nil "Wed, 12 Jun 2013 00:00:00 +0000" "<div class=\"info\">Posted on June 12, 2013</div>
<div class=\"tags\">Tags: <a href=\"http://blog.moertel.com/tags/programming.html\">programming</a>, <a href=\"http://blog.moertel.com/tags/recursion.html\">recursion</a>, <a href=\"http://blog.moertel.com/tags/iteration.html\">iteration</a>, <a href=\"http://blog.moertel.com/tags/python.html\">python</a>, <a href=\"http://blog.moertel.com/tags/recursion-to-iteration series.html\">recursion-to-iteration series</a>, <a href=\"http://blog.moertel.com/tags/tail calls.html\">tail calls</a>, <a href=\"http://blog.moertel.com/tags/data structures.html\">data structures</a>, <a href=\"http://blog.moertel.com/tags/trampolines.html\">trampolines</a></div>
<p>This is the fourth article in <a href=\"http://blog.moertel.com/tags/recursion-to-iteration%20series.html\">a series on converting recursive algorithms into iterative algorithms</a>. If you haven’t read the earlier articles first, you may want to do so before continuing.</p>
<p>In <a href=\"http://blog.moertel.com/posts/2013-05-11-recursive-to-iterative.html\">the first article of our series</a>, we showed that if you can convert an algorithm’s recursive calls into tail calls, you can eliminate those tail calls to create an iterative version of the algorithm using The Simple Method. In this article, we’ll look at another way to eliminate tail calls: the <em>trampoline</em>.</p>
<p>The idea behind the trampoline is this: before making a tail call, manually remove the current execution frame from the stack, eliminating stack build-up.</p>
<h3 id=\"execution-frames-and-the-stack\">Execution frames and the stack</h3>
<p>To understand why we might want to manually remove an execution frame, let’s back up and think about what happens when we call a function. The language runtime needs some place to store housekeeping information and any local variables the function may use, so it allocates a new execution frame on the stack. Then it turns control over to the function. When the function is done, it executes a <code>return</code> statement. This statement tells the runtime to remove the execution frame from the stack and to give control (and any result) back to the caller.</p>
<p>But what if the function doesn’t return right away? What if it makes another function call instead? In that case, the runtime must create a new execution frame for <em>that</em> call and push it onto the stack, on top of the current frame. If the function ends up calling itself many times recursively, each call will add another frame to the stack, and pretty soon we will have eaten up a lot of stack space.</p>
<h3 id=\"eliminating-stack-build-up\">Eliminating stack build-up</h3>
<p>To avoid this problem, some programming languages guarantee that they will recycle the current execution frame whenever a function makes a tail call. That is, if the function calls some other function (or itself recursively) and just returns that function’s result verbatim, that’s a tail call. In that case, the runtime will recycle the current function’s execution frame before transferring control to the other function, making it so that the other function will return its result directly to the original function’s caller. This process is called <em>tail-call elimination</em>.</p>
<p>But in languages like Python that don’t offer tail-call elimination, every call, even if it’s a tail call, pushes a new frame onto the stack. So if we want to prevent stack build-up, we must somehow eliminate the current frame from the stack ourselves, before making a tail call.</p>
<p>But how? The only obvious way to eliminate the current frame is to <code>return</code> to our caller. If we’re to make this work, then, the caller must be willing to help us out. That’s where the trampoline comes in. It’s our co-conspirator in the plot to eliminate stack build-up.</p>
<h3 id=\"the-trampoline\">The trampoline</h3>
<p>Here’s what the trampoline does:</p>
<ol style=\"\">
<li>It calls our function <code>f</code>, making itself the current caller.</li>
<li>When <code>f</code> wants to make a recursive tail call to itself, it returns the instruction <code>call(f)(*args, **kwds)</code>. The language runtime dutifully removes the current execution frame from the stack and returns control to the trampoline, passing it the instruction.</li>
<li>The trampoline interprets the instruction and calls <code>f</code> back, giving it the supplied arguments, and again making itself the caller.</li>
<li>This process repeats until <code>f</code> wants to return a final result <code>z</code>; then it returns the new instruction <code>result(z)</code> instead. As before, the runtime removes the current execution frame from the stack and returns control to the trampoline.</li>
<li>But now when the trampoline interprets the new instruction it will return <code>z</code> to <em>its</em> caller, ending the trampoline dance.</li>
</ol>
<p>Now you can see how the trampoline got its name. When our function uses a <code>return</code> statement to remove its own execution frame from the stack, the trampoline bounces control back to it with new arguments.</p>
<p>Here’s a simple implementation. First, we will encode our instructions to the trampoline as triples. We’ll let <code>call(f)(*args, **kwds)</code> be the triple <code>(f, args, kwds)</code>, and <code>result(z)</code> be the triple <code>(None, z, None)</code>:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> call(f):
<span class=\"co\">\"\"\"Instruct trampoline to call f with the args that follow.\"\"\"</span>
<span class=\"kw\">def</span> g(*args, **kwds):
<span class=\"kw\">return</span> f, args, kwds
<span class=\"kw\">return</span> g
<span class=\"kw\">def</span> result(value):
<span class=\"co\">\"\"\"Instruct trampoline to stop iterating and return a value.\"\"\"</span>
<span class=\"kw\">return</span> <span class=\"ot\">None</span>, value, <span class=\"ot\">None</span></code></pre>
<p>Now we’ll create a decorator to wrap a function with a trampoline that will interpret the instructions that the function returns:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"ch\">import</span> functools
<span class=\"kw\">def</span> with_trampoline(f):
<span class=\"co\">\"\"\"Wrap a trampoline around a function that expects a trampoline.\"\"\"</span>
<span class=\"ot\">@functools.wraps</span>(f)
<span class=\"kw\">def</span> g(*args, **kwds):
h = f
<span class=\"co\"># the trampoline</span>
<span class=\"kw\">while</span> h is not <span class=\"ot\">None</span>:
h, args, kwds = h(*args, **kwds)
<span class=\"kw\">return</span> args
<span class=\"kw\">return</span> g</code></pre>
<p>Note that the trampoline boils down to three lines:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">while</span> h is not <span class=\"ot\">None</span>:
h, args, kwds = h(*args, **kwds)
<span class=\"kw\">return</span> args</code></pre>
<p>Basically, the trampoline keeps calling whatever function is in <code>h</code> until that function returns a <code>result(z)</code> instruction, at which time the loop exits and <code>z</code> is returned. The original recursive tail calls have been boiled down to a <code>while</code> loop. Recursion has become iteration.</p>
<h3 id=\"example-factorial\">Example: factorial</h3>
<p>To see how we might use this implementation, let’s return to the factorial example from <a href=\"http://blog.moertel.com/posts/2013-05-11-recursive-to-iterative.html\">the first article in our series</a>:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> factorial(n):
<span class=\"kw\">if</span> n < <span class=\"dv\">2</span>:
<span class=\"kw\">return</span> <span class=\"dv\">1</span>
<span class=\"kw\">return</span> n * factorial(n - <span class=\"dv\">1</span>)</code></pre>
<p>Step one, as before, is to tail-convert the lone recursive call:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"> <span class=\"kw\">def</span> factorial(n, acc=<span class=\"dv\">1</span>):
<span class=\"kw\">if</span> n < <span class=\"dv\">2</span>:
<span class=\"kw\">return</span> acc
<span class=\"kw\">return</span> factorial(n - <span class=\"dv\">1</span>, acc * n)</code></pre>
<p>Now we can create an equivalent function that uses trampoline idioms:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> trampoline_factorial(n, acc=<span class=\"dv\">1</span>):
<span class=\"kw\">if</span> n < <span class=\"dv\">2</span>:
<span class=\"kw\">return</span> result(acc)
<span class=\"kw\">return</span> call(trampoline_factorial)(n - <span class=\"dv\">1</span>, n * acc)</code></pre>
<p>Note how the <code>return</code> statements have been transformed.</p>
<p>Finally, we can wrap this function with a trampoline to get a callable version that we can use just like the original:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\">factorial = with_trampoline(trampoline_factorial)</code></pre>
<p>Let’s take it for a spin:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\">>>> factorial(<span class=\"dv\">5</span>)
<span class=\"dv\">120</span></code></pre>
<p>To really see what’s going on, be sure to use the Online Python Tutor’s visualizer to step through the original, tail-recursive, and trampoline versions of the function. Just open this link: <a href=\"http://www.pythontutor.com/visualize.html#code=%23+our+trampoline+library%0A%0Aimport+functools%0A%0Adef+call(f)%3A%0A++++%22%22%22Instruct+trampoline+to+call+f+with+the+args+that+follow.%22%22%22%0A++++def+g(*args,+**kwds)%3A%0A++++++++return+f,+args,+kwds%0A++++return+g%0A%0Adef+result(value)%3A%0A++++%22%22%22Instruct+trampoline+to+stop+iterating+and+return+a+value.%22%22%22%0A++++return+None,+value,+None%0A%0Adef+with_trampoline(f)%3A%0A++++%22%22%22Wrap+a+trampoline+around+a+function+that+expects+a+trampoline.%22%22%22%0A++++%40functools.wraps(f)%0A++++def+g(*args,+**kwds)%3A%0A++++++++h+%3D+f%0A++++++++%23+the+trampoline%0A++++++++while+h+is+not+None%3A%0A++++++++++++h,+args,+kwds+%3D+h(*args,+**kwds)%0A++++++++return+args%0A++++return+g%0A%0A%0A%23+original+recursive+version+of+factorial+function%0A%0Adef+factorial(n)%3A%0A++++if+n+%3C+2%3A%0A++++++++return+1%0A++++return+n+*+factorial(n+-+1)%0A%0Aprint+factorial(5)%0A%0A%0A%23+tail-call+recursive+version%0A%0Adef+factorial(n,+acc%3D1)%3A%0A+++++if+n+%3C+2%3A%0A+++++++++return+acc%0A+++++return+factorial(n+-+1,+acc+*+n)%0A%0Aprint+factorial(5)%0A%0A%0A%23+trampoline-based+tail-call+version+(%3D+iterative)%0A%0Adef+trampoline_factorial(n,+acc%3D1)%3A%0A++++if+n+%3C+2%3A%0A++++++++return+result(acc)%0A++++return+call(trampoline_factorial)(n+-+1,+n+*+acc)%0A%0Afactorial+%3D+with_trampoline(trampoline_factorial)%0A%0Aprint+factorial(5)%0A&mode=display&cumulative=false&heapPrimitives=false&drawParentPointers=false&textReferences=false&showOnlyOutputs=false&py=2&curInstr=0\">Visualize the execution</a>. (ProTip: use a new tab.)</p>
<h3 id=\"why-use-the-trampoline\">Why use the trampoline?</h3>
<p>As I mentioned at the beginning of this article, if you can convert a function’s recursive calls into tail calls – which you must do to use a trampoline – you can also use the Simple Method on the function. For example, here’s what the Simple Method does to our original <code>factorial</code> function:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> factorial(n, acc=<span class=\"dv\">1</span>):
<span class=\"kw\">while</span> n > <span class=\"dv\">1</span>:
(n, acc) = (n - <span class=\"dv\">1</span>, acc * n)
<span class=\"kw\">return</span> acc</code></pre>
<p>This version is simpler and more efficient than the trampoline version. So why not use the Simple Method always?</p>
<p>The answer is that the Simple Method is tricky to apply to functions that make tail calls from within loops. Recall that it introduces a loop around a function’s body and replaces recursive tail calls with <code>continue</code> statements. But if the function already has its own loops, replacing a tail call within one of them with a <code>continue</code> statement will restart that inner loop instead of the whole-body loop, as desired. In that case, you must add condition flags to make sure the right loop gets restarted, and that gets old fast. Then, using a trampoline may be a win.</p>
<p>That said, I almost never use trampolines. Getting a function into tail-call form is nine tenths of the battle. If I’ve gone that far already, I’ll usually go the rest of the way to get a tight, iterative version.</p>
<p>Why, then, did we make this effort to understand the trampoline? Two reasons. First, it’s semi-common in programming lore, so it’s best to know about it. Second, it’s a stepping stone to a more-general, more-powerful technique: <em>continuation-passing-style expressions</em>. That’s our subject for next time.</p>
<p>In the meantime, if you want another take on trampolines in Python, Kyle Miller wrote a nice article on the subject: <a href=\"http://web.mit.edu/kmill/www/programming/tailcall.html\">Tail call recursion in Python</a>.</p>
<p>Thanks for reading! As always, if you have questions or comments, please leave a comment on the blog or hit me at <a href=\"https://twitter.com/tmoertel\">@tmoertel</a>.</p>" nil nil "d82d170f531ae2a3660a73071218b9f1") (49 (20928 8813 694800) "http://izbicki.me/blog/hlearns-code-is-shorter-and-clearer-than-wekas?utm_source=rss&utm_medium=rss&utm_campaign=hlearns-code-is-shorter-and-clearer-than-wekas" "Mike Izbicki: =?utf-8?Q?HLearn=E2=80=99s?= code is shorter and clearer than =?utf-8?Q?Weka=E2=80=99s?=" nil "Tue, 11 Jun 2013 17:50:09 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /></p>
<p>Haskell code is expressive.  The <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn library</a> uses 6 lines of Haskell to define a function for training a Bayesian classifier; the equivalent code in the <a href=\"http://www.cs.waikato.ac.nz/ml/weka/\">Weka library</a> uses over 100 lines of Java.  That’s a big difference!  In this post, we’ll look at the actual code and see why the Haskell is so much more concise.</p>
<p><strong>But first, a disclaimer:</strong>  It is really hard to fairly compare two code bases this way.  In both libraries, there is a lot of supporting code that goes into defining each classifier, and it’s not obvious what code to include and not include.  For example, both libraries implement interfaces to a number of probability distributions, and this code is not contained in the source count.  The Haskell code takes more advantage of this abstraction, so this is one language-agnostic reason why the Haskell code is shorter.  If you think I’m not doing a fair comparison, here’s some links to the full repositories so you can do it yourself:</p>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\"><a href=\"https://github.com/mikeizbicki/HLearn/blob/master/HLearn-classification/src/HLearn/Models/Classifiers/Bayes.hs\">HLearn’s bayesian classifier source code</a> (74 lines of code)</span></li>
<li><a href=\"https://svn.cms.waikato.ac.nz/svn/weka/trunk/weka/src/main/java/weka/classifiers/bayes/NaiveBayes.java\">Weka’s naive bayes source code</a> (946 lines of code)</li>
</ul>
<p><span id=\"more-2520\"></span></p>
<h3>The HLearn code</h3>
<p>HLearn implements training for a <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">bayesian classifier</a> with these six lines of Haskell:</p>
<pre>newtype Bayes labelIndex dist = Bayes dist
deriving (Read,Show,Eq,Ord,Monoid,Abelian,Group)
instance (Monoid dist, HomTrainer dist) => HomTrainer (Bayes labelIndex dist) where
type Datapoint (Bayes labelIndex dist) = Datapoint dist
train1dp dp = Bayes $ train1dp dp</pre>
<p>This code elegantly captures how to train a Bayesian classifier—just train a probability distribution.  Here’s an explanation:</p>
<ul>
<li>The first two lines define the Bayes data type as a wrapper around a distribution.</li>
<li>The fourth line says that we’re implementing the Bayesian classifier using the HomTrainer type class.  We do this because <strong>the Haskell compiler automatically generates a parallel batch training function, an online training function, and a fast cross-validation function for all HomTrainer instances.</strong></li>
<li>The fifth line says that our data points have the same type as the underlying distribution.</li>
<li>The sixth line says that in order to train, just train the corresponding distribution.</li>
</ul>
<p>We only get the benefits of the HomTrainer type class because the bayesian classifier is a monoid.  But we didn’t even have to specify what the monoid instance for bayesian classifiers looks like!  In this case, it’s automatically derived from the monoid instances for the base distributions using a language extension called <a href=\"http://www.haskell.org/ghc/docs/7.6.1/html/users_guide/deriving.html\">GeneralizedNewtypeDeriving</a>.  For examples of these monoid structures, check out the algebraic structure of the <a href=\"http://izbicki.me/blog/gausian-distributions-are-monoids\">normal</a> and <a href=\"http://izbicki.me/blog/the-categorical-distributions-algebraic-structure\">categorical</a> distributions, or more complex distributions using <a href=\"http://izbicki.me/blog/markov-networks-monoids-and-futurama\">Markov networks</a>.</p>
<h3>The Weka code</h3>
<p>Look for these differences between the HLearn and Weka source:</p>
<ul>
<li>In Weka we must separately define the online and batch trainers, whereas Haskell derived these for us automatically.</li>
<li>Weka must perform a variety of error handling that Haskell’s type system takes care of in HLearn.</li>
<li>The Weka code is tightly coupled to the underlying probability distribution, whereas the Haskell code was generic enough to handle any distribution. This means that while Weka must make the “naive bayes assumption” that all attributes are independent of each other, HLearn can support any dependence structure.</li>
<li>Weka’s code is made more verbose by for loops and if statements that aren’t necessary for HLearn.</li>
<li>The Java code requires extensive comments to maintain readability, but the Haskell code is simple enough to be self-documenting (at least once you know how to read Haskell).</li>
<li>Weka does not have parallel training, fast cross-validation, data point subtraction, or weighted data points, but HLearn does.</li>
</ul>
<pre>/**
* Generates the classifier.
*
* @param instances set of instances serving as training data
* @exception Exception if the classifier has not been generated
* successfully
*/
public void buildClassifier(Instances instances) throws Exception {
// can classifier handle the data?
getCapabilities().testWithFail(instances);
// remove instances with missing class
instances = new Instances(instances);
instances.deleteWithMissingClass();
m_NumClasses = instances.numClasses();
// Copy the instances
m_Instances = new Instances(instances);
// Discretize instances if required
if (m_UseDiscretization) {
m_Disc = new weka.filters.supervised.attribute.Discretize();
m_Disc.setInputFormat(m_Instances);
m_Instances = weka.filters.Filter.useFilter(m_Instances, m_Disc);
} else {
m_Disc = null;
}
// Reserve space for the distributions
m_Distributions = new Estimator[m_Instances.numAttributes() - 1]
[m_Instances.numClasses()];
m_ClassDistribution = new DiscreteEstimator(m_Instances.numClasses(),
true);
int attIndex = 0;
Enumeration enu = m_Instances.enumerateAttributes();
while (enu.hasMoreElements()) {
Attribute attribute = (Attribute) enu.nextElement();
// If the attribute is numeric, determine the estimator
// numeric precision from differences between adjacent values
double numPrecision = DEFAULT_NUM_PRECISION;
if (attribute.type() == Attribute.NUMERIC) {
m_Instances.sort(attribute);
if ( (m_Instances.numInstances() > 0)
    && !m_Instances.instance(0).isMissing(attribute)) {
  double lastVal = m_Instances.instance(0).value(attribute);
  double currentVal, deltaSum = 0;
  int distinct = 0;
  for (int i = 1; i < m_Instances.numInstances(); i++) { 	
Instance currentInst = m_Instances.instance(i); 	
if (currentInst.isMissing(attribute)) {
break; 	
}
	    currentVal = currentInst.value(attribute);
	    if (currentVal != lastVal) {
	      deltaSum += currentVal - lastVal;
	      lastVal = currentVal;
	      distinct++;
	    }
	  }
	  if (distinct > 0) {
    numPrecision = deltaSum / distinct;
  }
}
}
for (int j = 0; j < m_Instances.numClasses(); j++) {
switch (attribute.type()) {
case Attribute.NUMERIC:
  if (m_UseKernelEstimator) {
    m_Distributions[attIndex][j] =
      new KernelEstimator(numPrecision);
  } else {
    m_Distributions[attIndex][j] =
      new NormalEstimator(numPrecision);
  }
  break;
case Attribute.NOMINAL:
  m_Distributions[attIndex][j] =
    new DiscreteEstimator(attribute.numValues(), true);
  break;
default:
  throw new Exception(\"Attribute type unknown to NaiveBayes\");
}
}
attIndex++;
}
// Compute counts
Enumeration enumInsts = m_Instances.enumerateInstances();
while (enumInsts.hasMoreElements()) {
Instance instance =
(Instance) enumInsts.nextElement();
updateClassifier(instance);
}
// Save space
m_Instances = new Instances(m_Instances, 0);
}</pre>
<p>And the code for online learning is:</p>
<pre>/**
* Updates the classifier with the given instance.
*
* @param instance the new training instance to include in the model
* @exception Exception if the instance could not be incorporated in
* the model.
*/
public void updateClassifier(Instance instance) throws Exception {
if (!instance.classIsMissing()) {
Enumeration enumAtts = m_Instances.enumerateAttributes();
int attIndex = 0;
while (enumAtts.hasMoreElements()) {
Attribute attribute = (Attribute) enumAtts.nextElement();
if (!instance.isMissing(attribute)) {
  m_Distributions[attIndex][(int)instance.classValue()].
addValue(instance.value(attribute), instance.weight());
}
attIndex++;
}
m_ClassDistribution.addValue(instance.classValue(),
instance.weight());
}
}</pre>
<h3>Conclusion</h3>
<p>Every algorithm implemented in HLearn uses similarly concise code.  I invite you to <a href=\"https://github.com/mikeizbicki/HLearn/\">browse the repository</a> and see for yourself.  The most complicated algorithm is for Markov chains which use only <a href=\"https://github.com/mikeizbicki/HLearn/blob/master/HLearn-markov/src/HLearn/Models/Markov/MarkovChain.hs\">6 lines for training, and about 20 for defining the Monoid</a>.</p>
<p>You can expect lots of tutorials on how to incorporate the HLearn library into Haskell programs over the next few months.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned!</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2520\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "41828f6897d8b5596cca8a40ad1a51a4") (48 (20928 8813 693013) "http://wadler.blogspot.com/2013/06/iain-banks.html" "Philip Wadler: Iain Banks" "noreply@blogger.com (Philip Wadler)" "Tue, 11 Jun 2013 08:24:56 +0000" "<div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://1.bp.blogspot.com/-0cLAVwyWSKU/Ubbaw7r7N9I/AAAAAAAACKI/DItsN5fXHQE/s1600/scotsbanks-003.jpg\"><img src=\"http://1.bp.blogspot.com/-0cLAVwyWSKU/Ubbaw7r7N9I/AAAAAAAACKI/DItsN5fXHQE/s400/scotsbanks-003.jpg\" title=\"Writer Iain Banks seen in front of the Scottish Parliament Building at Holyrood in Edinburgh. Photograph: Murdo MacLeod (Observer)\" height=\"240\" width=\"400\" alt=\"Writer Iain Banks seen in front of the Scottish Parliament Building at Holyrood in Edinburgh. Photograph: Murdo MacLeod (Observer)\" border=\"0\" /></a></div>In April, Iain Banks discovered he had cancer of the gall bladder, and proposed to his girl friend by requesting she `do me the honour of becoming my widow'.  Yesterday his death was announced.  In his honour, here is something he <a href=\"http://www.guardian.co.uk/culture/2011/aug/28/scottish-independence-snp-iain-banks?INTCMP=SRCH\">wrote for the Observer</a>.  See also this <a href=\"http://www.guardian.co.uk/books/2013/jun/10/iain-banks-ken-macleod-science-fiction\">tribute from Ken McLeod</a>.<br /><blockquote class=\"tr_bq\"><div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://1.bp.blogspot.com/-0cLAVwyWSKU/Ubbaw7r7N9I/AAAAAAAACKI/DItsN5fXHQE/s1600/scotsbanks-003.jpg\"></a></div>These days, I support the idea of an independent Scotland. It's with a  heavy heart in some ways; I think I'd still sacrifice an independent  Scotland for a socialist UK, but… I can't really see that happening.  What I can imagine is England continuing to turn to the right and  eventually leaving the EU altogether.<br /><br />Scotland, though, could have  a viable future either as a completely independent country or – more  likely – within Europe. The European ideal is taking a battering right  now, certainly, and the gloss has come off comparing our prospects to  Ireland's or Iceland's, but it remains both possible and plausible that  Scotland could become a transparent, low-inequality society on the  Scandinavian model, with fair, non-regressive taxes, strong unions, a  nuclear-free policy, a non-punitive tertiary education system,  enlightened social policies in general and long-term support for green  energy programmes.<br /><br />We'd need to make sure our banks were small  enough to fail, and there are problems of poverty, ill health and  religious tribalism that will take decades to overcome. But with the  advantages and attractions that Scotland already has, and, more  importantly, taking into account the morale boost, the sheer  energisation of a whole people that would come about because we would  finally have our destiny at least largely back in our own hands again – I  think we could do it.<br /><br />And that we should.</blockquote>" nil nil "2d477fa106186a0bb1b16af182212152") (47 (20928 8813 691305) "http://theorylunch.wordpress.com/2013/05/30/when-does-an-endofunctor-derive-from-an-adjunction/" "Theory Lunch (Institute of Cybernetics, Tallinn): When does an endofunctor derive from an adjunction?" nil "Mon, 10 Jun 2013 11:27:39 +0000" "<p>This is the first of two talks based on Andrea Schalk’s very good introduction to monads, which can be retrieved <a href=\"http://www.cs.man.ac.uk/~schalk/notes/monads.pdf\" target=\"_blank\" title=\"http://www.cs.man.ac.uk/~schalk/notes/monads.pdf‎\">HERE</a></p>
<p>In the following, if <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> is a category, we indicate by <img src=\"http://s0.wp.com/latex.php?latex=%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"|\\mathcal{C}|\" class=\"latex\" title=\"|\\mathcal{C}|\" /> the collection of objects of <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" />, and by <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D%28A%2CB%29&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}(A,B)\" class=\"latex\" title=\"\\mathcal{C}(A,B)\" /> the collection of morphisms in <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> from <img src=\"http://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=333333&s=0\" alt=\"A\" class=\"latex\" title=\"A\" /> to <img src=\"http://s0.wp.com/latex.php?latex=B&bg=ffffff&fg=333333&s=0\" alt=\"B\" class=\"latex\" title=\"B\" />.</p>
<p>As we know, there are two basic ways of defining an adjunction: <span id=\"more-768\"></span></p>
<p><strong>Definition 1.</strong> Let <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{D}\" class=\"latex\" title=\"\\mathcal{D}\" /> be categories; let <img src=\"http://s0.wp.com/latex.php?latex=F+%3A+%5Cmathcal%7BC%7D+%5Cto+%5Cmathcal%7BD%7D&bg=ffffff&fg=333333&s=0\" alt=\"F : \\mathcal{C} \\to \\mathcal{D}\" class=\"latex\" title=\"F : \\mathcal{C} \\to \\mathcal{D}\" /> and <img src=\"http://s0.wp.com/latex.php?latex=F+%3A+%5Cmathcal%7BD%7D+%5Cto+%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"F : \\mathcal{D} \\to \\mathcal{C}\" class=\"latex\" title=\"F : \\mathcal{D} \\to \\mathcal{C}\" /> be functors. An <em>adjunction</em> from <img src=\"http://s0.wp.com/latex.php?latex=F&bg=ffffff&fg=333333&s=0\" alt=\"F\" class=\"latex\" title=\"F\" /> to <img src=\"http://s0.wp.com/latex.php?latex=G&bg=ffffff&fg=333333&s=0\" alt=\"G\" class=\"latex\" title=\"G\" />, written <img src=\"http://s0.wp.com/latex.php?latex=F+%5Cdashv+G&bg=ffffff&fg=333333&s=0\" alt=\"F \\dashv G\" class=\"latex\" title=\"F \\dashv G\" />, is a quadruple <img src=\"http://s0.wp.com/latex.php?latex=%28F%2CG%2C%5Ceta%2C%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F,G,\\eta,\\varepsilon)\" class=\"latex\" title=\"(F,G,\\eta,\\varepsilon)\" /> where <img src=\"http://s0.wp.com/latex.php?latex=%5Ceta%3A+%5Cmathrm%7BId%7D_%5Cmathcal%7BC%7D+%5Cto+GF&bg=ffffff&fg=333333&s=0\" alt=\"\\eta: \\mathrm{Id}_\\mathcal{C} \\to GF\" class=\"latex\" title=\"\\eta: \\mathrm{Id}_\\mathcal{C} \\to GF\" /> (the <em>unit</em> of the adjunction) and <img src=\"http://s0.wp.com/latex.php?latex=%5Cvarepsilon%3A+FG+%5Cto+%5Cmathrm%7BId%7D_%5Cmathcal%7BD%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\varepsilon: FG \\to \\mathrm{Id}_\\mathcal{D}\" class=\"latex\" title=\"\\varepsilon: FG \\to \\mathrm{Id}_\\mathcal{D}\" /> (the <em>counit</em>) are natural transformations such that , for every <img src=\"http://s0.wp.com/latex.php?latex=A+%5Cin+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"A \\in |\\mathcal{C}|\" class=\"latex\" title=\"A \\in |\\mathcal{C}|\" /> and <img src=\"http://s0.wp.com/latex.php?latex=S+%5Cin+%7C%5Cmathcal%7BD%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"S \\in |\\mathcal{D}|\" class=\"latex\" title=\"S \\in |\\mathcal{D}|\" />, <img src=\"http://s0.wp.com/latex.php?latex=G%5Cvarepsilon_S+%5Ccirc+%5Ceta_%7BGS%7D+%3D+%5Cmathrm%7Bid%7D_%7BGS%7D&bg=ffffff&fg=333333&s=0\" alt=\"G\\varepsilon_S \\circ \\eta_{GS} = \\mathrm{id}_{GS}\" class=\"latex\" title=\"G\\varepsilon_S \\circ \\eta_{GS} = \\mathrm{id}_{GS}\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cvarepsilon_%7BFA%7D+%5Ccirc+F%5Ceta_%7BA%7D+%3D+%5Cmathrm%7Bid%7D_%7BFA%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\varepsilon_{FA} \\circ F\\eta_{A} = \\mathrm{id}_{FA}\" class=\"latex\" title=\"\\varepsilon_{FA} \\circ F\\eta_{A} = \\mathrm{id}_{FA}\" />.</p>
<p><strong>Definition 2.</strong> Let <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{D}\" class=\"latex\" title=\"\\mathcal{D}\" /> be categories. We call <em>adjunction quadruple</em> a quadruple <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Csharp%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, (\\cdot)^\\sharp)\" class=\"latex\" title=\"(F, G, \\eta, (\\cdot)^\\sharp)\" /> such that:</p>
<ol>
<li><img src=\"http://s0.wp.com/latex.php?latex=G+%3A+%5Cmathcal%7BD%7D+%5Cto+%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"G : \\mathcal{D} \\to \\mathcal{C}\" class=\"latex\" title=\"G : \\mathcal{D} \\to \\mathcal{C}\" /> is a functor,</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=F+%3A+%7C%5Cmathcal%7BC%7D%7C+%5Cto+%7C%5Cmathcal%7BD%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"F : |\\mathcal{C}| \\to |\\mathcal{D}|\" class=\"latex\" title=\"F : |\\mathcal{C}| \\to |\\mathcal{D}|\" /> is a mapping, and</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%5Ceta&bg=ffffff&fg=333333&s=0\" alt=\"\\eta\" class=\"latex\" title=\"\\eta\" /> associates to every object <img src=\"http://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=333333&s=0\" alt=\"A\" class=\"latex\" title=\"A\" /> a morphism <img src=\"http://s0.wp.com/latex.php?latex=%5Ceta_A+%3A+A+%5Cto+GFA&bg=ffffff&fg=333333&s=0\" alt=\"\\eta_A : A \\to GFA\" class=\"latex\" title=\"\\eta_A : A \\to GFA\" /> so that</li>
<li>for every <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+A+%5Cto+GS&bg=ffffff&fg=333333&s=0\" alt=\"f : A \\to GS\" class=\"latex\" title=\"f : A \\to GS\" /> there exists a unique <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Csharp+%3A+FA+%5Cto+S&bg=ffffff&fg=333333&s=0\" alt=\"f^\\sharp : FA \\to S\" class=\"latex\" title=\"f^\\sharp : FA \\to S\" /> such that <img src=\"http://s0.wp.com/latex.php?latex=Gf%5E%5Csharp+%5Ccirc+%5Ceta_A+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"Gf^\\sharp \\circ \\eta_A = f\" class=\"latex\" title=\"Gf^\\sharp \\circ \\eta_A = f\" />.</li>
</ol>
<p>The two definitions above are equivalent in the following sense. If <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> is an adjunction according to Definition 1, and <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Csharp+%3D+%5Cvarepsilon_S+%5Ccirc+Ff&bg=ffffff&fg=333333&s=0\" alt=\"f^\\sharp = \\varepsilon_S \\circ Ff\" class=\"latex\" title=\"f^\\sharp = \\varepsilon_S \\circ Ff\" />, then <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Csharp%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, (\\cdot)^\\sharp)\" class=\"latex\" title=\"(F, G, \\eta, (\\cdot)^\\sharp)\" /> is an adjunction quadruple according to Definition 2. On the other hand, if <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Cast%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, (\\cdot)^\\ast)\" class=\"latex\" title=\"(F, G, \\eta, (\\cdot)^\\ast)\" /> is an adjunction quadruple according to Definition 2, and <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ccdot%29_%5Cflat&bg=ffffff&fg=333333&s=0\" alt=\"(\\cdot)_\\flat\" class=\"latex\" title=\"(\\cdot)_\\flat\" /> is the inverse operation of <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ccdot%29%5E%5Csharp&bg=ffffff&fg=333333&s=0\" alt=\"(\\cdot)^\\sharp\" class=\"latex\" title=\"(\\cdot)^\\sharp\" />—that is, <img src=\"http://s0.wp.com/latex.php?latex=g_%5Cflat+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"g_\\flat = f\" class=\"latex\" title=\"g_\\flat = f\" /> if and only if <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Csharp+%3D+g&bg=ffffff&fg=333333&s=0\" alt=\"f^\\sharp = g\" class=\"latex\" title=\"f^\\sharp = g\" />—then necessarily <img src=\"http://s0.wp.com/latex.php?latex=%5Ceta_A+%3D+%28%5Cmathrm%7Bid%7D_%7BFA%7D%29_%5Cflat&bg=ffffff&fg=333333&s=0\" alt=\"\\eta_A = (\\mathrm{id}_{FA})_\\flat\" class=\"latex\" title=\"\\eta_A = (\\mathrm{id}_{FA})_\\flat\" />, and by putting <img src=\"http://s0.wp.com/latex.php?latex=Ff+%3D+%28%5Ceta_B+%5Ccirc+f%29%5E%5Csharp&bg=ffffff&fg=333333&s=0\" alt=\"Ff = (\\eta_B \\circ f)^\\sharp\" class=\"latex\" title=\"Ff = (\\eta_B \\circ f)^\\sharp\" /> for <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D%28A%2CB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}(A,B)\" class=\"latex\" title=\"f \\in \\mathcal{C}(A,B)\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cvarepsilon_S+%3D+%28%5Cmathrm%7Bid%7D_%7BGS%7D%29%5E%5Csharp&bg=ffffff&fg=333333&s=0\" alt=\"\\varepsilon_S = (\\mathrm{id}_{GS})^\\sharp\" class=\"latex\" title=\"\\varepsilon_S = (\\mathrm{id}_{GS})^\\sharp\" /> for <img src=\"http://s0.wp.com/latex.php?latex=S+%5Cin+%7C%5Cmathcal%7BD%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"S \\in |\\mathcal{D}|\" class=\"latex\" title=\"S \\in |\\mathcal{D}|\" /> we define an adjunction according to Definition 1.</p>
<p>If <img src=\"http://s0.wp.com/latex.php?latex=%28F%2CG%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F,G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F,G, \\eta, \\varepsilon)\" /> is an adjunction, then <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+GF+%3A+%5Cmathcal%7BC%7D+%5Cto+%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"T = GF : \\mathcal{C} \\to \\mathcal{C}\" class=\"latex\" title=\"T = GF : \\mathcal{C} \\to \\mathcal{C}\" /> is an endofunctor.The first question that comes to our mind is:</p>
<p style=\"text-align: center;\"><em>when does an endofunctor derive from an adjunction?</em></p>
<p>Let us check some basic properties such an endofunctor must satisfy. First of all, <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu+%3A+T%5E2+%5Cto+T&bg=ffffff&fg=333333&s=0\" alt=\"\\mu : T^2 \\to T\" class=\"latex\" title=\"\\mu : T^2 \\to T\" /> defined by <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%3D+G%5Cvarepsilon_%7BFA%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A = G\\varepsilon_{FA}\" class=\"latex\" title=\"\\mu_A = G\\varepsilon_{FA}\" /> is a natural transformation and satisfies</p>
<p style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%5Ccirc+T%5Ceta_A+%3D+%5Cmu_A+%5Ccirc+%5Ceta_%7BTA%7D+%3D+%5Cmathrm%7Bid%7D_%7BTA%7D+%5C%3B%5C%3B+%5Cforall+A+%5Cin+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A \\circ T\\eta_A = \\mu_A \\circ \\eta_{TA} = \\mathrm{id}_{TA} \\;\\; \\forall A \\in |\\mathcal{C}|\" class=\"latex\" title=\"\\mu_A \\circ T\\eta_A = \\mu_A \\circ \\eta_{TA} = \\mathrm{id}_{TA} \\;\\; \\forall A \\in |\\mathcal{C}|\" /></p>
<p style=\"text-align: left;\">Moreover, as <img src=\"http://s0.wp.com/latex.php?latex=%5Cvarepsilon+%3A+FG+%5Cto+%5Cmathrm%7BId%7D_%7B%5Cmathcal%7BD%7D%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\varepsilon : FG \\to \\mathrm{Id}_{\\mathcal{D}}\" class=\"latex\" title=\"\\varepsilon : FG \\to \\mathrm{Id}_{\\mathcal{D}}\" /> is a natural transformation, by choosing <img src=\"http://s0.wp.com/latex.php?latex=f+%3D+%5Cvarepsilon_%7BFA%7D&bg=ffffff&fg=333333&s=0\" alt=\"f = \\varepsilon_{FA}\" class=\"latex\" title=\"f = \\varepsilon_{FA}\" /> we get <img src=\"http://s0.wp.com/latex.php?latex=%5Cvarepsilon_%7BFA%7D+%5Ccirc+%5Cvarepsilon_%7BFGFA%7D+%3D+%5Cvarepsilon_%7BFA%7D+%5Ccirc+FG%5Cvarepsilon_%7BFA%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\varepsilon_{FA} \\circ \\varepsilon_{FGFA} = \\varepsilon_{FA} \\circ FG\\varepsilon_{FA}\" class=\"latex\" title=\"\\varepsilon_{FA} \\circ \\varepsilon_{FGFA} = \\varepsilon_{FA} \\circ FG\\varepsilon_{FA}\" />, which after an application of <img src=\"http://s0.wp.com/latex.php?latex=G&bg=ffffff&fg=333333&s=0\" alt=\"G\" class=\"latex\" title=\"G\" /> yields</p>
<p style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%5Ccirc+%5Cmu_%7BTA%7D+%3D+%5Cmu_A+%5Ccirc+T%5Cmu_A+%5C%3B%5C%3B+%5Cforall+A+%5Cin+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A \\circ \\mu_{TA} = \\mu_A \\circ T\\mu_A \\;\\; \\forall A \\in |\\mathcal{C}|\" class=\"latex\" title=\"\\mu_A \\circ \\mu_{TA} = \\mu_A \\circ T\\mu_A \\;\\; \\forall A \\in |\\mathcal{C}|\" /></p>
<p style=\"text-align: left;\">It will turn out that these two properties are precisely what we need.</p>
<p style=\"text-align: left;\"><strong>Definition 3.</strong> A <em>monad</em> on a category <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> is a triple <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+%28T%2C+%5Ceta%2C+%5Cmu%29&bg=ffffff&fg=333333&s=0\" alt=\"T = (T, \\eta, \\mu)\" class=\"latex\" title=\"T = (T, \\eta, \\mu)\" /> where:</p>
<ol>
<li><img src=\"http://s0.wp.com/latex.php?latex=T+%3A+%5Cmathcal%7BC%7D+%5Cto+%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"T : \\mathcal{C} \\to \\mathcal{C}\" class=\"latex\" title=\"T : \\mathcal{C} \\to \\mathcal{C}\" /> is an endofunctor,</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%5Ceta+%3A+%5Cmathrm%7BId%7D_%5Cmathcal%7BC%7D+%5Cto+T&bg=ffffff&fg=333333&s=0\" alt=\"\\eta : \\mathrm{Id}_\\mathcal{C} \\to T\" class=\"latex\" title=\"\\eta : \\mathrm{Id}_\\mathcal{C} \\to T\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu%3A+T%5E2+%5Cto+T&bg=ffffff&fg=333333&s=0\" alt=\"\\mu: T^2 \\to T\" class=\"latex\" title=\"\\mu: T^2 \\to T\" /> are natural transformations, and</li>
<li>for every <img src=\"http://s0.wp.com/latex.php?latex=A+%5Cin+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"A \\in |\\mathcal{C}|\" class=\"latex\" title=\"A \\in |\\mathcal{C}|\" /> we have <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%5Ccirc+%5Ceta_%7BTA%7D+%3D+%5Cmu_A+%5Ccirc+T%5Ceta_A+%3D+%5Cmathrm%7Bid%7D_%7BTA%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A \\circ \\eta_{TA} = \\mu_A \\circ T\\eta_A = \\mathrm{id}_{TA}\" class=\"latex\" title=\"\\mu_A \\circ \\eta_{TA} = \\mu_A \\circ T\\eta_A = \\mathrm{id}_{TA}\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%5Ccirc+%5Cmu_%7BTA%7D+%3D+%5Cmu_A+%5Ccirc+T%5Cmu_A&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A \\circ \\mu_{TA} = \\mu_A \\circ T\\mu_A\" class=\"latex\" title=\"\\mu_A \\circ \\mu_{TA} = \\mu_A \\circ T\\mu_A\" />,</li>
</ol>
<p>As a very basic example, the <em>free monoid</em> construction is a monad on <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathbf%7BSet%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathbf{Set}\" class=\"latex\" title=\"\\mathbf{Set}\" />, where <img src=\"http://s0.wp.com/latex.php?latex=TA+%3D+A%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"TA = A^\\ast\" class=\"latex\" title=\"TA = A^\\ast\" />, <img src=\"http://s0.wp.com/latex.php?latex=Tf%28s%29+%3D+%5Bf%28a%29+%5C%3B+%5Cmathtt%7Bfor%7D+%5C%3B+a+%5C%3B+%5Cmathtt%7Bin%7D+%5C%3B+s%5D&bg=ffffff&fg=333333&s=0\" alt=\"Tf(s) = [f(a) \\; \\mathtt{for} \\; a \\; \\mathtt{in} \\; s]\" class=\"latex\" title=\"Tf(s) = [f(a) \\; \\mathtt{for} \\; a \\; \\mathtt{in} \\; s]\" />, <img src=\"http://s0.wp.com/latex.php?latex=%5Ceta_A%28a%29+%3D+%5Ba%5D&bg=ffffff&fg=333333&s=0\" alt=\"\\eta_A(a) = [a]\" class=\"latex\" title=\"\\eta_A(a) = [a]\" />, and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A%28%5B%5Ba%5E1_1%2C+%5Cldots%2C+a%5E1_%7Bn_1%7D%5D%2C+%5Cldots%2C+%5Ba%5Em_1%2C+%5Cldots%2C+a%5Em_%7Bn_m%7D%5D%5D+%3D+%5Ba%5E1_1%2C+%5Cldots%2C+a%5E1_%7Bn_1%7D%2C+%5Cldots%2C+a%5Em_1%2C+%5Cldots%2C+a%5Em_%7Bn_m%7D%5D&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A([[a^1_1, \\ldots, a^1_{n_1}], \\ldots, [a^m_1, \\ldots, a^m_{n_m}]] = [a^1_1, \\ldots, a^1_{n_1}, \\ldots, a^m_1, \\ldots, a^m_{n_m}]\" class=\"latex\" title=\"\\mu_A([[a^1_1, \\ldots, a^1_{n_1}], \\ldots, [a^m_1, \\ldots, a^m_{n_m}]] = [a^1_1, \\ldots, a^1_{n_1}, \\ldots, a^m_1, \\ldots, a^m_{n_m}]\" />.</p>
<p>As a less basic example, suppose <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D+%3D+%28S%2C+%5Cleq%29&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C} = (S, \\leq)\" class=\"latex\" title=\"\\mathcal{C} = (S, \\leq)\" /> is a poset: what is a monad on <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" />? First of all, an endofunctor on a poset is a monotone function; next, if there is <img src=\"http://s0.wp.com/latex.php?latex=%5Ceta_A+%3A+A+%5Cto+TA&bg=ffffff&fg=333333&s=0\" alt=\"\\eta_A : A \\to TA\" class=\"latex\" title=\"\\eta_A : A \\to TA\" />, then <img src=\"http://s0.wp.com/latex.php?latex=A+%5Cleq+TA&bg=ffffff&fg=333333&s=0\" alt=\"A \\leq TA\" class=\"latex\" title=\"A \\leq TA\" />; finally, if there is <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%3A+T%5E2A+%5Cto+TA&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A : T^2A \\to TA\" class=\"latex\" title=\"\\mu_A : T^2A \\to TA\" />, then <img src=\"http://s0.wp.com/latex.php?latex=T%5E2A+%5Cleq+TA&bg=ffffff&fg=333333&s=0\" alt=\"T^2A \\leq TA\" class=\"latex\" title=\"T^2A \\leq TA\" />, which together with the previous inequality yields <img src=\"http://s0.wp.com/latex.php?latex=T%5E2A+%3D+TA&bg=ffffff&fg=333333&s=0\" alt=\"T^2A = TA\" class=\"latex\" title=\"T^2A = TA\" />. On the other hand, any nondecreasing idempotent is the endofunctor component of a monad: the monad equations are actually ensured by <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> being a poset, so that any two maps with same domain and same codomain are equal.</p>
<p>We then restate our original problem as follows:</p>
<p style=\"text-align: center;\"><em>given a monad <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+%28T%2C+%5Ceta%2C+%5Cmu%29&bg=ffffff&fg=333333&s=0\" alt=\"T = (T, \\eta, \\mu)\" class=\"latex\" title=\"T = (T, \\eta, \\mu)\" />, find an adjunction <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> such that <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+GF&bg=ffffff&fg=333333&s=0\" alt=\"T = GF\" class=\"latex\" title=\"T = GF\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu+%3D+G+%5Cvarepsilon_F&bg=ffffff&fg=333333&s=0\" alt=\"\\mu = G \\varepsilon_F\" class=\"latex\" title=\"\\mu = G \\varepsilon_F\" /></em></p>
<p>If the adjunction <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> solves the problem above, we say that it <em>generates</em> the monad <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />.</p>
<p>The first solution to this problem was given by the Swiss mathematician Heinrich Kleisli, and is based on an alternative way of defining monads, as it is the case with adjunctions. Let us suppose <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+GF&bg=ffffff&fg=333333&s=0\" alt=\"T = GF\" class=\"latex\" title=\"T = GF\" /> with <img src=\"http://s0.wp.com/latex.php?latex=F+%5Cdashv+G&bg=ffffff&fg=333333&s=0\" alt=\"F \\dashv G\" class=\"latex\" title=\"F \\dashv G\" />. If <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+A+%5Cto+TB+%3D+G%28FB%29&bg=ffffff&fg=333333&s=0\" alt=\"f : A \\to TB = G(FB)\" class=\"latex\" title=\"f : A \\to TB = G(FB)\" />, then <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Csharp+%3A+FA+%5Cto+FB&bg=ffffff&fg=333333&s=0\" alt=\"f^\\sharp : FA \\to FB\" class=\"latex\" title=\"f^\\sharp : FA \\to FB\" />, so that <img src=\"http://s0.wp.com/latex.php?latex=Gf%5E%5Csharp+%3A+TA+%5Cto+TB&bg=ffffff&fg=333333&s=0\" alt=\"Gf^\\sharp : TA \\to TB\" class=\"latex\" title=\"Gf^\\sharp : TA \\to TB\" />: and we know from the definition of monad that <img src=\"http://s0.wp.com/latex.php?latex=Gf%5E%5Csharp+%5Ccirc+%5Ceta_A+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"Gf^\\sharp \\circ \\eta_A = f\" class=\"latex\" title=\"Gf^\\sharp \\circ \\eta_A = f\" />. We can thus define an operator <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ccdot%29%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"(\\cdot)^\\ast\" class=\"latex\" title=\"(\\cdot)^\\ast\" /> that takes <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D%28A%2CTB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}(A,TB)\" class=\"latex\" title=\"f \\in \\mathcal{C}(A,TB)\" /> into <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Cast+%5Cin+%5Cmathcal%7BC%7D%28TA%2CTB%29&bg=ffffff&fg=333333&s=0\" alt=\"f^\\ast \\in \\mathcal{C}(TA,TB)\" class=\"latex\" title=\"f^\\ast \\in \\mathcal{C}(TA,TB)\" /> in a way such that <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Cast+%5Ccirc+%5Ceta_A+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"f^\\ast \\circ \\eta_A = f\" class=\"latex\" title=\"f^\\ast \\circ \\eta_A = f\" /> whatever <img src=\"http://s0.wp.com/latex.php?latex=f&bg=ffffff&fg=333333&s=0\" alt=\"f\" class=\"latex\" title=\"f\" /> is. The simplest example is <img src=\"http://s0.wp.com/latex.php?latex=f+%3D+%5Ceta_A&bg=ffffff&fg=333333&s=0\" alt=\"f = \\eta_A\" class=\"latex\" title=\"f = \\eta_A\" /> itself, so that <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ceta_A%29%5E%5Cast+%5Ccirc+%5Ceta_A+%3D+%5Ceta_A&bg=ffffff&fg=333333&s=0\" alt=\"(\\eta_A)^\\ast \\circ \\eta_A = \\eta_A\" class=\"latex\" title=\"(\\eta_A)^\\ast \\circ \\eta_A = \\eta_A\" />, and <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ceta_A%29%5E%5Cast+%3D+%5Cmathrm%7Bid%7D_%7BTA%7D&bg=ffffff&fg=333333&s=0\" alt=\"(\\eta_A)^\\ast = \\mathrm{id}_{TA}\" class=\"latex\" title=\"(\\eta_A)^\\ast = \\mathrm{id}_{TA}\" /> by uniqueness in the definition of adjunction quadruple. Moreover, if <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+A+%5Cto+TB&bg=ffffff&fg=333333&s=0\" alt=\"f : A \\to TB\" class=\"latex\" title=\"f : A \\to TB\" /> and <img src=\"http://s0.wp.com/latex.php?latex=g+%3A+B+%5Cto+TC&bg=ffffff&fg=333333&s=0\" alt=\"g : B \\to TC\" class=\"latex\" title=\"g : B \\to TC\" />, then</p>
<p style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=g%5E%5Cast+%5Ccirc+f+%3D+Gg%5E%5Csharp+%5Ccirc+%28Gf%5E%5Csharp+%5Ccirc+%5Ceta_A%29+%3D+%28g%5E%5Cast+%5Ccirc+f%5E%5Cast%29+%5Ccirc+%5Ceta_A+%5C%3B%2C&bg=ffffff&fg=333333&s=0\" alt=\"g^\\ast \\circ f = Gg^\\sharp \\circ (Gf^\\sharp \\circ \\eta_A) = (g^\\ast \\circ f^\\ast) \\circ \\eta_A \\;,\" class=\"latex\" title=\"g^\\ast \\circ f = Gg^\\sharp \\circ (Gf^\\sharp \\circ \\eta_A) = (g^\\ast \\circ f^\\ast) \\circ \\eta_A \\;,\" /></p>
<p style=\"text-align: left;\">which implies <img src=\"http://s0.wp.com/latex.php?latex=%28g%5E%5Cast+%5Ccirc+f%29%5E%5Cast+%3D+g%5E%5Cast+%5Ccirc+f%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"(g^\\ast \\circ f)^\\ast = g^\\ast \\circ f^\\ast\" class=\"latex\" title=\"(g^\\ast \\circ f)^\\ast = g^\\ast \\circ f^\\ast\" /> by uniqueness.</p>
<p>This is the base of Kleisli’s solution to our problem, which we will discuss in a future talk.</p>
<br />  <a href=\"http://feeds.wordpress.com/1.0/gocomments/theorylunch.wordpress.com/768/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/theorylunch.wordpress.com/768/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=theorylunch.wordpress.com&blog=43735749&post=768&subd=theorylunch&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "b8ba9aeb3d90febcf3f2b4138d1ad02f") (46 (20928 8813 685039) "http://theorylunch.wordpress.com/2013/06/06/an-initial-solution-to-the-monad-problem-and-then-some-more/" "Theory Lunch (Institute of Cybernetics, Tallinn): An initial solution to the monad problem, and then some more" nil "Mon, 10 Jun 2013 11:27:02 +0000" "<p>This is the second of two talks about monads, based on <a href=\"http://www.cs.man.ac.uk/~schalk/notes/monads.pdf\" target=\"_blank\" title=\"http://www.cs.man.ac.uk/~schalk/notes/monads.pdf\">the very good notes by Andrea Schalk</a> and continuing <a href=\"http://theorylunch.wordpress.com/2013/05/30/when-does-an-endofunctor-derive-from-an-adjunction/\" target=\"_blank\" title=\"http://theorylunch.wordpress.com/2013/05/30/when-does-an-endofunctor-derive-from-an-adjunction/\">the one I gave on the 30th of May</a>. Recall that we are trying to solve the following problem:</p>
<p style=\"text-align: center;\"><em>given a monad <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+%28T%2C+%5Ceta%2C+%5Cmu%29&bg=ffffff&fg=333333&s=0\" alt=\"T = (T, \\eta, \\mu)\" class=\"latex\" title=\"T = (T, \\eta, \\mu)\" />, find an adjunction <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> such that <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+GF&bg=ffffff&fg=333333&s=0\" alt=\"T = GF\" class=\"latex\" title=\"T = GF\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu+%3D+G+%5Cvarepsilon_F&bg=ffffff&fg=333333&s=0\" alt=\"\\mu = G \\varepsilon_F\" class=\"latex\" title=\"\\mu = G \\varepsilon_F\" /></em></p>
<p>If the adjunction <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> solves the problem above, we say that it <em>generates</em> the monad <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />.</p>
<p>The first solution to this problem was given by the Swiss mathematician Heinrich Kleisli, and is based on an alternative way of defining monads, as it is the case with adjunctions. <span id=\"more-885\"></span> Let us suppose <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+GF&bg=ffffff&fg=333333&s=0\" alt=\"T = GF\" class=\"latex\" title=\"T = GF\" /> with <img src=\"http://s0.wp.com/latex.php?latex=F+%5Cdashv+G&bg=ffffff&fg=333333&s=0\" alt=\"F \\dashv G\" class=\"latex\" title=\"F \\dashv G\" />. If <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+A+%5Cto+TB+%3D+G%28FB%29&bg=ffffff&fg=333333&s=0\" alt=\"f : A \\to TB = G(FB)\" class=\"latex\" title=\"f : A \\to TB = G(FB)\" />, then <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Csharp+%3A+FA+%5Cto+FB&bg=ffffff&fg=333333&s=0\" alt=\"f^\\sharp : FA \\to FB\" class=\"latex\" title=\"f^\\sharp : FA \\to FB\" />, so that <img src=\"http://s0.wp.com/latex.php?latex=Gf%5E%5Csharp+%3A+TA+%5Cto+TB&bg=ffffff&fg=333333&s=0\" alt=\"Gf^\\sharp : TA \\to TB\" class=\"latex\" title=\"Gf^\\sharp : TA \\to TB\" />: and we know from the definition of monad that <img src=\"http://s0.wp.com/latex.php?latex=Gf%5E%5Csharp+%5Ccirc+%5Ceta_A+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"Gf^\\sharp \\circ \\eta_A = f\" class=\"latex\" title=\"Gf^\\sharp \\circ \\eta_A = f\" />. We can thus define an operator <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ccdot%29%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"(\\cdot)^\\ast\" class=\"latex\" title=\"(\\cdot)^\\ast\" /> that takes <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D%28A%2CTB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}(A,TB)\" class=\"latex\" title=\"f \\in \\mathcal{C}(A,TB)\" /> into <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Cast+%3D+Gf%5E%5Csharp+%5Cin+%5Cmathcal%7BC%7D%28TA%2CTB%29&bg=ffffff&fg=333333&s=0\" alt=\"f^\\ast = Gf^\\sharp \\in \\mathcal{C}(TA,TB)\" class=\"latex\" title=\"f^\\ast = Gf^\\sharp \\in \\mathcal{C}(TA,TB)\" /> so that <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Cast+%5Ccirc+%5Ceta_A+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"f^\\ast \\circ \\eta_A = f\" class=\"latex\" title=\"f^\\ast \\circ \\eta_A = f\" /> whatever <img src=\"http://s0.wp.com/latex.php?latex=f&bg=ffffff&fg=333333&s=0\" alt=\"f\" class=\"latex\" title=\"f\" /> is. The simplest example is <img src=\"http://s0.wp.com/latex.php?latex=f+%3D+%5Ceta_A&bg=ffffff&fg=333333&s=0\" alt=\"f = \\eta_A\" class=\"latex\" title=\"f = \\eta_A\" /> itself, which yields <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ceta_A%29%5E%5Cast+%5Ccirc+%5Ceta_A+%3D+%5Ceta_A&bg=ffffff&fg=333333&s=0\" alt=\"(\\eta_A)^\\ast \\circ \\eta_A = \\eta_A\" class=\"latex\" title=\"(\\eta_A)^\\ast \\circ \\eta_A = \\eta_A\" />, so that <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ceta_A%29%5E%5Csharp+%3D+%5Cmathrm%7Bid%7D_%7BFA%7D&bg=ffffff&fg=333333&s=0\" alt=\"(\\eta_A)^\\sharp = \\mathrm{id}_{FA}\" class=\"latex\" title=\"(\\eta_A)^\\sharp = \\mathrm{id}_{FA}\" /> by uniqueness in the definition of adjunction quadruple, and <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ceta_A%29%5E%5Cast+%3D+%5Cmathrm%7Bid%7D_%7BTA%7D&bg=ffffff&fg=333333&s=0\" alt=\"(\\eta_A)^\\ast = \\mathrm{id}_{TA}\" class=\"latex\" title=\"(\\eta_A)^\\ast = \\mathrm{id}_{TA}\" />. Moreover, if <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+A+%5Cto+TB&bg=ffffff&fg=333333&s=0\" alt=\"f : A \\to TB\" class=\"latex\" title=\"f : A \\to TB\" /> and <img src=\"http://s0.wp.com/latex.php?latex=g+%3A+B+%5Cto+TC&bg=ffffff&fg=333333&s=0\" alt=\"g : B \\to TC\" class=\"latex\" title=\"g : B \\to TC\" />, then <img src=\"http://s0.wp.com/latex.php?latex=g%5E%5Cast+%5Ccirc+f+%3D+g%5E%5Cast+%5Ccirc+f%5E%5Cast+%5Ccirc+%5Ceta_A&bg=ffffff&fg=333333&s=0\" alt=\"g^\\ast \\circ f = g^\\ast \\circ f^\\ast \\circ \\eta_A\" class=\"latex\" title=\"g^\\ast \\circ f = g^\\ast \\circ f^\\ast \\circ \\eta_A\" />, which implies <img src=\"http://s0.wp.com/latex.php?latex=%28g%5E%5Cast+%5Ccirc+f%29%5E%5Cast+%3D+g%5E%5Cast+%5Ccirc+f%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"(g^\\ast \\circ f)^\\ast = g^\\ast \\circ f^\\ast\" class=\"latex\" title=\"(g^\\ast \\circ f)^\\ast = g^\\ast \\circ f^\\ast\" /> by uniqueness.</p>
<p><strong>Definition 4.</strong> A <em>Kleisli triple</em> on a category <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> is a triple <img src=\"http://s0.wp.com/latex.php?latex=%28T%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Cast%29&bg=ffffff&fg=333333&s=0\" alt=\"(T, \\eta, (\\cdot)^\\ast)\" class=\"latex\" title=\"(T, \\eta, (\\cdot)^\\ast)\" /> where:</p>
<ol>
<li><img src=\"http://s0.wp.com/latex.php?latex=T+%3A+%7C%5Cmathcal%7BC%7D%7C+%5Cto+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"T : |\\mathcal{C}| \\to |\\mathcal{C}|\" class=\"latex\" title=\"T : |\\mathcal{C}| \\to |\\mathcal{C}|\" /> is a function,</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%5Ceta_A+%5Cin+%5Cmathcal%7BC%7D%28A%2C+TA%29&bg=ffffff&fg=333333&s=0\" alt=\"\\eta_A \\in \\mathcal{C}(A, TA)\" class=\"latex\" title=\"\\eta_A \\in \\mathcal{C}(A, TA)\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=A+%5Cin+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"A \\in |\\mathcal{C}|\" class=\"latex\" title=\"A \\in |\\mathcal{C}|\" />, and</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Cast+%5Cin+%5Cmathcal%7BC%7D%28TA%2CTB%29&bg=ffffff&fg=333333&s=0\" alt=\"f^\\ast \\in \\mathcal{C}(TA,TB)\" class=\"latex\" title=\"f^\\ast \\in \\mathcal{C}(TA,TB)\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D%28A%2CTB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}(A,TB)\" class=\"latex\" title=\"f \\in \\mathcal{C}(A,TB)\" /></li>
</ol>
<p>such that the following equations are satisfied:</p>
<ol>
<li><img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Cast+%5Ccirc+%5Ceta_A+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"f^\\ast \\circ \\eta_A = f\" class=\"latex\" title=\"f^\\ast \\circ \\eta_A = f\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+A+%5Cto+TB&bg=ffffff&fg=333333&s=0\" alt=\"f : A \\to TB\" class=\"latex\" title=\"f : A \\to TB\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%28%5Ceta_A%29%5E%5Cast+%3D+%5Cmathrm%7Bid%7D_%7BTA%7D&bg=ffffff&fg=333333&s=0\" alt=\"(\\eta_A)^\\ast = \\mathrm{id}_{TA}\" class=\"latex\" title=\"(\\eta_A)^\\ast = \\mathrm{id}_{TA}\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=333333&s=0\" alt=\"A\" class=\"latex\" title=\"A\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%28g%5E%5Cast+%5Ccirc+f%29%5E%5Cast+%3D+g%5E%5Cast+%5Ccirc+f%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"(g^\\ast \\circ f)^\\ast = g^\\ast \\circ f^\\ast\" class=\"latex\" title=\"(g^\\ast \\circ f)^\\ast = g^\\ast \\circ f^\\ast\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+A+%5Cto+TB&bg=ffffff&fg=333333&s=0\" alt=\"f : A \\to TB\" class=\"latex\" title=\"f : A \\to TB\" />, <img src=\"http://s0.wp.com/latex.php?latex=g+%3A+B+%5Cto+TC&bg=ffffff&fg=333333&s=0\" alt=\"g : B \\to TC\" class=\"latex\" title=\"g : B \\to TC\" />.</li>
</ol>
<p>If <img src=\"http://s0.wp.com/latex.php?latex=%28F%2CG%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Csharp%29&bg=ffffff&fg=333333&s=0\" alt=\"(F,G, \\eta, (\\cdot)^\\sharp)\" class=\"latex\" title=\"(F,G, \\eta, (\\cdot)^\\sharp)\" /> is an adjunction quadruple then <img src=\"http://s0.wp.com/latex.php?latex=%28GF%2C+%5Ceta%2C+G%28%5Ccdot%29%5E%5Csharp%29&bg=ffffff&fg=333333&s=0\" alt=\"(GF, \\eta, G(\\cdot)^\\sharp)\" class=\"latex\" title=\"(GF, \\eta, G(\\cdot)^\\sharp)\" /> is a Kleisli triple.</p>
<p><strong>Theorem 1.</strong> Let <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> be a category.</p>
<ol>
<li>If <img src=\"http://s0.wp.com/latex.php?latex=%28T%2C+%5Ceta%2C+%5Cmu%29&bg=ffffff&fg=333333&s=0\" alt=\"(T, \\eta, \\mu)\" class=\"latex\" title=\"(T, \\eta, \\mu)\" /> is a monad on <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" />, and if <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Cast+%3D+%5Cmu_B+%5Ccirc+Tf&bg=ffffff&fg=333333&s=0\" alt=\"f^\\ast = \\mu_B \\circ Tf\" class=\"latex\" title=\"f^\\ast = \\mu_B \\circ Tf\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+A+%5Cto+TB&bg=ffffff&fg=333333&s=0\" alt=\"f : A \\to TB\" class=\"latex\" title=\"f : A \\to TB\" />, then <img src=\"http://s0.wp.com/latex.php?latex=%28T%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Cast%29&bg=ffffff&fg=333333&s=0\" alt=\"(T, \\eta, (\\cdot)^\\ast)\" class=\"latex\" title=\"(T, \\eta, (\\cdot)^\\ast)\" /> is a Kleisli triple on <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" />.</li>
<li>If <img src=\"http://s0.wp.com/latex.php?latex=%28T%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Cast%29&bg=ffffff&fg=333333&s=0\" alt=\"(T, \\eta, (\\cdot)^\\ast)\" class=\"latex\" title=\"(T, \\eta, (\\cdot)^\\ast)\" /> is a Kleisli triple on <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" />, and if <img src=\"http://s0.wp.com/latex.php?latex=Tf+%3D+%28%5Ceta_B+%5Ccirc+f%29%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"Tf = (\\eta_B \\circ f)^\\ast\" class=\"latex\" title=\"Tf = (\\eta_B \\circ f)^\\ast\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+A+%5Cto+B&bg=ffffff&fg=333333&s=0\" alt=\"f : A \\to B\" class=\"latex\" title=\"f : A \\to B\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%3D+%28%5Cmathrm%7Bid%7D_%7BTA%7D%29%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A = (\\mathrm{id}_{TA})^\\ast\" class=\"latex\" title=\"\\mu_A = (\\mathrm{id}_{TA})^\\ast\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=333333&s=0\" alt=\"A\" class=\"latex\" title=\"A\" />, then <img src=\"http://s0.wp.com/latex.php?latex=%28T%2C+%5Ceta%2C+%5Cmu%29&bg=ffffff&fg=333333&s=0\" alt=\"(T, \\eta, \\mu)\" class=\"latex\" title=\"(T, \\eta, \\mu)\" /> is a monad on <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" />.</li>
<li>The two operations from the previous points are each other’s converse.</li>
</ol>
<p><em>Proof:</em> Point 1 follows from naturality of <img src=\"http://s0.wp.com/latex.php?latex=%5Ceta&bg=ffffff&fg=333333&s=0\" alt=\"\\eta\" class=\"latex\" title=\"\\eta\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu&bg=ffffff&fg=333333&s=0\" alt=\"\\mu\" class=\"latex\" title=\"\\mu\" /> and the three monad laws:</p>
<ul>
<li><img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Cast+%5Ccirc+%5Ceta_A+%3D+%5Cmu_B+%5Ccirc+Tf+%5Ccirc+%5Ceta_A+%3D+%5Cmu_B+%5Ccirc+%5Ceta_%7BTB%7D+%5Ccirc+f+%3D+%5Cmathrm%7Bid%7D_%7BTB%7D+%5Ccirc+f+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"f^\\ast \\circ \\eta_A = \\mu_B \\circ Tf \\circ \\eta_A = \\mu_B \\circ \\eta_{TB} \\circ f = \\mathrm{id}_{TB} \\circ f = f\" class=\"latex\" title=\"f^\\ast \\circ \\eta_A = \\mu_B \\circ Tf \\circ \\eta_A = \\mu_B \\circ \\eta_{TB} \\circ f = \\mathrm{id}_{TB} \\circ f = f\" /></li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%28%5Ceta_A%29%5E%5Cast+%3D+%5Cmu_%7BTA%7D+%5Ccirc+%5Ceta_A+%3D+%5Cmathrm%7Bid%7D_%7BTA%7D&bg=ffffff&fg=333333&s=0\" alt=\"(\\eta_A)^\\ast = \\mu_{TA} \\circ \\eta_A = \\mathrm{id}_{TA}\" class=\"latex\" title=\"(\\eta_A)^\\ast = \\mu_{TA} \\circ \\eta_A = \\mathrm{id}_{TA}\" /></li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%28g%5E%5Cast+%5Ccirc+f%29%5E%5Cast+%3D+%5Cmu_C+%5Ccirc+T%5Cmu_C+%5Ccirc+T%5E2g+%5Ccirc+Tf+%3D+%5Cmu_C+%5Ccirc+%5Cmu_%7BTC%7D+%5Ccirc+T%5E2g+%5Ccirc+Tf+%3D+%5Cmu_C+%5Ccirc+Tg+%5Ccirc+%5Cmu_B+%5Ccirc+Tf+%3D+g%5E%5Cast+%5Ccirc+f%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"(g^\\ast \\circ f)^\\ast = \\mu_C \\circ T\\mu_C \\circ T^2g \\circ Tf = \\mu_C \\circ \\mu_{TC} \\circ T^2g \\circ Tf = \\mu_C \\circ Tg \\circ \\mu_B \\circ Tf = g^\\ast \\circ f^\\ast\" class=\"latex\" title=\"(g^\\ast \\circ f)^\\ast = \\mu_C \\circ T\\mu_C \\circ T^2g \\circ Tf = \\mu_C \\circ \\mu_{TC} \\circ T^2g \\circ Tf = \\mu_C \\circ Tg \\circ \\mu_B \\circ Tf = g^\\ast \\circ f^\\ast\" /></li>
</ul>
<p>For point 2, functoriality of <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />, naturality of <img src=\"http://s0.wp.com/latex.php?latex=%5Ceta&bg=ffffff&fg=333333&s=0\" alt=\"\\eta\" class=\"latex\" title=\"\\eta\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu&bg=ffffff&fg=333333&s=0\" alt=\"\\mu\" class=\"latex\" title=\"\\mu\" />, and monad laws follow from Kleisli laws:</p>
<ul>
<li><img src=\"http://s0.wp.com/latex.php?latex=T%28g+%5Ccirc+f%29+%3D+%28%5Ceta_C+%5Ccirc+g+%5Ccirc+f%29%5E%5Cast+%3D+%28%28%5Ceta_C+%5Ccirc+g%29%5E%5Cast+%5Ccirc+%5Ceta_B+%5Ccirc+f%29%5E%5Cast+%3D+%28%5Ceta_C+%5Ccirc+g%29%5E%5Cast+%5Ccirc+%28%5Ceta_B+%5Ccirc+f%29%5E%5Cast+Tg+%5Ccirc+Tf&bg=ffffff&fg=333333&s=0\" alt=\"T(g \\circ f) = (\\eta_C \\circ g \\circ f)^\\ast = ((\\eta_C \\circ g)^\\ast \\circ \\eta_B \\circ f)^\\ast = (\\eta_C \\circ g)^\\ast \\circ (\\eta_B \\circ f)^\\ast Tg \\circ Tf\" class=\"latex\" title=\"T(g \\circ f) = (\\eta_C \\circ g \\circ f)^\\ast = ((\\eta_C \\circ g)^\\ast \\circ \\eta_B \\circ f)^\\ast = (\\eta_C \\circ g)^\\ast \\circ (\\eta_B \\circ f)^\\ast Tg \\circ Tf\" /></li>
<li><img src=\"http://s0.wp.com/latex.php?latex=T%5Cmathrm%7Bid%7D_A+%3D+%28%5Ceta_A%29%5E%5Cast+%3D+%5Cmathrm%7Bid%7D_%7BTA%7D&bg=ffffff&fg=333333&s=0\" alt=\"T\\mathrm{id}_A = (\\eta_A)^\\ast = \\mathrm{id}_{TA}\" class=\"latex\" title=\"T\\mathrm{id}_A = (\\eta_A)^\\ast = \\mathrm{id}_{TA}\" /></li>
<li><img src=\"http://s0.wp.com/latex.php?latex=Tf+%5Ccirc+%5Ceta_A+%3D+%28%5Ceta_B+%5Ccirc+f%29%5E%5Cast+%5Ccirc+%5Ceta_A+%3D+%5Ceta_B+%5Ccirc+f&bg=ffffff&fg=333333&s=0\" alt=\"Tf \\circ \\eta_A = (\\eta_B \\circ f)^\\ast \\circ \\eta_A = \\eta_B \\circ f\" class=\"latex\" title=\"Tf \\circ \\eta_A = (\\eta_B \\circ f)^\\ast \\circ \\eta_A = \\eta_B \\circ f\" /></li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_B+%5Ccirc+T%5E2f+%3D+%28%5Cmathrm%7Bid%7D_%7BTB%7D%5E%5Cast+%5Ccirc+%5Ceta_%7BTB%7D+%5Ccirc+%28%5Ceta_B+%5Ccirc+f%29%5E%5Cast%29%5E%5Cast+%3D+%28%5Ceta_B+%5Ccirc+Tf%29%5E%7B%5Cast%5Cast%7D+%3D+%28%28%5Ceta_B+%5Ccirc+f%29%5E%5Cast+%5Ccirc+%5Cmathrm%7Bid%7D_%7BTA%7D%29%5E%5Cast+%3D+Tf+%5Ccirc+%5Cmu_A&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_B \\circ T^2f = (\\mathrm{id}_{TB}^\\ast \\circ \\eta_{TB} \\circ (\\eta_B \\circ f)^\\ast)^\\ast = (\\eta_B \\circ Tf)^{\\ast\\ast} = ((\\eta_B \\circ f)^\\ast \\circ \\mathrm{id}_{TA})^\\ast = Tf \\circ \\mu_A\" class=\"latex\" title=\"\\mu_B \\circ T^2f = (\\mathrm{id}_{TB}^\\ast \\circ \\eta_{TB} \\circ (\\eta_B \\circ f)^\\ast)^\\ast = (\\eta_B \\circ Tf)^{\\ast\\ast} = ((\\eta_B \\circ f)^\\ast \\circ \\mathrm{id}_{TA})^\\ast = Tf \\circ \\mu_A\" /></li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%5Ccirc+%5Ceta_%7BTA%7D+%3D+%28%5Cmathrm%7Bid%7D_%7BTA%7D%29%5E%5Cast+%5Ccirc+%5Ceta_%7BTA%7D+%3D+%5Cmathrm%7Bid%7D_%7BTA%7D+%3D+%28%5Cmathrm%7Bid%7D_%7BTA%7D+%5Ccirc+%5Ceta_A%29%5E%5Cast+%3D+%28%28%5Cmathrm%7Bid%7D_%7BTA%7D%29%5E%5Cast+%5Ccirc+%5Ceta_%7BTA%7D+%5Ccirc+%5Ceta_A%29%5E%5Cast+%3D+%5Cmu_A+%5Ccirc+T%5Ceta_A&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A \\circ \\eta_{TA} = (\\mathrm{id}_{TA})^\\ast \\circ \\eta_{TA} = \\mathrm{id}_{TA} = (\\mathrm{id}_{TA} \\circ \\eta_A)^\\ast = ((\\mathrm{id}_{TA})^\\ast \\circ \\eta_{TA} \\circ \\eta_A)^\\ast = \\mu_A \\circ T\\eta_A\" class=\"latex\" title=\"\\mu_A \\circ \\eta_{TA} = (\\mathrm{id}_{TA})^\\ast \\circ \\eta_{TA} = \\mathrm{id}_{TA} = (\\mathrm{id}_{TA} \\circ \\eta_A)^\\ast = ((\\mathrm{id}_{TA})^\\ast \\circ \\eta_{TA} \\circ \\eta_A)^\\ast = \\mu_A \\circ T\\eta_A\" /></li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%5Ccirc+%5Cmu_%7BTA%7D+%3D+%28%5Cmathrm%7Bid%7D_%7BTA%7D%5E%5Cast+%5Ccirc+%5Cmathrm%7Bid%7D_%7BT%5E2A%7D%29%5E%5Cast+%3D+%28%5Cmathrm%7Bid%7D_A+%5Ccirc+%5Cmathrm%7Bid%7D_%7BTA%7D%5E%5Cast%29%5E%5Cast+%3D+%28%5Cmathrm%7Bid%7D_%7BTA%7D%5E%5Cast+%5Ccirc+%5Ceta_%7BTA%7D+%5Ccirc+%5Cmathrm%7Bid%7D_%7BTA%7D%5E%5Cast%29%5E%5Cast+%3D+%5Cmu_A+%5Ccirc+T%5Cmu_A&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A \\circ \\mu_{TA} = (\\mathrm{id}_{TA}^\\ast \\circ \\mathrm{id}_{T^2A})^\\ast = (\\mathrm{id}_A \\circ \\mathrm{id}_{TA}^\\ast)^\\ast = (\\mathrm{id}_{TA}^\\ast \\circ \\eta_{TA} \\circ \\mathrm{id}_{TA}^\\ast)^\\ast = \\mu_A \\circ T\\mu_A\" class=\"latex\" title=\"\\mu_A \\circ \\mu_{TA} = (\\mathrm{id}_{TA}^\\ast \\circ \\mathrm{id}_{T^2A})^\\ast = (\\mathrm{id}_A \\circ \\mathrm{id}_{TA}^\\ast)^\\ast = (\\mathrm{id}_{TA}^\\ast \\circ \\eta_{TA} \\circ \\mathrm{id}_{TA}^\\ast)^\\ast = \\mu_A \\circ T\\mu_A\" /></li>
</ul>
<p>Point 3 is straightforward. <img src=\"http://s0.wp.com/latex.php?latex=%5CBox&bg=ffffff&fg=333333&s=0\" alt=\"\\Box\" class=\"latex\" title=\"\\Box\" /></p>
<p>Considering again the free monoid example, the corresponding Kleisli triple has</p>
<p style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Cast%28s%29+%3D+%5B+x+%5C%3B+%5Cmathtt%7Bfor%7D+%5C%3B+x+%5C%3B+%5Cmathtt%7Bin%7D+%5C%3B+f%28a%29+%5C%3B+%5Cmathtt%7Bfor%7D+%5C%3B+a+%5C%3B+%5Cmathtt%7Bin%7D+%5C%3B+s+%5D&bg=ffffff&fg=333333&s=0\" alt=\"f^\\ast(s) = [ x \\; \\mathtt{for} \\; x \\; \\mathtt{in} \\; f(a) \\; \\mathtt{for} \\; a \\; \\mathtt{in} \\; s ]\" class=\"latex\" title=\"f^\\ast(s) = [ x \\; \\mathtt{for} \\; x \\; \\mathtt{in} \\; f(a) \\; \\mathtt{for} \\; a \\; \\mathtt{in} \\; s ]\" /></p>
<p>Theorem 1 says that we can restate our problem as follows:</p>
<p style=\"text-align: center;\"><em>given a Kleisli triple <img src=\"http://s0.wp.com/latex.php?latex=%28T%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Cast%29&bg=ffffff&fg=333333&s=0\" alt=\"(T, \\eta, (\\cdot)^\\ast)\" class=\"latex\" title=\"(T, \\eta, (\\cdot)^\\ast)\" />,</em><em> find an adjunction quadruple <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Csharp%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, (\\cdot)^\\sharp)\" class=\"latex\" title=\"(F, G, \\eta, (\\cdot)^\\sharp)\" /> such that <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+GF&bg=ffffff&fg=333333&s=0\" alt=\"T = GF\" class=\"latex\" title=\"T = GF\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%28%5Ccdot%29%5E%5Cast+%3D+G%28%28%5Ccdot%29%5E%5Csharp%29&bg=ffffff&fg=333333&s=0\" alt=\"(\\cdot)^\\ast = G((\\cdot)^\\sharp)\" class=\"latex\" title=\"(\\cdot)^\\ast = G((\\cdot)^\\sharp)\" /></em></p>
<p>If <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+GF&bg=ffffff&fg=333333&s=0\" alt=\"T = GF\" class=\"latex\" title=\"T = GF\" /> with <img src=\"http://s0.wp.com/latex.php?latex=F+%5Cdashv+G&bg=ffffff&fg=333333&s=0\" alt=\"F \\dashv G\" class=\"latex\" title=\"F \\dashv G\" />, then for every <img src=\"http://s0.wp.com/latex.php?latex=A%2CB+%5Cin+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"A,B \\in |\\mathcal{C}|\" class=\"latex\" title=\"A,B \\in |\\mathcal{C}|\" /> there is an isomorphism <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D%28FA%2CFB%29+%5Ccong+%5Cmathcal%7BC%7D%28A%2CTB%29&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{D}(FA,FB) \\cong \\mathcal{C}(A,TB)\" class=\"latex\" title=\"\\mathcal{D}(FA,FB) \\cong \\mathcal{C}(A,TB)\" />: this observation is at the base of Kleisli’s construction.</p>
<p><strong>Definition 5.</strong> Let <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+%28T%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Cast%29&bg=ffffff&fg=333333&s=0\" alt=\"T = (T, \\eta, (\\cdot)^\\ast)\" class=\"latex\" title=\"T = (T, \\eta, (\\cdot)^\\ast)\" /> be a Kleisli triple on a category <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" />. The <em>Kleisli category </em>of <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" /> is the category <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D_T&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}_T\" class=\"latex\" title=\"\\mathcal{C}_T\" /> defined as follows:</p>
<ul>
<li><img src=\"http://s0.wp.com/latex.php?latex=%7C%5Cmathcal%7BC%7D_T%7C+%3D+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"|\\mathcal{C}_T| = |\\mathcal{C}|\" class=\"latex\" title=\"|\\mathcal{C}_T| = |\\mathcal{C}|\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D_T%28A%2CB%29+%3D+%5Cmathcal%7BC%7D%28A%2CTB%29&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}_T(A,B) = \\mathcal{C}(A,TB)\" class=\"latex\" title=\"\\mathcal{C}_T(A,B) = \\mathcal{C}(A,TB)\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%5Cmathrm%7Bid%7D_%7BA%7D%5E%7B%5Cmathcal%7BC%7D_T%7D+%3D+%5Ceta_A&bg=ffffff&fg=333333&s=0\" alt=\"\\mathrm{id}_{A}^{\\mathcal{C}_T} = \\eta_A\" class=\"latex\" title=\"\\mathrm{id}_{A}^{\\mathcal{C}_T} = \\eta_A\" />, that is, the identity of <img src=\"http://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=333333&s=0\" alt=\"A\" class=\"latex\" title=\"A\" /> in <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D_T&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}_T\" class=\"latex\" title=\"\\mathcal{C}_T\" /> is <img src=\"http://s0.wp.com/latex.php?latex=%5Ceta_A&bg=ffffff&fg=333333&s=0\" alt=\"\\eta_A\" class=\"latex\" title=\"\\eta_A\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=g+%5Cbullet+f+%3D+g%5E%5Cast+%5Ccirc+f&bg=ffffff&fg=333333&s=0\" alt=\"g \\bullet f = g^\\ast \\circ f\" class=\"latex\" title=\"g \\bullet f = g^\\ast \\circ f\" />, that is, the composition of <img src=\"http://s0.wp.com/latex.php?latex=f&bg=ffffff&fg=333333&s=0\" alt=\"f\" class=\"latex\" title=\"f\" /> and <img src=\"http://s0.wp.com/latex.php?latex=g&bg=ffffff&fg=333333&s=0\" alt=\"g\" class=\"latex\" title=\"g\" /> in <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D_T&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}_T\" class=\"latex\" title=\"\\mathcal{C}_T\" /> is the composition of <img src=\"http://s0.wp.com/latex.php?latex=f&bg=ffffff&fg=333333&s=0\" alt=\"f\" class=\"latex\" title=\"f\" /> and <img src=\"http://s0.wp.com/latex.php?latex=g%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"g^\\ast\" class=\"latex\" title=\"g^\\ast\" /> in <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" />.</li>
</ul>
<p><strong>Theorem 2.</strong> <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D_T&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}_T\" class=\"latex\" title=\"\\mathcal{C}_T\" /> is a category.</p>
<p><em>Proof:</em> If <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D_T%28A%2CB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}_T(A,B)\" class=\"latex\" title=\"f \\in \\mathcal{C}_T(A,B)\" />, then <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cbullet+%5Cmathrm%7Bid%7D_%7BA%7D%5E%7B%5Cmathcal%7BC%7D_T%7D+%3D+f%5E%5Cast+%5Ccirc+%5Ceta_A+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"f \\bullet \\mathrm{id}_{A}^{\\mathcal{C}_T} = f^\\ast \\circ \\eta_A = f\" class=\"latex\" title=\"f \\bullet \\mathrm{id}_{A}^{\\mathcal{C}_T} = f^\\ast \\circ \\eta_A = f\" /> and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathrm%7Bid%7D_%7BB%7D%5E%7B%5Cmathcal%7BC%7D_T%7D+%5Cbullet+f+%3D+%28%5Ceta_B%29%5E%5Cast+%5Ccirc+f+%3D+%5Cmathrm%7Bid%7D_%7BTB%7D+%5Ccirc+f+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"\\mathrm{id}_{B}^{\\mathcal{C}_T} \\bullet f = (\\eta_B)^\\ast \\circ f = \\mathrm{id}_{TB} \\circ f = f\" class=\"latex\" title=\"\\mathrm{id}_{B}^{\\mathcal{C}_T} \\bullet f = (\\eta_B)^\\ast \\circ f = \\mathrm{id}_{TB} \\circ f = f\" /> by the Kleisli laws. If <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D_T%28A%2CB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}_T(A,B)\" class=\"latex\" title=\"f \\in \\mathcal{C}_T(A,B)\" />, <img src=\"http://s0.wp.com/latex.php?latex=g+%5Cin+%5Cmathcal%7BC%7D_T%28B%2CC%29&bg=ffffff&fg=333333&s=0\" alt=\"g \\in \\mathcal{C}_T(B,C)\" class=\"latex\" title=\"g \\in \\mathcal{C}_T(B,C)\" />, and <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D_T%28C%2CD%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}_T(C,D)\" class=\"latex\" title=\"f \\in \\mathcal{C}_T(C,D)\" />, then <img src=\"http://s0.wp.com/latex.php?latex=%28h+%5Cbullet+g%29+%5Cbullet+f+%3D+%28h%5E%5Cast+%5Ccirc+g%29%5E%5Cast+%5Ccirc+f+%3D+h%5E%5Cast+%5Ccirc+g%5E%5Cast+%5Ccirc+f+%3D+h+%5Cbullet+%28g+%5Cbullet+f%29.&bg=ffffff&fg=333333&s=0\" alt=\"(h \\bullet g) \\bullet f = (h^\\ast \\circ g)^\\ast \\circ f = h^\\ast \\circ g^\\ast \\circ f = h \\bullet (g \\bullet f).\" class=\"latex\" title=\"(h \\bullet g) \\bullet f = (h^\\ast \\circ g)^\\ast \\circ f = h^\\ast \\circ g^\\ast \\circ f = h \\bullet (g \\bullet f).\" /> <img src=\"http://s0.wp.com/latex.php?latex=%5CBox&bg=ffffff&fg=333333&s=0\" alt=\"\\Box\" class=\"latex\" title=\"\\Box\" /></p>
<p>Our plan is to construct an adjunction quadruple <img src=\"http://s0.wp.com/latex.php?latex=%28F_T%2C+G_T%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Csharp%29&bg=ffffff&fg=333333&s=0\" alt=\"(F_T, G_T, \\eta, (\\cdot)^\\sharp)\" class=\"latex\" title=\"(F_T, G_T, \\eta, (\\cdot)^\\sharp)\" />, with <img src=\"http://s0.wp.com/latex.php?latex=F_T+%3A+%5Cmathcal%7BC%7D+%5Cto+%5Cmathcal%7BC%7D_T&bg=ffffff&fg=333333&s=0\" alt=\"F_T : \\mathcal{C} \\to \\mathcal{C}_T\" class=\"latex\" title=\"F_T : \\mathcal{C} \\to \\mathcal{C}_T\" /> and <img src=\"http://s0.wp.com/latex.php?latex=G_T+%3A+%5Cmathcal%7BC%7D_T+%5Cto+%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"G_T : \\mathcal{C}_T \\to \\mathcal{C}\" class=\"latex\" title=\"G_T : \\mathcal{C}_T \\to \\mathcal{C}\" />, such that <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+G_T+F_T&bg=ffffff&fg=333333&s=0\" alt=\"T = G_T F_T\" class=\"latex\" title=\"T = G_T F_T\" /> and <img src=\"http://s0.wp.com/latex.php?latex=G_T+f%5E%5Csharp+%3D+f%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"G_T f^\\sharp = f^\\ast\" class=\"latex\" title=\"G_T f^\\sharp = f^\\ast\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D_T%28A%2CB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}_T(A,B)\" class=\"latex\" title=\"f \\in \\mathcal{C}_T(A,B)\" />. We do this as follows:</p>
<ul>
<li><img src=\"http://s0.wp.com/latex.php?latex=F_T+A+%3D+A&bg=ffffff&fg=333333&s=0\" alt=\"F_T A = A\" class=\"latex\" title=\"F_T A = A\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=A+%5Cin+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"A \\in |\\mathcal{C}|\" class=\"latex\" title=\"A \\in |\\mathcal{C}|\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=G_T+A+%3D+TA&bg=ffffff&fg=333333&s=0\" alt=\"G_T A = TA\" class=\"latex\" title=\"G_T A = TA\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=A+%5Cin+%7C%5Cmathcal%7BC%7D_T%7C&bg=ffffff&fg=333333&s=0\" alt=\"A \\in |\\mathcal{C}_T|\" class=\"latex\" title=\"A \\in |\\mathcal{C}_T|\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=G_T+f+%3D+f%5E%5Cast&bg=ffffff&fg=333333&s=0\" alt=\"G_T f = f^\\ast\" class=\"latex\" title=\"G_T f = f^\\ast\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D_T%28A%2CB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}_T(A,B)\" class=\"latex\" title=\"f \\in \\mathcal{C}_T(A,B)\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Csharp+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"f^\\sharp = f\" class=\"latex\" title=\"f^\\sharp = f\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D%28A%2C+G_T+B%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}(A, G_T B)\" class=\"latex\" title=\"f \\in \\mathcal{C}(A, G_T B)\" />.</li>
</ul>
<p>Let us quickly check that <img src=\"http://s0.wp.com/latex.php?latex=G_T&bg=ffffff&fg=333333&s=0\" alt=\"G_T\" class=\"latex\" title=\"G_T\" /> is indeed a functor.<em></em> If <img src=\"http://s0.wp.com/latex.php?latex=A+%5Cin+%7C%5Cmathcal%7BC%7D_T%7C&bg=ffffff&fg=333333&s=0\" alt=\"A \\in |\\mathcal{C}_T|\" class=\"latex\" title=\"A \\in |\\mathcal{C}_T|\" /> then <img src=\"http://s0.wp.com/latex.php?latex=G_T+%5Cmathrm%7Bid%7D_%7BA%7D%5E%7B%5Cmathcal%7BC%7D_T%7D+%3D+%28%5Ceta_A%29%5E%5Cast+%3D+%5Cmathrm%7Bid%7D_%7BTA%7D+%3D+%5Cmathrm%7Bid%7D_%7BG_T+A%7D&bg=ffffff&fg=333333&s=0\" alt=\"G_T \\mathrm{id}_{A}^{\\mathcal{C}_T} = (\\eta_A)^\\ast = \\mathrm{id}_{TA} = \\mathrm{id}_{G_T A}\" class=\"latex\" title=\"G_T \\mathrm{id}_{A}^{\\mathcal{C}_T} = (\\eta_A)^\\ast = \\mathrm{id}_{TA} = \\mathrm{id}_{G_T A}\" />. If <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D_T%28A%2CB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}_T(A,B)\" class=\"latex\" title=\"f \\in \\mathcal{C}_T(A,B)\" /> and <img src=\"http://s0.wp.com/latex.php?latex=g+%5Cin+%5Cmathcal%7BC%7D_T%28B%2CC%29&bg=ffffff&fg=333333&s=0\" alt=\"g \\in \\mathcal{C}_T(B,C)\" class=\"latex\" title=\"g \\in \\mathcal{C}_T(B,C)\" />, then <img src=\"http://s0.wp.com/latex.php?latex=G_T%28g+%5Cbullet+f%29+%3D+%28g%5E%5Cast+%5Ccirc+f%29%5E%5Cast+%3D+g%5E%5Cast+%5Ccirc+f%5E%5Cast+%3D+G_Tg+%5Ccirc+G_Tf&bg=ffffff&fg=333333&s=0\" alt=\"G_T(g \\bullet f) = (g^\\ast \\circ f)^\\ast = g^\\ast \\circ f^\\ast = G_Tg \\circ G_Tf\" class=\"latex\" title=\"G_T(g \\bullet f) = (g^\\ast \\circ f)^\\ast = g^\\ast \\circ f^\\ast = G_Tg \\circ G_Tf\" />. We are only left to determine, for every <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D%28A%2C+G_T+B%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}(A, G_T B)\" class=\"latex\" title=\"f \\in \\mathcal{C}(A, G_T B)\" />, a unique <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Csharp+%5Cin+%5Cmathcal%7BC%7D_T%28F_T+A%2C+B%29&bg=ffffff&fg=333333&s=0\" alt=\"f^\\sharp \\in \\mathcal{C}_T(F_T A, B)\" class=\"latex\" title=\"f^\\sharp \\in \\mathcal{C}_T(F_T A, B)\" /> such that <img src=\"http://s0.wp.com/latex.php?latex=G_T+f%5E%5Csharp+%5Ccirc+%5Ceta_A+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"G_T f^\\sharp \\circ \\eta_A = f\" class=\"latex\" title=\"G_T f^\\sharp \\circ \\eta_A = f\" />: but the entire construction leads to the choice <img src=\"http://s0.wp.com/latex.php?latex=f%5E%5Csharp+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"f^\\sharp = f\" class=\"latex\" title=\"f^\\sharp = f\" />! Indeed, <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D_T%28F_T+A%2C+B%29+%3D+%5Cmathcal%7BC%7D_T%28A%2CB%29+%3D+%5Cmathcal%7BC%7D%28A%2CTB%29+%3D+%5Cmathcal%7BC%7D%28A%2C+G_T+B%29&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}_T(F_T A, B) = \\mathcal{C}_T(A,B) = \\mathcal{C}(A,TB) = \\mathcal{C}(A, G_T B)\" class=\"latex\" title=\"\\mathcal{C}_T(F_T A, B) = \\mathcal{C}_T(A,B) = \\mathcal{C}(A,TB) = \\mathcal{C}(A, G_T B)\" />, and <img src=\"http://s0.wp.com/latex.php?latex=G_Tf+%5Ccirc+%5Ceta_A+%3D+f%5E%5Cast+%5Ccirc+%5Ceta_A+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"G_Tf \\circ \\eta_A = f^\\ast \\circ \\eta_A = f\" class=\"latex\" title=\"G_Tf \\circ \\eta_A = f^\\ast \\circ \\eta_A = f\" /> by the Kleisli laws. Observe that the functor <img src=\"http://s0.wp.com/latex.php?latex=G_T&bg=ffffff&fg=333333&s=0\" alt=\"G_T\" class=\"latex\" title=\"G_T\" /> is the one that does all the work, while the function <img src=\"http://s0.wp.com/latex.php?latex=F_T&bg=ffffff&fg=333333&s=0\" alt=\"F_T\" class=\"latex\" title=\"F_T\" /> is little more than a placeholder.</p>
<p>By our identification of adjunctions with adjunction quadruples (see the previous talk) we also get <img src=\"http://s0.wp.com/latex.php?latex=F_T+f+%3D+%28%5Ceta_B+%5Ccirc+f%29%5E%5Csharp+%3D+%5Ceta_B+%5Ccirc+f&bg=ffffff&fg=333333&s=0\" alt=\"F_T f = (\\eta_B \\circ f)^\\sharp = \\eta_B \\circ f\" class=\"latex\" title=\"F_T f = (\\eta_B \\circ f)^\\sharp = \\eta_B \\circ f\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D%28A%2CB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}(A,B)\" class=\"latex\" title=\"f \\in \\mathcal{C}(A,B)\" />, and <img src=\"http://s0.wp.com/latex.php?latex=%28%5Cvarepsilon_T%29_S+%3D+%28%5Cmathrm%7Bid%7D_%7BG_T+S%7D%5E%7B%5Cmathcal%7BC%7D%7D%29%5E%5Csharp+%3D+%5Cmathrm%7Bid%7D_%7BTS%7D+%5Cin+%5Cmathcal%7BC%7D%28G_TF_TS%2C+TS%29+%3D+%5Cmathcal%7BC%7D_T%28F_TG_TS%2C+S%29&bg=ffffff&fg=333333&s=0\" alt=\"(\\varepsilon_T)_S = (\\mathrm{id}_{G_T S}^{\\mathcal{C}})^\\sharp = \\mathrm{id}_{TS} \\in \\mathcal{C}(G_TF_TS, TS) = \\mathcal{C}_T(F_TG_TS, S)\" class=\"latex\" title=\"(\\varepsilon_T)_S = (\\mathrm{id}_{G_T S}^{\\mathcal{C}})^\\sharp = \\mathrm{id}_{TS} \\in \\mathcal{C}(G_TF_TS, TS) = \\mathcal{C}_T(F_TG_TS, S)\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=S+%5Cin+%7C%5Cmathcal%7BC%7D_T%7C+%3D+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"S \\in |\\mathcal{C}_T| = |\\mathcal{C}|\" class=\"latex\" title=\"S \\in |\\mathcal{C}_T| = |\\mathcal{C}|\" />.</p>
<p>Kleisli’s solution is not the only one, but just one among many: and, in a sense that will be clear later, the “simplest” one. Another solution was constructed by Eilenberg and Moore, and is based on a completely different approach: instead of keeping the objects and specializing the morphisms, one expands the objects and redefines the morphisms.</p>
<p><strong>Definition 6.</strong> Let <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> be a category and let <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+%28T%2C+%5Ceta%2C+%5Cmu%29&bg=ffffff&fg=333333&s=0\" alt=\"T = (T, \\eta, \\mu)\" class=\"latex\" title=\"T = (T, \\eta, \\mu)\" /> be a monad on <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" />.</p>
<ol>
<li>A <em><img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebra</em> on <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> is a pair <img src=\"http://s0.wp.com/latex.php?latex=a+%3D+%28A%2Ca%29&bg=ffffff&fg=333333&s=0\" alt=\"a = (A,a)\" class=\"latex\" title=\"a = (A,a)\" /> where <img src=\"http://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=333333&s=0\" alt=\"A\" class=\"latex\" title=\"A\" /> is an object in <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> and <img src=\"http://s0.wp.com/latex.php?latex=a+%3A+TA+%5Cto+A&bg=ffffff&fg=333333&s=0\" alt=\"a : TA \\to A\" class=\"latex\" title=\"a : TA \\to A\" /> is such that <img src=\"http://s0.wp.com/latex.php?latex=a+%5Ccirc+%5Ceta_A+%3D+%5Cmathrm%7Bid%7D_A&bg=ffffff&fg=333333&s=0\" alt=\"a \\circ \\eta_A = \\mathrm{id}_A\" class=\"latex\" title=\"a \\circ \\eta_A = \\mathrm{id}_A\" /> and <img src=\"http://s0.wp.com/latex.php?latex=a+%5Ccirc+%5Cmu_A+%3D+a+%5Ccirc+Ta&bg=ffffff&fg=333333&s=0\" alt=\"a \\circ \\mu_A = a \\circ Ta\" class=\"latex\" title=\"a \\circ \\mu_A = a \\circ Ta\" />.</li>
<li>A morphism of <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebras from a <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebra <img src=\"http://s0.wp.com/latex.php?latex=a+%3D+%28A%2Ca%29&bg=ffffff&fg=333333&s=0\" alt=\"a = (A,a)\" class=\"latex\" title=\"a = (A,a)\" /> to a <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebra <img src=\"http://s0.wp.com/latex.php?latex=b+%3D+%28B%2Cb%29&bg=ffffff&fg=333333&s=0\" alt=\"b = (B,b)\" class=\"latex\" title=\"b = (B,b)\" /> is an arrow <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D%28A%2CB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}(A,B)\" class=\"latex\" title=\"f \\in \\mathcal{C}(A,B)\" /> such that <img src=\"http://s0.wp.com/latex.php?latex=b+%5Ccirc+Tf+%3D+f+%5Ccirc+a&bg=ffffff&fg=333333&s=0\" alt=\"b \\circ Tf = f \\circ a\" class=\"latex\" title=\"b \\circ Tf = f \\circ a\" />.</li>
<li>The category of <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebras on <img src=\"http://s0.wp.com/latex.php?latex=C&bg=ffffff&fg=333333&s=0\" alt=\"C\" class=\"latex\" title=\"C\" /> is the category <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D%5ET&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}^T\" class=\"latex\" title=\"\\mathcal{C}^T\" /> which has <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebras as objects, morphisms of <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebras as morphisms, and where identities and composition are defined as in <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" />.</li>
</ol>
<p>If <img src=\"http://s0.wp.com/latex.php?latex=T%3DM&bg=ffffff&fg=333333&s=0\" alt=\"T=M\" class=\"latex\" title=\"T=M\" /> is the free monoid construction, then an <img src=\"http://s0.wp.com/latex.php?latex=M&bg=ffffff&fg=333333&s=0\" alt=\"M\" class=\"latex\" title=\"M\" />-algebra is a function <img src=\"http://s0.wp.com/latex.php?latex=a+%3A+A%5E%5Cast+%5Cto+A&bg=ffffff&fg=333333&s=0\" alt=\"a : A^\\ast \\to A\" class=\"latex\" title=\"a : A^\\ast \\to A\" /> such that</p>
<ul>
<li><img src=\"http://s0.wp.com/latex.php?latex=a%5Bx%5D+%3D+x&bg=ffffff&fg=333333&s=0\" alt=\"a[x] = x\" class=\"latex\" title=\"a[x] = x\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=x+%5Cin+A&bg=ffffff&fg=333333&s=0\" alt=\"x \\in A\" class=\"latex\" title=\"x \\in A\" />, and</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=a%5Bu%5E1_1+%5Ccdots+u%5E1_%7Bn_1%7D+%5Ccdots+u%5Em_1+%5Ccdots+u%5Em_%7Bn_m%7D%5D+%3D+a%5Ba%5Bu%5E1_1+%5Ccdots+u%5E1_%7Bn_1%7D%5D+%5Ccdots+a%5Bu%5Em_1+%5Ccdots+u%5Em_%7Bn_m%7D%5D%5D&bg=ffffff&fg=333333&s=0\" alt=\"a[u^1_1 \\cdots u^1_{n_1} \\cdots u^m_1 \\cdots u^m_{n_m}] = a[a[u^1_1 \\cdots u^1_{n_1}] \\cdots a[u^m_1 \\cdots u^m_{n_m}]]\" class=\"latex\" title=\"a[u^1_1 \\cdots u^1_{n_1} \\cdots u^m_1 \\cdots u^m_{n_m}] = a[a[u^1_1 \\cdots u^1_{n_1}] \\cdots a[u^m_1 \\cdots u^m_{n_m}]]\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=u%5E1_1%2C+%5Cldots%2C+u%5E1_%7Bn_1%7D%2C+%5Cldots%2C+u%5Em_1%2C+%5Cldots%2C+u%5Em_%7Bn_m%7D+%5Cin+A&bg=ffffff&fg=333333&s=0\" alt=\"u^1_1, \\ldots, u^1_{n_1}, \\ldots, u^m_1, \\ldots, u^m_{n_m} \\in A\" class=\"latex\" title=\"u^1_1, \\ldots, u^1_{n_1}, \\ldots, u^m_1, \\ldots, u^m_{n_m} \\in A\" />.</li>
</ul>
<p>As <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" /> is a monad, for every object <img src=\"http://s0.wp.com/latex.php?latex=A&bg=ffffff&fg=333333&s=0\" alt=\"A\" class=\"latex\" title=\"A\" /> of <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> there is a <em>free <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebra</em> <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%3D+%28TA%2C+%5Cmu_A%29&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A = (TA, \\mu_A)\" class=\"latex\" title=\"\\mu_A = (TA, \\mu_A)\" />, and every arrow <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D%28A%2CB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}(A,B)\" class=\"latex\" title=\"f \\in \\mathcal{C}(A,B)\" /> induces a morphism of free <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebras <img src=\"http://s0.wp.com/latex.php?latex=Tf+%5Cin+%5Cmathcal%7BC%7D%5ET%28%5Cmu_A%2C+%5Cmu_B%29&bg=ffffff&fg=333333&s=0\" alt=\"Tf \\in \\mathcal{C}^T(\\mu_A, \\mu_B)\" class=\"latex\" title=\"Tf \\in \\mathcal{C}^T(\\mu_A, \\mu_B)\" />. Moreover, <em>any</em> <img src=\"http://s0.wp.com/latex.php?latex=a+%5Cin+%5Cmathcal%7BC%7D%28TA%2CA%29&bg=ffffff&fg=333333&s=0\" alt=\"a \\in \\mathcal{C}(TA,A)\" class=\"latex\" title=\"a \\in \\mathcal{C}(TA,A)\" /><em></em> is, by definition, also a morphism from <img src=\"http://s0.wp.com/latex.php?latex=%28TA%2C+%5Cmu_A%29&bg=ffffff&fg=333333&s=0\" alt=\"(TA, \\mu_A)\" class=\"latex\" title=\"(TA, \\mu_A)\" /> to <img src=\"http://s0.wp.com/latex.php?latex=%28TA%2C+a%29&bg=ffffff&fg=333333&s=0\" alt=\"(TA, a)\" class=\"latex\" title=\"(TA, a)\" /> in <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D%5ET&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}^T\" class=\"latex\" title=\"\\mathcal{C}^T\" />.</p>
<p>This time, our plan is to construct an adjunction <img src=\"http://s0.wp.com/latex.php?latex=%28F%5ET%2C+G%5ET%2C+%5Ceta%2C+%5Cmu%29&bg=ffffff&fg=333333&s=0\" alt=\"(F^T, G^T, \\eta, \\mu)\" class=\"latex\" title=\"(F^T, G^T, \\eta, \\mu)\" /> such that <img src=\"http://s0.wp.com/latex.php?latex=F%5ET+%3A+%5Cmathcal%7BC%7D+%5Cto+%5Cmathcal%7BC%7D%5ET&bg=ffffff&fg=333333&s=0\" alt=\"F^T : \\mathcal{C} \\to \\mathcal{C}^T\" class=\"latex\" title=\"F^T : \\mathcal{C} \\to \\mathcal{C}^T\" />, <img src=\"http://s0.wp.com/latex.php?latex=G%5ET+%3A+%5Cmathcal%7BC%7D%5ET+%5Cto+%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"G^T : \\mathcal{C}^T \\to \\mathcal{C}\" class=\"latex\" title=\"G^T : \\mathcal{C}^T \\to \\mathcal{C}\" />, <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+G%5ET+F%5ET&bg=ffffff&fg=333333&s=0\" alt=\"T = G^T F^T\" class=\"latex\" title=\"T = G^T F^T\" />, and <img src=\"http://s0.wp.com/latex.php?latex=%5Cmu_A+%3D+G%5ET+%5Cvarepsilon_%7BF%5ET+A%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mu_A = G^T \\varepsilon_{F^T A}\" class=\"latex\" title=\"\\mu_A = G^T \\varepsilon_{F^T A}\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=A+%5Cin+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"A \\in |\\mathcal{C}|\" class=\"latex\" title=\"A \\in |\\mathcal{C}|\" />. We do this as follows:</p>
<ul>
<li><img src=\"http://s0.wp.com/latex.php?latex=F%5ET+A+%3D+%5Cmu_A+%3D+%28TA%2C+%5Cmu_A%29&bg=ffffff&fg=333333&s=0\" alt=\"F^T A = \\mu_A = (TA, \\mu_A)\" class=\"latex\" title=\"F^T A = \\mu_A = (TA, \\mu_A)\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=F%5ET+f+%3D+Tf&bg=ffffff&fg=333333&s=0\" alt=\"F^T f = Tf\" class=\"latex\" title=\"F^T f = Tf\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=G%5ET+a+%3D+A&bg=ffffff&fg=333333&s=0\" alt=\"G^T a = A\" class=\"latex\" title=\"G^T a = A\" /> if <img src=\"http://s0.wp.com/latex.php?latex=a+%3A+TA+%5Cto+A&bg=ffffff&fg=333333&s=0\" alt=\"a : TA \\to A\" class=\"latex\" title=\"a : TA \\to A\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=G%5ET+f+%3D+f&bg=ffffff&fg=333333&s=0\" alt=\"G^T f = f\" class=\"latex\" title=\"G^T f = f\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=%5Cvarepsilon%5ET_a+%3D+a&bg=ffffff&fg=333333&s=0\" alt=\"\\varepsilon^T_a = a\" class=\"latex\" title=\"\\varepsilon^T_a = a\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=a+%3D+%28A%2Ca%29+%5Cin+%7C%5Cmathcal%7BC%7D%5ET%7C&bg=ffffff&fg=333333&s=0\" alt=\"a = (A,a) \\in |\\mathcal{C}^T|\" class=\"latex\" title=\"a = (A,a) \\in |\\mathcal{C}^T|\" />.</li>
</ul>
<p>Then clearly <img src=\"http://s0.wp.com/latex.php?latex=G%5ET+F%5ET+%3D+T&bg=ffffff&fg=333333&s=0\" alt=\"G^T F^T = T\" class=\"latex\" title=\"G^T F^T = T\" />, while naturality of <img src=\"http://s0.wp.com/latex.php?latex=%5Cvarepsilon&bg=ffffff&fg=333333&s=0\" alt=\"\\varepsilon\" class=\"latex\" title=\"\\varepsilon\" /> follows from the properties of free <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebras with respect to <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebra morphisms. In addition, if <img src=\"http://s0.wp.com/latex.php?latex=S+%3D+a+%3D+%28A%2Ca%29+%5Cin+%7C%5Cmathcal%7BC%7D%5ET%7C&bg=ffffff&fg=333333&s=0\" alt=\"S = a = (A,a) \\in |\\mathcal{C}^T|\" class=\"latex\" title=\"S = a = (A,a) \\in |\\mathcal{C}^T|\" /> then <img src=\"http://s0.wp.com/latex.php?latex=G%5ET+%5Cvarepsilon%5ET_S+%5Ccirc+%5Ceta_%7BG%5ET+S%7D+%3D+a+%5Ccirc+%5Ceta_A+%3D+%5Cmathrm%7Bid%7D_%7BG%5ET+S%7D&bg=ffffff&fg=333333&s=0\" alt=\"G^T \\varepsilon^T_S \\circ \\eta_{G^T S} = a \\circ \\eta_A = \\mathrm{id}_{G^T S}\" class=\"latex\" title=\"G^T \\varepsilon^T_S \\circ \\eta_{G^T S} = a \\circ \\eta_A = \\mathrm{id}_{G^T S}\" />, and if <img src=\"http://s0.wp.com/latex.php?latex=A+%5Cin+%5Cmathrm%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"A \\in \\mathrm{C}\" class=\"latex\" title=\"A \\in \\mathrm{C}\" /> then <img src=\"http://s0.wp.com/latex.php?latex=%5Cvarepsilon%5ET_%7BF%5ET+A%7D+%5Ccirc+F%5ET+%5Ceta_A+%3D+%5Cmu_A+%5Ccirc+T%5Ceta_A+%5Cmathrm%7Bid%7D_%7BTA%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\varepsilon^T_{F^T A} \\circ F^T \\eta_A = \\mu_A \\circ T\\eta_A \\mathrm{id}_{TA}\" class=\"latex\" title=\"\\varepsilon^T_{F^T A} \\circ F^T \\eta_A = \\mu_A \\circ T\\eta_A \\mathrm{id}_{TA}\" />. We thus have a full-featured adjunction: this time, <img src=\"http://s0.wp.com/latex.php?latex=F%5ET&bg=ffffff&fg=333333&s=0\" alt=\"F^T\" class=\"latex\" title=\"F^T\" /> is doing all the work, and <img src=\"http://s0.wp.com/latex.php?latex=G%5ET&bg=ffffff&fg=333333&s=0\" alt=\"G^T\" class=\"latex\" title=\"G^T\" /> is just a forgetful functor.</p>
<p><strong>Theorem 3.</strong> Let <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+%28T%2C+%5Ceta%2C+%5Cmu%29&bg=ffffff&fg=333333&s=0\" alt=\"T = (T, \\eta, \\mu)\" class=\"latex\" title=\"T = (T, \\eta, \\mu)\" /> be a monad on a <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" />. Identify the monad <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" /> with the corresponding Kleisli triple <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+%28T%2C+%5Ceta%2C+%28%5Ccdot%29%5E%5Cast%29&bg=ffffff&fg=333333&s=0\" alt=\"T = (T, \\eta, (\\cdot)^\\ast)\" class=\"latex\" title=\"T = (T, \\eta, (\\cdot)^\\ast)\" />. The Kleisli category <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D_T&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}_T\" class=\"latex\" title=\"\\mathcal{C}_T\" /> is equivalent to the full subcategory of <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D%5ET&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}^T\" class=\"latex\" title=\"\\mathcal{C}^T\" /> generated by the free <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebras.</p>
<p><em>Proof:</em> Define a functor <img src=\"http://s0.wp.com/latex.php?latex=J+%3A+%5Cmathcal%7BC%7D_T+%5Cto+%5Cmathcal%7BC%7D%5ET&bg=ffffff&fg=333333&s=0\" alt=\"J : \\mathcal{C}_T \\to \\mathcal{C}^T\" class=\"latex\" title=\"J : \\mathcal{C}_T \\to \\mathcal{C}^T\" /> by setting <img src=\"http://s0.wp.com/latex.php?latex=JA+%3D+%5Cmu_A+%3D+%28TA%2C+%5Cmu_A%29&bg=ffffff&fg=333333&s=0\" alt=\"JA = \\mu_A = (TA, \\mu_A)\" class=\"latex\" title=\"JA = \\mu_A = (TA, \\mu_A)\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=A+%5Cin+%7C%5Cmathcal%7BC%7D_T%7C+%3D+%7C%5Cmathcal%7BC%7D%7C&bg=ffffff&fg=333333&s=0\" alt=\"A \\in |\\mathcal{C}_T| = |\\mathcal{C}|\" class=\"latex\" title=\"A \\in |\\mathcal{C}_T| = |\\mathcal{C}|\" />, and <img src=\"http://s0.wp.com/latex.php?latex=Jf+%3D+%5Cmu_B+%5Ccirc+Tf+%3D+f%5E%5Cast+%5Cin+%5Cmathcal%7BC%7D%5ET%28JA%2C+JB%29&bg=ffffff&fg=333333&s=0\" alt=\"Jf = \\mu_B \\circ Tf = f^\\ast \\in \\mathcal{C}^T(JA, JB)\" class=\"latex\" title=\"Jf = \\mu_B \\circ Tf = f^\\ast \\in \\mathcal{C}^T(JA, JB)\" /> for every <img src=\"http://s0.wp.com/latex.php?latex=f+%5Cin+%5Cmathcal%7BC%7D_T%28A%2CB%29+%3D+%5Cmathcal%7BC%7D%28A%2C+TB%29&bg=ffffff&fg=333333&s=0\" alt=\"f \\in \\mathcal{C}_T(A,B) = \\mathcal{C}(A, TB)\" class=\"latex\" title=\"f \\in \\mathcal{C}_T(A,B) = \\mathcal{C}(A, TB)\" />. Then <img src=\"http://s0.wp.com/latex.php?latex=J&bg=ffffff&fg=333333&s=0\" alt=\"J\" class=\"latex\" title=\"J\" /> is a faithful functor, because if <img src=\"http://s0.wp.com/latex.php?latex=f%2Cg+%5Cin+%5Cmathcal%7BC%7D_T%28A%2CB%29&bg=ffffff&fg=333333&s=0\" alt=\"f,g \\in \\mathcal{C}_T(A,B)\" class=\"latex\" title=\"f,g \\in \\mathcal{C}_T(A,B)\" />, then <img src=\"http://s0.wp.com/latex.php?latex=f+%3D+%5Cmu_B+%5Ccirc+%5Ceta_%7BTB%7D+%5Ccirc+f+%3D+%5Cmu_B+%5Ccirc+Tf+%5Ccirc+%5Ceta_A&bg=ffffff&fg=333333&s=0\" alt=\"f = \\mu_B \\circ \\eta_{TB} \\circ f = \\mu_B \\circ Tf \\circ \\eta_A\" class=\"latex\" title=\"f = \\mu_B \\circ \\eta_{TB} \\circ f = \\mu_B \\circ Tf \\circ \\eta_A\" /> and similarly <img src=\"http://s0.wp.com/latex.php?latex=g+%3D+%5Cmu_B+%5Ccirc+%5Ceta_%7BTB%7D+%5Ccirc+g+%3D+%5Cmu_B+%5Ccirc+Tg+%5Ccirc+%5Ceta_A&bg=ffffff&fg=333333&s=0\" alt=\"g = \\mu_B \\circ \\eta_{TB} \\circ g = \\mu_B \\circ Tg \\circ \\eta_A\" class=\"latex\" title=\"g = \\mu_B \\circ \\eta_{TB} \\circ g = \\mu_B \\circ Tg \\circ \\eta_A\" />, so that <img src=\"http://s0.wp.com/latex.php?latex=f+%3D+g&bg=ffffff&fg=333333&s=0\" alt=\"f = g\" class=\"latex\" title=\"f = g\" /> if <img src=\"http://s0.wp.com/latex.php?latex=Jf+%3D+Jg&bg=ffffff&fg=333333&s=0\" alt=\"Jf = Jg\" class=\"latex\" title=\"Jf = Jg\" />. But <img src=\"http://s0.wp.com/latex.php?latex=J&bg=ffffff&fg=333333&s=0\" alt=\"J\" class=\"latex\" title=\"J\" /> is also full, because if <img src=\"http://s0.wp.com/latex.php?latex=f+%3A+%28TA%2C+%5Cmu_A%29+%5Cto+%28TB%2C+%5Cmu_B%29&bg=ffffff&fg=333333&s=0\" alt=\"f : (TA, \\mu_A) \\to (TB, \\mu_B)\" class=\"latex\" title=\"f : (TA, \\mu_A) \\to (TB, \\mu_B)\" /> is a morphism of free <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-algebras, then from the laws of monads follows that <img src=\"http://s0.wp.com/latex.php?latex=f+%3D+J%28f+%5Ccirc+%5Ceta_A%29&bg=ffffff&fg=333333&s=0\" alt=\"f = J(f \\circ \\eta_A)\" class=\"latex\" title=\"f = J(f \\circ \\eta_A)\" />. <img src=\"http://s0.wp.com/latex.php?latex=%5CBox&bg=ffffff&fg=333333&s=0\" alt=\"\\Box\" class=\"latex\" title=\"\\Box\" /></p>
<p>But things get even more interesting than this! Let <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+%28T%2C+%5Ceta%2C+%5Cmu%29&bg=ffffff&fg=333333&s=0\" alt=\"T = (T, \\eta, \\mu)\" class=\"latex\" title=\"T = (T, \\eta, \\mu)\" /> be a monad: let us consider <em>all</em> the adjunctions <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> that generate <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />. What can be a <em>morphism</em> of such adjunctions? First, if <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> is a solution with <img src=\"http://s0.wp.com/latex.php?latex=F+%3A+%5Cmathcal%7BC%7D+%5Cto+%5Cmathcal%7BD%7D&bg=ffffff&fg=333333&s=0\" alt=\"F : \\mathcal{C} \\to \\mathcal{D}\" class=\"latex\" title=\"F : \\mathcal{C} \\to \\mathcal{D}\" />, and <img src=\"http://s0.wp.com/latex.php?latex=%28F%27%2C+G%27%2C+%5Ceta%2C+%5Cvarepsilon%27%29&bg=ffffff&fg=333333&s=0\" alt=\"(F', G', \\eta, \\varepsilon')\" class=\"latex\" title=\"(F', G', \\eta, \\varepsilon')\" /> is a solution with <img src=\"http://s0.wp.com/latex.php?latex=F%27+%3A+%5Cmathcal%7BC%7D+%5Cto+%5Cmathcal%7BD%7D%27&bg=ffffff&fg=333333&s=0\" alt=\"F' : \\mathcal{C} \\to \\mathcal{D}'\" class=\"latex\" title=\"F' : \\mathcal{C} \\to \\mathcal{D}'\" />, we may consider a functor <img src=\"http://s0.wp.com/latex.php?latex=L+%3A+%5Cmathcal%7BD%7D+%5Cto+%5Cmathcal%7BD%27%7D&bg=ffffff&fg=333333&s=0\" alt=\"L : \\mathcal{D} \\to \\mathcal{D'}\" class=\"latex\" title=\"L : \\mathcal{D} \\to \\mathcal{D'}\" /> as a morphism from <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> to <img src=\"http://s0.wp.com/latex.php?latex=%28F%27%2C+G%27%2C+%5Ceta%2C+%5Cvarepsilon%27%29&bg=ffffff&fg=333333&s=0\" alt=\"(F', G', \\eta, \\varepsilon')\" class=\"latex\" title=\"(F', G', \\eta, \\varepsilon')\" />. Next, we want that the equalities <img src=\"http://s0.wp.com/latex.php?latex=GF+%3D+T+%3D+G%27F%27&bg=ffffff&fg=333333&s=0\" alt=\"GF = T = G'F'\" class=\"latex\" title=\"GF = T = G'F'\" /> are not affected by mid-way application of <img src=\"http://s0.wp.com/latex.php?latex=L&bg=ffffff&fg=333333&s=0\" alt=\"L\" class=\"latex\" title=\"L\" />: this translates into the two conditions <img src=\"http://s0.wp.com/latex.php?latex=L+%5Ccirc+F+%3D+F%27&bg=ffffff&fg=333333&s=0\" alt=\"L \\circ F = F'\" class=\"latex\" title=\"L \\circ F = F'\" /> and <img src=\"http://s0.wp.com/latex.php?latex=G%27+%5Ccirc+L+%3D+G&bg=ffffff&fg=333333&s=0\" alt=\"G' \\circ L = G\" class=\"latex\" title=\"G' \\circ L = G\" />. Finally, as the previous point yields <img src=\"http://s0.wp.com/latex.php?latex=LFG+%3D+F%27G%27L&bg=ffffff&fg=333333&s=0\" alt=\"LFG = F'G'L\" class=\"latex\" title=\"LFG = F'G'L\" />, we want that <img src=\"http://s0.wp.com/latex.php?latex=L&bg=ffffff&fg=333333&s=0\" alt=\"L\" class=\"latex\" title=\"L\" /> does not interfere with the counits: that is, <img src=\"http://s0.wp.com/latex.php?latex=L%5Cvarepsilon+%3D+%5Cvarepsilon%27_L&bg=ffffff&fg=333333&s=0\" alt=\"L\\varepsilon = \\varepsilon'_L\" class=\"latex\" title=\"L\\varepsilon = \\varepsilon'_L\" />.</p>
<p><strong>Definition 7.</strong> Let <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+%28T%2C+%5Ceta%2C+%5Cmu%29&bg=ffffff&fg=333333&s=0\" alt=\"T = (T, \\eta, \\mu)\" class=\"latex\" title=\"T = (T, \\eta, \\mu)\" /> be a monad on a category <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{C}\" class=\"latex\" title=\"\\mathcal{C}\" /> and let <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" />, <img src=\"http://s0.wp.com/latex.php?latex=%28F%27%2C+G%27%2C+%5Ceta%2C+%5Cvarepsilon%27%29&bg=ffffff&fg=333333&s=0\" alt=\"(F', G', \\eta, \\varepsilon')\" class=\"latex\" title=\"(F', G', \\eta, \\varepsilon')\" /> be two adjunctions that generate <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />, with <img src=\"http://s0.wp.com/latex.php?latex=F+%3A+%5Cmathcal%7BC%7D+%5Cto+%5Cmathcal%7BD%7D&bg=ffffff&fg=333333&s=0\" alt=\"F : \\mathcal{C} \\to \\mathcal{D}\" class=\"latex\" title=\"F : \\mathcal{C} \\to \\mathcal{D}\" /> and <img src=\"http://s0.wp.com/latex.php?latex=F%27+%3A+%5Cmathcal%7BC%7D+%5Cto+%5Cmathcal%7BD%7D%27&bg=ffffff&fg=333333&s=0\" alt=\"F' : \\mathcal{C} \\to \\mathcal{D}'\" class=\"latex\" title=\"F' : \\mathcal{C} \\to \\mathcal{D}'\" />, respectively. A <em><img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-preserving functor</em> from <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> to <img src=\"http://s0.wp.com/latex.php?latex=%28F%27%2C+G%27%2C+%5Ceta%2C+%5Cvarepsilon%27%29&bg=ffffff&fg=333333&s=0\" alt=\"(F', G', \\eta, \\varepsilon')\" class=\"latex\" title=\"(F', G', \\eta, \\varepsilon')\" /> is a functor <img src=\"http://s0.wp.com/latex.php?latex=L+%3A+%5Cmathcal%7BD%7D+%5Cto+%5Cmathcal%7BD%7D%27&bg=ffffff&fg=333333&s=0\" alt=\"L : \\mathcal{D} \\to \\mathcal{D}'\" class=\"latex\" title=\"L : \\mathcal{D} \\to \\mathcal{D}'\" /> such that <img src=\"http://s0.wp.com/latex.php?latex=L+%5Ccirc+F+%3D+F%27&bg=ffffff&fg=333333&s=0\" alt=\"L \\circ F = F'\" class=\"latex\" title=\"L \\circ F = F'\" />, <img src=\"http://s0.wp.com/latex.php?latex=G%27+%5Ccirc+L+%3D+G&bg=ffffff&fg=333333&s=0\" alt=\"G' \\circ L = G\" class=\"latex\" title=\"G' \\circ L = G\" />, and <img src=\"http://s0.wp.com/latex.php?latex=L%5Cvarepsilon+%3D+%5Cvarepsilon%27_L&bg=ffffff&fg=333333&s=0\" alt=\"L\\varepsilon = \\varepsilon'_L\" class=\"latex\" title=\"L\\varepsilon = \\varepsilon'_L\" />.</p>
<p>It is straightforward to see that <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-generating adjunctions together with <img src=\"http://s0.wp.com/latex.php?latex=T&bg=ffffff&fg=333333&s=0\" alt=\"T\" class=\"latex\" title=\"T\" />-preserving functors form a category <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathrm%7BAdj%7D%28T%29&bg=ffffff&fg=333333&s=0\" alt=\"\\mathrm{Adj}(T)\" class=\"latex\" title=\"\\mathrm{Adj}(T)\" />: composition is provided by the usual composition of functors, while the identity of <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> in <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathrm%7BAdj%7D%28T%29&bg=ffffff&fg=333333&s=0\" alt=\"\\mathrm{Adj}(T)\" class=\"latex\" title=\"\\mathrm{Adj}(T)\" /> is the identity functor of <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\mathcal{D}\" class=\"latex\" title=\"\\mathcal{D}\" /> if <img src=\"http://s0.wp.com/latex.php?latex=F+%3A+%5Cmathcal%7BC%7D+%5Cto+%5Cmathcal%7BD%7D&bg=ffffff&fg=333333&s=0\" alt=\"F : \\mathcal{C} \\to \\mathcal{D}\" class=\"latex\" title=\"F : \\mathcal{C} \\to \\mathcal{D}\" />.</p>
<p>To confirm that our intuition is correct, let us verify that <img src=\"http://s0.wp.com/latex.php?latex=J&bg=ffffff&fg=333333&s=0\" alt=\"J\" class=\"latex\" title=\"J\" /> satisfies the three given equations:</p>
<ul>
<li><img src=\"http://s0.wp.com/latex.php?latex=J+F_T+A+%3D+JA+%3D+%28T_A%2C+%5Cmu_A%29+%3D+F%5ET+A&bg=ffffff&fg=333333&s=0\" alt=\"J F_T A = JA = (T_A, \\mu_A) = F^T A\" class=\"latex\" title=\"J F_T A = JA = (T_A, \\mu_A) = F^T A\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=J+F_T+f+%3D+%5Cmu_B+%5Ccirc+T%28%5Ceta_B+%5Ccirc+f%29+%3D+%5Cmu_B+%5Ccirc+T%5Ceta_B+%5Ccirc+Tf+%3D+%5Cmathrm%7Bid%7D_%7BTB%7D+%5Ccirc+Tf+%3D+F%5ETf&bg=ffffff&fg=333333&s=0\" alt=\"J F_T f = \\mu_B \\circ T(\\eta_B \\circ f) = \\mu_B \\circ T\\eta_B \\circ Tf = \\mathrm{id}_{TB} \\circ Tf = F^Tf\" class=\"latex\" title=\"J F_T f = \\mu_B \\circ T(\\eta_B \\circ f) = \\mu_B \\circ T\\eta_B \\circ Tf = \\mathrm{id}_{TB} \\circ Tf = F^Tf\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=G%5ET+J+A+%3D+G%5ET+%28TA%2C+%5Cmu_A%29+%3D+TA+%3D+G_T+A&bg=ffffff&fg=333333&s=0\" alt=\"G^T J A = G^T (TA, \\mu_A) = TA = G_T A\" class=\"latex\" title=\"G^T J A = G^T (TA, \\mu_A) = TA = G_T A\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=G%5ET+J+f+%3D+G%5ET+%28%5Cmu_B+%5Ccirc+Tf%29+%3D+%5Cmu_B+%5Ccirc+Tf+%3D+f%5E%5Cast+%3D+G_T+f&bg=ffffff&fg=333333&s=0\" alt=\"G^T J f = G^T (\\mu_B \\circ Tf) = \\mu_B \\circ Tf = f^\\ast = G_T f\" class=\"latex\" title=\"G^T J f = G^T (\\mu_B \\circ Tf) = \\mu_B \\circ Tf = f^\\ast = G_T f\" />;</li>
<li><img src=\"http://s0.wp.com/latex.php?latex=J%28%5Cvarepsilon_T%29_S+%3D+J%5Cmathrm%7Bid%7D_%7BTS%7D%3D+%5Cmu_S+%5Ccirc+T%5Cmathrm%7Bid%7D_%7BTS%7D+%3D+%5Cmu_S+%3D+%5Cvarepsilon%5ET_%7B%28TS%2C+%5Cmu_S%29%7D+%3D+%5Cvarepsilon%5ET_%7BJS%7D&bg=ffffff&fg=333333&s=0\" alt=\"J(\\varepsilon_T)_S = J\\mathrm{id}_{TS}= \\mu_S \\circ T\\mathrm{id}_{TS} = \\mu_S = \\varepsilon^T_{(TS, \\mu_S)} = \\varepsilon^T_{JS}\" class=\"latex\" title=\"J(\\varepsilon_T)_S = J\\mathrm{id}_{TS}= \\mu_S \\circ T\\mathrm{id}_{TS} = \\mu_S = \\varepsilon^T_{(TS, \\mu_S)} = \\varepsilon^T_{JS}\" />.</li>
</ul>
<p><strong>Theorem 4.</strong> Let <img src=\"http://s0.wp.com/latex.php?latex=T+%3D+%28T%2C+%5Ceta%2C+%5Cmu%29&bg=ffffff&fg=333333&s=0\" alt=\"T = (T, \\eta, \\mu)\" class=\"latex\" title=\"T = (T, \\eta, \\mu)\" /> be a monad. Then the Kleisli adjunction is the initial object of <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathrm%7BAdj%7D%28T%29&bg=ffffff&fg=333333&s=0\" alt=\"\\mathrm{Adj}(T)\" class=\"latex\" title=\"\\mathrm{Adj}(T)\" />, the Eilenberg-Moore adjunction is the final object. In particular, <img src=\"http://s0.wp.com/latex.php?latex=J&bg=ffffff&fg=333333&s=0\" alt=\"J\" class=\"latex\" title=\"J\" /> is the only arrow in <img src=\"http://s0.wp.com/latex.php?latex=%5Cmathrm%7BAdj%7D%28T%29&bg=ffffff&fg=333333&s=0\" alt=\"\\mathrm{Adj}(T)\" class=\"latex\" title=\"\\mathrm{Adj}(T)\" /> from the former to the latter.</p>
<p><em>Proof:</em> If <img src=\"http://s0.wp.com/latex.php?latex=%28F%2C+G%2C+%5Ceta%2C+%5Cvarepsilon%29&bg=ffffff&fg=333333&s=0\" alt=\"(F, G, \\eta, \\varepsilon)\" class=\"latex\" title=\"(F, G, \\eta, \\varepsilon)\" /> is the Kleisli adjunction, then the only choice for <img src=\"http://s0.wp.com/latex.php?latex=L&bg=ffffff&fg=333333&s=0\" alt=\"L\" class=\"latex\" title=\"L\" /> is <img src=\"http://s0.wp.com/latex.php?latex=LA+%3D+F%27A&bg=ffffff&fg=333333&s=0\" alt=\"LA = F'A\" class=\"latex\" title=\"LA = F'A\" /> and <img src=\"http://s0.wp.com/latex.php?latex=Lf+%3D+%5Cvarepsilon%27_%7BF%27B%7D+%5Ccirc+F%27+f&bg=ffffff&fg=333333&s=0\" alt=\"Lf = \\varepsilon'_{F'B} \\circ F' f\" class=\"latex\" title=\"Lf = \\varepsilon'_{F'B} \\circ F' f\" />. If <img src=\"http://s0.wp.com/latex.php?latex=%28F%27%2C+G%27%2C+%5Ceta%2C+%5Cvarepsilon%27%29&bg=ffffff&fg=333333&s=0\" alt=\"(F', G', \\eta, \\varepsilon')\" class=\"latex\" title=\"(F', G', \\eta, \\varepsilon')\" /> is the Eilenberg-Moore adjunction, then the only choice for <img src=\"http://s0.wp.com/latex.php?latex=L&bg=ffffff&fg=333333&s=0\" alt=\"L\" class=\"latex\" title=\"L\" /> is <img src=\"http://s0.wp.com/latex.php?latex=LS+%3D+%28GS%2C+G+%5Cvarepsilon_S%29&bg=ffffff&fg=333333&s=0\" alt=\"LS = (GS, G \\varepsilon_S)\" class=\"latex\" title=\"LS = (GS, G \\varepsilon_S)\" /> and <img src=\"http://s0.wp.com/latex.php?latex=Lf+%3D+Gf&bg=ffffff&fg=333333&s=0\" alt=\"Lf = Gf\" class=\"latex\" title=\"Lf = Gf\" />. <img src=\"http://s0.wp.com/latex.php?latex=%5CBox&bg=ffffff&fg=333333&s=0\" alt=\"\\Box\" class=\"latex\" title=\"\\Box\" /></p>
<br />  <a href=\"http://feeds.wordpress.com/1.0/gocomments/theorylunch.wordpress.com/885/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/theorylunch.wordpress.com/885/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=theorylunch.wordpress.com&blog=43735749&post=885&subd=theorylunch&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "ac0dd757f3a558396792ce36528f4a1d") (45 (20928 8813 677256) "http://kenta.blogspot.com/2013/06/sjhltpdo-unscope-symbol.html" "Ken T Takusagawa: [sjhltpdo] Unscope symbol" "noreply@blogger.com (Ken)" "Mon, 10 Jun 2013 08:49:00 +0000" "<p dir=\"ltr\"><code>let { foo = ... } in let { hide foo } in foo</code></p><p dir=\"ltr\">This should cause the compiler to signal an error.  We wish to assert that a certain symbol is not used within an inner scope, perhaps to avoid programmer typos of similar symbols.  \"hide foo\" can also be a statement in <code>do</code> notation.</p><p dir=\"ltr\">If we have <a href=\"http://kenta.blogspot.com/2013/04/isjnkupe-local-types-and-imports.html\">local imports</a>, then perhaps syntax like <code>let { import OUTER-SCOPE hiding (foo) }</code>, where <code>OUTER-SCOPE</code> is a new keyword.</p><p dir=\"ltr\">We could also hide everything in the outer scope except a few symbols.  <code>let { import OUTER-SCOPE(foo); import Prelude }</code>.</p>" nil nil "ee14afb90b62307826c2fe7bffc4fc2f") (44 (20928 8813 676875) "http://winterkoninkje.dreamwidth.org/84469.html" "wren ng thornton: Dungeon World: Assassin class" nil "Sun, 09 Jun 2013 00:32:03 +0000" "<p>After far too long, I've finally found a new roleplaying group. We're using <a href=\"http://www.dungeon-world.com/\">Dungeon World</a>, a lightweight system I've never used before. It's a class-based system, which I've never been too fond of, but it does seem like it gets rid of most of the things I hate about class-based systems. The core book only gives the standard D&D-style classes, but they give some guidelines on making up your own classes. For my character I worked with the GM to come up with a new <a href=\"http://llama.freegeek.org/~wren/resources/blog/assassin.pdf\">Assassin</a> class which combines some of the traits of the Thief and the Fighter. I tried to make sure it's balanced against the other classes and doesn't obviate the Thief/Fighter, but not having used DW before it's hard to be sure. If you've used DW and have any comments, I'd be interested in hearing them.</p>
<p><i>Edit:</i> I've posted a new version which adjusts the damage option for the Death Dealer and Assassin's Strike moves. Also included is a discussion about how different ways of doing DD/AS would affect DPS, which is necessary for doing a fair comparison against other classes. If you run a game with this class, let me know how it goes.</p><br /><br /><img src=\"http://www.dreamwidth.org/tools/commentcount?user=winterkoninkje&ditemid=84469\" alt=\"comment count unavailable\" height=\"12\" style=\"vertical-align: middle;\" width=\"30\" /> comments" nil nil "d35578c59936a1dfeb4121d32d3adbe9") (43 (20928 8813 676154) "http://praisecurseandrecurse.blogspot.com/2013/06/objective-c-day-5.html" "Paul Potts: Objective-C, Day 5" "noreply@blogger.com (Paul Potts)" "Fri, 07 Jun 2013 23:17:00 +0000" "<p>(Warning: non-FP content). (I've been including this for the benefit of any \"Planet X\" aggregators who are including my feed, where X is a functional language like Haskell. I'm assuming you've got that by now and either don't care or are unsubscribing/ignoring this series if it bothers you. I expect to get back to more functional language code at some point, maybe even implementing the same problem. But I dabble in different languages and sometimes the digressions go on for a while...)</p> <p>So, today's topic is <b>dispatch</b>. I'm starting to design and implement the logic for pieces interacting on the board. The key in object-oriented designs is always to determine who (which object) manages which state. The design I've come up with is a sort of hybrid design, where position on the board is not actually a property of the board tiles. Instead, there's a board which keeps track of them. The instances of, say, a tree on the board don't have any unique state, so I'm not instantiating different objects for each one; they all point to a singleton (which I should properly enforce with a singleton factory method at some point).</p> <p>There are trade-offs. On paper, my design involved adding a \"push\" method to the classes for tile pieces. In a language like Dylan, this \"push\" method would be a generic function, and dispatch on multiple parameter types, so that I could write some very short methods and use the method dispatcher, instead of explicit <b>if-then</b> or <b>switch</b> logic to find the right bit of code at run-time according to the types of the interacting objects (either their literal types or an enum, or some such). I could even do this in C++ because it has method overloading based on the parameters -- as long as this is <a href=\"http://stackoverflow.com/questions/6897662/matching-an-overloaded-function-to-its-polymorphic-argument\">based on their static type known at compile-time</a>. Which... isn't true in this case. I miss Dylan's generic function dispatch! <a href=\"http://stackoverflow.com/questions/2286312/method-overloading-in-objective-c\">Objective-C is a underpowered</a> in this respect even compared to C++. For example, I'd like to be able to write methods like this for the bomb class (this is pseudocode):</p> <pre>bomb::push(mountain)<br />{<br />    // blow up the mountain<br />}<br /><br />bomb::push(empty)<br />{<br />    // slide the bomb onto the tile<br />}</pre> <p>But I can't. I can't just use the class construct to organize methods to call without an instance -- there doesn't seem to be the equivalent of C++ static methods. There also is no equivalent of a pure virtual function; I can't declare the need for a push() method in the common base class of the tile pieces and have the compiler demand that I implement in any subclasses to make them instantiable. The closest I can come, I think, is to create a method that generates an error if it itself is called instead of being overridden in a subclass. That seems to lack semantic clarity.  So maybe I could do this, with <a href=\"http://en.wikipedia.org/wiki/Double_dispatch\">double dispatch</a>, but it doesn't seem worth the trouble for a small number of collision behaviors, when the behavior isn't simply supported by the language. I keep telling myself \"thin layer on top of C... thin layer on top of C...\"</p> <p>So last night I had my Mac running upstairs in the office, and I used my iPad downstairs to connect to it via VNC, and write some code, running it on the iPad simulator, which I then viewed and controlled with a real iPad (mad scientist laugh). It needs a little tweaking this morning but here's more-or-less what I came up with. Note that I have started using some different naming conventions for file-scope and local variables. I'm not sure they are very standard Objective-C but they are closer to what I've grown comfortable with over the years in C and C++.</p> <pre>typedef struct {<br />    int x_idx;<br />    int y_idx;<br />} pos_t;<br /><br />typedef enum {<br />    dir_east,<br />    dir_west,<br />    dir_south,<br />    dir_north<br />} dir_e;<br /><br />// A straight C function to return a pos_t updated with a dir_e;<br />// the result may be out of bounds<br />pos_t getUpdatedPos( pos_t original_pos, dir_e dir );<br />BOOL posValid( pos_t pos );<br /><br />static const int board_width = 24, board_height = 4;<br />// The short board design is part of what makes it so<br />// easy to get sliding objects stuck against the edges<br />// of the world or in corners where you can't get the<br />// penguin avatar around to the other side to push them.<br />// We could consider a bigger board later and maybe<br />// implement the original puzzles surrounded by water,<br />// or something like that.<br /><br />// Equivalent of C++ class forward declaration<br />@class ArcticSlideTile;<br />@class ArcticSlideBomb;<br />@class ArcticSlideEmpty;<br />@class ArcticSlideHeart;<br />@class ArcticSlideHouse;<br />@class ArcticSlideIceBlock;<br />@class ArcticSlideMountain;<br />@class ArcticSlideTree;<br /><br />@interface ArcticSlideModel : NSObject<br />{<br />    ArcticSlideTile* board[board_height][board_width];<br />}<br /><br />- (id)init;<br />- (id)initWithLevelIndex:(int)level_idx;<br />- (NSString*) description;<br />- (ArcticSlideTile*)getTileFromPosition:(pos_t)pos<br />                            inDirection:(dir_e)dir;<br />- (void)setTileAtPosition:(pos_t)pos<br />                       to:(ArcticSlideTile*)type;<br /><br />@end<br /><br />@interface ArcticSlideTile : NSObject<br /><br />- (BOOL)pushFromPosition:(pos_t)pos inDirection:(dir_e)dir;<br /><br />@end<br /><br /><br />@interface ArcticSlideBomb : ArcticSlideTile<br />// Bombs can be pushed and will slide until they hit an<br />// object and stop. If the object is a mountain, both bomb<br />// and mountain are destroyed. If another object hits a bomb<br />// it stops (I think -- I'm not sure it is possible to set <br />// up a board such that you can slide something into a bomb).<br /><br />// push is called when the penguin pushes against a tile.<br />// It returns YES if the penguin can move onto the tile with<br />// this action. This is only ever the case for a tree or empty<br />// tile.<br />- (BOOL)pushFromPosition:(pos_t)pos inDirection:(dir_e)dir;<br />- (NSString*) description;<br />@end<br /><br />@interface ArcticSlideEmpty : ArcticSlideTile<br />// The penguin can always step onto an empty tile<br />- (BOOL)pushFromPosition:(pos_t)pos inDirection:(dir_e)dir;<br />- (BOOL)slideFromPosition:(pos_t)pos inDirection:(dir_e)dir;<br />- (NSString*) description;<br />@end<br /><br />@interface ArcticSlideHeart : ArcticSlideTile<br />// When a heart hits a house the heart disappears (getting<br />// all the hearts into the house is how you win the game).<br />// Otherwise they cannot be destroyed, and slide like other<br />// slidable items.<br />- (BOOL)pushFromPosition:(pos_t)pos inDirection:(dir_e)dir;<br />- (NSString*) description;<br />@end<br /><br />@interface ArcticSlideHouse : ArcticSlideTile<br />// Houses cannot be pushed and stop other objects except<br />// hearts. When a heart hits a house the heart disappears<br />// (getting the hearts into the house is how you win the game).<br />// So the model should keep track of the number of hearts<br />// on the board and trigger a \"win the level\" behavior when<br />// the last heart is removed.<br />- (BOOL)pushFromPosition:(pos_t)pos inDirection:(dir_e)dir;<br />- (NSString*) description;<br />@end<br /><br />@interface ArcticSlideIceBlock : ArcticSlideTile<br />// Ice blocks can be pushed and will slide until they hit<br />// an object and stop. If they are pushed directly against<br />// an object they will be crushed (there should be an animation)<br />// and disappear.<br />- (BOOL)pushFromPosition:(pos_t)pos inDirection:(dir_e)dir;<br />- (NSString*) description;<br />@end<br /><br />@interface ArcticSlideMountain : ArcticSlideTile<br />// Mountains cannot be moved and are destroyed by bombs.<br />- (BOOL)pushFromPosition:(pos_t)pos inDirection:(dir_e)dir;<br />- (NSString*) description;<br />@end<br /><br />@interface ArcticSlideTree : ArcticSlideTile<br />// Trees cannot be pushed or destroyed and stop all sliding<br />// objects, but the penguin avatar character can walk through<br />// them.<br />- (BOOL)pushFromPosition:(pos_t)pos inDirection:(dir_e)dir;<br />- (NSString*) description;<br />@end</pre> <p>Here's part of the implementation. It seems way too wordy; I need to rethink the amount of code required for each step. At the least, some refactoring seems to be in order. As I mentioned earlier, I'm not sure the tile classes are really earning their keep. I got rid of the singleton instantiation machinery but now there are order of initialization dependencies. I'll need to do further thinking as I consider what communication needs to happen between the \"model\" part and \"controller\" part -- how to interact with the GUI, how to indicate that tiles need to be redrawn, or animated transitions should play, or sound effects should play, or that the score is changed, and what to do when a level is completed. There is lots more to think about for such a simple little game! And of course I haven't really even begun to implement the \"view\" parts.</p> <pre>static ArcticSlideEmpty* empty_p;<br />static ArcticSlideTree* tree_p;<br />static ArcticSlideMountain* mountain_p;<br />static ArcticSlideHouse* house_p;<br />static ArcticSlideIceBlock* ice_block_p;<br />static ArcticSlideHeart* heart_p;<br />static ArcticSlideBomb* bomb_p;<br /><br />static ArcticSlideModel* model_p;<br /><br />pos_t getUpdatedPos( pos_t original_pos, dir_e dir )<br />{<br />    pos_t updated_pos = original_pos;<br />    int x_offset = 0;<br />    int y_offset = 0;<br />    if ( dir_east == dir )<br />    {<br />        x_offset = 1;<br />        y_offset = 0;<br />    }<br />    else if ( dir_west == dir )<br />    {<br />        x_offset = -1;<br />        y_offset = 0;<br />    }<br />    else if ( dir_north == dir )<br />    {<br />        x_offset = 0;<br />        y_offset = -1;<br />    }<br />    else if ( dir_south == dir )<br />    {<br />        x_offset = 0;<br />        y_offset = +1;<br />    }<br />    updated_pos.x_idx += x_offset;;<br />    updated_pos.y_idx += y_offset;<br />    return updated_pos;<br />}<br /><br />BOOL posValid( pos_t pos )<br />{<br />    return ( ( ( pos.x_idx >= 0 ) ||<br />               ( pos.x_idx < board_width  ) ) ||<br />             ( ( pos.y_idx >= 0 ) ||<br />               ( pos.y_idx < board_height ) ) );<br />}<br /><br />@implementation ArcticSlideTile<br /><br />- (BOOL)pushFromPosition:(pos_t)pos inDirection:(dir_e)dir<br />{<br />    // Should be implemented in subclass<br />    return NO;<br />}<br /><br />@end<br /><br />@implementation ArcticSlideBomb<br /><br />- (BOOL)pushFromPosition:(pos_t)pos inDirection:(dir_e)dir<br />{<br />    // Penguin has pushed bomb in the given direction.<br />    // Get our own position:<br />    pos_t bomb_pos = getUpdatedPos( pos, dir );<br />    // What are we being pushed into?<br />    ArcticSlideTile *target_tile_p =<br />    [model_p getTileFromPosition:bomb_pos<br />                     inDirection:dir];<br />    <br />    if ( nil == target_tile_p )<br />    {<br />        // Edge of the world. TODO:<br />        // queue a \"boop\" sound effect<br />    }<br />    else if ( mountain_p == target_tile_p )<br />    {<br />        // bomb pushed into mountain<br />        // TODO: queue animation of bomb moving onto<br />        // mountain, animate explosion<br />        // remove bomb and mountain<br />        pos_t new_bomb_pos = getUpdatedPos( bomb_pos, dir );<br />        [model_p setTileAtPosition:new_bomb_pos<br />                                to:empty_p];<br />        new_bomb_pos = getUpdatedPos( new_bomb_pos, dir );<br />        [model_p setTileAtPosition:new_bomb_pos<br />                                to:empty_p];<br />    }<br />    else if ( empty_p == target_tile_p )<br />    {<br />        // TODO: queue bomb moving into space<br />        pos_t new_bomb_pos = getUpdatedPos( bomb_pos, dir );<br />        // Set bomb at new position<br />        [model_p setTileAtPosition:new_bomb_pos<br />                                to:bomb_p];<br />        // Remove bomb from old position<br />        [model_p setTileAtPosition:bomb_pos<br />                                to:empty_p];<br /><br />        // Bombs will continue to slide until stopped<br />        ArcticSlideTile *target_tile_p =<br />        [model_p getTileFromPosition:new_bomb_pos<br />                         inDirection:dir];<br /><br />        while ( empty_p == target_tile_p )<br />        {<br />            // TODO: animate bomb moving into space<br />            pos_t new_bomb_pos = getUpdatedPos( bomb_pos, dir );<br />            // set bomb at new position<br />            [model_p setTileAtPosition:new_bomb_pos<br />                                    to:bomb_p];<br />            // remove bomb from old position<br />            [model_p setTileAtPosition:bomb_pos<br />                                    to:empty_p];<br />        }<br /><br />        if ( mountain_p == target_tile_p )<br />        {<br />            // bomb pushed into mountain<br />            // TODO: queue animation of bomb moving<br />            // onto mountain, animate explosion<br />            // remove bomb and mountain<br />            [model_p setTileAtPosition:new_bomb_pos<br />                                    to:empty_p];<br />            new_bomb_pos = getUpdatedPos( new_bomb_pos, dir );<br />            [model_p setTileAtPosition:new_bomb_pos<br />                                    to:empty_p];<br />        }<br />    }<br />    // The penguin cannot actually move in this turn<br />    return NO;<br />}<br /><br />- (NSString*) description<br />{<br />    return @\"Bomb  \";<br />}<br /><br />@end<br /><br />@implementation ArcticSlideEmpty<br />- (BOOL)pushFromPosition:(pos_t)pos inDirection:(dir_e)dir<br />{<br />    // If the penguin pushes onto an empty tile, he can always<br />    // move there<br />    return YES;<br />}<br /><br />- (NSString*) description<br />{<br />    return @\"      \";<br />}<br />@end</pre> <p>I'm leaving out unfinished tile classes for clarity, but here is the model implementation:</p> <pre>@implementation ArcticSlideModel<br /><br />- (id)init<br />{<br />    // Initialize the global tile objects. I messed around<br />    // with singleton factory methods for creating a single<br />    // instance of each of these and accessing it everywhere<br />    // but the resulting code was too wordy to justify this.<br /><br />    empty_p = [[ArcticSlideEmpty alloc] init];<br />    tree_p = [[ArcticSlideTree alloc] init];<br />    mountain_p = [[ArcticSlideMountain alloc] init];<br />    house_p = [[ArcticSlideHouse alloc] init];<br />    ice_block_p = [[ArcticSlideIceBlock alloc] init];<br />    heart_p = [[ArcticSlideHeart alloc] init];<br />    bomb_p = [[ArcticSlideBomb alloc] init];<br /><br />    self = [super init];<br /><br />    for ( unsigned int idx_y = 0;<br />         idx_y < board_height; idx_y++ )<br />    {<br />        for ( unsigned int idx_x = 0;<br />             idx_x < board_width; idx_x++ )<br />        {<br />            board[idx_y][idx_x] = empty_p;<br />        }<br />    }<br /><br />    return self;<br />}<br /><br />- (id)initWithLevelIndex:(int)level_idx<br />{<br />    self = [self init];<br /><br />    // Lookup table to decode the original Polar resource<br />    // data as strings<br />    ArcticSlideTile *<br />        polar_data_tile_map[POLAR_DATA_NUM_TILE_VALS] =<br />    {<br />        empty_p, tree_p, mountain_p, house_p, ice_block_p,<br />        heart_p, bomb_p<br />    };<br /><br />    if ( level_idx > ( num_polar_levels - 1) )<br />    {<br />        NSLog(@\"initWithLevelIndex: bad level_idx %d!\\n\",<br />              level_idx);<br />    }<br />    else<br />    {<br />        unsigned int level_data_idx = 0;<br />        for ( unsigned int idx_y = 0;<br />             idx_y < board_height; idx_y++ )<br />        {<br />            for ( unsigned int idx_x = 0;<br />                 idx_x < board_width; idx_x++ )<br />            {<br />                int polar_data_tile_val =<br />                    polar_levels[level_idx]<br />                                [level_data_idx] - '0';<br />                if ( ( polar_data_tile_val < 0 ) ||<br />                     ( polar_data_tile_val > <br />                       polar_data_max_tile_val ) )<br />                {<br />                    NSLog(@\"tile value %d out of range!\\n\",<br />                          polar_data_tile_val );<br />                    self = nil;<br />                }<br />                else<br />                {<br />                    board[idx_y][idx_x] =<br />                        polar_data_tile_map[polar_data_tile_val];<br />                    level_data_idx++;<br />                }<br />            }<br />        }<br />    }<br /><br />    return self;<br /><br />}<br /><br />- (ArcticSlideTile*)getTileFromPosition:(pos_t)pos <br />                            inDirection:(dir_e)dir<br />{<br />    pos_t updated_pos = getUpdatedPos(pos, dir);<br />    if ( posValid( updated_pos ) )<br />    {<br />        return board[updated_pos.y_idx]<br />                    [updated_pos.x_idx];<br />    }<br />    else<br />    {<br />        return nil;<br />    }<br />}<br /><br />- (NSString*)description<br />{<br />    NSMutableString *desc_str =[[NSMutableString alloc]init];<br />    <br />    [desc_str appendString:@\"ArcticSlideModel board state:\\n\"];<br />    for ( unsigned int idx_y = 0;<br />         idx_y < board_height; idx_y++ )<br />    {<br />        for ( unsigned int idx_x = 0;<br />             idx_x < board_width; idx_x++ )<br />        {<br />            [desc_str appendString:[board[idx_y][idx_x] <br />                                    description]];<br />        }<br />        [desc_str appendString:@\"\\n\"];<br />    }<br />    return desc_str;<br />}<br /><br />- (void)setTileAtPosition:(pos_t)pos to:(ArcticSlideTile*)type<br />{<br />    board[pos.y_idx][pos.x_idx] = type;<br />}<br /><br />@end</pre> <p>It's not much yet, and it doesn't have any kind of user interface outside of <b>NSLog</b>, but my code will successfully respond to moving the penguin through trees, through open space, and pushing a bomb, which then moves into an open space, continues to slide until it comes up against a mountain, and destroys the mountain. I'm driving this with a test method like this:</p> <pre>NSLog(@\"%@\\n\", model_p);<br />// Penguin starts at 0,0, on a tree tile<br />pos_t penguin_pos = { 0, 0 };<br /><br />// Walk the penguin south onto another tree tile<br />ArcticSlideTile* tile_p =<br />[model_p getTileFromPosition:penguin_pos <br />                 inDirection:dir_south];<br />NSLog(@\"Penguin is facing: %@\\n\", tile_p);<br />BOOL allowed = [tile_p pushFromPosition:penguin_pos<br />                            inDirection:dir_south];<br />NSLog(@\"Penguin allowed: %s\\n\", ( allowed ? \"YES\" : \"NO\" ) );<br />tile_p = [model_p getTileFromPosition:penguin_pos<br />                              inDirection:dir_south];<br />penguin_pos = getUpdatedPos(penguin_pos, dir_south);<br />NSLog(@\"Penguin is facing: %@\\n\", tile_p);<br />    <br />// Walk the penguin east onto an empty space<br />tile_p = [model_p getTileFromPosition:penguin_pos<br />                              inDirection:dir_east];<br />NSLog(@\"Penguin is facing: %@\\n\", tile_p);<br />allowed = [tile_p pushFromPosition:penguin_pos<br />                       inDirection:dir_east];<br />NSLog(@\"Penguin allowed: %s\\n\", ( allowed ? \"YES\" : \"NO\" ) );<br />tile_p = [model_p getTileFromPosition:penguin_pos<br />                          inDirection:dir_east];<br />penguin_pos = getUpdatedPos(penguin_pos, dir_east);<br /><br />// Try walking into a bomb, which should slide<br />// and blow up a mountain<br />tile_p = [model_p getTileFromPosition:penguin_pos<br />                          inDirection:dir_east];<br />NSLog(@\"Penguin is facing: %@\\n\", tile_p);<br />allowed = [tile_p pushFromPosition:penguin_pos<br />                           inDirection:dir_east];<br />NSLog(@\"Penguin allowed: %s\\n\", ( allowed ? \"YES\" : \"NO\" ) );<br /><br />NSLog(@\"%@\\n\", model_p);</pre> <p>I'll think on this whole model of updates some more. Maybe it can be even simpler. And I have to consider how the penguin state will be managed, including its orientation (in the original, the penguin can face in the cardinal directions). Should I preserve that in a touch-driven game user interface?</p>" nil nil "92a4cbabbc70a3e2c94f290e38a2d950") (42 (20928 8813 672886) "http://feedproxy.google.com/~r/FpComplete/~3/eSA5S2IjGkc/call-for-submissions" "FP Complete: FP Complete Launches Haskell in Real World Competition" nil "Fri, 07 Jun 2013 19:18:00 +0000" "<h4>FP Complete Launches Haskell in Real World Competition with $1,000 Cash Prize Each Month</h4><p>I’m very excited to announce our Haskell in Real World contest: a call out for sample Haskell code and tutorials of real-world engineering and business solutions. Each entry consists of a working solution to an applied problem, plus accompanying tutorial material to teach others how to build similar programs.</p><p>The winning entry each month will get $1,000 cash prize. There may be multiple prizes each month or none at all if none meet the winning criteria. There are no limits on how many prizes each individual, team or group can win in any month or the duration of the contest.  In other words, you can make some serious play money here! Anyone not affiliated with FP Complete is eligible to enter.</p><p>Why are we doing this?  Simple: because the Haskell community needs to vastly expand for Haskell to become a mainstream language. To do this we must show people how to use this amazing language in solving real-world business problems. People tell us they need to see running and documented examples of real-world problems and solutions, so they can quickly see how to design their own working solutions. They also want material to show their colleagues and bosses just how useful Haskell is today.  In essence this contest intends to compile recipes which, taken together, could be seen as an applied Haskell cookbook. </p><p>The competition starts in July.  Official Rules and sign-ups will be published on our website www.fpcomplete.com at the end of June / early July.  So check back then and let the games begin!</p><div class=\"feedflare\">
<a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=eSA5S2IjGkc:l31aYdR7xbk:yIl2AUoC8zA\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=yIl2AUoC8zA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=eSA5S2IjGkc:l31aYdR7xbk:V_sGLiPBpWU\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=eSA5S2IjGkc:l31aYdR7xbk:V_sGLiPBpWU\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=eSA5S2IjGkc:l31aYdR7xbk:qj6IDK7rITs\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=qj6IDK7rITs\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=eSA5S2IjGkc:l31aYdR7xbk:gIN9vFwOqvQ\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=eSA5S2IjGkc:l31aYdR7xbk:gIN9vFwOqvQ\" border=\"0\" /></a>
</div><img src=\"http://feeds.feedburner.com/~r/FpComplete/~4/eSA5S2IjGkc\" height=\"1\" width=\"1\" />" nil nil "f4d0d1d22d9edae38c90332a407dc9bf") (41 (20928 8813 672356) "http://joyful.com/blog/2013-06-06-blog-tinkering-hledger.org.html" "Simon Michael: Blog tinkering, hledger.org" nil "Fri, 07 Jun 2013 01:00:00 +0000" "<div style=\"font-style: italic;\">June  7, 2013</div>
<h2>Blog tinkering, hledger.org</h2>
<p>
</p><h3 id=\"a-better-ghci-fix\">A better ghci fix</h3>
<p>I forgot to commit <a href=\"http://joyful.com/2013-06-05-ghci-fix.html\">last night’s ghci fix</a>, which is good because I <a href=\"https://github.com/simonmichael/hledger/commit/39f6ec9f04a5f077ac8e0f4036d81d5185c23c4a\">improved it</a> today, fixing the code duplication.</p>
<h3 id=\"blog-tinkering\">Blog tinkering</h3>
<p>Thanks to help from #hakyll, I spent some time figuring out how to safely update published blog posts without having them reappear as new on Planet Haskell. The problem seemed to be that I wasn’t setting a separate <code>updated</code> date, which caused the <code>published</code> date to change, which caused the post to reappear as new, at least in my feed reader.</p>
<p>Solution: Start blog posts with metadata like this:</p>
<pre><code>---
title:     6/6
author:    Simon Michael
published: 2013-06-06 16:00:00PDT
updated:   2013-06-06 17:00:00PDT
---</code></pre>
<h3 id=\"hledger.org\">hledger.org</h3>
<p>Worked on the next hledger backlog item, improving the website update process. Did some file cleanup and testing.</p>
<p>I found that I had broken hledger.org several days ago, when I gratuitously enhanced:</p>
<pre><code>RewriteRule ^/bugs?/?$   https://github.com/simonmichael/hledger/issues [L,NE]</code></pre>
<p>to:</p>
<pre><code>RewriteRule ^/(bugs|issues)?/?$   https://github.com/simonmichael/hledger/issues [L,NE]</code></pre>
<p>Doh. Fixed it:</p>
<pre><code>RewriteRule ^/(bugs?|issues)/?$   https://github.com/simonmichael/hledger/issues [L,NE]</code></pre>
<p>Next: yes, the cron job for updating the site is reporting an error - though it seems to successfully update the site all the same:</p>
<pre><code>From github.com:simonmichael/hledger
47ebc21..e87f492  master     -> origin/master
Updating 47ebc21..e87f492
Fast-forward
README.md |    2 +-
1 file changed, 1 insertion(+), 1 deletion(-)
cd site; ghc site.hs -L/usr/lib -package-db ~/src/joyful.com/cabal-dev/packages-*.conf
cd site; ./site build
Initialising...
Creating store...
Creating provider...
Running rules...
Checking for out-of-date items
Compiling
site: _site/README.html: commitBuffer: invalid argument (invalid character)
updated README.md
make: *** [site] Error 1</code></pre>
<p>Re-enabling <code>export LANG=en_US.UTF-8</code> in the Makefile seems to have fixed it. I have a non-ascii character in the site footer. Setting the LANG environment variable is the quick way to configure a locale, which used to be very much required to avoid encoding errors with GHC 6, but which I thought was less necessary with GHC 7. Perhaps not.</p>" nil nil "4d8695257900cef4bcf8fb4de65fc0f0") (40 (20928 8813 671629) "http://praisecurseandrecurse.blogspot.com/2013/06/objective-c-day-4.html" "Paul Potts: Objective-C, Day 4" "noreply@blogger.com (Paul Potts)" "Thu, 06 Jun 2013 19:06:00 +0000" "<p>(Warning: more non-FP content)</p> <p>It's time to get the board representation filled out with a real board. I've only got a couple of hours left before I have to pack up my computer to leave my Undisclosed Location, but let's see if I can get a little more done. Let's review what level 1 looks like:</p> <a href=\"http://4.bp.blogspot.com/-7lLSOnNaHd8/Ua4uWuQMFmI/AAAAAAAADBs/8ByFzRW9Ccs/s1600/level_1_blown_up.tiff\"><img src=\"http://4.bp.blogspot.com/-7lLSOnNaHd8/Ua4uWuQMFmI/AAAAAAAADBs/8ByFzRW9Ccs/s640/level_1_blown_up.tiff\" height=\"120\" border=\"0\" width=\"512\" /></a> <p>Level layouts are taken from the original Macintosh Polar game created by Go Endo. These were originally MacOS resources of type 'STGE.' Let's see if we can decode them. Using ResEdit, the raw data for 'STGE' resource ID -16000 looks like:</p> <pre>0x0000 0x0000 0x0003 0x0001<br />0x0000 0x0000 0x0000 0x0000<br />0x0000 0x0000 0x0000 0x0000<br />0x0000 0x0000 0x0000 0x0000<br />0x0000 0x0000 0x0001 0x0000<br />0x0000 0x0000 0x0000 0x0000<br />0x0004 0x0000 0x0000 0x0001<br />0x0000 0x0006 0x0000 0x0002<br />0x0000 0x0005 0x0004 0x0005<br />0x0000 0x0000 0x0000 0x0000<br />0x0000 0x0000 0x0000 0x0000<br />0x0000 0x0001 0x0000 0x0000<br />0x0001 0x0000 0x0000 0x0001<br />0x0000 0x0000 0x0000 0x0000<br />0x0000 0x0000 0x0000 0x0000<br />0x0000 0x0000 0x0000 0x0000<br />0x0000 0x0000 0x0000 0x0005<br />0x0000 0x0000 0x0000 0x0002<br />0x0003 0x0000 0x0000 0x0001<br />0x0001 0x0000 0x0000 0x0000<br />0x0000 0x0001 0x0000 0x0000<br />0x0000 0x0000 0x0000 0x0000<br />0x0000 0x0000 0x0000 0x0000<br />0x0000 0x0000 0x0000 0x0000<br />0x0000 0x0000 0x0000</pre> <p>There are 99 16-bit values. My best guess is that this corresponds to the 24x4 grid (96 board positions) plus 3 extras for some kind of of header of footer data (maybe the total number of hearts is indicated, for example). There are 7 unique values, so it seems extremely likely that they correspond almost exactly to our eight different tile types, with zero representing a blank space. But the counts of each type don't _quite_ match up. The first board has 8 trees, 1 bomb, 2 hearts, 2 ice blocks, 2 mountains, 3 hearts, 1 house, and 1 penguin (there is always 1 penguin), while this 'STGE' resource has: 9 ones, 2 twos, 2 threes, 2 fours, 3 fives, and 1 six. The counts are very close, so this has to represent level 1, and the the 5 almost certainly represents a heart, but I'm not clearly seeing the layout. The first vertical column goes penguin, tree, tree, tree. I don't quite see a pattern that looks like that, but resources -1599 and -15996 give me a hint that the \"extra\" data is at the front: they contain 0x0007 and 0x0008 as their third values. Those don't appear anywhere else so they probably don't indicate tiles. So let's try rearranging resource -16000 without the first 6 bytes, remove redundant zeroes for clarity, and looking at the values aligned by groups of 24 instead of 4:</p> <pre>1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 4 0 0<br />1 0 6 0 2 0 5 4 5 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0<br />1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 2 3 0 0<br />1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</pre> <p>There's the board. The left column is actually all trees -- when the board first appears, the penguin is hiding a tree. There are actually nine trees. So the encoding looks like so: empty space = 0, tree = 1, mountain = 2, home = 3, ice block = 4, heart = 5, and bomb = 6. The penguin doesn't have a value, but his starting position is probably represented by the first two values, (0,0), most likely encoded as row index, column index to correspond to row-major indexing, and there are 3 hearts to count down as the game is solved.</p> <p>Can we validate this with the second board? Yes, it looks like there's a 4 indicating 4 hearts. In all the boards I've seen so far (the first four), the penguin is in the upper left. The fifth resource has 0, 1 for its first two values, so I'm guessing I can confirm the encoding of the penguin's position if and when I get to that stage.</p> <p>And now to come up with a quick way to populate the board in my code. As I'm still a complete n00b in Objective-C, and on the general principle that there's no real need to make this any more clever or less obvious than it has to be, let's just use a string with the data from the resource. Let's add an init method to the interface for the model class:</p> <pre>- (id)initWithLevelIndex:(int)level_idx;</pre> <p>And here is some data, and an initializer method:</p> <pre>static const int num_polar_levels = 1;<br />static const int polar_data_len = 96;<br />static const int polar_data_num_tile_vals = 7; // 0-6 inclusive<br />static const int polar_data_max_tile_val = 6;<br />static const NSString *polar_levels[num_polar_levels] =<br />{<br />    @\"100000000000000100000400\" \\<br />    @\"106020545000000000100100\" \\<br />    @\"100000000000000050002300\" \\<br />    @\"110000100000000000000000\"<br />};<br /><br />- (id)initWithLevelIndex:(int)level_idx<br />{<br />    // Call our own basic initializer. This will <br />    // result in redundant setting of board values,<br />    // but maybe I will clean that up later.<br />    self = [self init];<br /><br />    // A simple lookup table to decode the original<br />    // Polar resource data as strings<br />    ArcticSlideTile <br />        *polar_data_tile_map[polar_data_num_tile_vals] = {<br />        empty, tree, mountain, house,<br />        ice_block, heart, bomb };<br /><br />    if ( level_idx > ( num_polar_levels - 1) )<br />    {<br />        NSLog( @\"initWithLevelLayout: level %d out of range!\\n\",<br />               level_idx );<br />        self = nil;<br />    }<br />    else<br />    {<br />        const NSString* level_str = polar_levels[level_idx];<br />        unsigned int level_data_idx = 0;<br />        for ( unsigned int idx_y = 0;<br />             idx_y < board_height; idx_y++ )<br />        {<br />            for ( unsigned int idx_x = 0;<br />                 idx_x < board_width; idx_x++ )<br />            {<br />                NSRange range = NSMakeRange(level_data_idx, 1);<br />                const NSString * item_str =<br />                    [level_str substringWithRange: range];<br />                int polar_data_tile_val = [item_str intValue];<br />                if ( polar_data_tile_val ><br />                    polar_data_max_tile_val )<br />                {<br />                    NSLog(@\"tile val %d out of range!\\n\",<br />                        polar_data_tile_val );<br />                    self = nil;<br />                }<br />                else<br />                {<br />                    board[idx_y][idx_x] =<br />                        polar_data_tile_map[polar_data_tile_val];<br />                    level_data_idx++;<br />                }<br />            }<br />        }<br />    }<br />    return self;<br />}<br /></pre> <p>Hmmm, that seems overly complicated. There probably is a better, more idiomatic Objective-C way to use NSStrings for that, but I'm tempted to just write it with a basic C string. Using NSString objects in this context didn't even really help me catch bugs or avoid crashes, since I had forgotten to initialize a heart object and the result was hitting a nil object pointer at runtime and crashing, pretty much the same result as dereferencing a null pointer in straight C except with a better error logged. I'm a little disconcerted by Objective-C's inability to allocate objects on the stack, but that comes down to the aforementioned \"thin veneer\" over C. I don't really care about the overhead in using method dispatch in this simple piece of code operating on such a small amount of data, but I do care about simplicity. Just to compare, here's a more straightforward C implementation of that inner loop:</p> <pre>static const char *polar_levels[num_polar_levels] =<br />{<br />    \"100000000000000100000400\"<br />    \"106020545000000000100100\"<br />    \"100000000000000050002300\"<br />    \"110000100000000000000000\"<br />};<br /><br />int polar_data_tile_val = level_str_p[level_data_idx] - '0';<br />if ( ( polar_data_tile_val < 0 ) || <br />     ( polar_data_tile_val > <br />       polar_data_max_tile_val ) )<br />{<br />    NSLog(@\"polar data tile value %d out of range!\\n\",<br />          polar_data_tile_val );<br />    self = nil<br />}</pre> <p>Maybe the lesson here is \"use Objective-C objects only when objects are a win.\"</p> <p>I'm going to continue with this project, developing the code to handle the interactions of objects on the playing field and eventually the user interface. However, now that my week away from home is done, I might not be able to make progress very quickly. Stay tuned -- I'll post what I can, when I can. As always, if you have any comments or questions, I'm happy to have feedback.</p>" nil nil "41c78c39e640d6957aba75d69a3d693e") (39 (20928 8813 669969) "http://tomschrijvers.blogspot.com/2013/06/ppdp-13-last-call-for-papers.html" "Tom Schrijvers: PPDP '13: Last Call for Papers" "noreply@blogger.com (Tom Schrijvers)" "Thu, 06 Jun 2013 15:56:18 +0000" "<div style=\"text-align: left;\" dir=\"ltr\"><br />=====================================================================<br /><br />                        Last Call for papers<br />               15th International Symposium on<br />       Principles and Practice of Declarative Programming<br />                           PPDP 2013<br /><br /><span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Special Issue of Science of Computer Programming (SCP)<br /><br />            Madrid, Spain, September 16-18, 2013<br />                 (co-located with LOPSTR 2013)<br /><br />              http://users.ugent.be/~tschrijv/PPDP2013/<br /><br />======================================================================<br /><br />PPDP 2013 is a forum that brings together researchers from the declarative<br />programming communities, including those working in the logic, constraint and<br />functional programming paradigms, but also embracing a variety of other<br />paradigms such as visual programming, executable specification languages,<br />database languages, and knowledge representation languages.<br /><br />The goal is to stimulate research in the use of logical formalisms and methods<br />for specifying, performing, and analysing computations, including mechanisms<br />for mobility, modularity, concurrency, object-orientation, security,<br />verification and static analysis. Papers related to the use of declarative<br />paradigms and tools in industry and education are especially solicited. Topics<br />of interest include, but are not limited to:<br /><br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Functional programming<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Logic programming<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Answer-set programming<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Functional-logic programming<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Declarative visual languages<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Constraint Handling Rules<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Parallel implementation and concurrency<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Monads, type classes and dependent type systems<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Declarative domain-specific languages<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Termination, resource analysis and the verification of declarative programs<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Transformation and partial evaluation of declarative languages<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Language extensions for security and tabulation<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Probabilistic modelling in a declarative language and modelling reactivity<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Memory management and the implementation of declarative systems<br />*<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Practical experiences and industrial application<br /><br />This year the conference will be co-located with the 23nd International<br />Symposium on Logic-Based Program Synthesis and Transformation (LOPSTR 2013) and<br />held in cooperation with ACM SIGPLAN.  The conference will be held in Madrid,<br />Spain. Previous symposia were held at Leuven (Belgium), Odense (Denmark),<br />Hagenberg (Austria), Coimbra (Portugal), Valencia (Spain), Wroclaw (Poland),<br />Venice (Italy), Lisboa (Portugal), Verona (Italy), Uppsala (Sweden), Pittsburgh<br />(USA), Florence (Italy), Montreal (Canada), and Paris (France).<br /><br />Papers must describe original work, be written and presented in English, and<br />must not substantially overlap with papers that have been published or that are<br />simultaneously submitted to a journal, conference, or workshop with refereed<br />proceedings. Work that already appeared in unpublished or informally published<br />workshop proceedings may be submitted (please contact the PC chair in case of<br />questions).  Proceedings will be published in the ACM International Conference<br />Proceedings Series.<br /><br /><br />After the symposium, a selection of the best papers will be invited to extend<br />their submissions in the light of the feedback solicited at the symposium.  The<br />papers are expected to include at least 30% extra material over and above the<br />PPDP version. Then, after another round of reviewing, these revised papers will<br />be published in a special issue of SCP with a target publication date by<br />Elsevier of 2014.<br /><br />Important Dates<br /><br /><span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Abstract Submission: <span style=\"white-space: pre;\" class=\"Apple-tab-span\">  </span>June 10, 2013<br /><span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Paper submission: <span style=\"white-space: pre;\" class=\"Apple-tab-span\">  </span>June 13, 2013<br /><span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Notification: <span style=\"white-space: pre;\" class=\"Apple-tab-span\">   </span>July 18, 2013<br /><span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Camera-ready: <span style=\"white-space: pre;\" class=\"Apple-tab-span\">   </span>August 4, 2013<br /><br /><span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Symposium: <span style=\"white-space: pre;\" class=\"Apple-tab-span\">   </span>September 16-18, 2013 <br /><br /><span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Invites for SCP: <span style=\"white-space: pre;\" class=\"Apple-tab-span\">  </span>October 2, 2013<br /><span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Submission of SCP: <span style=\"white-space: pre;\" class=\"Apple-tab-span\">  </span>December 11, 2013<br /><span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Notification from SCP: <span style=\"white-space: pre;\" class=\"Apple-tab-span\">  </span>February 22, 2014<br /><span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>Camera-ready for SCP: <span style=\"white-space: pre;\" class=\"Apple-tab-span\">  </span>March 14, 2014<br /><br />Authors should submit an electronic copy of the paper (written in English) in<br />PDF.  Each submission must include on its first page the paper title; authors<br />and their affiliations; abstract; and three to four keywords. The keywords will<br />be used to assist us in selecting appropriate reviewers for the paper. Papers<br />should consist of no more than 12 pages, formatted following the ACM SIG<br />proceedings template (option 1). The 12 page limit must include references but<br />excludes well-marked appendices not intended for publication. Referees are not<br />required to read the appendices, and thus papers should be intelligible without<br />them.<br /><br />Program Committee<br /><br />Sergio Antoy               Portland State University, USA<br />Manuel Carro               IMDEA Software Institute, Spain<br />Iliano Cervesato           Carnegie Mellon University, Qatar<br />Agostino Dovier            Universita degli Studi di Udine, Italy<br />Maria Garcia de la Banda   Monash University, Australia<br />Ralf Hinze                 University of Oxford, UK<br />Yukiyoshi Kameyama         University of Tsukuba, Japan<br />Oleg Kiselyov              USA<br />Yanhong Annie Liu          State University of New York at Stony Brook, USA<br />Stefan Monnier             Universite de Montreal, Canada<br />Alan Mycroft               University of Cambrige, UK<br />Bruno C. d. S. Oliveira<span style=\"white-space: pre;\" class=\"Apple-tab-span\"> </span>   National University of Singapore, Singapore<br />Alberto Pettorossi         Universita di Roma Tor Vergata, Italy<br />Enrico Pontelli            New Mexico State University, USA<br />Kristoffer Rose            IBM Research, USA<br />Sukyoung Ryu               KAIST, South Korea<br />Vitor Santos Costa         University of Porto, Portugal<br />Torsten Schaub             University Potsdam, Germany<br />Tom Schrijvers             Ghent University, Belgium<br />Martin Sulzmann            Hochschule Karlsruhe, Germany<br />Wouter Swierstra           Universiteit Utrecht, The Netherlands<br />Tarmo Uustalu              Institute of Cybernetics, Estonia<br />Janis Voigtlaender         University of Bonn, Germany<br />Meng Wang                  Chalmers University of Technology, Sweden<br />Jan Wielemaker             Universiteit van Amsterdam, The Netherlands<br /><br />Program Chair<br /><br />    Tom Schrijvers<br />    Department of Applied Mathematics and Computer Science<br />    Ghent University<br />    9000 Gent, Belgium<br /><br />General Chair<br /><br />    Ricardo Pena<br />    Facultad de Informatica<br />    Universidad Complutense de Madrid<br />    28040 Madrid, Spain<br /><div><br /></div></div>" nil nil "49eca3a9517b1439879b36c3d00d63ae") (38 (20928 8813 668458) "http://joyful.com/blog/2013-06-05-ghci-fix.html" "Simon Michael: GHCI fix" nil "Thu, 06 Jun 2013 06:00:00 +0000" "<div style=\"font-style: italic;\">June  6, 2013</div>
<h2>GHCI fix</h2>
<p>
</p><p><a href=\"http://joyful.com/2013-06-04-bugfix-planning-autoweb.html\">Yesterday</a>.</p>
<p>Today:</p>
<p>Next item on the 0.22 backlog: fix <code>make ghci</code> and <code>make ghciweb</code>.</p>
<p>The goal of these make rules is to bring up a GHCI prompt with as much as possible of the guts of hledger (or hledger-web) loaded, in scope, and visible. This can be really valuable for debugging, sanity-checking, and exploratory development, but it’s quite hard to set up by hand, as the necessary flags tend to proliferate. Hence these rules.</p>
<p>The latest breakage was due to my using cabal’s MIN_version_* macros (to make Hledger.Cli.Utils compatible with both the versions of directory currently found on user machines). It’s hard to ensure these macros are available in all circumstances (sp/ghc builds, haddock, ghci..) So I’ve made it work with or without them, with this not-very-pretty kludge:</p>
<pre class=\"sourceCode haskell\"><code class=\"sourceCode haskell\"><span class=\"fu\">#</span>ifdef <span class=\"dt\">MIN_VERSION_directory</span>
<span class=\"fu\">#</span>if <span class=\"dt\">MIN_VERSION_directory</span>(<span class=\"dv\">1</span>,<span class=\"dv\">2</span>,<span class=\"dv\">0</span>)
utc <span class=\"ot\"><-</span> getModificationTime f
<span class=\"kw\">let</span> nom <span class=\"fu\">=</span> utcTimeToPOSIXSeconds utc
<span class=\"kw\">let</span> clo <span class=\"fu\">=</span> <span class=\"dt\">TOD</span> (<span class=\"fu\">read</span> <span class=\"fu\">$</span> <span class=\"fu\">takeWhile</span> (<span class=\"ot\">`elem`</span> <span class=\"st\">\"0123456789\"</span>) <span class=\"fu\">$</span> <span class=\"fu\">show</span> nom) <span class=\"dv\">0</span> <span class=\"co\">-- XXX read</span>
<span class=\"fu\">#</span>else
clo <span class=\"ot\"><-</span> getModificationTime f
<span class=\"fu\">#</span>endif
<span class=\"fu\">#</span>else
<span class=\"co\">-- cabal macros aren't available, assume the new directory</span>
utc <span class=\"ot\"><-</span> getModificationTime f
<span class=\"kw\">let</span> nom <span class=\"fu\">=</span> utcTimeToPOSIXSeconds utc
<span class=\"kw\">let</span> clo <span class=\"fu\">=</span> <span class=\"dt\">TOD</span> (<span class=\"fu\">read</span> <span class=\"fu\">$</span> <span class=\"fu\">takeWhile</span> (<span class=\"ot\">`elem`</span> <span class=\"st\">\"0123456789\"</span>) <span class=\"fu\">$</span> <span class=\"fu\">show</span> nom) <span class=\"dv\">0</span> <span class=\"co\">-- XXX read</span>
<span class=\"fu\">#</span>endif</code></pre>
<p>And now I’ve got ghci prompts again. It looks like they could do some more importing though:</p>
<pre><code>~/src/hledger$ make ghciweb
ghci -rtsopts -W -fwarn-tabs -fno-warn-unused-do-bind -fno-warn-name-shadowing  -ihledger-lib -ihledger -ihledger-web -ihledger-web/app -L/usr/lib  -optP-include -optPhledger/dist/build/autogen/cabal_macros.h -DPATCHLEVEL=0 -DDEVELOPMENT -DVERSION='\"0.21.2dev\"' -XCPP -XMultiParamTypeClasses -XOverloadedStrings -XQuasiQuotes -XRecordWildCards -XTemplateHaskell  hledger-web/app/main.hs
GHCi, version 7.6.3: http://www.haskell.org/ghc/  :? for help
Loading package ghc-prim ... linking ... done.
Loading package integer-gmp ... linking ... done.
Loading package base ... linking ... done.
[ 1 of 52] Compiling Settings.Development ( hledger-web/Settings/Development.hs, interpreted ) [flags changed]
[ 2 of 52] Compiling Settings         ( hledger-web/Settings.hs, interpreted ) [flags changed]
Loading package array-0.4.0.1 ... linking ... done.
...
[52 of 52] Compiling Main             ( hledger-web/app/main.hs, interpreted )
Ok, modules loaded: Hledger, Hledger.Data, Hledger.Data.Account, Hledger.Data.AccountName, Hledger.Data.Amount, Hledger.Data.Commodity, Hledger.Data.Dates, Hledger.Data.FormatStrings, Hledger.Data.Journal, Hledger.Data.Ledger, Hledger.Data.Posting, Hledger.Data.TimeLog, Hledger.Data.Transaction, Hledger.Data.Types, Hledger.Query, Hledger.Read, Hledger.Read.CsvReader, Hledger.Read.JournalReader, Hledger.Read.TimelogReader, Hledger.Reports, Hledger.Utils, Hledger.Utils.UTF8IOCompat, Hledger.Cli, Hledger.Cli.Options, Hledger.Cli.Utils, Hledger.Cli.Version, Hledger.Cli.Add, Hledger.Cli.Balance, Hledger.Cli.Balancesheet, Hledger.Cli.Cashflow, Hledger.Cli.Histogram, Hledger.Cli.Incomestatement, Hledger.Cli.Print, Hledger.Cli.Register, Hledger.Cli.Stats, Application, Foundation, Import, Settings, Settings.StaticFiles, Settings.Development, Handler.Common, Handler.JournalEditR, Handler.JournalEntriesR, Handler.JournalR, Handler.Post, Handler.RegisterR, Handler.RootR, Handler.Utils, Hledger.Web.Main, Hledger.Web.Options, Main.
>>> :t defbaseurl
<interactive>:1:1: Not in scope: `defbaseurl'
>>> import Settings
>>> :t defbaseurl
defbaseurl :: GHC.Types.Int -> GHC.Base.String
>>> </code></pre>" nil nil "dffa59e484adb1e97a4ff03431954918") (37 (20928 8813 667392) "http://praisecurseandrecurse.blogspot.com/2013/06/objective-c-day-3.html" "Paul Potts: Objective-C, Day 3" "noreply@blogger.com (Paul Potts)" "Wed, 05 Jun 2013 05:05:00 +0000" "<p>(Warning: non-FP content)</p> <p>So, this is day 5 in my Undisclosed Location and I haven't gotten much done -- I'm still engaged in a job search, and spent about eight hours working on a \"take-home test\" for an employer (with a few interruptions), and I'm pursuing more leads, and I'm trying to socialize with my hosts occasionally, so there are some distractions. But I've got enough information to go on to start implementing something original.</p> <p>What I want to implement is a small game. I'll get as far as I can in the back-end code today (the Model and Controller parts of the MVC \"trinity\") and we'll see just how productive I really am in Objective-C. I read most of Objective-C Programming by Aaron Hillegass last night -- it's a very quick read for someone well-versed in C, and it reiterates parts of the iOS Programming book. I haven't covered protocols, categories, blocks, or run loops, but I think I can get by without those things for now.</p> <p>Many years ago there existed on old-school MacOS a small game called \"Polar.\" It was a very simple game, written by a guy (Go Endo) who was probably a student at the time, but I was fond of it -- fond enough to save it for 23 years, with the intention of studying its design and re-implementing it in the future. (In fact, I've saved a lot of old bits and bobs like this). I made notes of how to beat the first 3 levels (it was one of those \"incredibly simple game play, but maddeningly tricky\" games), drew out the levels, made notes on how the objects behaved, etc. I haven't been able to run that game for a long time, but today I just got it working under SheepShaver. Here's what level 1 looks like (blown up a bit):</p> <a href=\"http://4.bp.blogspot.com/-7lLSOnNaHd8/Ua4uWuQMFmI/AAAAAAAADBs/8ByFzRW9Ccs/s1600/level_1_blown_up.tiff\"><img src=\"http://4.bp.blogspot.com/-7lLSOnNaHd8/Ua4uWuQMFmI/AAAAAAAADBs/8ByFzRW9Ccs/s640/level_1_blown_up.tiff\" height=\"120\" border=\"0\" width=\"512\" /></a> <p>The penguin is your avatar. The rest of the objects are ice blocks, trees, hearts, bombs, mountains, and houses. The world is a sheet of ice. You can walk around on the ice. You can walk through trees. Some objects (trees, mountains, and houses) can't be moved. Bombs, hearts, and ice blocks move without friction -- if you push them, they will keep going until they hit the edge of the world or another object. If an sliding ice block hits another object, it stops. If you push it against another object, it crumbles and disappears. The penguin can walk through trees, but other objects can't. Bombs will blow up mountains when they slide into them. Everything else simply stops them. The goal of the game is to slide all the hearts into a house (cute, huh?) But because the ice is frictionless, it's incredibly easy to get objects stuck against walls or corners where you can no longer move them the way you need to. So you have to carefully plan out your moves, and if you get stuck, there's an option to start the level over.</p> <p>I should mention that the original game had a copyright notice (1990), and was shareware ($2.00). I can't remember if I ever sent the author $2.00. I'm not sure how he would feel about me taking apart and trying to re-implement his game, or whether he'd try to assert that copyright prevented me from doing so, but I'll assume he's a  nice guy and wouldn't care as long as I don't charge for it, and go ahead, on the theory that easier to ask forgiveness than permission. I was not able to find him online -- maybe \"Go Endo\" was a pseudonym?</p> <p>Back in 1991 I came up with a C++ class design (actually, it doesn't quite look like C++; I think it was written using THINK C's object-oriented extensions, which are sort of lost in the mists of time to me -- what is that <b>indirect</b> keyword? What did <b>#pragma options(virtual)</b> do? I don't remember for sure, but let's see if we can come up with an Objective-C implementation. The objects, other than the penguin, which can face in different directions, don't seem to have any real distinct properties except for their locations in the board, so I'm tempted not to take the obvious route and implement a board full of instances of the objects. I'm more inclined to just define a class for the board, and let it encapsulate most of the game logic. For the objects themselves, I'd like to just make references (pointers) to their classes (the class object) rather than putting them in a container. That's apparently not really possible -- there are no predefined singletons for the class objects that are accessible at run-time the way there are for NSNull. So I have to make some (sort of) singletons.</p> <p>Here's what I've got today:</p> <pre>@interface ArcticSlideTile : NSObject<br />// Not necessarily useful yet, but I am guessing it might<br />// be helpful to have a separate base class at some point.<br />@end<br /><br />@interface ArcticSlideTileStateless : ArcticSlideTile<br />// In implementation, there will be a single shared instance.<br />@end<br /><br />@interface ArcticSlideBomb : ArcticSlideTileStateless<br />// Bombs can be pushed and will slide until they<br />// hit an object and stop. If the object is a mountain,<br />// both bomb and mountain are destroyed and<br />// there should be an animation. If another object<br />// hits a bomb it stops (I'm not sure you can test this<br />// combination in the original game with the board layouts<br />// available<br />- (NSString*) description;<br />@end<br /><br />@interface ArcticSlideEmpty : ArcticSlideTileStateless<br />// The penguin can walk on empty space. Pushable objects<br />// on empty space are on ice and they slide until something<br />// stops them.<br />- (NSString*) description;<br />@end<br /><br />@interface ArcticSlideHeart : ArcticSlideTileStateless<br />// When a heart hits a house the heart disappears (getting<br />// all the hearts into the house is how you win the game).<br />// Otherwise they cannot be destroyed, and slide like other<br />// slidable items.<br />- (NSString*) description;<br />@end<br /><br />@interface ArcticSlideHouse : ArcticSlideTileStateless<br />// Houses cannot be pushed and stop other objects<br />// except hearts. When a heart hits a house the heart<br />// disappears (getting the hearts into the house is<br />// how you win the game). So the model should keep track<br />// of the number of hearts on the board and trigger a<br />// \"win the level\" behavior when the last heart is <br />// destroyed.<br />- (NSString*) description;<br />@end<br /><br />@interface ArcticSlideIceBlock : ArcticSlideTileStateless<br />// Ice blocks can be pushed and will slide until they<br />// hit an object and stop. If they are pushed directly<br />// against an object they will be crushed (there should<br />// be an animation) and disappear.<br />- (NSString*) description;<br />@end<br /><br />@interface ArcticSlideMountain : ArcticSlideTileStateless<br />// Mountains cannot be moved and are destroyed by bombs.<br />- (NSString*) description;<br />@end<br /><br />@interface ArcticSlidePenguin : ArcticSlideTile<br />// The penguin is the avatar. It has the special<br />// quality of being able to face different directions<br />// in the original game, although that's because you <br />// can click near him to turn him and make him walk in<br />// different directions. In a touchscreen implementation<br />// I'm not sure how this should be implemented -- maybe<br />// he can slide in discreet steps. The penguin has the<br />// ability to walk through trees. We might want to <br />// implement this temporary state using using an<br />// \"override\" object reference in the model. Sliding<br />// objects might be implemented the same way.<br />typedef enum {<br />    north, south, east, west<br />}penguinDirection_e;<br /><br />@property penguinDirection_e facing;<br />- (NSString*) description;<br />@end<br /><br />@interface ArcticSlideTree : ArcticSlideTile<br />// Trees cannot be pushed or destroyed and stop<br />// all sliding objects, but the penguin avatar <br />// character can walk through them.<br />- (NSString*) description;<br />@end<br /><br />static const int board_width = 24, board_height = 4;<br />// The short board design is part of what makes it<br />// so easy to get sliding objects stuck against the<br />// edges of the world or in corners where you can no longer<br />// get around to the other side to push them. We could<br />// consider a bigger board later and maybe implement the<br />// original puzzles surrounded by impassible water.<br /><br />@interface ArcticSlideModel : NSObject<br />{<br />    ArcticSlideTile* board[board_height][board_width];<br />}<br /><br />- (id)init;<br />- (NSString*) description;<br /><br />@end<br /><br />@implementation ArcticSlideTile<br />{<br />}<br />@end<br /><br />@implementation ArcticSlideTileStateless<br />{<br />}<br />@end<br /><br />@implementation ArcticSlideBomb<br />- (NSString*) description<br />{<br />    return @\"Bomb\";<br />}<br />@end<br /><br />@implementation ArcticSlideEmpty<br />- (NSString*) description<br />{<br />    return @\"Empty\";<br />}<br />@end<br /><br />@implementation ArcticSlideHouse<br />- (NSString*) description<br />{<br />    return @\"House\";<br />}<br />@end<br /><br />@implementation ArcticSlideIceBlock<br />- (NSString*) description<br />{<br />    return @\"Ice Block\";<br />}<br />@end<br /><br />@implementation ArcticSlideMountain<br />- (NSString*) description<br />{<br />    return @\"Mountain\";<br />}<br />@end<br /><br />@implementation ArcticSlidePenguin<br />- (NSString*) description<br />{<br />    return @\"Mountain\";<br />}<br />@end<br /><br />@implementation ArcticSlideTree<br />- (NSString*) description<br />{<br />    return @\"Tree\";<br />}<br />@end<br /><br />@implementation ArcticSlideModel<br />{<br />    ArcticSlideBomb *bomb;<br />    ArcticSlideEmpty *empty;<br />    ArcticSlideHeart *heart;<br />    ArcticSlideHouse *house;<br />    ArcticSlideIceBlock *ice_block;<br />    ArcticSlideMountain *mountain;<br />    ArcticSlidePenguin *penguin;<br />    ArcticSlideTree* tree;<br /><br />}<br />- (id)init<br />{<br />    bomb = [[ArcticSlideBomb alloc] init];<br />    empty = [[ArcticSlideEmpty alloc] init];<br />    heart = [[ArcticSlideHeart alloc] init];<br />    house = [[ArcticSlideHouse alloc] init];<br />    ice_block = [[ArcticSlideIceBlock alloc] init];<br />    mountain = [[ArcticSlideMountain alloc] init];<br />    penguin = [[ArcticSlidePenguin alloc] init];<br />    tree = [[ArcticSlideTree alloc] init];<br /><br />    for ( unsigned int idx_y = 0;<br />         idx_y < board_height; idx_y++ )<br />    {<br />        for ( unsigned int idx_x = 0;<br />             idx_x < board_width; idx_x++ )<br />        {<br />            board[idx_y][idx_x] = empty;<br />        }<br />    }<br />    return self;<br />}<br /><br />- (NSString*)description<br />{<br />    NSMutableString *desc_str =<br />        [[NSMutableString alloc]init];<br />    <br />    [desc_str appendString:@\"ArcticSlideModel board state:\\n\"];<br />    for ( unsigned int idx_y = 0;<br />         idx_y < board_height; idx_y++ )<br />    {<br />        for ( unsigned int idx_x = 0;<br />             idx_x < board_width; idx_x++ )<br />        {<br />            [desc_str<br />             appendString:[board[idx_y][idx_x] description]];<br />            [desc_str appendString:@\" \"];<br />        }<br />        [desc_str appendString:@\"\\n\"];<br />    }<br />    return desc_str;<br />}<br /><br />@end<br /></pre> <p>My quiet time at my undisclosed location ends tomorrow. I'm not sure I'll be able to get back to this for a few days. I haven't gotten nearly as much done with this as I've hoped. I've been distracted by a lot of job-search things. But hey, it's a start!</p>" nil nil "ef3201d94d907cc7e80b5df5a252573b") (36 (20928 8813 665064) "http://twdkz.wordpress.com/2013/05/31/data-analysis-with-monoids/" "Tim Docker: Data analysis with Monoids" nil "Tue, 04 Jun 2013 22:05:36 +0000" "<p>This post expresses the key ideas of a talk I gave at FP-SYD this week.</p>
<p><a href=\"http://www.haskell.org/ghc/docs/latest/html/libraries/base/Data-Monoid.html\">Monoids</a> are a pretty simple concept in haskell. Some years ago I learnt of them through the excellent <a href=\"http://www.haskell.org/haskellwiki/Typeclassopedia\">Typeclassopedia</a>, looked at the examples, and understood them quickly (which is more than can be said for many of the new ideas that one learns in haskell). However that was it. Having learnt the idea, I realised that monoids are everywhere in programming, but I’d not found much use for the Monoid typeclass abstraction itself. Recently, I’ve found they can be a useful tool for data analysis…</p>
<h2 id=\"monoids\">Monoids</h2>
<p>First a quick recap. A monoid is a type with a binary operation, and an identity element:</p>
<pre><code>class Monoid a where
mempty :: a
mappend :: a -> a -> a</code></pre>
<p>It must satisfy a simple set of laws, specifically that the binary operation much be associative, and the identity element must actually be the identity for the given operation:</p>
<pre><code>mappend a (mappend b c) = mappend (mappend a b) c
mappend mempty x = x
mappend x mempty = x</code></pre>
<p>As is hinted by the names of the typeclass functions, lists are an obvious Monoid instance:</p>
<pre><code>instance Monoid [a] where
mempty  = []
mappend = (++)</code></pre>
<p>However, many types can be Monoids. In fact, often a type can be a monoid in multiple ways. Numbers are monoids under both addition and multiplication, with 0 and 1 as their respective identity elements. In the haskell standard libraries, rather than choose one kind of monoid for numbers, newtype declarations are used to given instances for both:</p>
<pre><code>newtype Sum a = Sum { getSum :: a }
deriving (Eq, Ord, Read, Show, Bounded)
instance Num a => Monoid (Sum a) where
mempty = Sum 0
Sum x `mappend` Sum y = Sum (x + y)
newtype Product a = Product { getProduct :: a }
deriving (Eq, Ord, Read, Show, Bounded)
instance Num a => Monoid (Product a) where
mempty = Product 1
Product x `mappend` Product y = Product (x * y)</code></pre>
<p>We’ve now established and codified the common structure for a few monoids, but it’s not yet clear what it has gained us. The Sum and Product instances are unwieldly – you are unlikely to want to use Sum directly to add two numbers:</p>
<pre><code>Prelude> :m Data.Monoid
Prelude Data.Monoid> 5+4
9
Prelude Data.Monoid> getSum (mappend (Sum 5) (Sum 4))
9</code></pre>
<p>Before we progress, however, let’s define a few more monoid instances, potentially useful for data analysis.</p>
<pre><code>data Min a = Min a | MinEmpty deriving (Show)

data Max a = Max a | MaxEmpty deriving (Show)
newtype Count = Count Int deriving (Show)
instance (Ord a) => Monoid (Min a) where
mempty = MinEmpty
mappend MinEmpty m = m
mappend m MinEmpty = m
mappend (Min a) (Min b) = (Min (P.min a b))
instance (Ord a) => Monoid (Max a) where
mempty = MaxEmpty
mappend MaxEmpty m = m
mappend m MaxEmpty = m
mappend (Max a) (Max b) = (Max (P.max a b))
instance Monoid Count where
mempty = Count 0
mappend (Count n1) (Count n2) = Count (n1+n2)</code></pre>
<p>Also some helper functions to construct values of all these monoid types:</p>
<pre><code>sum :: (Num a) => a -> Sum a
sum = Sum
product :: (Num a) => a -> Product a
product = Product
min :: (Ord a) => a -> Min a
min = Min
max :: (Ord a) => a -> Max a
max = Max
count :: a -> Count
count _ = Count 1</code></pre>
<p>These functions are trivial, but they put a consistent interface on creating monoid values. They all have a signature (a -> m) where m is some monoid. For lack of a better name, I’ll call functions with such signatures \"monoid functions\".</p>
<h2 id=\"foldable\">Foldable</h2>
<p>It’s time to introduce another typeclass, <a href=\"http://www.haskell.org/ghc/docs/latest/html/libraries/base/Data-Foldable.html\">Foldable</a>. This class abstracts the classic foldr and foldl functions away from lists, making them applicable to arbitrary structures. (There’s a robust debate going on right now about the merits of replacing the list specific fold functions in the standard prelude with the more general versions from Foldable.) Foldable is a large typeclass – here’s the key function of interest to us:</p>
<pre><code>class Foldable t where
...
foldMap :: Monoid m => (a -> m) -> t a -> m
...</code></pre>
<p>foldMap takes a monoid function and a Foldable structure, and reduces the structure down to a single value of the monoid. Lists are, of course, instances of foldable, so we can demo our helper functions:</p>
<pre><code>*Examples> let as = [45,23,78,10,11,1]
*Examples> foldMap count as
Count 6
*Examples> foldMap sum as
Sum {getSum = 168}
*Examples> foldMap max as
Max 78</code></pre>
<p>Notice how the results are all still wrapped with the newtype constructors. We’ll deal with this later.</p>
<h2 id=\"composition\">Composition</h2>
<p>As it turns out, tuples are already instances of Monoids:</p>
<pre><code>instance (Monoid a,Monoid b) => Monoid (a,b) where
mempty = (mempty,mempty)
mappend (a1,b1) (a2,b2) = (mappend a1 a2,mappend b1 b2)</code></pre>
<p>A pair is a monoid if it’s elements are monoids. There are similar instances for longer tuples. We need some helper monoid functions for tuples also:</p>
<pre><code>a2 :: (a -> b) -> (a -> c) -> a -> (b,c)
a2 b c = (,) <$> b <*> c
a3 :: (a -> b) -> (a -> c) -> (a -> d) -> a -> (b,c,d)
a3 b c d = (,,) <$> b <*> c <*> d</code></pre>
<p>These are implemented above using <a href=\"http://www.haskell.org/ghc/docs/latest/html/libraries/base/Control-Applicative.html\">Applicative</a> operators, though I’ve given them more restrictive types to make their intended use here clearer. Now I can compose monoid functions:</p>
<pre><code>*Examples> let as = [45,23,78,10,11,1]
*Examples> :t (a2 min max)
(a2 min max) :: Ord a => a -> (Min a, Max a)
*Examples> foldMap (a2 min max) as
(Min 1,Max 78)
*Examples> :t (a3 count (a2 min max) (a2 sum product))
(a3 count (a2 min max) (a2 sum product))
:: (Num a, Ord a) =>
a -> (Count, (Min a, Max a), (Sum a, Product a))
*Examples> foldMap (a3 count (a2 min max) (a2 sum product)) as
(Count 6,(Min 1,Max 78),(Sum {getSum = 168},Product {getProduct = 8880300}))</code></pre>
<p>It’s worth noting here that the composite computations are done in a single traversal of the input list.</p>
<h2 id=\"more-complex-calculations\">More complex calculations</h2>
<p>Happy with this, I decide to extend my set of basic computations with the arithmetic mean. There is a problem, however. The arithmetic mean doesn’t \"fit\" as a monoid – there’s no binary operation such that a mean for a combined set of data can be calculated from the mean of two subsets.</p>
<p>What to do? Well, the mean is the sum divided by the count, both of which are monoids:</p>
<pre><code>newtype Mean a = Mean (Sum a,Count) deriving (Show)
instance (Num a) => Monoid (Mean a) where
mempty = Mean mempty
mappend (Mean m1) (Mean m2) = Mean (mappend m1 m2)
mean v = Mean (Sum v,Count 1)</code></pre>
<p>So I can calculate the mean if I am prepared to do a calculation after the foldMap:</p>
<pre><code>*Examples> let as = [45,23,78,10,11,1.5]
*Examples> foldMap mean as
Mean (Sum {getSum = 168.5},Count 6)
*Examples> let (Mean (Sum t,Count n)) = foldMap mean as in t / fromIntegral n
28.083333333333332</code></pre>
<h2 id=\"the-aggregation-type-class\">The Aggregation type class</h2>
<p>For calculations like <code>mean</code>, I need something more than a monoid. I need a monoid for accumulating the values, and then, once the accumulation is complete, a postprocessing function to compute the final result. Hence a new typeclass to extend Monoid:</p>
<pre><code>{-# LANGUAGE TypeFamilies #-}
class (Monoid a) => Aggregation a where
type AggResult a :: *
aggResult :: a -> AggResult a</code></pre>
<p>This makes use of the <a href=\"http://www.haskell.org/haskellwiki/GHC/Type_families\">type families ghc extension</a>. We need this to express the fact that our postprocessing function aggResult has a different return type to the type of the monoid. In the above definition:</p>
<ul>
<li>aggResult is a function that gives you the <em>value</em> of the final result from the <em>value</em> of the monoid</li>
<li>AggResult is a <em>type</em> function that gives you the <em>type</em> of the final result from the <em>type</em> of the monoid</li>
</ul>
<p>We can write an instance of Aggregation for Mean:</p>
<pre><code>instance (Fractional a) => Aggregation (Mean a) where
type AggResult (Mean a) = a
aggResult (Mean (Sum t,Count n)) = t/fromIntegral n</code></pre>
<p>and test it out:</p>
<pre><code>*Examples> let as = [45,23,78,10,11,1.5]
*Examples> aggResult (foldMap mean as)
28.083333333333332
*Examples> </code></pre>
<p>Nice. Given that <code>aggResult (foldMap ...)</code> will be a common pattern, lets write a helper:</p>
<pre><code>afoldMap :: (Foldable t, Aggregation a) => (v -> a) -> t v -> AggResult a
afoldMap f vs = aggResult (foldMap f vs)</code></pre>
<p>In order to use the monoids we defined before (sum,product etc) we need to define Aggregation instances for them also. Even though they are trivial, it turns out to be useful, as we can make the aggResult function strip off the newtype constructors that were put there to enable the Monoid typeclass:</p>
<pre><code>instance (Num a) => Aggregation (Sum a)  where
type AggResult (Sum a) = a
aggResult (Sum a) = a

instance (Num a) => Aggregation (Product a)  where
type AggResult (Product a) = a
aggResult (Product a) = a
instance (Ord a) => Aggregation (Min a)  where
type AggResult (Min a) = a
aggResult (Min a) = a
instance (Ord a) => Aggregation (Max a)  where
type AggResult (Max a) = a
aggResult (Max a) = a
instance Aggregation Count where
type AggResult Count = Int
aggResult (Count n) = n
instance (Aggregation a, Aggregation b) => Aggregation (a,b) where
type AggResult (a,b) = (AggResult a, AggResult b)
aggResult (a,b) = (aggResult a, aggResult b)
instance (Aggregation a, Aggregation b, Aggregation c) => Aggregation (a,b,c) where
type AggResult (a,b,c) = (AggResult a, AggResult b, AggResult c)
aggResult (a,b,c) = (aggResult a, aggResult b, aggResult c)</code></pre>
<p>This is mostly boilerplate, though notice how the tuple instances delve into their components in order to postprocess the results. Now everything fits together cleanly:</p>
<pre><code>*Examples> let as = [45,23,78,10,11,1.5]
*Examples> :t (a3 count (a2 min max) mean)
(a3 count (a2 min max) mean)
:: Ord a => a -> (Count, (Min a, Max a), Mean a)
*Examples> afoldMap (a3 count (a2 min max) mean) as
(6,(1.5,78.0),28.083333333333332)
*Examples> </code></pre>
<p>The 4 computations have been calculated all in a single pass over the input list, and the results are free of the type constructors that are no longer required once the aggregation is complete.</p>
<p>Another example of an Aggregation where we need to postprocess the result is counting the number of unique items. For this we will keep a set of the items seen, and then return the size of this set at the end:</p>
<pre><code>newtype CountUnique a = CountUnique (Set.Set a)
instance Ord a => Monoid (CountUnique a) where
mempty = CountUnique Set.empty
mappend (CountUnique s1) (CountUnique s2) = CountUnique (Set.union s1 s2)
instance Ord a => Aggregation (CountUnique a) where
type AggResult (CountUnique a) = Int
aggResult (CountUnique s1) = Set.size s1
countUnique :: Ord a => a -> CountUnique a
countUnique a = CountUnique (Set.singleton a)</code></pre>
<p>.. in use:</p>
<pre><code>*Examples> let as = [5,7,8,7,11,10,11]
*Examples> afoldMap (a2 countUnique count) as
(5,7)</code></pre>
<h2 id=\"higher-order-aggregation-functions\">Higher order aggregation functions</h2>
<p>All of the calculations seen so far have worked consistently across all values in the source data structure. We can make use of the <code>mempty</code> monoid value in order to filter our data set, and or aggregate in groups. Here’s a couple of higher order monoid functions for this:</p>
<pre><code>afilter :: Aggregation m => (a -> Bool) -> (a -> m) -> (a -> m)
afilter match mf = \\a -> if match a then mf a else mempty
newtype MMap k v = MMap (Map.Map k v)
deriving Show
instance (Ord k, Monoid v) => Monoid (MMap k v) where
mempty = MMap (Map.empty)
mappend (MMap m1) (MMap m2) = MMap (Map.unionWith mappend m1 m2)
instance (Ord k, Aggregation v) => Aggregation (MMap k v) where
type AggResult (MMap k v) = Map.Map k (AggResult v)
aggResult (MMap m) = Map.map aggResult m
groupBy :: (Ord k, Aggregation m) => (a -> k) -> (a -> m) -> (a -> MMap k m)
groupBy keyf valuef = \\a -> MMap (Map.singleton (keyf a) (valuef a))</code></pre>
<p><code>afilter</code> restricts the application of a monoid function to a subset of the input data. eg to calculate the sum of all the values, and the sum of values less than 20:</p>
<pre><code>*Examples> let as = [5,10,20,45.4,35,1,3.4]
*Examples> afoldMap (a2 sum (afilter (<=20) sum)) as
(119.8,39.4)</code></pre>
<p><code>groupBy</code> takes a key function and a monoid function. It partitions the data set using the key function, and applies a monoid function to each subset, returning all of the results in a map. Non-numeric data works better as an example here. Let’s take a set of words as input, and for each starting letter, calculate the number of words with that letter, the length of the shortest word, and and the length of longest word:</p>
<pre><code>*Examples> let as = words \"monoids are a pretty simple concept in haskell some years ago i learnt of them through the excellent typeclassopedia looked at the examples and understood them straight away which is more than can be said for many of the new ideas that one learns in haskell\"
*Examples> :t groupBy head (a3 count (min.length) (max.length))
groupBy head (a3 count (min.length) (max.length))
:: Ord k => [k] -> MMap k (Count, Min Int, Max Int)
*Examples> afoldMap (groupBy head (a3 count (min.length) (max.length))) as
fromList [('a',(6,1,4)),('b',(1,2,2)),('c',(2,3,7)),('e',(2,8,9)),('f',(1,3,3)),('h',(2,7,7)),('i',(5,1,5)),('l',(3,6,6)),('m',(3,4,7)),('n',(1,3,3)),('o',(3,2,3)),('p',(1,6,6)),('s',(4,4,8)),('t',(9,3,15)),('u',(1,10,10)),('w',(1,5,5)),('y',(1,5,5))]</code></pre>
<p>Many useful data analysis functions can be written through simple function application and composition using these primitive monoid functions, the product combinators a2 and a3 and these new filtering and grouping combinators.</p>
<h2 id=\"disk-based-data\">Disk-based data</h2>
<p>As pointed out before, regardless of the complexity of the computation, it’s done with a single traversal of the input data. This means that we don’t need to limit ourselves to lists and other in memory Foldable data structures. Here’s a function similar to foldMap, but that works over the lines in a file:</p>
<pre><code>foldFile :: Monoid m => FilePath -> (BS.ByteString -> Maybe a) -> (a -> m) -> IO m
foldFile fpath pf mf = do
h <- openFile fpath ReadMode
m <- loop h mempty
return m
where
loop h m = do
eof <- hIsEOF h
if eof
then (return m)
else do
l <- BS.hGetLine h
case pf l of
Nothing -> loop h m
(Just a) -> let m' = mappend m (mf a)
in loop h m'
afoldFile :: Aggregation m => FilePath -> (BS.ByteString -> Maybe a) -> (a -> m) -> IO (AggResult m)
afoldFile fpath pf mf = fmap aggResult (foldFile fpath pf mf)</code></pre>
<p>foldFile take two parameters – a function to parse each line of the file, the other is the monoid function to do the aggregation. Lines that fail to parse are skipped. (I can here questions in the background \"What about strictness and space leaks?? – I’ll come back to that). As an example usage of aFoldFile, I’ll analyse some stock data. Assume that I have it in a CSV file, and I’ve got a function to parse one CSV line into a sensible data value:</p>
<pre><code>import qualified Data.ByteString.Char8 as BS
import Data.Time.Calendar
data Prices = Prices {
pName :: String,          -- The stock code
pDate :: Day,             -- The historic date
pOpen :: Double,          -- The price at market open
pHigh :: Double,          -- The highest price on the date
pLow :: Double,           -- The lowest price on the date
pClose :: Double,         -- The price at market close
pVolume :: Double         -- How many shares were traded
} deriving (Show)
parsePrices :: BS.ByteString -> Maybe Prices
parsePrices = ...</code></pre>
<p>Now I can use my monoid functions to analyse the file based data. How many google prices do I have, over what date range:</p>
<pre><code>*Examples> let stats =  afilter ((\"GOOG\"==).pName) (a3 count (min.pDate) (max.pDate))
*Examples> :t stats
stats
:: Prices
-> (Count,
Min time-1.4:Data.Time.Calendar.Days.Day,
Max time-1.4:Data.Time.Calendar.Days.Day)
*Examples> afoldFile \"prices.csv\" parsePrices stats
(1257,2008-05-29,2013-05-24)
*Examples> </code></pre>
<p>Perhaps I want to aggregate my data per month, getting traded price range and total volume. We need a helper function to work out the month of each date:</p>
<pre><code>startOfMonth :: Day -> Day
startOfMonth t = let (y,m,d) = toGregorian t
in fromGregorian y m 1</code></pre>
<p>And then we can use groupBy to collect data monthly:</p>
<pre><code>:*Examples> let stats =  afilter ((\"GOOG\"==).pName) (groupBy (startOfMonth.pDate) (a3 (min.pLow) (max.pHigh) (sum.pVolume)))
*Examples> :t stats
stats
:: Prices
-> MMap
time-1.4:Data.Time.Calendar.Days.Day
(Min Double, Max Double, Sum Double)
*Examples> results <- afoldFile \"prices.csv\" parsePrices stats
*Examples> mapM_ print (Map.toList results)
(2008-05-01,(573.2,589.92,8073107.0))
(2008-06-01,(515.09,588.04,9.3842716e7))
(2008-07-01,(465.6,555.68,1.04137619e8))
...
(2013-03-01,(793.3,844.0,4.2559856e7))
(2013-04-01,(761.26,827.64,5.3574633e7))
(2013-05-01,(816.36,920.6,4.1080028e7))</code></pre>
<h2 id=\"conclusion\">Conclusion</h2>
<p>So, I hope I’ve shown that monoids are useful indeed. They can form the core of a framework for cleanly specifing quite complex data analysis tasks.</p>
<p>An additional typeclass which I called \"Aggregation\" extends Monoid and provides for a broader range of computations and also cleaner result types (thanks to type families). There was some discussion when I presented this talk as to whether a single method typeclass like Aggregation was a \"true\" abstraction, given it has no associated laws. This is a valid point, however using it simplifies the syntax and usage of monoidal calculations significantly, and for me, this makes it worth having.</p>
<p>There remains an elephant in the room, however, and this is space leakage. Lazy evalulation means that, as written, most of the calculations shown run in space proportional to the input data set. Appropriate strictness annotations and related modifications will fix this, but it turns out to be slightly irritating. This blog post is already long enough, so I’ll address space leaks in in a subsequent post…</p>
<br />  <a href=\"http://feeds.wordpress.com/1.0/gocomments/twdkz.wordpress.com/65/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/twdkz.wordpress.com/65/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=twdkz.wordpress.com&blog=33863535&post=65&subd=twdkz&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "ffc5e04a3dc6d59cb5bdf9d6ce0ba591") (35 (20928 8813 662093) "http://joyful.com/blog/2013-06-04-bugfix-planning-autoweb.html" "Simon Michael: Bugfix, planning, autoweb" nil "Tue, 04 Jun 2013 19:00:00 +0000" "<div style=\"font-style: italic;\">June  4, 2013</div>
<h2>Bugfix, planning, autoweb</h2>
<p>
</p><p><a href=\"http://joyful.com/2013-06-03-chart-fix.html\">Yesterday</a>.</p>
<p>Today:</p>
<p>Fixed a build failure from last night’s late session, caught by <a href=\"http://hydra.cryp.to:8080/project/hledger\">Peter’s build bot</a>, which is being very helpful. It’s like having R2D2 at my back! I do worry a little about the gratuitous added carbon footprint from a bunch of builds on every github commit.</p>
<p>Loaded up the 0.22 release backlog with a bunch of items on the <a href=\"http://hledger.org/trello\">planning board</a>. (Scroll over to the right).</p>
<p>Did the first backlog item, removing some troublesome friction in hledger-web development. When I’m working on hledger[-web] and need rapid compiler feedback, I use the <a href=\"https://github.com/simonmichael/hledger/blob/master/Makefile#L168\">“auto” rules</a> - <code>make auto</code>, <code>make auto-test</code>, or <code>make autoweb</code>. These watch for file changes and recompile as needed, using <a href=\"http://hub.darcs.net/simon/searchpath\">searchpath</a>. Searchpath is old, but still works well and can build from multiple packages, unlike cabal-based autobuilders. So it’s very useful when I’m tweaking things in hledger-lib for hledger-web. (I’d use <code>yesod devel</code> if I was just working just in hledger-web, and changing routes, templates, or the cabal file).</p>
<p>The problem: when compiling hledger-web, hledger and hledger-lib together, how to enable the hairy yesodish language extensions only for hledger-web code, and not for hledger-lib and hledger, which don’t compile with them (and seem to get obfuscated if I make them compile).</p>
<p>The solution: wrestle with ghc, sp, cabal; identify required and incompatible language extensions by trial and error; specify the compatible ones in the makefile, and add the rest as source file pragmas. Now my trusty autoweb runs again!</p>
<pre><code>~/src/hledger$ make autoweb
sp --no-exts --no-default-map ghc  -O0  hledger-web/app/main.hs -o bin/hledger-webdev -rtsopts -W -fwarn-tabs -fno-warn-unused-do-bind -fno-warn-name-shadowing  -ihledger-lib -ihledger -ihledger-web -ihledger-web/app -L/usr/lib  -optP-include -optPhledger/dist/build/autogen/cabal_macros.h -DPATCHLEVEL=2 -DDEVELOPMENT -DVERSION='\\\"0.21.1dev\\\"'  -XCPP -XMultiParamTypeClasses -XOverloadedStrings -XQuasiQuotes -XRecordWildCards -XTemplateHaskell  --run -B --port 5001 --base-url http://localhost:5001 -f webtest.j
[ 1 of 52] Compiling Hledger.Data.Types ( hledger-lib/Hledger/Data/Types.hs, hledger-lib/Hledger/Data/Types.o )
[ 2 of 52] Compiling Hledger.Data.FormatStrings ( hledger-lib/Hledger/Data/FormatStrings.hs, hledger-lib/Hledger/Data/FormatStrings.o )
...
Loading package yesod-static-1.2.0 ... linking ... done.
[40 of 52] Compiling Foundation       ( hledger-web/Foundation.hs, hledger-web/Foundation.o )
hledger-web/Foundation.hs:106:37: Not in scope: `css_bootstrap_css'</code></pre>
<p>Hmm. That didn’t happen on the other machine. Never mind, something for tomorrow.</p>
<p>Finally, realised I need to do <a href=\"http://hackage.haskell.org/package/hledger-0.21.2\">yet another release</a> including this morning’s build fix. This time I waited to see <a href=\"http://hydra.cryp.to:8080/eval/211\">green lights</a> on the buildbot before uploading.</p>" nil nil "c5c0e2279b535a8be25a38c53a4812bc") (34 (20928 8813 661435) "http://jpmoresmau.blogspot.com/2013/06/eclipse-hate-and-haskell-ides.html" "JP Moresmau: Eclipse Hate and Haskell IDEs" "noreply@blogger.com (JP Moresmau)" "Tue, 04 Jun 2013 18:14:33 +0000" "A few weeks ago I was <a href=\"http://www.reddit.com/r/programming/comments/1eeoqu/android_studio/\">reading the comments about the release of Android Studio on reddit</a>. I was a bit shocked by all the Eclipse hate. But hey, I suppose I use <a href=\"http://eclipse.org/\">Eclipse</a> and not <a href=\"http://www.jetbrains.com/idea/\">IntelliJ</a>, so I don't know what I'm missing and how great it would be to work on IDEA. But then I was surprised to see that there has been no release of <a href=\"http://code.google.com/p/ideah/\">ideah</a>, the Haskell plug-in for IDEA, for <a href=\"http://ideah-plugin.blogspot.fr/\">a year and a half</a>. How come there isn't more momentum if IntelliJ is such a great IDE to build on and work with?<br /><br />Maybe we're just suffering from too much dispersion in the <a href=\"http://www.haskell.org/haskellwiki/IDE\">Haskell IDE space</a>. We have plug-ins for the major IDEs, but none of them can probably called great (I know, some people positively hate EclipseFP, but for my defence I'll say I get much more bug reports and feature requests than pull requests, I probably need a course on \"building a passionate programming community around your open source project\"). They however have the massive advantage of being able to reuse a wealth of existing code (I can use the <a href=\"http://www.eclipse.org/egit/\">Eclipse Git plugin</a> to work with Github, I don't need somebody to write the Haskell version). An IDE in Haskell like <a href=\"http://leksah.org/\">Leksah</a> or something built on top of <a href=\"https://github.com/yi-editor/yi\">Yi</a> would be amazing to showcase that you can do real applications in Haskell (since you still get people saying that Haskell is only for toying with), but then you need to build everything, which requires people (see note above on building a community). Then we have web based editors like the offering from <a href=\"https://www.fpcomplete.com/school/how-to-use-the-school-of-haskell/creating-your-own-content\">FPComplete</a>, but for developers to use them on real projects we need to think on how to package a web based interface and what it means for a development work-flow: I'm not sure developers would embrace developing using a browser. Of course we have plug-ins for the Unixy editors, <a href=\"https://github.com/haskell/haskell-mode\">emacs</a> and <a href=\"http://projects.haskell.org/haskellmode-vim/\">vim</a>, but if we want to open up Haskell to non hackers, maybe we need something more...<br /><br />So can we continue like that and hope to have a few decent environments? Or shall we all agree on a direction and unite to provide the one true development environment for Haskell? Sometimes people say \"Haskell is so different and advanced as a programming language, it needs a new type of editor/IDE\". I don't disagree with it, but who has the vision of what the Haskell IDE should be?" nil nil "363b72eac76a4343dad1eda94c635155") (33 (20928 8813 660769) "http://joyful.com/blog/2013-06-03-chart-fix.html" "Simon Michael: Chart fix" nil "Tue, 04 Jun 2013 05:30:00 +0000" "<div style=\"font-style: italic;\">June  4, 2013</div>
<h2>Chart fix</h2>
<p>
</p><p><a href=\"http://joyful.com/2013-06-02-earth-nap.html\">Yesterday</a>.</p>
<p>Here’s the developer diary entry for monday.</p>
<p>Peter Simons <a href=\"http://thread.gmane.org/gmane.comp.finance.ledger.hledger/935\">argued convincingly</a> against depending on yesod-platform.</p>
<p>I released hledger 0.21.1, fixing a <a href=\"https://github.com/simonmichael/hledger/issues/122\">regression</a> in hledger-web 0.21 where it showed the wrong chart Y-values when filtering by date. The chart appears at the top of the <a href=\"http://demo.hledger.org/register\">register view</a>, and simply shows the register’s running total in graphical form. Here’s the report type which provides values for the chart:</p>
<pre class=\"sourceCode haskell\"><code class=\"sourceCode haskell\"><span class=\"co\">-- | A transactions report includes a list of transactions</span>
<span class=\"co\">-- (posting-filtered and unfiltered variants), a running balance, and some</span>
<span class=\"co\">-- other information helpful for rendering a register view (a flag</span>
<span class=\"co\">-- indicating multiple other accounts and a display string describing</span>
<span class=\"co\">-- them) with or without a notion of current account(s).</span>
<span class=\"kw\">type</span> <span class=\"dt\">TransactionsReport</span> <span class=\"fu\">=</span> (<span class=\"dt\">String</span>                   <span class=\"co\">-- label for the balance column, eg \"balance\" or \"total\"</span>
,[<span class=\"dt\">TransactionsReportItem</span>] <span class=\"co\">-- line items, one per transaction</span>
)
<span class=\"kw\">type</span> <span class=\"dt\">TransactionsReportItem</span> <span class=\"fu\">=</span> (<span class=\"dt\">Transaction</span> <span class=\"co\">-- the corresponding transaction</span>
,<span class=\"dt\">Transaction</span> <span class=\"co\">-- the transaction with postings to the current account(s) removed</span>
,<span class=\"dt\">Bool</span>        <span class=\"co\">-- is this a split, ie more than one other account posting</span>
,<span class=\"dt\">String</span>      <span class=\"co\">-- a display string describing the other account(s), if any</span>
,<span class=\"dt\">MixedAmount</span> <span class=\"co\">-- the amount posted to the current account(s) (or total amount posted)</span>
,<span class=\"dt\">MixedAmount</span> <span class=\"co\">-- the running balance for the current account(s) after this transaction</span>
)
triDate (t,_,_,_,_,_) <span class=\"fu\">=</span> tdate t
triAmount (_,_,_,_,a,_) <span class=\"fu\">=</span> a
triBalance (_,_,_,_,_,a) <span class=\"fu\">=</span> a
triSimpleBalance (_,_,_,_,_,<span class=\"dt\">Mixed</span> a) <span class=\"fu\">=</span> <span class=\"kw\">case</span> a <span class=\"kw\">of</span> [] <span class=\"ot\">-></span> <span class=\"st\">\"0\"</span>
(<span class=\"dt\">Amount</span>{aquantity<span class=\"fu\">=</span>q})<span class=\"fu\">:</span>_ <span class=\"ot\">-></span> <span class=\"fu\">show</span> q</code></pre>
<p>and here’s the slightly tricky new code to split it into separate reports, each covering one commodity:</p>
<pre class=\"sourceCode haskell\"><code class=\"sourceCode haskell\"><span class=\"co\">-- Split a transactions report whose items may involve several commodities,</span>
<span class=\"co\">-- into one or more single-commodity transactions reports.</span>
<span class=\"ot\">transactionsReportByCommodity ::</span> <span class=\"dt\">TransactionsReport</span> <span class=\"ot\">-></span> [<span class=\"dt\">TransactionsReport</span>]
transactionsReportByCommodity tr <span class=\"fu\">=</span>
[filterTransactionsReportByCommodity c tr <span class=\"fu\">|</span> c <span class=\"ot\"><-</span> transactionsReportCommodities tr]
<span class=\"kw\">where</span>
transactionsReportCommodities (_,items) <span class=\"fu\">=</span>
nub <span class=\"fu\">$</span> <span class=\"fu\">sort</span> <span class=\"fu\">$</span> <span class=\"fu\">map</span> acommodity <span class=\"fu\">$</span> <span class=\"fu\">concatMap</span> (amounts <span class=\"fu\">.</span> triAmount) items
<span class=\"co\">-- Remove transaction report items and item amount (and running</span>
<span class=\"co\">-- balance amount) components that don't involve the specified</span>
<span class=\"co\">-- commodity. Other item fields such as the transaction are left unchanged.</span>
<span class=\"ot\">filterTransactionsReportByCommodity ::</span> <span class=\"dt\">Commodity</span> <span class=\"ot\">-></span> <span class=\"dt\">TransactionsReport</span> <span class=\"ot\">-></span> <span class=\"dt\">TransactionsReport</span>
filterTransactionsReportByCommodity c (label,items) <span class=\"fu\">=</span>
(label, fixTransactionsReportItemBalances <span class=\"fu\">$</span> <span class=\"fu\">concat</span> [filterTransactionsReportItemByCommodity c i <span class=\"fu\">|</span> i <span class=\"ot\"><-</span> items])
<span class=\"kw\">where</span>
filterTransactionsReportItemByCommodity c (t,t2,s,o,a,bal)
<span class=\"fu\">|</span> c <span class=\"ot\">`elem`</span> cs <span class=\"fu\">=</span> [item']
<span class=\"fu\">|</span> <span class=\"fu\">otherwise</span>   <span class=\"fu\">=</span> []
<span class=\"kw\">where</span>
cs <span class=\"fu\">=</span> <span class=\"fu\">map</span> acommodity as
item' <span class=\"fu\">=</span> (t,t2,s,o,a',bal)
a' <span class=\"fu\">=</span> filterMixedAmountByCommodity c a
fixTransactionsReportItemBalances [] <span class=\"fu\">=</span> []
fixTransactionsReportItemBalances [i] <span class=\"fu\">=</span> [i]
fixTransactionsReportItemBalances items <span class=\"fu\">=</span> <span class=\"fu\">reverse</span> <span class=\"fu\">$</span> i<span class=\"fu\">:</span>(go startbal is)
<span class=\"kw\">where</span>
i<span class=\"fu\">:</span>is <span class=\"fu\">=</span> <span class=\"fu\">reverse</span> items
startbal <span class=\"fu\">=</span> filterMixedAmountByCommodity c <span class=\"fu\">$</span> triBalance i
go _ [] <span class=\"fu\">=</span> []
go bal ((t,t2,s,o,amt,_)<span class=\"fu\">:</span>is) <span class=\"fu\">=</span> (t,t2,s,o,amt,bal')<span class=\"fu\">:</span>go bal' is
<span class=\"kw\">where</span> bal' <span class=\"fu\">=</span> bal <span class=\"fu\">+</span> amt
<span class=\"co\">-- | Filter out all but the specified commodity from this amount.</span>
<span class=\"ot\">filterMixedAmountByCommodity ::</span> <span class=\"dt\">Commodity</span> <span class=\"ot\">-></span> <span class=\"dt\">MixedAmount</span> <span class=\"ot\">-></span> <span class=\"dt\">MixedAmount</span>
filterMixedAmountByCommodity c (<span class=\"dt\">Mixed</span> as) <span class=\"fu\">=</span> <span class=\"dt\">Mixed</span> <span class=\"fu\">$</span> <span class=\"fu\">filter</span> ((<span class=\"fu\">==</span>c)<span class=\"fu\">.</span> acommodity) as</code></pre>
<p>so that we can render one line for each commodity:</p>
<pre class=\"sourceCode haskell\"><code class=\"sourceCode haskell\"><span class=\"ot\">registerChartHtml ::</span> [[<span class=\"dt\">TransactionsReportItem</span>]] <span class=\"ot\">-></span> <span class=\"dt\">HtmlUrl</span> <span class=\"dt\">AppRoute</span>
registerChartHtml itemss <span class=\"fu\">=</span>
<span class=\"fu\">...</span>
\\<span class=\"fu\">$.</span>plot(chartdiv,
[
<span class=\"fu\">$</span>forall items <span class=\"ot\"><-</span> itemss
[
<span class=\"fu\">$</span>forall i <span class=\"ot\"><-</span> <span class=\"fu\">reverse</span> items
[<span class=\"fu\">#</span>{dayToJsTimestamp <span class=\"fu\">$</span> triDate i}, <span class=\"fu\">#</span>{triSimpleBalance i}],
[]
],
[]
],
{
xaxis<span class=\"fu\">:</span> {
mode<span class=\"fu\">:</span> <span class=\"st\">\"time\"</span>,
timeformat<span class=\"fu\">:</span> <span class=\"st\">\"%y/%m/%d\"</span>
}
}
);
<span class=\"fu\">...</span></code></pre>" nil nil "0fea40d5913d1eed57abf648872dae4d") (32 (20928 8813 659255) "http://praisecurseandrecurse.blogspot.com/2013/06/objective-c-day-2.html" "Paul Potts: Objective-C, Day 2" "noreply@blogger.com (Paul Potts)" "Tue, 04 Jun 2013 02:57:00 +0000" "<p>(Warning: non-FP content)</p> <p>So today I'm working on chapter 3 in <i>iOS Programming</i>. This is about memory management. I have vague memories of manual reference-counting using retain and release in earlier experiments with Objective-C, but this book teaches ARM (Automatic Reference Counting). You enable ARM when you configure an XCode project of iOS.</p> <p>The idea behind object references (well, pointers in iOS) and trees of objects and their owners is not new to me. And here they they still do not clarify whether a statement like <b>items = nil</b> actually invokes runtime behavior to destroy objects. I believe it does not. When I override a <b>dealloc</b> method to log, I see that the <b>dealloc</b> methods are called when the curly brace at the end of @autoreleasepool is reached. This makes sense, as in C it is the point where variables go out of scope. So reference-counting bookkeeping must be invoked then. It does not seem to be possible to step in with the debugger at this point to view what is happening, though -- Apple's Objective-C runtime is proprietary software.</p> <p>We next get into weak references. There's a <b>__weak</b> specifier that can appear as part of an object pointer declaration, and <i>iOS Programming</i> says that \"an interesting property of weak references is that they know when the object they reference is destroyed... the [parent object] automatically sets its [child object] instance variable to <b>nil</b>.\" I'm going to have to read more about that. I really wish this book were more precise in its language. There's another specifier, <b>__unsafe_unretained</b>, which is not set -- and so a pointer to a destroyed object could still be dereferenced. I suppose I should just be happy that this works and use it, but I'm the type to want to know what is going on at the register level. Apparently ARC (the \"automatic\" in reference-counting) is all due to some amazing work done in clang, where the static analysis actually figures out all the possible points of object creation and deletion and can wrap up your reference-counting for you. That seems like a great development -- because I've never quite liked how garbage collectors (at least, those without hardware support), no matter how efficient they are, had to actually be implemented, looking at dumb machine pointers. It seems to me that there could be room in purely-GC'ed languages for this kind of static analysis. But I haven't thought very hard about that yet.</p> <p><i>Properties</i> seem to be a shorthand, asking the compiler to provide getters and setters. There's a great example as to how much code this can eliminate. There's a strange wart in that we are asked to specify (nonatomic) in every property, because that is not the default setting. Presumably this is to support multiple threads accessing the object. Again, a dark corner to look into.</p> <p>For a little refresher, I took a break by reading the first few chapters of Brad Cox's book. He outlines his vision of a software IC, along the lines of a hardware C, that would support reusability primarily through late binding, limited interfaces, and wrapping up functionality with data so that clients don't have to write the operations on an object's data type. It's an interesting vision.</p> <p>Cox writes of early Objective-C:</p> <blockquote>Objective-C adds precisely one new data type, the object, to those C provides already, and precisely one new operation, the message expression.</blockquote> <p>Cox's book indicates that early versions of Objective-C used an intermediate preprocessor step, between the C macro-preprocessing step and the regular C compiler. If you are my age you might recall that, early on, C++ was treated similarly, with a program called <a href=\"http://en.wikipedia.org/wiki/Cfront\">CFront</a>. This is no longer the case with either Objective-C or C++, although this approach lives on in tools like <a href=\"http://en.wikipedia.org/wiki/Qt_(framework)\">Qt, with its Meta Object Compiler</a>, or moc).</p> <p>Cox describes the pragmatic design of Objective-C:</p> <blockquote>One of Objective-C's key features is that it is always possible to bypass the object-oriented machinery to access an object's private information directly. This is one of a hybrid language's greatest theoretical weaknesses and one of its greatest pragmatic strengths. Low-level code is often best developed in a conventional manner, exploiting static binding to obtain high machine efficiency and strong type checking. Conversely, user-level code is often best written as objects. It is important that these levels interface smoothly and efficiently.</blockquote> <p>There is an interesting passage about object identifiers. In a slight muddling of his earlier statement he writes that \"objects are identified by a new Objective-C data type called an id, or object identifier.\" In practice, though, this isn't really a new data type <i>per se</i>. The address (a pointer to) an object is this identifier. The veneer over C is so thin that, he writes, it would have been perfectly feasible to implement the dynamic message sends using straightforward C language calls like </p><pre>reply = _msg_(aReceiver, \"aMessage\", argument1, ...)</pre> (I assume he'd use C's <a href=\"http://en.wikipedia.org/wiki/Varargs.h#.3Cvarargs.h.3E\">variable-length argument list</a> mechanism here), but for efficiency he wanted to avoid string comparison in the dispatch mechanism. Cox was quite aware of the reaction that messages like [anObject do:arg1 with:arg2] would inspire in C programmers, writing \"the convention seems strange to those accustomed to conventional function call syntax, and frankly, I find it a mixed blessing.\"<p></p> <p>In this formulation, Objective-C classes were still objects, and class methods were called \"factory methods\" (but I'm peeking ahead a number of pages, so there might be some differences from their current incarnation), as distinct from instance methods. Cox writes \"...the programmer conceives the initial object... the loader gives it life by installing it in memory... this is done once for each class in the system. These primal objects are called factory objects... every factory's name is published in a global variable.\"</p> <p>Cox is a very thoughtful writer and he presents a minimalist view of what an object-oriented language requires in order to provide the most basic advantage of OOP. He writes:</p> <blockquote>One last time: the only substantive difference between conventional programming and object-oriented programming is the selection mechanism. This is not to minimize its importance, but to demystify what is basically a very simple notion. Its significance is that it moves a single responsibility across the boundary between the consumer of a service and the supplier of that service. In conventional programming, the consumer is responsible for choosing functions that operate properly on the data managed by that service. The selection mechanism moves that single responsibility off the consumer and onto the supplier. In this small change lies all the power of the technique.</blockquote> <p>That really caused me to, as they say, nearly drop my monocle. Could this really be where most of the advantage, such as it is, imperfectly realized, understood, and applied, of OOP comes from?</p> <p>The mainstream business world got C++ instead, a mash-up of C and <a href=\"http://en.wikipedia.org/wiki/Simula\">Simula</a>, and then Java instead, <a href=\"http://www.infoworld.com/d/developer-world/java-becoming-new-cobol-204\">the Cobol of object-oriented programming languages</a>. I was not pleased. As I consider my career I also consider which implementation languages I should focus my efforts on, for the next decade. After exposure to Haskell it's hard to believe that, ultimately, functions -- without explicit state -- won't prove to be a cleaner reusable element than classes, whatever kind of binding they use. And don't get me wrong -- I like classes. I'm pretty certain that I'll still be writing C code, at least occasionally, in ten years. I'd prefer to be writing less C++. But what I'd really like is to move on -- to pick a \"<a href=\"http://skillsmatter.com/podcast/agile-testing/bobs-last-language\">last programming language</a>.\" Objective-C isn't that, for me -- it's too imperative, and can't truly be made safe, just <i>safer</i>. I'm enjoying it in this context, but would Objective-C even be an viable option outside of the Apple ecosystem? It doesn't seem to have gained much adoption. The state of GnuStep doesn't seem terribly robust. And so my career-long quest for a Better Way continues, while at the same time trying to gain facility with all the Good Ways along the way.</p>" nil nil "a42437793f9dc3d44ebd00e3aa6efe12") (31 (20928 8813 657871) "http://lukepalmer.wordpress.com/2013/04/01/the-plan/" "Luke Palmer: The Plan" nil "Mon, 03 Jun 2013 20:49:26 +0000" "<p>Last September, I decided that it was time to get a programming job again.  After two months of trying to find paid work (of any kind, $10 would have been great!) as a composer, I realized that it’s really hard.  There are a lot of people willing to work for free, and without much of a scoring portfolio (as opposed to the “pure music” I do) I have no way to distinguish myself to the studios that have a budget.  Also, a lot of games want orchestral scores, and I don’t have the hardware and software I need to make convincing-sounding synthetic orchestral scores.  Also, I’m sure once I get the necessary hardware and software, I will need time to practice with it.  In short, I needed money and time.  I am extremely fortunate to have, in my free-flowing way, stumbled onto a skill that is valued by the economy, and so I decided it was once again time to utilize that skill to achieve my other goals.  I planned to live reasonably cheaply, save up money so that I can buy equipment and support myself for enough time to build up a portfolio by doing free projects.</p>
<p>Now I have been programming for Clozure for almost six months.  As far as jobs go, it’s great.  I get to work in my favorite language, Haskell, and they give me enough freedom to experiment with designs and come up with solutions that not only work, but that I would even consider <i>good</i>.  My fear of programming jobs was based on having jobs where I constantly have to compromise my values, either by working in crappy languages or on startup-style timelines where there is no time to lose.  With this job, I feel reunited with my love of software, and my inspirations for developer support tools have been once again ignited.</p>
<p>And so I have amended the plan: after I have saved enough money to support myself for several years, I will not only attempt to bootstrap a career composing, but dedicate my current work week to making a reality the software ideas which have been floating around in my head for half a decade.  This prospect <i>really</i> excites me — the reason I have not been able to make my ideas is mostly the time pressure: there’s was always something else I <i>should</i> be doing, and so I always felt guilty working on my pet projects.  I wonder, what am I capable of if my pet projects are the main thing?</p>
<p>I want to revive <a href=\"https://github.com/luqui/CodeCatalog\">CodeCatalog</a>.  Max and I lost steam on that project for a number of reasons.</p>
<ol>
<li>Due to family pressure, I returned to school.</li>
<li>I fell in love with a girl and got my heart all broken.  That can be kind of a downer.</li>
<li>The priorities of the project compromised my vision.  We were attempting to use modern wisdom to make the project successful: first impressions and intuitive usability came first.  Our focus was on making it pretty and satisfying to use (which took a long time since neither of us were experienced web front-end developers), and that required me to strip off the most interesting parts of the project because noobs wouldn’t immediately understand it.</li>
</ol>
<p>So I want to re-orient (3) to make it more satisfying for me.  I want to allow myself to make the large strides that I envisage rather than baby-stepping toward success — to encourage myself to use my own talents in design and abstraction rather than trying to be a front-end person, to emphasize the exciting parts (what Audrey Tang calles <tt>-Ofun</tt>).  By funding myself, I will not feel the guilt that comes with working on a project at the same time as (1).  I can do no more than hope that something like (2) doesn’t happen.  (I have a wonderful, stable and supportive relationship right now, so if that continues, that’d cover it :-)</p>
<p>I have many ideas; the reason I want to return to CodeCatalog in particular is mainly because I have identified most of my ideas as aspects of this project.  My specific fancies change frequently (usually to things I have thought about before but never implemented), and so by focusing on this project in a researchy rather than producty way, I can entertain them while still working toward a larger goal and eventually benefitting the community.  </p>
<p>Here is a summary of some ideas that fit in the CodeCatalog umbrella (just because I’m excited and want to remember):</p>
<ul>
<li><a href=\"http://lukepalmer.wordpress.com/2008/11/12/sketch-of-udon-version-controlpackaging-system/\">Inter-project version control</a> — I have always been frustrated by the inability of git and hg to merge two projects while still allowing interoperation with where they came from.  The “project” quantum seems arbitrary, and I want to globalize it.</li>
<li>Package adapters — evolving the interface of a package without breaking users of the old interface by rewriting the old package in terms of the new one.  There is a great deal that can be done automatically in this area with sufficient knowledge about the meaning of changes. I talked with Michael Sloan about this some, and some of the resulting ideas are contained in <a href=\"http://www.mgsloan.com/wordpress/?p=219\">this writeup</a>.</li>
<li>Informal checked documentation — documenting the assumptions of code in a machine-readable semi-formal language, to get the computer to pair-program with you (e.g. you write a division <tt>x/y</tt> and you have no <tt>y /= 0</tt> assumption in scope, you’d get a “documentation obligation” to explain in english why <tt>y</tt> can’t be 0).</li>
<li>Structural editing — coding by transforming valid syntax trees.  Yes it’d be cool, but the main reason it’s compelling to me is in its synergy with other features.  Once you have the notion of focusing on expressions, holes with contextual information (a la Agda), semi-automatic creation of package and data-type adapters, smarter version control (e.g. a change might rename <i>all</i> references to an identifier, even the ones that weren’t there when the change was made) all come as natural extensions to the idea.</li>
</ul>
<p>I think the challenge for me will be to focus on one of these for long enough to make it cool before getting distracted by another.  My plan for that is to set short-term goals here on my blog and use it to keep myself in check.  I am considering involving other people in my project as a way to keep myself focused (i.e. maybe I can make a little mini-kickstarter in which my devotees can pledge small amounts in exchange for me completing a specific goal on time).</p>
<p>This is all two years away or more, which feels like a long time, but in the grand scheme is not that long in exchange for what I see as the potential of this endeavor.  I’m just excited and couldn’t help but to think about it and get pumped up.  Thanks for reading!</p>
<p>Oh, despite the date, this is totally not an April Fools joke (as far as I know ;-).</p>
<br />  <img src=\"http://stats.wordpress.com/b.gif?host=lukepalmer.wordpress.com&blog=5292379&post=2154&subd=lukepalmer&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "97cf98c3159da6cfc492fd16eadf31a7") (30 (20928 8813 656706) "http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka?utm_source=rss&utm_medium=rss&utm_campaign=hlearn-cross-validates-400x-faster-than-weka" "Mike Izbicki: HLearn cross-validates >400x faster than Weka" nil "Mon, 03 Jun 2013 15:33:16 +0000" "<p><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/weka-lambda-haskell-300x150.png\" alt=\"weka-lambda-haskell\" height=\"120\" class=\"alignright  wp-image-2478\" width=\"240\" /><a href=\"http://www.cs.waikato.ac.nz/~ml/weka/\">Weka</a> is one of the most popular tools for data analysis.  But Weka takes <strong>70 minutes</strong> to perform leave-one-out cross-validate using a simple <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">naive bayes classifier</a> on the <a href=\"http://archive.ics.uci.edu/ml/datasets/Census-Income+(KDD)\">census income</a> data set, whereas Haskell’s <a href=\"https://github.com/mikeizbicki/HLearn\">HLearn</a> library only takes <strong>9 seconds</strong>.  Weka is 465x slower!</p>
<p><strong>Code and instructions for reproducing these experiments are <a href=\"https://github.com/mikeizbicki/HLearn/tree/master/HLearn-classification/src/examples/weka-cv#readme\">available on github</a>.</strong></p>
<p><strong><span id=\"more-2468\"></span></strong></p>
<p>Why is HLearn so much faster?</p>
<p>Well, it turns out that the bayesian classifier has the algebraic structure of a <a href=\"https://en.wikipedia.org/wiki/Monoid\">monoid</a>, a <a href=\"https://en.wikipedia.org/wiki/Abelian_group\">group</a>, and a <a href=\"https://en.wikipedia.org/wiki/Vector_space\">vector space</a>.  HLearn uses a new cross-validation algorithm that can exploit these algebraic structures.  The standard algorithm runs in time <span id=\"tex_9745\"></span>, where <span id=\"tex_8353\"></span> is the number of “folds” and <span id=\"tex_3668\"></span> is the number of data points.  The algebraic algorithms, however, run in time <span id=\"tex_5274\"></span>.  In other words, it doesn’t matter how many folds we do, the run time is constant!  And not only are we faster, but we get the <em>exact same answer</em>.  Algebraic cross-validation is not an approximation, it’s just fast.</p>
<p>Here’s some run times for k-fold cross-validation on the census income data set.  Notice that HLearn’s run time is constant as we add more folds.<i><br />
</i></p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/k-fold-cross-validation-weka1.png\" alt=\"k-fold-cross-validation-weka\" height=\"336\" class=\"aligncenter size-full wp-image-2479\" width=\"555\" /></p>
<p>And when we set k=n, we have leave-one-out cross-validation.  Notice that Weka’s cross-validation has quadratic run time, whereas HLearn has linear run time.</p>
<p style=\"text-align: center;\"><img src=\"http://izbicki.me/blog/wp-content/uploads/2013/05/leave-one-out-fast-cross-validation-weka1.png\" alt=\"leave-one-out-fast-cross-validation-weka\" height=\"333\" class=\"aligncenter size-full wp-image-2480\" width=\"553\" /></p>
<p>HLearn certainly isn’t going to replace Weka any time soon, but it’s got a number of cool tricks like this going on inside.  If you want to read more, you should check out these two recent papers:</p>
<ul>
<li>(ICML13) <a href=\"http://izbicki.me/public/papers/icml2013-algebraic-classifiers.pdf\">Algebraic Classifiers: a generic approach to fast cross-validation, online training, and parallel training</a></li>
</ul>
<ul>
<li><span style=\"line-height: 12px;\" class=\"Apple-style-span\">(TFP13) <a href=\"http://izbicki.me/public/papers/tfp2013-hlearn-a-machine-learning-library-for-haskell.pdf\">HLearn: a machine learning library for Haskell</a></span></li>
</ul>
<p>I’ll continue to write more about these tricks in future blog posts.</p>
<p>Subscribe to the <a href=\"http://izbicki.me/blog/feed\">RSS feed</a> to stay tuned.</p>
<img src=\"http://izbicki.me/blog/?feed-stats-post-id=2468\" style=\"display: none;\" height=\"1\" width=\"1\" />" nil nil "bb8ca14d64a7e950977e724b2359e7b2") (29 (20928 8813 655955) "http://joyful.com/blog/2013-06-02-earth-nap.html" "Simon Michael: Earth Nap" nil "Mon, 03 Jun 2013 06:45:00 +0000" "<div style=\"font-style: italic;\">June  3, 2013</div>
<h2>Earth Nap</h2>
<p>
</p><p>Let’s take a break from all this <a href=\"http://joyful.com/2013-06-01-hledger-0.21-released.html\">hledger stuff</a>. I’ve been programming for about 30 years, and I’ve acquired - often the hard way - some tricks, tools and habits helpful for balance and productivity as a working programmer. We are all different, but I bet some of you could also use these. Here’s one - I’ll call it <strong>Earth Nap</strong>. It’s very simple:</p>
<ol style=\"\">
<li><p>Find a patch of earth where you can lie down without being disturbed.</p></li>
<li><p>Lie down. If possible, cover your eyes or head.</p></li>
<li><p>Rest with eyes closed, doze, or nap for 5-30 minutes.</p></li>
<li><p>Reactivate gently. Stretch, rub your face/hands/feet, roll up, maybe sing, shake out the cobwebs or walk a little.</p></li>
</ol>
<p>A good time is after lunch, or early/mid/late afternoon. Or any time you feel fatigued, over-pressured, or burnt out. There is always time for a 5m break.</p>
<p>Direct contact between your skin and the earth is ideal. Lately I’ve done it on the beach and under a tree in a nearby quiet park - perfect. At my last client gig, I was onsite all day and there was no park and no quiet.. but there was an unused stair leading up to a small concrete landing where no one went. A few minutes in my secret lair made a big difference!</p>
<p>If you’re likely to sleep longer than 30m, set a gentle alarm (a deeper sleep rhythm kicks in after about 45 minutes which would leave you feeling groggy). Or, just watch/trust your body/mind’s natural napping cycle. It’s not necessary to fall asleep. You may notice yourself sink into a dozing/free association/dreaming state, then return to wakefulness.</p>
<p>Each time you do this, observe the effects. You might notice:</p>
<ul>
<li>more calmness/cheerfulness</li>
<li>less mental noise</li>
<li>better concentration</li>
<li>better coping skills and emotional resilience</li>
<li>slower, more powerful energy</li>
<li>less addiction/aversion to pleasant/unpleasant tasks</li>
<li>less vulnerability to “rabbit holes” (mentally enticing, demanding tasks which fan out endlessly and lead nowhere)</li>
<li>new ideas and solutions appearing effortlessly</li>
<li>more energy left over at end of day</li>
</ul>" nil nil "6fd6dfd6b0983d7578a559644facaded") (28 (20928 8813 655134) "http://blog.moertel.com/posts/2013-06-03-recursion-to-iteration-3.html" "Tom Moertel: Tricks of the trade: Recursion to Iteration, Part 3: Recursive Data Structures" nil "Mon, 03 Jun 2013 00:00:00 +0000" "<div class=\"info\">Posted on June  3, 2013</div>
<div class=\"tags\">Tags: <a href=\"http://blog.moertel.com/tags/programming.html\">programming</a>, <a href=\"http://blog.moertel.com/tags/recursion.html\">recursion</a>, <a href=\"http://blog.moertel.com/tags/iteration.html\">iteration</a>, <a href=\"http://blog.moertel.com/tags/python.html\">python</a>, <a href=\"http://blog.moertel.com/tags/recursion-to-iteration series.html\">recursion-to-iteration series</a>, <a href=\"http://blog.moertel.com/tags/tail calls.html\">tail calls</a>, <a href=\"http://blog.moertel.com/tags/data structures.html\">data structures</a></div>
<p>This is the third article in <a href=\"http://blog.moertel.com/tags/recursion-to-iteration%20series.html\">a series on converting recursive algorithms into iterative algorithms</a>. If any of what follows seems confusing, you may want to read the earlier articles first.</p>
<p>This is an extra article that I hadn’t planned. I’m writing it because in a comment on the previous article a reader asked me to show a less mathematical example and suggested tree traversal. So that’s the subject of this article: We’ll take a binary tree and flatten it into a list, first recursively, then iteratively.</p>
<h3 id=\"the-challenge\">The challenge</h3>
<p>First, let’s define a binary tree to be either empty or given by a node having three parts: (1) a value, (2) a left subtree, and (3) a right subtree, where both of the subtrees are themselves binary trees. In Haskell, we might define it like so:</p>
<pre class=\"sourceCode haskell\"><code class=\"sourceCode haskell\"><span class=\"kw\">data</span> <span class=\"dt\">BinaryTree</span> a <span class=\"fu\">=</span> <span class=\"dt\">Empty</span> <span class=\"fu\">|</span> <span class=\"dt\">Node</span> a (<span class=\"dt\">BinaryTree</span> a) (<span class=\"dt\">BinaryTree</span> a)</code></pre>
<p>In Python, which we’ll use for the rest of this article, we’ll say that <code>None</code> represents an empty tree and that the following class represents a node:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"ch\">import</span> collections
Node = collections.namedtuple(<span class=\"st\">'Node'</span>, <span class=\"st\">'val left right'</span>)
<span class=\"co\"># some sample trees having various node counts</span>
tree0 = <span class=\"ot\">None</span>  <span class=\"co\"># empty tree</span>
tree1 = Node(<span class=\"dv\">5</span>, <span class=\"ot\">None</span>, <span class=\"ot\">None</span>)
tree2 = Node(<span class=\"dv\">7</span>, tree1, <span class=\"ot\">None</span>)
tree3 = Node(<span class=\"dv\">7</span>, tree1, Node(<span class=\"dv\">9</span>, <span class=\"ot\">None</span>, <span class=\"ot\">None</span>))
tree4 = Node(<span class=\"dv\">2</span>, <span class=\"ot\">None</span>, tree3)
tree5 = Node(<span class=\"dv\">2</span>, Node(<span class=\"dv\">1</span>, <span class=\"ot\">None</span>, <span class=\"ot\">None</span>), tree3)</code></pre>
<p>Let us now define a function to flatten a tree using an <a href=\"http://en.wikipedia.org/wiki/Tree_traversal#In-order\">in-order traversal</a>. The recursive definition is absurdly simple, the data type having only two cases to consider:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> flatten(bst):
<span class=\"co\"># empty case</span>
<span class=\"kw\">if</span> bst is <span class=\"ot\">None</span>:
<span class=\"kw\">return</span> []
<span class=\"co\"># node case</span>
<span class=\"kw\">return</span> flatten(bst.left) + [bst.val] + flatten(bst.right)</code></pre>
<p>A few tests to check that it does what we expect:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> check_flattener(f):
<span class=\"kw\">assert</span> f(tree0) == []
<span class=\"kw\">assert</span> f(tree1) == [<span class=\"dv\">5</span>]
<span class=\"kw\">assert</span> f(tree2) == [<span class=\"dv\">5</span>, <span class=\"dv\">7</span>]
<span class=\"kw\">assert</span> f(tree3) == [<span class=\"dv\">5</span>, <span class=\"dv\">7</span>, <span class=\"dv\">9</span>]
<span class=\"kw\">assert</span> f(tree4) == [<span class=\"dv\">2</span>, <span class=\"dv\">5</span>, <span class=\"dv\">7</span>, <span class=\"dv\">9</span>]
<span class=\"kw\">assert</span> f(tree5) == [<span class=\"dv\">1</span>, <span class=\"dv\">2</span>, <span class=\"dv\">5</span>, <span class=\"dv\">7</span>, <span class=\"dv\">9</span>]
<span class=\"kw\">print</span> <span class=\"st\">'ok'</span>
check_flattener(flatten)  <span class=\"co\"># ok</span></code></pre>
<p>Our challenge for today is to convert <code>flatten</code> into an iterative version. Other than a new trick – partial evaluation – the transformation is straightforward, so I’ll move quickly.</p>
<p>Let’s do this!</p>
<h3 id=\"eliminating-the-first-recursive-call\">Eliminating the first recursive call</h3>
<p>First, let’s separate the base case from the incremental work:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(bst):
<span class=\"kw\">return</span> flatten(bst.left) + [bst.val] + flatten(bst.right)
<span class=\"kw\">def</span> flatten(bst):
<span class=\"kw\">if</span> bst is <span class=\"ot\">None</span>:
<span class=\"kw\">return</span> []
<span class=\"kw\">return</span> step(bst)</code></pre>
<p>And let’s break the incremental work into smaller pieces to see what’s going on.</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(bst):
left = flatten(bst.left)
left.append(bst.val)
right = flatten(bst.right)
left.extend(right)
<span class=\"kw\">return</span> left
<span class=\"kw\">def</span> flatten(bst):
<span class=\"kw\">if</span> bst is <span class=\"ot\">None</span>:
<span class=\"kw\">return</span> []
<span class=\"kw\">return</span> step(bst)</code></pre>
<p>Let’s try to get rid of the first recursive call by assuming that somebody has passed us its result via a secret argument <code>left</code>:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(bst, left=<span class=\"ot\">None</span>):
<span class=\"kw\">if</span> left is <span class=\"ot\">None</span>:
left = flatten(bst.left)
left.append(bst.val)
right = flatten(bst.right)
left.extend(right)
<span class=\"kw\">return</span> left
<span class=\"kw\">def</span> flatten(bst):
<span class=\"kw\">if</span> bst is <span class=\"ot\">None</span>:
<span class=\"kw\">return</span> []
<span class=\"kw\">return</span> step(bst)</code></pre>
<p>And now we’ll make <code>step</code> return values that parallel its input arguments:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(bst, left=<span class=\"ot\">None</span>):
<span class=\"kw\">if</span> left is <span class=\"ot\">None</span>:
left = flatten(bst.left)
left.append(bst.val)
right = flatten(bst.right)
left.extend(right)
<span class=\"kw\">return</span> bst, left  <span class=\"co\"># <-- add bst</span>
<span class=\"kw\">def</span> flatten(bst):
<span class=\"kw\">if</span> bst is <span class=\"ot\">None</span>:
<span class=\"kw\">return</span> []
<span class=\"kw\">return</span> step(bst)[-<span class=\"dv\">1</span>]  <span class=\"co\"># <-- note [-1]</span></code></pre>
<p>In the first recursive call, the transformation applied to <code>bst</code> is <code>.left</code>, so we want to apply the opposite transformation to <code>bst</code> in the returned values. And what’s the opposite of descending to a node’s left subtree? It’s ascending to the node’s parent. So we want something like this:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"co\"># this code does not work!</span>
<span class=\"kw\">def</span> step(bst, left=<span class=\"ot\">None</span>):
<span class=\"kw\">if</span> left is <span class=\"ot\">None</span>:
left = flatten(bst.left)
left.append(bst.val)
right = flatten(bst.right)
left.extend(right)
<span class=\"kw\">return</span> get_parent(bst), left  <span class=\"co\"># <-- need get_parent</span></code></pre>
<p>But we’re stuck. We can’t define <code>get_parent</code> because our tree data structure doesn’t keep track of parents, only children.</p>
<p>New plan: Maybe we can assume that someone has <em>passed us</em> the node’s parent and go from there?</p>
<p>But this plan hits the same brick wall: If we add a new argument to accept the parent, we must for parallelism add a new return value to emit the transformed parent, which is the parent of the parent. But we can’t compute the parent of the parent because, as before, we have no way of implementing <code>get_parent</code>.</p>
<p>So we do what mathematicians do when their assumptions hit a brick wall: we strengthen our assumption! Now we assume that someone has passed us <em>all of the parents</em>, right up to the tree’s root. And that assumption gives us what we need:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(bst, parents, left=<span class=\"ot\">None</span>):
<span class=\"kw\">if</span> left is <span class=\"ot\">None</span>:
left = flatten(bst.left)
left.append(bst.val)
right = flatten(bst.right)
left.extend(right)
<span class=\"kw\">return</span> parents[-<span class=\"dv\">1</span>], parents[:-<span class=\"dv\">1</span>], left</code></pre>
<p>Note that we’re using the Python stack convention for <code>parents</code>; thus the immediate parent of <code>bst</code> is given by the final element <code>parents[-1]</code>.</p>
<p>As a simplification, we can eliminate the <code>bst</code> argument by considering it the final parent pushed onto the stack:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(parents, left=<span class=\"ot\">None</span>):
bst = parents.pop()  <span class=\"co\"># <-- bst = top of parents stack</span>
<span class=\"kw\">if</span> left is <span class=\"ot\">None</span>:
left = flatten(bst.left)
left.append(bst.val)
right = flatten(bst.right)
left.extend(right)
<span class=\"kw\">return</span> parents, left</code></pre>
<p>Now that <code>step</code> requires the <code>parents</code> stack as an argument, the base function must provide it:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> flatten(bst):
<span class=\"kw\">if</span> bst is <span class=\"ot\">None</span>:
<span class=\"kw\">return</span> []
parents = [bst]
<span class=\"kw\">return</span> step(parents)[-<span class=\"dv\">1</span>]</code></pre>
<p>But we still haven’t eliminated the first recursive call. To do that, we’ll need to pass the <code>step</code> function a value for its <code>left</code> argument, which will cause the recursive call to be skipped.</p>
<p>But we only know what that value should be for one case, the base case, when <code>bst</code> is <code>None</code>; then <code>left</code> must be <code>[]</code>. To get to that case from the tree’s root, where <code>bst</code> is definitely not <code>None</code>, we must iteratively replicate the normal recursive calls on <code>bst.left</code> until we hit the leftmost leaf node. And then, to compute the desired result, we must reverse the trip, iterating the <code>step</code> function until we have returned to the tree’s root, where the <code>parents</code> stack must be empty:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> flatten(bst):
<span class=\"co\"># find initial conditions for secret-feature \"left\"</span>
left = []
parents = []
<span class=\"kw\">while</span> bst is not <span class=\"ot\">None</span>:
parents.append(bst)
bst = bst.left
<span class=\"co\"># iterate to compute the result</span>
<span class=\"kw\">while</span> parents:
parents, left = step(parents, left)
<span class=\"kw\">return</span> left</code></pre>
<p>And just like that, one of the recursive calls has been transformed into iteration. We’re halfway to the finish line!</p>
<h3 id=\"eliminating-the-second-recursive-call\">Eliminating the second recursive call</h3>
<p>But we still have to eliminate that final recursive call to <code>flatten</code>, now sequestered in <code>step</code>. Let’s take a closer look at that function after we make its <code>left</code> argument required since it always gets called with a value now:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(parents, left):
bst = parents.pop()
left.append(bst.val)
right = flatten(bst.right)
left.extend(right)
<span class=\"kw\">return</span> parents, left</code></pre>
<p>To get rid of the recursive call to <code>flatten</code>, we’re going to use a new trick: partial evaluation. Basically, we’re going to replace the call to <code>flatten</code> with the function body of <code>flatten</code>, after we rename all its variables to prevent conflicts. So let’s make a copy of <code>flatten</code> and suffix all its variables with <code>1</code>:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> flatten1(bst1):
left1 = []
parents1 = []
<span class=\"kw\">while</span> bst1 is not <span class=\"ot\">None</span>:
parents1.append(bst1)
bst1 = bst1.left
<span class=\"kw\">while</span> parents1:
parents1, left1 = step(parents1, left1)
<span class=\"kw\">return</span> left1</code></pre>
<p>And then let’s make its arguments and return values explicit:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\">    (bst1, ) = ARGUMENTS
left1 = []
parents1 = []
<span class=\"kw\">while</span> bst1 is not <span class=\"ot\">None</span>:
parents1.append(bst1)
bst1 = bst1.left
<span class=\"kw\">while</span> parents1:
parents1, left1 = step(parents1, left1)
RETURNS = (left1, )</code></pre>
<p>And then we’ll drop this expansion into <code>step</code>:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(parents, left):
bst = parents.pop()
left.append(bst.val)
<span class=\"co\"># -- begin partial evaluation --</span>
(bst1, ) = (bst.right, )
left1 = []
parents1 = []
<span class=\"kw\">while</span> bst1 is not <span class=\"ot\">None</span>:
parents1.append(bst1)
bst1 = bst1.left
<span class=\"kw\">while</span> parents1:
parents1, left1 = step(parents1, left1)
(right, ) = (left1, )
<span class=\"co\"># -- end partial evaluation --</span>
left.extend(right)
<span class=\"kw\">return</span> parents, left</code></pre>
<p>Now we can eliminate code by fusion across the partial-evaluation boundary.</p>
<p>First up: <code>left1</code>. We can now see that this variable accumulates values that, in the end, get appended to <code>left</code> (via the return variable <code>right</code>). But we can just as well append those values to <code>left</code> directly, eliminating <code>left1</code> within the boundary and the call to <code>left.extend(right)</code> without:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(parents, left):
bst = parents.pop()
left.append(bst.val)
<span class=\"co\"># -- begin partial evaluation --</span>
(bst1, ) = (bst.right, )
<span class=\"co\"># left1 = []  # <-- eliminate and use left instead</span>
parents1 = []
<span class=\"kw\">while</span> bst1 is not <span class=\"ot\">None</span>:
parents1.append(bst1)
bst1 = bst1.left
<span class=\"kw\">while</span> parents1:
parents1, left = step(parents1, left)
<span class=\"co\"># (right, ) = (left, )  # <-- eliminated</span>
<span class=\"co\"># -- end partial evaluation --</span>
<span class=\"co\"># left.extend(right)  # <-- eliminated</span>
<span class=\"kw\">return</span> parents, left</code></pre>
<p>For this next fusion, we’re going to need to recall our base function to get the necessary outside scope:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(parents, left):
bst = parents.pop()
left.append(bst.val)
<span class=\"co\"># -- begin partial evaluation --</span>
(bst1, ) = (bst.right, )
parents1 = []
<span class=\"kw\">while</span> bst1 is not <span class=\"ot\">None</span>:
parents1.append(bst1)
bst1 = bst1.left
<span class=\"kw\">while</span> parents1:
parents1, left = step(parents1, left)
<span class=\"co\"># -- end partial evaluation --</span>
<span class=\"kw\">return</span> parents, left
<span class=\"kw\">def</span> flatten(bst):
left = []
parents = []
<span class=\"kw\">while</span> bst is not <span class=\"ot\">None</span>:
parents.append(bst)
bst = bst.left
<span class=\"kw\">while</span> parents:
parents, left = step(parents, left)
<span class=\"kw\">return</span> left</code></pre>
<p>When <code>flatten</code> calls <code>step</code> and the code within the partially evaluated region executes, it builds up a stack of nodes <code>parents1</code> and then calls <code>step</code> iteratively to pop values off of that stack and process them. When it’s finished, control returns to <code>step</code> proper, which then returns to its caller, <code>flatten</code>, with the values (<code>parents</code>, <code>left</code>). But look at what <code>flatten</code> then does with <code>parents</code>: it calls <code>step</code> iteratively to pop values off of that stack and process them in exactly the same way.</p>
<p>So we can eliminate the <code>while</code> loop in <code>step</code> – and the recursive call! – by returning not <code>parents</code> but <code>parents + parents1</code>, which will make the <code>while</code> loop in <code>flatten</code> do the exact same work.</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(parents, left):
bst = parents.pop()
left.append(bst.val)
<span class=\"co\"># -- begin partial evaluation --</span>
(bst1, ) = (bst.right, )
parents1 = []
<span class=\"kw\">while</span> bst1 is not <span class=\"ot\">None</span>:
parents1.append(bst1)
bst1 = bst1.left
<span class=\"co\"># while parents1:                            # <-- eliminated</span>
<span class=\"co\">#     parents1, left = step(parents1, left)  #</span>
<span class=\"co\"># -- end partial evaluation --</span>
<span class=\"kw\">return</span> parents + parents1, left  <span class=\"co\"># parents -> parents + parents1</span></code></pre>
<p>And then we can eliminate <code>parents1</code> completely by taking the values we would have appended to it and appending them directly to <code>parents</code>:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(parents, left):
bst = parents.pop()
left.append(bst.val)
<span class=\"co\"># -- begin partial evaluation --</span>
(bst1, ) = (bst.right, )
<span class=\"co\"># parents1 = []  # <-- eliminated</span>
<span class=\"kw\">while</span> bst1 is not <span class=\"ot\">None</span>:
parents.append(bst1)  <span class=\"co\"># parents1 -> parents</span>
bst1 = bst1.left
<span class=\"co\"># -- end partial evaluation --</span>
<span class=\"kw\">return</span> parents, left  <span class=\"co\"># parents + parents1 -> parents</span></code></pre>
<p>And now, once we remove our partial-evaluation scaffolding, our <code>step</code> function is looking simple again:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> step(parents, left):
bst = parents.pop()
left.append(bst.val)
bst1 = bst.right
<span class=\"kw\">while</span> bst1 is not <span class=\"ot\">None</span>:
parents.append(bst1)
bst1 = bst1.left
<span class=\"kw\">return</span> parents, left</code></pre>
<p>For the final leg of our journey – simplification – let’s inline the <code>step</code> logic back into the base function:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> flatten(bst):
left = []
parents = []
<span class=\"kw\">while</span> bst is not <span class=\"ot\">None</span>:
parents.append(bst)
bst = bst.left
<span class=\"kw\">while</span> parents:
parents, left = parents, left
bst = parents.pop()
left.append(bst.val)
bst1 = bst.right
<span class=\"kw\">while</span> bst1 is not <span class=\"ot\">None</span>:
parents.append(bst1)
bst1 = bst1.left
parents, left = parents, left
<span class=\"kw\">return</span> left</code></pre>
<p>Let’s eliminate the trivial argument-binding and return-value assignments:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> flatten(bst):
left = []
parents = []
<span class=\"kw\">while</span> bst is not <span class=\"ot\">None</span>:
parents.append(bst)
bst = bst.left
<span class=\"kw\">while</span> parents:
<span class=\"co\"># parents, left = parents, left  # = no-op</span>
bst = parents.pop()
left.append(bst.val)
bst1 = bst.right
<span class=\"kw\">while</span> bst1 is not <span class=\"ot\">None</span>:
parents.append(bst1)
bst1 = bst1.left
<span class=\"co\"># parents, left = parents, left  # = no-op</span>
<span class=\"kw\">return</span> left</code></pre>
<p>And, finally, factor out the duplicated <code>while</code> loop into a local function:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> flatten(bst):
left = []
parents = []
<span class=\"kw\">def</span> descend_left(bst):
<span class=\"kw\">while</span> bst is not <span class=\"ot\">None</span>:
parents.append(bst)
bst = bst.left
descend_left(bst)
<span class=\"kw\">while</span> parents:
bst = parents.pop()
left.append(bst.val)
descend_left(bst.right)
<span class=\"kw\">return</span> left</code></pre>
<p>And that’s it! We now have a tight, efficient, and iterative version of our original function. Further, the code is close to idiomatic.</p>
<p>That’s it for this time. If you have any questions or comments, just hit me at <a href=\"https://twitter.com/tmoertel\">@tmoertel</a> or use the comment form below.</p>
<p>Thanks for reading!</p>" nil nil "83eb257f316b6261382cd7938fdda54f") (27 (20928 8813 651520) "http://feedproxy.google.com/~r/FpComplete/~3/2D5iyiU03QM/haskell-from-c" "FP Complete: Haskell from C: Where are the for Loops?" nil "Sun, 02 Jun 2013 18:00:00 +0000" "<p>This post contains fragments of active Haskell code, best viewed and executed at
<a href=\"https://www.fpcomplete.com/blog/2013/06/haskell-from-c\">https://www.fpcomplete.com/blog/2013/06/haskell-from-c</a>
</p>
<p>If you're coming from a language like C, Haskell can take some getting used to. It's typical for a new language to feel a little different, but in Haskell the differences are more dramatic, and more fundamental. In particular...</p><h2>Where are the <code>for</code> loops?</h2><p>In most imperative languages, <code>for</code> loops are all over the place, and are used for a wide variety of <i>different things</i>. Whether you're squaring every value of an array or finding its sum, you're probably using a <code>for</code> loop.</p><p>In Haskell, control structures are more expressive. Sure, there's a counterpart to C's <code>for</code> (Haskell's <code>forM_</code>). But that's a discussion for another time. Today, we'll see some <code>for</code> loops in C that can be written very differently in Haskell, and why that's a good thing.</p><p>Consider the simple example of computing the norm of a vector. For a vector <b>x</b>∈ℝ<sup>n</sup>, this is just</p>
<math xmlns=\"http://www.w3.org/1998/Math/MathML\">
<mtable style=\"width: 98%; margin-top: 1.0em; margin-right: 1.0em; margin-bottom: 2.0em; margin-left: 2.0em;\" displaystyle=\"true\" class=\"m-equation-square\">
<mtr>
<mtd columnalign=\"left\">
<mrow>
<mo>|</mo>
<mo>|</mo>
</mrow>
<mi mathvariant=\"bold\">x</mi>
<mrow>
<mo>|</mo>
<mo>|</mo>
</mrow>
<mo>=</mo>
<msqrt>
<mrow>
<mstyle displaystyle=\"true\">
<munderover>
<mo>∑</mo>
<mrow>
<mi>i</mi>
<mo>=</mo>
<mn>0</mn>
</mrow>
<mrow>
<mi>n</mi>
<mo>-</mo>
<mn>1</mn>
</mrow>
</munderover>
</mstyle>
<msubsup>
<mi mathvariant=\"bold\">x</mi>
<mi>i</mi>
<mn>2</mn>
</msubsup>
</mrow>
</msqrt>
</mtd>
</mtr>
</mtable>
</math>
<p>Conceptually, there are three stages to this computation:</p><ol><li><b><code>mapSq</code></b>: Square each element</li><li><b><code>sum</code></b>: Compute the sum</li><li><b><code>sqrt</code></b>: Compute the square root</li></ol><p>We can think of the first step as building (at least abstractly) a new array whose <code>i</code>th element is <code>y[i] = x[i] * x[i]</code>. In functional programming, we refer to this as <i>mapping</i> the square function over the array. </p><p>Putting everything in terms of functions, we can write this (in Haskell-like pseudocode) as</p><pre><code>norm(x) = sqrt(sum(mapSq(x))) ,</code></pre><p>To clean up the syntax a bit, we can instead use the notation for function composition and write</p><pre><code>norm(x) = (sqrt ○ sum ○ mapSq)(x) ,</code></pre><p>or just </p><pre><code>norm = sqrt ○ sum ○ mapSq .</code></pre><h2>Computing Norms in C</h2><p>In C, this modular approach leads to something like</p><pre><code>void mapSq(double *x, double *y, int n) {
int i;
for(i=0; i<n; i++) {
y[i] = x[i] * x[i];
}
}
double sum(double *x, int n) {
double result = 0;
int i;
for(i=0; i<n; i++) {
result += x[i];
}
return result;
}
double norm1(double *x, int n) {
double *y = malloc(n * sizeof(double));
mapSq(x, y, n);
theSum = sum(y, n);
free(y);
return sqrt(theSum);
}</code></pre><p>We'd probably never do it this way, for a few reasons:</p><ul><li>For such a simple computation, it's way too verbose.</li><li>It uses two separate <code>for</code> loops, where only one is needed.</li><li>There's an unnecessary <code>malloc</code> that's unlikely to be removed by the compiler.</li></ul><p>If it weren't for these issues, we probably would write code like the above. It has the advantage of being more modular and of faithfully representing the concepts. But the problems are too big to ignore, so we typically make some code transformations in our head, and instead write</p><pre><code>double norm2(double *x, int n) {
double theSum = 0.0;
for (int i = 0; i < n; i++) {
theSum += x[i]*x[i]; }
return sqrt(theSum);
}</code></pre><p>This code is very clear, and performs well, but we've entirely lost modularity. In this case the code is very short, so we don't give the compromise a second thought. But at a larger scale, this kind of manual optimization reduces code reuse and makes components more complex. Code becomes harder to understand, and harder to test for correctness.</p><h2>Computing Norms in Haskell</h2><p>In Haskell, we could write <code>norm</code> as</p><pre><code class=\"active haskell\">import Prelude hiding (sum)
import Data.List (foldl')
-- show
mapSq x = map sq x
where
sq xi = xi * xi
sum x = foldl' (+) 0.0 x
norm x = (sqrt . sum . mapSq) x
main = print (norm [1,2,3,4,5])</code></pre><p>While the C example is in terms of arrays, this Haskell example instead uses <i>lazy linked lists</i>. We'll change this in a bit.</p><p>Let's step through this code. The first function, <code>mapSq</code>, is defined in terms of the <code>map</code> function, and produces a new list by squaring every element of the original list. The squaring function <code>sq</code> can also be written as <code>(\\x -> x*x)</code>, allowing us to write the function as</p><pre><code class=\"haskell\">mapSq x = map (\\x -> x*x) x</code></pre><p>or simply</p><pre><code class=\"haskell\">mapSq = map (\\x -> x*x)</code></pre><p>Next, the <code>sum</code> function is defined in terms of <code>foldl'</code>. Before you worry too much about the name, you should know that a <i>fold</i> is just a function that traverses some data structure, using a given function to update some <i>accumulator</i> as it goes. In the current case, the accumulator is the counterpart of \"<code>theSum</code>\" in the C version. Accumulation is via addition, and starts at 0.0.</p><p>Lists can be folded from either side. In our case, we're using <code>foldl'</code>. The \"<code>l</code>\" in this function name is for \"left\", the side we're starting on, and the \"<code>'</code>\" indicates that this fold is <i>strict</i>. Haskell is lazy by default, but for numeric there's no point in delaying evaluation of the accumulator (and for large lists it can lead to a stack overflow), so in this case we prefer to evaluate it at every step.</p><p>As it turns out, our <code>sum</code> function is common enough that it's included in Haskell's Prelude; we can use it exactly as described with no need to define it.<sup>1</sup> Our <code>norm</code> function is now simple:</p><pre><code class=\"active haskell\">norm = sqrt . sum . map (\\x -> x*x)
main = print (norm [1,2,3,4,5])</code></pre><p>This looks remarkably like the mathematical specification; some have affectionately refered to Haskell as an <i>executable specification language</i>.</p><h2>But what about performance?</h2><p>Let's compare performance with C. In order to measure easily across languages, we'll make the vector much bigger - lets say a billion elements. We'll start with a standard list implementation in Haskell and compare this to an implementation in C using arrays. Then we'll make a couple of minor changes in Haskell that allow us to use unboxed vectors.</p><p>We'll test using an AMD A6-3670 APU running Ubuntu 13.04. For compilation, we'll use GHC 7.6.3 (with <code>-O2</code>) and GCC 4.7.3 (with <code>-O3</code>). </p><h3>Haskell - Lists</h3><p>Our Haskell version is certainly elegant, but using linked lists in this way is not the best approach for performance. For a billion elements, the running time is <b>over 2 minutes</b>. What's going on here?</p><p>Haskell lists are <i>lazy</i> (only those elements required by later calculations are computed) and <i>polymorphic</i> (you can have a list of elements of any type, even if elements of that type don't take up a fixed number of bytes). In order to implement this, a list in Haskell is really a <i>list of pointers to elements</i>. In cases like this, all that pointer chasing adds up.</p><p>We'll soon see an easy way to improve this and get Haskell running really fast.</p><h3>C - Arrays</h3><p>Before we get Haskell zipping along, let's look at how we would do this in C. We'll use the faster version of our norm in C (<code>norm2</code> above). Here's the plan:</p><ol><li><code>malloc</code> an array of a billion elements</li><li>Fill the array so that <code>x[i] = i</code></li><li>Find the norm of the vector</li><li>Free the array and print the result</li></ol><p>We'll use the OS to measure the time of the whole process, and insert some code to measure step (3) alone. So all together we have this:</p><pre><code>#include <time.h>
#include <math.h>
#include <stdio.h>
#include <stdlib.h>
#define x_size 1000000000
double norm(double *x, int n) {
double theSum = 0.0;
int i;
for (i=0; i<n; i++) {
theSum += x[i]*x[i];
}
return sqrt(theSum);
}
int main() {
double *x = malloc(x_size * sizeof(double));
int i;
for(i=0; i<x_size; i++) {
x[i] = (double) i;
}
clock_t start = clock();
double result = norm(x, x_size);
clock_t end = clock();
printf(\"%3.2f\\n\", result);
printf(\"%3.2f sec\\n\", (end-start)/(double)CLOCKS_PER_SEC);
free(x);
return 0;
}</code></pre><p>The whole thing takes about <b>7 seconds</b> to run, with the <code>norm</code> function itself taking <b>1.9 seconds</b>.</p><h3>Haskell - Unboxed Vectors</h3><p>To close in on C, let's make some minor changes. Instead of using lists, we'll use  unboxed <i>vector</i>s. The \"unboxed\" qualifier just means that the elements are available directly, without the need to follow a pointer. </p><p>From a data structure standpoint, Haskell's vectors are a lot like C's arrays. There is an important difference, though; many operations on vectors (even boxed ones) are subject to <i>fusion</i>. A <code>map</code> followed by a <code>sum</code> will be represented as a tight loop, but the code can remain modular. Remember the malloc in our original C code? Through fusion, it's eliminated entirely. </p><p>Updating the original code to operate on vectors is straightforward. And To stay entirely outside the realm of lists, we can generate our vector using <code>iterateN</code>, which plays the role of our data-filling loop in C.</p><p>[EDIT: Because School of Haskell compilation does not use <code>-O2</code>, there is no fusion, so we'll need to keep the values a bit smaller. In this case, I'll use an unusually small value for <code>oneBillion</code>, though for benchmarking I still use 10<sup>9</sup>]</p><pre><code class=\"active haskell\">import Data.Vector.Unboxed as V
norm ::  Vector Double -> Double
norm = sqrt . V.sum . V.map (\\x -> x*x)
oneBillion = 100
main = print $ norm $ V.iterateN oneBillion (+1) 0.0 </code></pre><p>This code runs in about <b>2.5 seconds</b>. It's just a bit longer than C's inner loop alone, but much less than the 7 seconds if the malloc is included.</p><p>EDIT: As Pedro Vasconcelos points out, tight numerical loops like this can often benefit from using the LLVM back-end, via <code>-fllvm</code>. This brings the time for the entire Haskell run down to <b>1.9 seconds</b>, the same as the inner loop alone in C!</p><h2>Conclusion</h2><p>Haskell's control structures express that a reduction (a <i>fold</i> in Haskell) is very different than a <i>map</i>.<sup>2</sup> Libraries like <b>vector</b> implement powerful fusion techniques to combine loops and eliminate intermediate data structures. And <i>unboxing</i> elminates excessive pointer chasing required by built-in lists.</p><p>All in all, this lets us write <i>high-level code without sacrificing high performance</i>. The need for any compromise between the two is becoming more rare every day.</p><hr /><p> <sup>1</sup> The Prelude's <code>sum</code> function is not defined in terms of <code>foldl'</code>, but instead relies on GHC's strictness analysis. In GHC 7.6.3 there's a regression, as described in <a href=\"http://hackage.haskell.org/trac/ghc/ticket/7954\">this ticket</a>. Because of this, we stuck with <code>foldl' (+) 0.0</code> in timing our Haskell version using lists.</p><br />
<sup>2</sup>  EDIT: Michael Sloan has pointed out that the difference is not so fundamental, since `map f = foldr ((:) . f) []`. <div class=\"feedflare\">
<a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=2D5iyiU03QM:TrJEQ8HeCec:yIl2AUoC8zA\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=yIl2AUoC8zA\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=2D5iyiU03QM:TrJEQ8HeCec:V_sGLiPBpWU\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=2D5iyiU03QM:TrJEQ8HeCec:V_sGLiPBpWU\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=2D5iyiU03QM:TrJEQ8HeCec:qj6IDK7rITs\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?d=qj6IDK7rITs\" border=\"0\" /></a> <a href=\"http://feeds.feedburner.com/~ff/FpComplete?a=2D5iyiU03QM:TrJEQ8HeCec:gIN9vFwOqvQ\"><img src=\"http://feeds.feedburner.com/~ff/FpComplete?i=2D5iyiU03QM:TrJEQ8HeCec:gIN9vFwOqvQ\" border=\"0\" /></a>
</div><img src=\"http://feeds.feedburner.com/~r/FpComplete/~4/2D5iyiU03QM\" height=\"1\" width=\"1\" />" nil nil "7e8d098c2661f157bf6baf2946e47bb5") (26 (20928 8813 649361) "http://lpuppet.banquise.net/blog/2013/06/01/hruby-package-released/" "language-puppet: Hruby package released" nil "Sat, 01 Jun 2013 06:42:00 +0000" "<p>I finally released the <a href=\"http://hackage.haskell.org/package/hruby\">hruby</a> package, along with an updated version of the <a href=\"http://hackage.haskell.org/package/language-puppet\">language-puppet</a> package. It is very unfortunate this package will never get proper haddocks on Hackage, as the documentation is quite useful. If someone has a suggestion for getting haddocks without having the ruby1.8 library installed, I am interested. Also the path to the Ruby include files is hardcoded, meaning it might require manual tweaking to get it right.</p>
<p>Both libraries now have build flags :</p>
<ul>
<li>Hruby has a flag for ruby1.9. This flag is mostly cosmetic as I didn’t even test it, and just copied the files for ruby1.8.</li>
<li>Language-puppet now has a <code>-fhruby</code> option, to build with this library.</li>
</ul>
<p>The immediate result is a two-fold speed increase for single runs of <code>puppetresource</code>, and a six-time speed-up for scripts computing several catalogs. The
reason is that the parser is not too fast, but its results get cached. Also, the language-puppet daemon infrastructure still let you define the number of
threads that should be spawned to compute templates. <em>This should be set to 1</em>. The ruby interpreter cannot be used in a thread-safe way.</p>
<p>There are still several issues to address. The first is related to the multiple variable assignment problem. In Puppet all variables are immutable, and can’t be
reassigned. Well, <em>except</em> when overwriting variables belonging to an inherited class. I wish they never introduced inheritance, as it introduces all kind of
special rules, and seems generally fragile. Moreover, given how I (have not) implemented scopes, it is not trivial to have a robust way to check if the overwrite is valid
or not.</p>
<p>The second most important issue is the fact that the dependency system isn’t working as it should be. I still get dependency loops in Puppet that are not
catched by language-puppet. This is a show-stopper, and must be fixed soon. It is however a big challenge.</p>
<p>Finally, as language-puppet is Linux only for now, I would like to start using the inotify feature. The current caching mechanism works by issuing <code>stat</code> system
calls on all files that might have changed. Inotify would greatly reduce the number of system calls, which is always a good thing. I am not sure this would lead
to a big speed increase however.</p>" nil nil "0d773225ab6a6cccb8cf1b68c3146e3e") (25 (20928 8813 648784) "http://kenta.blogspot.com/2012/05/spovtkwt-equiangular-pentagon.html" "Ken T Takusagawa: [spovtkwt] Equiangular pentagon" "noreply@blogger.com (Ken)" "Fri, 31 May 2013 17:56:36 +0000" "<p>Finding not many good pictures of a pentagon with equal angles but unequal sides, I drew one.  For reference, inside it is a regular pentagon; corresponding sides are parallel.</p><p><img src=\"http://mit.edu/kenta/www/three/pentagon-equiangular/spovtkwt/equiangular-pentagon.png\" alt=\"Equiangular Pentagon\" height=\"572\" width=\"699\" /></p><p><a href=\"http://mit.edu/kenta/www/three/pentagon-equiangular/spovtkwt\">Haskell source code is here</a>.</p><p>And in Scalable Vector Graphics (SVG) format:<br />
</p><div style=\"background: white;\"><object data=\"http://mit.edu/kenta/www/three/pentagon-equiangular/spovtkwt/pentagon.svg\" height=\"473\" type=\"image/svg+xml\" width=\"600\"></object></div><a href=\"http://mit.edu/kenta/www/three/pentagon-equiangular/spovtkwt/pentagon.svg\">Equiangular Pentagon in SVG</a><br />
<p></p><p>Someday, an amoeba-like animation which explores possible shapes of an equiangular pentagon of a constant area.</p>" nil nil "868451a221bbf6c7860dac11996daeef") (24 (20928 8813 648338) "http://wadler.blogspot.com/2013/05/the-eff-oracle-google-and-me.html" "Philip Wadler: The EFF, Oracle, Google, and me" "noreply@blogger.com (Philip Wadler)" "Fri, 31 May 2013 15:39:13 +0000" "<div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://2.bp.blogspot.com/-oUdfjPrpGnk/UajDtRgxfqI/AAAAAAAACDI/Tshk9t5yiY4/s1600/EFF.png\"><img src=\"http://2.bp.blogspot.com/-oUdfjPrpGnk/UajDtRgxfqI/AAAAAAAACDI/Tshk9t5yiY4/s320/EFF.png\" height=\"222\" border=\"0\" width=\"320\" /></a></div><br /><div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://2.bp.blogspot.com/-JymkWK6ziMQ/UajBL4yXzhI/AAAAAAAACC4/m41WF6Ms4Bw/s1600/oracle-v-google.jpg\"><img src=\"http://2.bp.blogspot.com/-JymkWK6ziMQ/UajBL4yXzhI/AAAAAAAACC4/m41WF6Ms4Bw/s1600/oracle-v-google.jpg\" border=\"0\" /></a></div><div style=\"clear: both; text-align: center;\" class=\"separator\"><br /></div>The Electronic Frontier Foundation has <a href=\"https://www.eff.org/press/releases/computer-scientists-urge-court-block-copyright-claims-oracle-v-google-api-fight\">submitted an amicus brief</a> for the case of Oracle vs. Google, arguing that copyright should apply to code that implements an API, but not to the API itself, which anyone should be free to implement.  The brief details a number of cases where the freedom to implement an API has led to social benefits.  I am pleased to be a signatory of the brief, in the company of luminaries including John Parry Barlow, Jon Bentley, Frederick Brooks, David Dill, Les Earnest, Doug Lea, Martin Odersky, Bruce Schneier, Bjarne Stoustroup, and others.<br /><br />" nil nil "7da444e577993ecd4081421170f04664") (23 (20928 8813 645465) "http://idontgetoutmuch.wordpress.com/2013/05/31/neural-networks-and-automated-differentiation-3/" "Dominic Steinitz: Neural Networks and Automated Differentiation" nil "Fri, 31 May 2013 14:30:22 +0000" "<h2 id=\"introduction\">Introduction</h2>
<p>Neural networks are a method for classifying data based on a theory of how biological systems operate. They can also be viewed as a generalization of logistic regression. A method for determining the coefficients of a given model, backpropagation, was developed in the 1970’s and rediscovered in the 1980’s.</p>
<p>The article “A Functional Approach to Neural Networks” in the <a href=\"http://themonadreader.files.wordpress.com/2013/03/issue214.pdf\">Monad Reader</a> shows how to use a neural network to classify handwritten digits in the <a href=\"http://yann.lecun.com/exdb/mnist/\">MNIST database</a> using backpropagation.</p>
<p>The reader is struck by how similar <a href=\"http://en.wikipedia.org/wiki/Backpropagation\">backpropagation</a> is to <a href=\"http://en.wikipedia.org/wiki/Automatic_differentiation\">automatic differentiation</a>. The reader may not therefore be surprised to find that this observation had been made before: <a href=\"http://justindomke.wordpress.com/2009/02/17/automatic-differentiation-the-most-criminally-underused-tool-in-the-potential-machine-learning-toolbox/\">Domke2009a</a>. Indeed as Dan Piponi observes: “the grandaddy machine-learning algorithm of them all, back-propagation, is nothing but steepest descent with reverse mode automatic differentiation”.</p>
<h2 id=\"neural-networks\">Neural Networks</h2>
<p>We can view neural nets or at least a multi layer perceptron as a generalisation of (multivariate) linear logistic regression.</p>
<p>We follow <span class=\"citation\">(Rojas 1996; Bishop 2006)</span>. We are given a training set:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%7B%28%5Cboldsymbol%7Bx%7D_0%2C+%5Cboldsymbol%7By%7D_0%29%2C+%28%5Cboldsymbol%7Bx%7D_1%2C+%5Cboldsymbol%7By%7D_1%29%2C+%5Cldots%2C+%28%5Cboldsymbol%7Bx%7D_p%2C+%5Cboldsymbol%7By%7D_p%29%5C%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\{(\\boldsymbol{x}_0, \\boldsymbol{y}_0), (\\boldsymbol{x}_1, \\boldsymbol{y}_1), \\ldots, (\\boldsymbol{x}_p, \\boldsymbol{y}_p)\\}  \" class=\"latex\" title=\"\\displaystyle  \\{(\\boldsymbol{x}_0, \\boldsymbol{y}_0), (\\boldsymbol{x}_1, \\boldsymbol{y}_1), \\ldots, (\\boldsymbol{x}_p, \\boldsymbol{y}_p)\\}  \" /></div>
<p>of pairs of <img src=\"http://s0.wp.com/latex.php?latex=n&bg=ffffff&fg=333333&s=0\" alt=\"n\" class=\"latex\" title=\"n\" />-dimensional and <img src=\"http://s0.wp.com/latex.php?latex=m&bg=ffffff&fg=333333&s=0\" alt=\"m\" class=\"latex\" title=\"m\" />-dimensional vectors called the input and output patterns in Machine Learning parlance. We wish to build a neural network model using this training set.</p>
<p>A neural network model (or at least the specific model we discuss: the <a href=\"http://en.wikipedia.org/wiki/Multilayer_perceptron\">multi-layer perceptron</a>) consists of a sequence of transformations. The first transformation creates weighted sums of the inputs.</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a_j%5E%7B%281%29%7D+%3D+%5Csum_%7Bi%3D1%7D%5E%7BK_0%7D+w%5E%7B%281%29%7D_%7Bij%7Dx_i+%2B+w_%7B0j%7D%5E%7B%281%29%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  a_j^{(1)} = \\sum_{i=1}^{K_0} w^{(1)}_{ij}x_i + w_{0j}^{(1)}  \" class=\"latex\" title=\"\\displaystyle  a_j^{(1)} = \\sum_{i=1}^{K_0} w^{(1)}_{ij}x_i + w_{0j}^{(1)}  \" /></div>
<p>where <img src=\"http://s0.wp.com/latex.php?latex=K_0+%5Cequiv+n&bg=ffffff&fg=333333&s=0\" alt=\"K_0 \\equiv n\" class=\"latex\" title=\"K_0 \\equiv n\" /> is the size of the input vector and there are <img src=\"http://s0.wp.com/latex.php?latex=j+%3D+1%2C%5Cldots%2CK_1&bg=ffffff&fg=333333&s=0\" alt=\"j = 1,\\ldots,K_1\" class=\"latex\" title=\"j = 1,\\ldots,K_1\" /> neurons in the so called first hidden layer of the network. The weights are unknown.</p>
<p>The second transformation then applies a non-linear activation function <img src=\"http://s0.wp.com/latex.php?latex=f&bg=ffffff&fg=333333&s=0\" alt=\"f\" class=\"latex\" title=\"f\" /> to each <img src=\"http://s0.wp.com/latex.php?latex=a_j&bg=ffffff&fg=333333&s=0\" alt=\"a_j\" class=\"latex\" title=\"a_j\" /> to give the output from the <img src=\"http://s0.wp.com/latex.php?latex=j&bg=ffffff&fg=333333&s=0\" alt=\"j\" class=\"latex\" title=\"j\" />-th neuron in the first hidden layer.</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++z_j%5E%7B%281%29%7D+%3D+f%28a_j%5E%7B%281%29%7D%29++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  z_j^{(1)} = f(a_j^{(1)})  \" class=\"latex\" title=\"\\displaystyle  z_j^{(1)} = f(a_j^{(1)})  \" /></div>
<p>Typically, <img src=\"http://s0.wp.com/latex.php?latex=f&bg=ffffff&fg=333333&s=0\" alt=\"f\" class=\"latex\" title=\"f\" /> is chosen to be <img src=\"http://s0.wp.com/latex.php?latex=%5Ctanh&bg=ffffff&fg=333333&s=0\" alt=\"\\tanh\" class=\"latex\" title=\"\\tanh\" /> or the logistic function. Note that if it were chosen to be the identity then our neural network would be the same as a multivariate linear logistic regression.</p>
<p>We now repeat these steps for the second hidden layer:</p>
<p>Ultimately after we applied <img src=\"http://s0.wp.com/latex.php?latex=L-1&bg=ffffff&fg=333333&s=0\" alt=\"L-1\" class=\"latex\" title=\"L-1\" /> transformations (through <img src=\"http://s0.wp.com/latex.php?latex=L-1&bg=ffffff&fg=333333&s=0\" alt=\"L-1\" class=\"latex\" title=\"L-1\" /> hidden layers) we produce some output:</p>
<p>We show an example neural in the diagram below.</p>
<div style=\"text-align: center;\">
<p><img src=\"http://idontgetoutmuch.files.wordpress.com/2013/05/3e46ca17f20285d1315961aa7dc6196f.png?w=450\" alt=\"\" /></p>
</div>
<p>The input layer has 7 nodes. There are 2 hidden layers, the first has 3 nodes and the second has 5. The output layer has 3 nodes.</p>
<p>We are also given a cost function:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++E%28%5Cboldsymbol%7Bw%7D%3B+%5Cboldsymbol%7Bx%7D%2C+%5Cboldsymbol%7By%7D%29+%3D+%5Cfrac%7B1%7D%7B2%7D%5C%7C%28%5Chat%7B%5Cboldsymbol%7By%7D%7D+-+%5Cboldsymbol%7By%7D%29%5C%7C%5E2++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  E(\\boldsymbol{w}; \\boldsymbol{x}, \\boldsymbol{y}) = \\frac{1}{2}\\|(\\hat{\\boldsymbol{y}} - \\boldsymbol{y})\\|^2  \" class=\"latex\" title=\"\\displaystyle  E(\\boldsymbol{w}; \\boldsymbol{x}, \\boldsymbol{y}) = \\frac{1}{2}\\|(\\hat{\\boldsymbol{y}} - \\boldsymbol{y})\\|^2  \" /></div>
<p>where <img src=\"http://s0.wp.com/latex.php?latex=%5Chat%7B%5Cboldsymbol%7By%7D%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\hat{\\boldsymbol{y}}\" class=\"latex\" title=\"\\hat{\\boldsymbol{y}}\" /> is the predicted output of the neural net and <img src=\"http://s0.wp.com/latex.php?latex=%5Cboldsymbol%7By%7D&bg=ffffff&fg=333333&s=0\" alt=\"\\boldsymbol{y}\" class=\"latex\" title=\"\\boldsymbol{y}\" /> is the observed output.</p>
<p>As with logistic regression, our goal is to find weights for the neural network which minimises this cost function. We initialise the weights to some small non-zero amount and then use the method of steepest descent (aka gradient descent). The idea is that if <img src=\"http://s0.wp.com/latex.php?latex=f&bg=ffffff&fg=333333&s=0\" alt=\"f\" class=\"latex\" title=\"f\" /> is a function of several variables then to find its minimum value, one ought to take a small step in the direction in which it is decreasing most quickly and repeat until no step in any direction results in a decrease. The analogy is that if one is walking in the mountains then the quickest way down is to walk in the direction which goes down most steeply. Of course one get stuck at a local minimum rather than the global minimum but from a machine learning point of view this may be acceptable; alternatively one may start at random points in the search space and check they all give the same minimum.</p>
<p>We therefore need calculate the gradient of the loss function with respect to the weights (since we need to minimise the cost function). In other words we need to find:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cnabla+E%28%5Cboldsymbol%7Bx%7D%29+%5Cequiv+%28%5Cfrac%7B%5Cpartial+E%7D%7B%5Cpartial+w_1%7D%2C+%5Cldots%2C+%5Cfrac%7B%5Cpartial+E%7D%7B%5Cpartial+w_n%7D%29++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  \\nabla E(\\boldsymbol{x}) \\equiv (\\frac{\\partial E}{\\partial w_1}, \\ldots, \\frac{\\partial E}{\\partial w_n})  \" class=\"latex\" title=\"\\displaystyle  \\nabla E(\\boldsymbol{x}) \\equiv (\\frac{\\partial E}{\\partial w_1}, \\ldots, \\frac{\\partial E}{\\partial w_n})  \" /></div>
<p>Once we have this we can take our random starting position and move down the steepest gradient:</p>
<div style=\"text-align: center;\"><img src=\"http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++w%27_i+%3D+w_i+-+%5Cgamma%5Cfrac%7B%5Cpartial+E%7D%7B%5Cpartial+w_i%7D++&bg=ffffff&fg=333333&s=0\" alt=\"\\displaystyle  w'_i = w_i - \\gamma\\frac{\\partial E}{\\partial w_i}  \" class=\"latex\" title=\"\\displaystyle  w'_i = w_i - \\gamma\\frac{\\partial E}{\\partial w_i}  \" /></div>
<p>where <img src=\"http://s0.wp.com/latex.php?latex=%5Cgamma&bg=ffffff&fg=333333&s=0\" alt=\"\\gamma\" class=\"latex\" title=\"\\gamma\" /> is the step length known in machine learning parlance as the learning rate.</p>
<h2 id=\"haskell-foreword\">Haskell Foreword</h2>
<p>Some pragmas and imports required for the example code.</p>
<pre><code>> <span style=\"color: green;\">{-# LANGUAGE RankNTypes                #-}</span>
> <span style=\"color: green;\">{-# LANGUAGE DeriveFunctor             #-}</span>
> <span style=\"color: green;\">{-# LANGUAGE DeriveFoldable            #-}</span>
> <span style=\"color: green;\">{-# LANGUAGE DeriveTraversable         #-}</span>
> <span style=\"color: green;\">{-# LANGUAGE ScopedTypeVariables       #-}</span>
> <span style=\"color: green;\">{-# LANGUAGE TupleSections             #-}</span>
> <span style=\"color: green;\">{-# LANGUAGE NoMonomorphismRestriction #-}</span>
</code>
<code>> <span style=\"color: green;\">{-# OPTIONS_GHC -Wall                     #-}</span>
> <span style=\"color: green;\">{-# OPTIONS_GHC -fno-warn-name-shadowing  #-}</span>
> <span style=\"color: green;\">{-# OPTIONS_GHC -fno-warn-type-defaults   #-}</span>
> <span style=\"color: green;\">{-# OPTIONS_GHC -fno-warn-unused-do-bind  #-}</span>
> <span style=\"color: green;\">{-# OPTIONS_GHC -fno-warn-missing-methods #-}</span>
</code>
<code>> <span style=\"color: blue; font-weight: bold;\">module</span> NeuralNet
>        <span style=\"color: red;\">(</span> test1
>        <span style=\"color: red;\">,</span> test2
>        <span style=\"color: red;\">,</span> test3
>        <span style=\"color: red;\">)</span> <span style=\"color: blue; font-weight: bold;\">where</span>
</code>
<code>> <span style=\"color: blue; font-weight: bold;\">import</span> Numeric.AD
> <span style=\"color: blue; font-weight: bold;\">import</span> Numeric.AD.Types
</code>
<code>> <span style=\"color: blue; font-weight: bold;\">import</span> Data.Traversable <span style=\"color: red;\">(</span>Traversable<span style=\"color: red;\">)</span>
> <span style=\"color: blue; font-weight: bold;\">import</span> Data.Foldable <span style=\"color: red;\">(</span>Foldable<span style=\"color: red;\">)</span>
> <span style=\"color: blue; font-weight: bold;\">import</span> Data.List
> <span style=\"color: blue; font-weight: bold;\">import</span> Data.List.Split
> <span style=\"color: blue; font-weight: bold;\">import</span> System.Random
> <span style=\"color: blue; font-weight: bold;\">import</span> <span style=\"color: blue; font-weight: bold;\">qualified</span> Data.Vector <span style=\"color: blue; font-weight: bold;\">as</span> V
</code>
<code>> <span style=\"color: blue; font-weight: bold;\">import</span> Control.Monad
> <span style=\"color: blue; font-weight: bold;\">import</span> Control.Monad.State
</code>
<code>> <span style=\"color: blue; font-weight: bold;\">import</span> Data.Random ()
> <span style=\"color: blue; font-weight: bold;\">import</span> Data.Random.Distribution.Beta
> <span style=\"color: blue; font-weight: bold;\">import</span> Data.Random.Distribution.Uniform
> <span style=\"color: blue; font-weight: bold;\">import</span> Data.RVar
</code>
<code>> <span style=\"color: blue; font-weight: bold;\">import</span> Text.Printf
</code></pre>
<h2 id=\"logistic-regression-redux\">Logistic Regression Redux</h2>
<p>Let us first implement logistic regression. This will give us a reference against which to compare the equivalent solution expressed as a neural network.</p>
<p>Instead of maximimizing the log likelihood, we will minimize a cost function.</p>
<pre><code>> cost <span style=\"color: red;\">::</span> Floating a <span style=\"color: red;\">=></span> V.Vector a <span style=\"color: red;\">-></span> a <span style=\"color: red;\">-></span> V.Vector a <span style=\"color: red;\">-></span> a
> cost theta y x <span style=\"color: red;\">=</span> <span class=\"hs-num\">0.5</span> * <span style=\"color: red;\">(</span>y <span style=\"color: green;\">-</span> yhat<span style=\"color: red;\">)</span>^<span class=\"hs-num\">2</span>
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     yhat <span style=\"color: red;\">=</span> logit $ V.sum $ V.zipWith <span style=\"color: red;\">(</span>*<span style=\"color: red;\">)</span> theta x
</code>
<code>> logit <span style=\"color: red;\">::</span> Floating a <span style=\"color: red;\">=></span>
>          a <span style=\"color: red;\">-></span> a
> logit x <span style=\"color: red;\">=</span> <span class=\"hs-num\">1</span> / <span style=\"color: red;\">(</span><span class=\"hs-num\">1</span> + exp <span style=\"color: red;\">(</span>negate x<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span>
</code></pre>
<p>We add a regularization term into the total cost so that the parameters do not grow too large. Note that we do not regularize over the bias.</p>
<pre><code>> delta <span style=\"color: red;\">::</span> Floating a <span style=\"color: red;\">=></span> a
> delta <span style=\"color: red;\">=</span> <span class=\"hs-num\">0.01</span>
</code>
<code>> totalCost <span style=\"color: red;\">::</span> Floating a <span style=\"color: red;\">=></span>
>              V.Vector a <span style=\"color: red;\">-></span>
>              V.Vector a <span style=\"color: red;\">-></span>
>              V.Vector <span style=\"color: red;\">(</span>V.Vector a<span style=\"color: red;\">)</span> <span style=\"color: red;\">-></span>
>              a
> totalCost theta y x <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span>a + delta * b<span style=\"color: red;\">)</span> / l
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     l <span style=\"color: red;\">=</span> fromIntegral $ V.length y
>     a <span style=\"color: red;\">=</span> V.sum $ V.zipWith <span style=\"color: red;\">(</span>cost theta<span style=\"color: red;\">)</span> y x
>     b <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span>/<span class=\"hs-num\">2</span><span style=\"color: red;\">)</span> $ V.sum $ V.map <span style=\"color: red;\">(</span>^<span class=\"hs-num\">2</span><span style=\"color: red;\">)</span> $ V.drop <span class=\"hs-num\">1</span> theta
</code></pre>
<p>We determine the gradient of the regularized cost function.</p>
<pre><code>> delTotalCost <span style=\"color: red;\">::</span> Floating a <span style=\"color: red;\">=></span>
>                 V.Vector a <span style=\"color: red;\">-></span>
>                 V.Vector <span style=\"color: red;\">(</span>V.Vector a<span style=\"color: red;\">)</span> <span style=\"color: red;\">-></span>
>                 V.Vector a <span style=\"color: red;\">-></span>
>                 V.Vector a
> delTotalCost y x <span style=\"color: red;\">=</span> grad f
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     f theta <span style=\"color: red;\">=</span> totalCost theta <span style=\"color: red;\">(</span>V.map auto y<span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>V.map <span style=\"color: red;\">(</span>V.map auto<span style=\"color: red;\">)</span> x<span style=\"color: red;\">)</span>
</code></pre>
<p>And finally we can apply <a href=\"http://en.wikipedia.org/wiki/Gradient_descent\">gradient descent</a>.</p>
<pre><code>> gamma <span style=\"color: red;\">::</span> Double
> gamma <span style=\"color: red;\">=</span> <span class=\"hs-num\">0.4</span>
</code>
<code>> stepOnceCost <span style=\"color: red;\">::</span> Floating a <span style=\"color: red;\">=></span>
>                  a <span style=\"color: red;\">-></span>
>                  V.Vector a <span style=\"color: red;\">-></span>
>                  V.Vector <span style=\"color: red;\">(</span>V.Vector a<span style=\"color: red;\">)</span> <span style=\"color: red;\">-></span>
>                  V.Vector a <span style=\"color: red;\">-></span>
>                  V.Vector a
> stepOnceCost gamma y x theta <span style=\"color: red;\">=</span>
>   V.zipWith <span style=\"color: red;\">(</span><span style=\"color: green;\">-</span><span style=\"color: red;\">)</span> theta <span style=\"color: red;\">(</span>V.map <span style=\"color: red;\">(</span>* gamma<span style=\"color: red;\">)</span> $ del theta<span style=\"color: red;\">)</span>
>     <span style=\"color: blue; font-weight: bold;\">where</span>
>       del <span style=\"color: red;\">=</span> delTotalCost y x
</code></pre>
<h2 id=\"neural-network-representation\">Neural Network Representation</h2>
<p>Let us borrow, generalize and prune the data structures used in <a href=\"http://themonadreader.files.wordpress.com/2013/03/issue214.pdf\">“A Functional Approach to Neural Networks”</a>. Some of the fields in the borrowed data structures are probably no longer necessary given that we are going to use automated differentiation rather than backpropagation. Caveat lector!</p>
<p>The activation function itself is a function which takes any type in the <em>Floating</em> class to the same type in the <em>Floating</em> class e.g. <em>Double</em>.</p>
<pre><code>> <span style=\"color: blue; font-weight: bold;\">newtype</span> ActivationFunction <span style=\"color: red;\">=</span>
>   ActivationFunction
>   <span style=\"color: red;\">{</span>
>     activationFunction <span style=\"color: red;\">::</span> Floating a <span style=\"color: red;\">=></span> a <span style=\"color: red;\">-></span> a
>   <span style=\"color: red;\">}</span>
</code></pre>
<p>A neural network is a collection of layers.</p>
<pre><code>> <span style=\"color: blue; font-weight: bold;\">data</span> Layer a <span style=\"color: red;\">=</span>
>   Layer
>   <span style=\"color: red;\">{</span>
>     layerWeights  <span style=\"color: red;\">::</span> <span style=\"color: red;\">[</span><span style=\"color: red;\">[</span>a<span style=\"color: red;\">]</span><span style=\"color: red;\">]</span><span style=\"color: red;\">,</span>
>     layerFunction <span style=\"color: red;\">::</span> ActivationFunction
>   <span style=\"color: red;\">}</span> <span style=\"color: blue; font-weight: bold;\">deriving</span> <span style=\"color: red;\">(</span>Functor<span style=\"color: red;\">,</span> Foldable<span style=\"color: red;\">,</span> Traversable<span style=\"color: red;\">)</span>
</code>
<code>> <span style=\"color: blue; font-weight: bold;\">data</span> BackpropNet a <span style=\"color: red;\">=</span> BackpropNet
>     <span style=\"color: red;\">{</span>
>       layers       <span style=\"color: red;\">::</span> <span style=\"color: red;\">[</span>Layer a<span style=\"color: red;\">]</span><span style=\"color: red;\">,</span>
>       learningRate <span style=\"color: red;\">::</span> Double
>     <span style=\"color: red;\">}</span> <span style=\"color: blue; font-weight: bold;\">deriving</span> <span style=\"color: red;\">(</span>Functor<span style=\"color: red;\">,</span> Foldable<span style=\"color: red;\">,</span> Traversable<span style=\"color: red;\">)</span>
</code></pre>
<p>We need some helper functions to build our neural network and to extract information from it.</p>
<pre><code>> buildBackpropNet <span style=\"color: red;\">::</span>
>   Double <span style=\"color: red;\">-></span>
>   <span style=\"color: red;\">[</span><span style=\"color: red;\">[</span><span style=\"color: red;\">[</span>a<span style=\"color: red;\">]</span><span style=\"color: red;\">]</span><span style=\"color: red;\">]</span> <span style=\"color: red;\">-></span>
>   ActivationFunction <span style=\"color: red;\">-></span>
>   BackpropNet a
> buildBackpropNet learningRate ws f <span style=\"color: red;\">=</span>
>   BackpropNet <span style=\"color: red;\">{</span>
>       layers       <span style=\"color: red;\">=</span> map buildLayer checkedWeights
>     <span style=\"color: red;\">,</span> learningRate <span style=\"color: red;\">=</span> learningRate
>     <span style=\"color: red;\">}</span>
>   <span style=\"color: blue; font-weight: bold;\">where</span> checkedWeights <span style=\"color: red;\">=</span> scanl1 checkDimensions ws
>         buildLayer w   <span style=\"color: red;\">=</span> Layer <span style=\"color: red;\">{</span> layerWeights  <span style=\"color: red;\">=</span> w
>                                 <span style=\"color: red;\">,</span> layerFunction <span style=\"color: red;\">=</span> f
>                                 <span style=\"color: red;\">}</span>
>         checkDimensions <span style=\"color: red;\">::</span> <span style=\"color: red;\">[</span><span style=\"color: red;\">[</span>a<span style=\"color: red;\">]</span><span style=\"color: red;\">]</span> <span style=\"color: red;\">-></span> <span style=\"color: red;\">[</span><span style=\"color: red;\">[</span>a<span style=\"color: red;\">]</span><span style=\"color: red;\">]</span> <span style=\"color: red;\">-></span> <span style=\"color: red;\">[</span><span style=\"color: red;\">[</span>a<span style=\"color: red;\">]</span><span style=\"color: red;\">]</span>
>         checkDimensions w1 w2 <span style=\"color: red;\">=</span>
>           <span style=\"color: blue; font-weight: bold;\">if</span> <span class=\"hs-num\">1</span> + length w1 == length <span style=\"color: red;\">(</span>head w2<span style=\"color: red;\">)</span>
>           <span style=\"color: blue; font-weight: bold;\">then</span> w2
>           <span style=\"color: blue; font-weight: bold;\">else</span> error $ <span style=\"color: teal;\">\"Inconsistent dimensions in weight matrix\\n\"</span> ++
>                         show <span style=\"color: red;\">(</span>length w1<span style=\"color: red;\">)</span>        ++ <span style=\"color: teal;\">\"\\n\"</span> ++
>                         show <span style=\"color: red;\">(</span>length w2<span style=\"color: red;\">)</span>        ++ <span style=\"color: teal;\">\"\\n\"</span> ++
>                         show <span style=\"color: red;\">(</span>length $ head w1<span style=\"color: red;\">)</span> ++ <span style=\"color: teal;\">\"\\n\"</span> ++
>                         show <span style=\"color: red;\">(</span>length $ head w2<span style=\"color: red;\">)</span>
</code>
<code>> extractWeights <span style=\"color: red;\">::</span> BackpropNet a <span style=\"color: red;\">-></span> <span style=\"color: red;\">[</span><span style=\"color: red;\">[</span><span style=\"color: red;\">[</span>a<span style=\"color: red;\">]</span><span style=\"color: red;\">]</span><span style=\"color: red;\">]</span>
> extractWeights x <span style=\"color: red;\">=</span> map layerWeights $ layers x
</code></pre>
<p>In order to undertake gradient descent on the data structure in which we store a neural network, <em>BackpropNet</em>, it will be convenient to be able to add such structures together point-wise.</p>
<pre><code>> <span style=\"color: blue; font-weight: bold;\">instance</span> Num a <span style=\"color: red;\">=></span> Num <span style=\"color: red;\">(</span>Layer a<span style=\"color: red;\">)</span> <span style=\"color: blue; font-weight: bold;\">where</span>
>   <span style=\"color: red;\">(</span>+<span style=\"color: red;\">)</span> <span style=\"color: red;\">=</span> addLayer
>
> addLayer <span style=\"color: red;\">::</span> Num a <span style=\"color: red;\">=></span> Layer a <span style=\"color: red;\">-></span> Layer a <span style=\"color: red;\">-></span> Layer a
> addLayer x y <span style=\"color: red;\">=</span>
>   Layer <span style=\"color: red;\">{</span> layerWeights  <span style=\"color: red;\">=</span> zipWith <span style=\"color: red;\">(</span>zipWith <span style=\"color: red;\">(</span>+<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span>
>                                   <span style=\"color: red;\">(</span>layerWeights x<span style=\"color: red;\">)</span>
>                                   <span style=\"color: red;\">(</span>layerWeights y<span style=\"color: red;\">)</span>
>         <span style=\"color: red;\">,</span> layerFunction <span style=\"color: red;\">=</span> layerFunction x
>         <span style=\"color: red;\">}</span>
</code>
<code>> <span style=\"color: blue; font-weight: bold;\">instance</span> Num a <span style=\"color: red;\">=></span> Num <span style=\"color: red;\">(</span>BackpropNet a<span style=\"color: red;\">)</span> <span style=\"color: blue; font-weight: bold;\">where</span>
>   <span style=\"color: red;\">(</span>+<span style=\"color: red;\">)</span> <span style=\"color: red;\">=</span> addBPN
</code>
<code>> addBPN <span style=\"color: red;\">::</span> Num a <span style=\"color: red;\">=></span> BackpropNet a <span style=\"color: red;\">-></span> BackpropNet a <span style=\"color: red;\">-></span> BackpropNet a
> addBPN x y <span style=\"color: red;\">=</span> BackpropNet <span style=\"color: red;\">{</span> layers <span style=\"color: red;\">=</span> zipWith <span style=\"color: red;\">(</span>+<span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>layers x<span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>layers y<span style=\"color: red;\">)</span>
>                           <span style=\"color: red;\">,</span> learningRate <span style=\"color: red;\">=</span> learningRate x
>                           <span style=\"color: red;\">}</span>
</code></pre>
<p>We store information about updating of output values in each layer in the neural network as we move forward through the network (aka forward propagation).</p>
<pre><code>> <span style=\"color: blue; font-weight: bold;\">data</span> PropagatedLayer a
>     <span style=\"color: red;\">=</span> PropagatedLayer
>         <span style=\"color: red;\">{</span>
>           propLayerIn         <span style=\"color: red;\">::</span> <span style=\"color: red;\">[</span>a<span style=\"color: red;\">]</span><span style=\"color: red;\">,</span>
>           propLayerOut        <span style=\"color: red;\">::</span> <span style=\"color: red;\">[</span>a<span style=\"color: red;\">]</span><span style=\"color: red;\">,</span>
>           propLayerWeights    <span style=\"color: red;\">::</span> <span style=\"color: red;\">[</span><span style=\"color: red;\">[</span>a<span style=\"color: red;\">]</span><span style=\"color: red;\">]</span><span style=\"color: red;\">,</span>
>           propLayerActFun     <span style=\"color: red;\">::</span> ActivationFunction
>         <span style=\"color: red;\">}</span>
>     <span style=\"color: red;\">|</span> PropagatedSensorLayer
>         <span style=\"color: red;\">{</span>
>           propLayerOut <span style=\"color: red;\">::</span> <span style=\"color: red;\">[</span>a<span style=\"color: red;\">]</span>
>         <span style=\"color: red;\">}</span> <span style=\"color: blue; font-weight: bold;\">deriving</span> <span style=\"color: red;\">(</span>Functor<span style=\"color: red;\">,</span> Foldable<span style=\"color: red;\">,</span> Traversable<span style=\"color: red;\">)</span>
</code></pre>
<p>Sadly we have to use an inefficient calculation to multiply matrices; see this <a href=\"http://www.haskell.org/pipermail/haskell-cafe/2013-April/107543.html\">email</a> for further details.</p>
<pre><code>> matMult <span style=\"color: red;\">::</span> Num a <span style=\"color: red;\">=></span> <span style=\"color: red;\">[</span><span style=\"color: red;\">[</span>a<span style=\"color: red;\">]</span><span style=\"color: red;\">]</span> <span style=\"color: red;\">-></span> <span style=\"color: red;\">[</span>a<span style=\"color: red;\">]</span> <span style=\"color: red;\">-></span> <span style=\"color: red;\">[</span>a<span style=\"color: red;\">]</span>
> matMult m v <span style=\"color: red;\">=</span> result
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     lrs <span style=\"color: red;\">=</span> map length m
>     l   <span style=\"color: red;\">=</span> length v
>     result <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">if</span> all <span style=\"color: red;\">(</span>== l<span style=\"color: red;\">)</span> lrs
>              <span style=\"color: blue; font-weight: bold;\">then</span> map <span style=\"color: red;\">(</span><span style=\"color: red;\">\\</span>r <span style=\"color: red;\">-></span> sum $ zipWith <span style=\"color: red;\">(</span>*<span style=\"color: red;\">)</span> r v<span style=\"color: red;\">)</span> m
>              <span style=\"color: blue; font-weight: bold;\">else</span> error $ <span style=\"color: teal;\">\"Matrix has rows of length \"</span> ++ show lrs ++
>                           <span style=\"color: teal;\">\" but vector is of length \"</span> ++ show l
</code></pre>
<p>Now we can propagate forwards. Note that the code from which this is borrowed assumes that the inputs are images which are <img src=\"http://s0.wp.com/latex.php?latex=m+%5Ctimes+m&bg=ffffff&fg=333333&s=0\" alt=\"m \\times m\" class=\"latex\" title=\"m \\times m\" /> pixels each encoded using a grayscale, hence the references to bits and the check that values lie in the range <img src=\"http://s0.wp.com/latex.php?latex=0+%5Cleq+x+%5Cleq+1&bg=ffffff&fg=333333&s=0\" alt=\"0 \\leq x \\leq 1\" class=\"latex\" title=\"0 \\leq x \\leq 1\" />.</p>
<pre><code>> propagateNet <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span>Floating a<span style=\"color: red;\">,</span> Ord a<span style=\"color: red;\">,</span> Show a<span style=\"color: red;\">)</span> <span style=\"color: red;\">=></span>
>                 <span style=\"color: red;\">[</span>a<span style=\"color: red;\">]</span> <span style=\"color: red;\">-></span>
>                 BackpropNet a <span style=\"color: red;\">-></span>
>                 <span style=\"color: red;\">[</span>PropagatedLayer a<span style=\"color: red;\">]</span>
> propagateNet input net <span style=\"color: red;\">=</span> tail calcs
>   <span style=\"color: blue; font-weight: bold;\">where</span> calcs <span style=\"color: red;\">=</span> scanl propagate layer0 <span style=\"color: red;\">(</span>layers net<span style=\"color: red;\">)</span>
>         layer0 <span style=\"color: red;\">=</span> PropagatedSensorLayer $ validateInput net input
>
>         validateInput net <span style=\"color: red;\">=</span> validateInputValues .
>                             validateInputDimensions net
>
>         validateInputDimensions net input <span style=\"color: red;\">=</span>
>           <span style=\"color: blue; font-weight: bold;\">if</span> got == expected
>           <span style=\"color: blue; font-weight: bold;\">then</span> input
>           <span style=\"color: blue; font-weight: bold;\">else</span> error <span style=\"color: red;\">(</span><span style=\"color: teal;\">\"Input pattern has \"</span> ++ show got ++
>                       <span style=\"color: teal;\">\" bits, but \"</span> ++
>                       show expected ++ <span style=\"color: teal;\">\" were expected\"</span><span style=\"color: red;\">)</span>
>           <span style=\"color: blue; font-weight: bold;\">where</span> got      <span style=\"color: red;\">=</span> length input
>                 expected <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span>+<span style=\"color: red;\">(</span>negate <span class=\"hs-num\">1</span><span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> $
>                            length $
>                            head $
>                            layerWeights $
>                            head $
>                            layers net
>
>         validateInputValues input <span style=\"color: red;\">=</span>
>           <span style=\"color: blue; font-weight: bold;\">if</span> <span style=\"color: red;\">(</span>minimum input >= <span class=\"hs-num\">0</span><span style=\"color: red;\">)</span> && <span style=\"color: red;\">(</span>maximum input <= <span class=\"hs-num\">1</span><span style=\"color: red;\">)</span>
>           <span style=\"color: blue; font-weight: bold;\">then</span> input
>           <span style=\"color: blue; font-weight: bold;\">else</span> error <span style=\"color: teal;\">\"Input bits outside of range [0,1]\"</span>
</code></pre>
<p>Note that we add a 1 to the inputs to each layer to give the bias.</p>
<pre><code>> propagate <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span>Floating a<span style=\"color: red;\">,</span> Show a<span style=\"color: red;\">)</span> <span style=\"color: red;\">=></span>
>              PropagatedLayer a <span style=\"color: red;\">-></span>
>              Layer a <span style=\"color: red;\">-></span>
>              PropagatedLayer a
> propagate layerJ layerK <span style=\"color: red;\">=</span> result
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     result <span style=\"color: red;\">=</span>
>       PropagatedLayer
>         <span style=\"color: red;\">{</span>
>           propLayerIn         <span style=\"color: red;\">=</span> layerJOut<span style=\"color: red;\">,</span>
>           propLayerOut        <span style=\"color: red;\">=</span> map f a<span style=\"color: red;\">,</span>
>           propLayerWeights    <span style=\"color: red;\">=</span> weights<span style=\"color: red;\">,</span>
>           propLayerActFun     <span style=\"color: red;\">=</span> layerFunction layerK
>         <span style=\"color: red;\">}</span>
>     layerJOut <span style=\"color: red;\">=</span> propLayerOut layerJ
>     weights   <span style=\"color: red;\">=</span> layerWeights layerK
>     a <span style=\"color: red;\">=</span> weights `matMult` <span style=\"color: red;\">(</span><span class=\"hs-num\">1</span>:layerJOut<span style=\"color: red;\">)</span>
>     f <span style=\"color: red;\">::</span> Floating a <span style=\"color: red;\">=></span> a <span style=\"color: red;\">-></span> a
>     f <span style=\"color: red;\">=</span> activationFunction $ layerFunction layerK
</code>
<code>> evalNeuralNet <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span>Floating a<span style=\"color: red;\">,</span> Ord a<span style=\"color: red;\">,</span> Show a<span style=\"color: red;\">)</span> <span style=\"color: red;\">=></span>
>                  BackpropNet a <span style=\"color: red;\">-></span> <span style=\"color: red;\">[</span>a<span style=\"color: red;\">]</span> <span style=\"color: red;\">-></span> <span style=\"color: red;\">[</span>a<span style=\"color: red;\">]</span>
> evalNeuralNet net input <span style=\"color: red;\">=</span> propLayerOut $ last calcs
>   <span style=\"color: blue; font-weight: bold;\">where</span> calcs <span style=\"color: red;\">=</span> propagateNet input net
</code></pre>
<p>We define a cost function.</p>
<pre><code>> costFn <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span>Floating a<span style=\"color: red;\">,</span> Ord a<span style=\"color: red;\">,</span> Show a<span style=\"color: red;\">)</span> <span style=\"color: red;\">=></span>
>           Int <span style=\"color: red;\">-></span>
>           Int <span style=\"color: red;\">-></span>
>           <span style=\"color: red;\">[</span>a<span style=\"color: red;\">]</span> <span style=\"color: red;\">-></span>
>           BackpropNet a <span style=\"color: red;\">-></span>
>           a
> costFn nDigits expectedDigit input net <span style=\"color: red;\">=</span> <span class=\"hs-num\">0.5</span> * sum <span style=\"color: red;\">(</span>map <span style=\"color: red;\">(</span>^<span class=\"hs-num\">2</span><span style=\"color: red;\">)</span> diffs<span style=\"color: red;\">)</span>
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     predicted <span style=\"color: red;\">=</span> evalNeuralNet net input
>     diffs <span style=\"color: red;\">=</span> zipWith <span style=\"color: red;\">(</span><span style=\"color: green;\">-</span><span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>targets nDigits<span style=\"color: red;\">)</span>!!expectedDigit<span style=\"color: red;\">)</span> predicted
</code>
<code>> targets <span style=\"color: red;\">::</span> Floating a <span style=\"color: red;\">=></span> Int <span style=\"color: red;\">-></span> <span style=\"color: red;\">[</span><span style=\"color: red;\">[</span>a<span style=\"color: red;\">]</span><span style=\"color: red;\">]</span>
> targets nDigits <span style=\"color: red;\">=</span> map row <span style=\"color: red;\">[</span><span class=\"hs-num\">0</span> <span style=\"color: red;\">..</span> nDigits <span style=\"color: green;\">-</span> <span class=\"hs-num\">1</span><span style=\"color: red;\">]</span>
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     row m <span style=\"color: red;\">=</span> concat <span style=\"color: red;\">[</span>x<span style=\"color: red;\">,</span> <span class=\"hs-num\">1.0</span> : y<span style=\"color: red;\">]</span>
>       <span style=\"color: blue; font-weight: bold;\">where</span>
>         <span style=\"color: red;\">(</span>x<span style=\"color: red;\">,</span> y<span style=\"color: red;\">)</span> <span style=\"color: red;\">=</span> splitAt m <span style=\"color: red;\">(</span>take <span style=\"color: red;\">(</span>nDigits <span style=\"color: green;\">-</span> <span class=\"hs-num\">1</span><span style=\"color: red;\">)</span> $ repeat <span class=\"hs-num\">0.0</span><span style=\"color: red;\">)</span>
</code></pre>
<p>If instead we would rather perform gradient descent over the whole training set (rather than stochastically) then we can do so. Note that we do not regularize the weights for the biases.</p>
<pre><code>> totalCostNN <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span>Floating a<span style=\"color: red;\">,</span> Ord a<span style=\"color: red;\">,</span> Show a<span style=\"color: red;\">)</span> <span style=\"color: red;\">=></span>
>                Int <span style=\"color: red;\">-></span>
>                V.Vector Int <span style=\"color: red;\">-></span>
>                V.Vector <span style=\"color: red;\">[</span>a<span style=\"color: red;\">]</span> <span style=\"color: red;\">-></span>
>                BackpropNet a <span style=\"color: red;\">-></span>
>                a
> totalCostNN nDigits expectedDigits inputs net <span style=\"color: red;\">=</span> cost
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     cost <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span>a + delta * b<span style=\"color: red;\">)</span> / l
>
>     l <span style=\"color: red;\">=</span> fromIntegral $ V.length expectedDigits
>
>     a <span style=\"color: red;\">=</span> V.sum $ V.zipWith <span style=\"color: red;\">(</span><span style=\"color: red;\">\\</span>expectedDigit input <span style=\"color: red;\">-></span>
>                             costFn nDigits expectedDigit input net<span style=\"color: red;\">)</span>
>                           expectedDigits inputs
>
>     b <span style=\"color: red;\">=</span> <span style=\"color: red;\">(</span>/<span style=\"color: red;\">(</span><span class=\"hs-num\">2</span> * m<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> $ sum $ map <span style=\"color: red;\">(</span>^<span class=\"hs-num\">2</span><span style=\"color: red;\">)</span> ws
>
>     m <span style=\"color: red;\">=</span> fromIntegral $ length ws
>
>     ws <span style=\"color: red;\">=</span> concat $ concat $
>          map stripBias $
>          extractWeights net
>
>     stripBias xss <span style=\"color: red;\">=</span> map <span style=\"color: red;\">(</span>drop <span class=\"hs-num\">1</span><span style=\"color: red;\">)</span> xss
</code>
<code>> delTotalCostNN <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span>Floating a<span style=\"color: red;\">,</span> Ord a<span style=\"color: red;\">,</span> Show a<span style=\"color: red;\">)</span> <span style=\"color: red;\">=></span>
>                   Int <span style=\"color: red;\">-></span>
>                   V.Vector Int <span style=\"color: red;\">-></span>
>                   V.Vector <span style=\"color: red;\">[</span>a<span style=\"color: red;\">]</span> <span style=\"color: red;\">-></span>
>                   BackpropNet a <span style=\"color: red;\">-></span>
>                   BackpropNet a
> delTotalCostNN nDigits expectedDigits inputs <span style=\"color: red;\">=</span> grad f
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     f net <span style=\"color: red;\">=</span> totalCostNN nDigits expectedDigits
>                         <span style=\"color: red;\">(</span>V.map <span style=\"color: red;\">(</span>map auto<span style=\"color: red;\">)</span> inputs<span style=\"color: red;\">)</span> net
</code>
<code>> stepOnceTotal <span style=\"color: red;\">::</span> Int <span style=\"color: red;\">-></span>
>                  Double <span style=\"color: red;\">-></span>
>                  V.Vector Int <span style=\"color: red;\">-></span>
>                  V.Vector <span style=\"color: red;\">[</span>Double<span style=\"color: red;\">]</span> <span style=\"color: red;\">-></span>
>                  BackpropNet Double <span style=\"color: red;\">-></span>
>                  BackpropNet Double
> stepOnceTotal nDigits gamma y x net <span style=\"color: red;\">=</span>
>   net + fmap <span style=\"color: red;\">(</span>* <span style=\"color: red;\">(</span>negate gamma<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>delTotalCostNN nDigits y x net<span style=\"color: red;\">)</span>
</code></pre>
<h2 id=\"example-i\">Example I</h2>
<p>Let’s try it out. First we need to generate some data. Rather arbitrarily let us create some populations from the <code>beta</code> distribution.</p>
<pre><code>> betas <span style=\"color: red;\">::</span> Int <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> Double <span style=\"color: red;\">-></span> <span style=\"color: red;\">[</span>Double<span style=\"color: red;\">]</span>
> betas n a b <span style=\"color: red;\">=</span>
>   fst $ runState <span style=\"color: red;\">(</span>replicateM n <span style=\"color: red;\">(</span>sampleRVar <span style=\"color: red;\">(</span>beta a b<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>mkStdGen seed<span style=\"color: red;\">)</span>
>     <span style=\"color: blue; font-weight: bold;\">where</span>
>       seed <span style=\"color: red;\">=</span> <span class=\"hs-num\">0</span>
</code></pre>
<p>We can plot the populations we wish to distinguish by sampling.</p>
<pre><code>> a<span style=\"color: red;\">,</span> b <span style=\"color: red;\">::</span> Double
> a          <span style=\"color: red;\">=</span> <span class=\"hs-num\">15</span>
> b          <span style=\"color: red;\">=</span> <span class=\"hs-num\">6</span>
> nSamples <span style=\"color: red;\">::</span> Int
> nSamples   <span style=\"color: red;\">=</span> <span class=\"hs-num\">100000</span>
>
> sample0<span style=\"color: red;\">,</span> sample1 <span style=\"color: red;\">::</span> <span style=\"color: red;\">[</span>Double<span style=\"color: red;\">]</span>
> sample0 <span style=\"color: red;\">=</span> betas nSamples a b
> sample1 <span style=\"color: red;\">=</span> betas nSamples b a
</code>
<code>> mixSamples <span style=\"color: red;\">::</span> <span style=\"color: red;\">[</span>Double<span style=\"color: red;\">]</span> <span style=\"color: red;\">-></span> <span style=\"color: red;\">[</span>Double<span style=\"color: red;\">]</span> <span style=\"color: red;\">-></span> <span style=\"color: red;\">[</span><span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> Double<span style=\"color: red;\">)</span><span style=\"color: red;\">]</span>
> mixSamples xs ys <span style=\"color: red;\">=</span> unfoldr g <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>map <span style=\"color: red;\">(</span><span class=\"hs-num\">0</span><span style=\"color: red;\">,</span><span style=\"color: red;\">)</span> xs<span style=\"color: red;\">)</span><span style=\"color: red;\">,</span> <span style=\"color: red;\">(</span>map <span style=\"color: red;\">(</span><span class=\"hs-num\">1</span><span style=\"color: red;\">,</span><span style=\"color: red;\">)</span> ys<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span>
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     g <span style=\"color: red;\">(</span>[]<span style=\"color: red;\">,</span> []<span style=\"color: red;\">)</span>         <span style=\"color: red;\">=</span> Nothing
>     g <span style=\"color: red;\">(</span>[]<span style=\"color: red;\">,</span>  <span style=\"color: blue; font-weight: bold;\">_</span><span style=\"color: red;\">)</span>         <span style=\"color: red;\">=</span> Nothing
>     g <span style=\"color: red;\">(</span> <span style=\"color: blue; font-weight: bold;\">_</span><span style=\"color: red;\">,</span> []<span style=\"color: red;\">)</span>         <span style=\"color: red;\">=</span> Nothing
>     g <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>x:xs<span style=\"color: red;\">)</span><span style=\"color: red;\">,</span> <span style=\"color: red;\">(</span>y:ys<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> <span style=\"color: red;\">=</span> Just $ <span style=\"color: red;\">(</span>x<span style=\"color: red;\">,</span> <span style=\"color: red;\">(</span>y:ys<span style=\"color: red;\">,</span> xs<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span>
</code>
<code>> createSample <span style=\"color: red;\">::</span> V.Vector <span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> Double<span style=\"color: red;\">)</span>
> createSample <span style=\"color: red;\">=</span> V.fromList $ take <span class=\"hs-num\">100</span> $ mixSamples sample1 sample0
</code>
<code>> lRate <span style=\"color: red;\">::</span> Double
> lRate <span style=\"color: red;\">=</span> <span class=\"hs-num\">0.01</span>
> actualTheta <span style=\"color: red;\">::</span> V.Vector Double
> actualTheta <span style=\"color: red;\">=</span> V.fromList <span style=\"color: red;\">[</span><span class=\"hs-num\">0.0</span><span style=\"color: red;\">,</span> <span class=\"hs-num\">1.0</span><span style=\"color: red;\">]</span>
> initTheta <span style=\"color: red;\">::</span> V.Vector Double
> initTheta <span style=\"color: red;\">=</span> V.replicate <span style=\"color: red;\">(</span>V.length actualTheta<span style=\"color: red;\">)</span> <span class=\"hs-num\">0.1</span>
</code>
<code>> logitAF <span style=\"color: red;\">::</span> ActivationFunction
> logitAF <span style=\"color: red;\">=</span> ActivationFunction logit
</code>
<code>> test1 <span style=\"color: red;\">::</span> IO ()
> test1 <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>
>   <span style=\"color: blue; font-weight: bold;\">let</span> testNet <span style=\"color: red;\">=</span> buildBackpropNet lRate <span style=\"color: red;\">[</span><span style=\"color: red;\">[</span><span style=\"color: red;\">[</span><span class=\"hs-num\">0.1</span><span style=\"color: red;\">,</span> <span class=\"hs-num\">0.1</span><span style=\"color: red;\">]</span><span style=\"color: red;\">,</span> <span style=\"color: red;\">[</span><span class=\"hs-num\">0.1</span><span style=\"color: red;\">,</span> <span class=\"hs-num\">0.1</span><span style=\"color: red;\">]</span><span style=\"color: red;\">]</span><span style=\"color: red;\">]</span> logitAF
</code>
<code>>   <span style=\"color: blue; font-weight: bold;\">let</span> vals <span style=\"color: red;\">::</span> V.Vector <span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> V.Vector Double<span style=\"color: red;\">)</span>
>       vals <span style=\"color: red;\">=</span> V.map <span style=\"color: red;\">(</span><span style=\"color: red;\">\\</span><span style=\"color: red;\">(</span>y<span style=\"color: red;\">,</span> x<span style=\"color: red;\">)</span> <span style=\"color: red;\">-></span> <span style=\"color: red;\">(</span>y<span style=\"color: red;\">,</span> V.fromList <span style=\"color: red;\">[</span><span class=\"hs-num\">1.0</span><span style=\"color: red;\">,</span> x<span style=\"color: red;\">]</span><span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> $ createSample
>
>   <span style=\"color: blue; font-weight: bold;\">let</span> gs <span style=\"color: red;\">=</span> iterate <span style=\"color: red;\">(</span>stepOnceCost gamma <span style=\"color: red;\">(</span>V.map fst vals<span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>V.map snd vals<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span>
>                    initTheta
>       theta <span style=\"color: red;\">=</span> head $ drop <span class=\"hs-num\">1000</span> gs
>   printf <span style=\"color: teal;\">\"Logistic regression: theta_0 = %5.3f, theta_1 = %5.3f\\n\"</span>
>          <span style=\"color: red;\">(</span>theta V.! <span class=\"hs-num\">0</span><span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>theta V.! <span class=\"hs-num\">1</span><span style=\"color: red;\">)</span>
>
>   <span style=\"color: blue; font-weight: bold;\">let</span> us <span style=\"color: red;\">=</span> V.map <span style=\"color: red;\">(</span>round . fst<span style=\"color: red;\">)</span> createSample
>   <span style=\"color: blue; font-weight: bold;\">let</span> vs <span style=\"color: red;\">=</span> V.map snd createSample
>   <span style=\"color: blue; font-weight: bold;\">let</span> fs <span style=\"color: red;\">=</span> iterate <span style=\"color: red;\">(</span>stepOnceTotal <span class=\"hs-num\">2</span> gamma us <span style=\"color: red;\">(</span>V.map return vs<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> testNet
>       phi <span style=\"color: red;\">=</span> extractWeights $ head $ drop <span class=\"hs-num\">1000</span> fs
>   printf <span style=\"color: teal;\">\"Neural network: theta_00 = %5.3f, theta_01 = %5.3f\\n\"</span>
>          <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>phi!!<span class=\"hs-num\">0</span><span style=\"color: red;\">)</span>!!<span class=\"hs-num\">0</span><span style=\"color: red;\">)</span>!!<span class=\"hs-num\">0</span><span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>phi!!<span class=\"hs-num\">0</span><span style=\"color: red;\">)</span>!!<span class=\"hs-num\">0</span><span style=\"color: red;\">)</span>!!<span class=\"hs-num\">1</span><span style=\"color: red;\">)</span>
>   printf <span style=\"color: teal;\">\"Neural network: theta_10 = %5.3f, theta_11 = %5.3f\\n\"</span>
>          <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>phi!!<span class=\"hs-num\">0</span><span style=\"color: red;\">)</span>!!<span class=\"hs-num\">1</span><span style=\"color: red;\">)</span>!!<span class=\"hs-num\">0</span><span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span><span style=\"color: red;\">(</span>phi!!<span class=\"hs-num\">0</span><span style=\"color: red;\">)</span>!!<span class=\"hs-num\">1</span><span style=\"color: red;\">)</span>!!<span class=\"hs-num\">1</span><span style=\"color: red;\">)</span>
</code>
<code><span style=\"color: gray;\">ghci> </span>test1
Logistic regression: theta_0 = -2.383, theta_1 = 4.852
Neural network: theta_00 = 2.386, theta_01 = -4.861
Neural network: theta_10 = -2.398, theta_11 = 4.886
</code></pre>
<h2 id=\"example-ii\">Example II</h2>
<p>Now let’s try a neural net with 1 hidden layer using the data we prepared earlier.</p>
<p>We seed the weights in the neural with small random values; if we set all the weights to 0 then the gradient descent algorithm might get stuck.</p>
<pre><code>> uniforms <span style=\"color: red;\">::</span> Int <span style=\"color: red;\">-></span> <span style=\"color: red;\">[</span>Double<span style=\"color: red;\">]</span>
> uniforms n <span style=\"color: red;\">=</span>
>   fst $ runState <span style=\"color: red;\">(</span>replicateM n <span style=\"color: red;\">(</span>sampleRVar stdUniform<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span> <span style=\"color: red;\">(</span>mkStdGen seed<span style=\"color: red;\">)</span>
>     <span style=\"color: blue; font-weight: bold;\">where</span>
>       seed <span style=\"color: red;\">=</span> <span class=\"hs-num\">0</span>
</code>
<code>> randomWeightMatrix <span style=\"color: red;\">::</span> Int <span style=\"color: red;\">-></span> Int <span style=\"color: red;\">-></span> <span style=\"color: red;\">[</span><span style=\"color: red;\">[</span>Double<span style=\"color: red;\">]</span><span style=\"color: red;\">]</span>
> randomWeightMatrix numInputs numOutputs <span style=\"color: red;\">=</span> y
>   <span style=\"color: blue; font-weight: bold;\">where</span>
>     y <span style=\"color: red;\">=</span> chunksOf numInputs weights
>     weights <span style=\"color: red;\">=</span> map <span style=\"color: red;\">(</span>/ <span class=\"hs-num\">100.0</span><span style=\"color: red;\">)</span> $ uniforms <span style=\"color: red;\">(</span>numOutputs * numInputs<span style=\"color: red;\">)</span>
</code>
<code>> w1<span style=\"color: red;\">,</span> w2 <span style=\"color: red;\">::</span> <span style=\"color: red;\">[</span><span style=\"color: red;\">[</span>Double<span style=\"color: red;\">]</span><span style=\"color: red;\">]</span>
> w1  <span style=\"color: red;\">=</span> randomWeightMatrix <span class=\"hs-num\">2</span> <span class=\"hs-num\">2</span>
> w2  <span style=\"color: red;\">=</span> randomWeightMatrix <span class=\"hs-num\">3</span> <span class=\"hs-num\">2</span>
</code>
<code>> initNet2 <span style=\"color: red;\">::</span> BackpropNet Double
> initNet2 <span style=\"color: red;\">=</span> buildBackpropNet lRate <span style=\"color: red;\">[</span>w1<span style=\"color: red;\">,</span> w2<span style=\"color: red;\">]</span> logitAF
>
> labels <span style=\"color: red;\">::</span> V.Vector Int
> labels <span style=\"color: red;\">=</span> V.map <span style=\"color: red;\">(</span>round . fst<span style=\"color: red;\">)</span> createSample
</code>
<code>> inputs <span style=\"color: red;\">::</span> V.Vector <span style=\"color: red;\">[</span>Double<span style=\"color: red;\">]</span>
> inputs <span style=\"color: red;\">=</span> V.map <span style=\"color: red;\">(</span>return . snd<span style=\"color: red;\">)</span> createSample
</code></pre>
<p>Instead of hand-crafting gradient descent, let us use the library function as it performs better and is easier to implement.</p>
<pre><code>> estimates <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span>Floating a<span style=\"color: red;\">,</span> Ord a<span style=\"color: red;\">,</span> Show a<span style=\"color: red;\">)</span> <span style=\"color: red;\">=></span>
>              V.Vector Int <span style=\"color: red;\">-></span>
>              V.Vector <span style=\"color: red;\">[</span>a<span style=\"color: red;\">]</span> <span style=\"color: red;\">-></span>
>              BackpropNet a <span style=\"color: red;\">-></span>
>              <span style=\"color: red;\">[</span>BackpropNet a<span style=\"color: red;\">]</span>
> estimates y x <span style=\"color: red;\">=</span> gradientDescent $
>                 <span style=\"color: red;\">\\</span>theta <span style=\"color: red;\">-></span> totalCostNN <span class=\"hs-num\">2</span> y <span style=\"color: red;\">(</span>V.map <span style=\"color: red;\">(</span>map auto<span style=\"color: red;\">)</span> x<span style=\"color: red;\">)</span> theta
</code></pre>
<p>Now we can examine the weights of our fitted neural net and apply it to some test data.</p>
<pre><code>> test2 <span style=\"color: red;\">::</span> IO ()
> test2 <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>
>   <span style=\"color: blue; font-weight: bold;\">let</span> fs <span style=\"color: red;\">=</span> estimates labels inputs initNet2
>   mapM_ putStrLn $ map <span style=\"color: red;\">(</span>take <span class=\"hs-num\">60</span><span style=\"color: red;\">)</span> $
>                    map show $ extractWeights $
>                    head $ drop <span class=\"hs-num\">1000</span> fs
>   putStrLn $ show $ evalNeuralNet <span style=\"color: red;\">(</span>head $ drop <span class=\"hs-num\">1000</span> fs<span style=\"color: red;\">)</span> <span style=\"color: red;\">[</span><span class=\"hs-num\">0.1</span><span style=\"color: red;\">]</span>
>   putStrLn $ show $ evalNeuralNet <span style=\"color: red;\">(</span>head $ drop <span class=\"hs-num\">1000</span> fs<span style=\"color: red;\">)</span> <span style=\"color: red;\">[</span><span class=\"hs-num\">0.9</span><span style=\"color: red;\">]</span>
</code>
<code><span style=\"color: gray;\">ghci> </span>test2
[[3.3809809537916933,-6.778365921046131],[-5.157492699008754
[[1.2771246165025043,5.294090869351353,-8.264801192310706],[
[0.997782987249909,2.216698813392053e-3]
[1.4853346509852003e-3,0.9985148392767443]
</code></pre>
<h2 id=\"example-iii\">Example III</h2>
<p>Let’s try a more sophisticated example and create a population of 4 groups which we measure with 2 variables.</p>
<pre><code>> c<span style=\"color: red;\">,</span> d <span style=\"color: red;\">::</span> Double
> c          <span style=\"color: red;\">=</span> <span class=\"hs-num\">15</span>
> d          <span style=\"color: red;\">=</span> <span class=\"hs-num\">8</span>
> sample2<span style=\"color: red;\">,</span> sample3 <span style=\"color: red;\">::</span> <span style=\"color: red;\">[</span>Double<span style=\"color: red;\">]</span>
> sample2 <span style=\"color: red;\">=</span> betas nSamples c d
> sample3 <span style=\"color: red;\">=</span> betas nSamples d c
</code>
<code>> mixSamples3 <span style=\"color: red;\">::</span> Num t <span style=\"color: red;\">=></span> <span style=\"color: red;\">[</span><span style=\"color: red;\">[</span>a<span style=\"color: red;\">]</span><span style=\"color: red;\">]</span> <span style=\"color: red;\">-></span> <span style=\"color: red;\">[</span><span style=\"color: red;\">(</span>t<span style=\"color: red;\">,</span> a<span style=\"color: red;\">)</span><span style=\"color: red;\">]</span>
> mixSamples3 xss <span style=\"color: red;\">=</span> concat $ transpose $
>                   zipWith <span style=\"color: red;\">(</span><span style=\"color: red;\">\\</span>n xs <span style=\"color: red;\">-></span> map <span style=\"color: red;\">(</span>n<span style=\"color: red;\">,</span><span style=\"color: red;\">)</span> xs<span style=\"color: red;\">)</span>
>                           <span style=\"color: red;\">(</span>map fromIntegral <span style=\"color: red;\">[</span><span class=\"hs-num\">0</span><span style=\"color: red;\">..</span><span style=\"color: red;\">]</span><span style=\"color: red;\">)</span>
>                           xss
> sample02<span style=\"color: red;\">,</span> sample03<span style=\"color: red;\">,</span> sample12<span style=\"color: red;\">,</span> sample13 <span style=\"color: red;\">::</span> <span style=\"color: red;\">[</span><span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> Double<span style=\"color: red;\">)</span><span style=\"color: red;\">]</span>
> sample02 <span style=\"color: red;\">=</span> <span style=\"color: red;\">[</span><span style=\"color: red;\">(</span>x<span style=\"color: red;\">,</span> y<span style=\"color: red;\">)</span> <span style=\"color: red;\">|</span> x <span style=\"color: red;\"><-</span> sample0<span style=\"color: red;\">,</span> y <span style=\"color: red;\"><-</span> sample2<span style=\"color: red;\">]</span>
> sample03 <span style=\"color: red;\">=</span> <span style=\"color: red;\">[</span><span style=\"color: red;\">(</span>x<span style=\"color: red;\">,</span> y<span style=\"color: red;\">)</span> <span style=\"color: red;\">|</span> x <span style=\"color: red;\"><-</span> sample0<span style=\"color: red;\">,</span> y <span style=\"color: red;\"><-</span> sample3<span style=\"color: red;\">]</span>
> sample12 <span style=\"color: red;\">=</span> <span style=\"color: red;\">[</span><span style=\"color: red;\">(</span>x<span style=\"color: red;\">,</span> y<span style=\"color: red;\">)</span> <span style=\"color: red;\">|</span> x <span style=\"color: red;\"><-</span> sample1<span style=\"color: red;\">,</span> y <span style=\"color: red;\"><-</span> sample2<span style=\"color: red;\">]</span>
> sample13 <span style=\"color: red;\">=</span> <span style=\"color: red;\">[</span><span style=\"color: red;\">(</span>x<span style=\"color: red;\">,</span> y<span style=\"color: red;\">)</span> <span style=\"color: red;\">|</span> x <span style=\"color: red;\"><-</span> sample1<span style=\"color: red;\">,</span> y <span style=\"color: red;\"><-</span> sample3<span style=\"color: red;\">]</span>
</code>
<code>> createSample3 <span style=\"color: red;\">::</span> <span style=\"color: blue; font-weight: bold;\">forall</span> t. Num t <span style=\"color: red;\">=></span> V.Vector <span style=\"color: red;\">(</span>t<span style=\"color: red;\">,</span> <span style=\"color: red;\">(</span>Double<span style=\"color: red;\">,</span> Double<span style=\"color: red;\">)</span><span style=\"color: red;\">)</span>
> createSample3 <span style=\"color: red;\">=</span> V.fromList $ take <span class=\"hs-num\">512</span> $ mixSamples3 <span style=\"color: red;\">[</span> sample02
>                                                     <span style=\"color: red;\">,</span> sample03
>                                                     <span style=\"color: red;\">,</span> sample12
>                                                     <span style=\"color: red;\">,</span> sample13
>                                                     <span style=\"color: red;\">]</span>
</code></pre>
<p>Rather annoyingly picking random weights seemed to give a local but not global minimum. This may be a feature of having more nodes in the hidden layer than in the input layer. By fitting a neural net with no hidden layers to the data and using the outputs as inputs to fit another neural net with no hidden layers, we can get a starting point from which we can converge to the global minimum.</p>
<pre><code>> w31<span style=\"color: red;\">,</span> w32 <span style=\"color: red;\">::</span> <span style=\"color: red;\">[</span><span style=\"color: red;\">[</span>Double<span style=\"color: red;\">]</span><span style=\"color: red;\">]</span>
> w31 <span style=\"color: red;\">=</span> <span style=\"color: red;\">[</span><span style=\"color: red;\">[</span><span style=\"color: green;\">-</span><span class=\"hs-num\">1.795626449637491</span><span style=\"color: red;\">,</span><span class=\"hs-num\">1.0687662199549477</span><span style=\"color: red;\">,</span><span class=\"hs-num\">0.6780994566671094</span><span style=\"color: red;\">]</span><span style=\"color: red;\">,</span>
>        <span style=\"color: red;\">[</span><span style=\"color: green;\">-</span><span class=\"hs-num\">0.8953174631646047</span><span style=\"color: red;\">,</span><span class=\"hs-num\">1.536931540024011</span><span style=\"color: red;\">,</span><span style=\"color: green;\">-</span><span class=\"hs-num\">1.7631220370122578</span><span style=\"color: red;\">]</span><span style=\"color: red;\">,</span>
>        <span style=\"color: red;\">[</span><span style=\"color: green;\">-</span><span class=\"hs-num\">0.4762453998497917</span><span style=\"color: red;\">,</span><span style=\"color: green;\">-</span><span class=\"hs-num\">2.005243268058972</span><span style=\"color: red;\">,</span><span class=\"hs-num\">1.2945899127545906</span><span style=\"color: red;\">]</span><span style=\"color: red;\">,</span>
>        <span style=\"color: red;\">[</span><span class=\"hs-num\">0.43019763097582875</span><span style=\"color: red;\">,</span><span style=\"color: green;\">-</span><span class=\"hs-num\">1.5711869072989957</span><span style=\"color: red;\">,</span><span style=\"color: green;\">-</span><span class=\"hs-num\">1.187180183656747</span><span style=\"color: red;\">]</span><span style=\"color: red;\">]</span>
> w32 <span style=\"color: red;\">=</span> <span style=\"color: red;\">[</span><span style=\"color: red;\">[</span><span style=\"color: green;\">-</span><span class=\"hs-num\">0.65116209142284</span><span style=\"color: red;\">,</span><span class=\"hs-num\">0.4837310591797774</span><span style=\"color: red;\">,</span><span style=\"color: green;\">-</span><span class=\"hs-num\">0.17870333721054968</span><span style=\"color: red;\">,</span>
>         <span style=\"color: green;\">-</span><span class=\"hs-num\">0.6692619856605464</span><span style=\"color: red;\">,</span><span style=\"color: green;\">-</span><span class=\"hs-num\">1.062292154441557</span><span style=\"color: red;\">]</span><span style=\"color: red;\">,</span>
>        <span style=\"color: red;\">[</span><span style=\"color: green;\">-</span><span class=\"hs-num\">0.7521274440366631</span><span style=\"color: red;\">,</span><span style=\"color: green;\">-</span><span class=\"hs-num\">1.2071835415415136e-2</span><span style=\"color: red;\">,</span><span class=\"hs-num\">1.0078929981538551</span><span style=\"color: red;\">,</span>
>         <span style=\"color: green;\">-</span><span class=\"hs-num\">1.3144243587577473</span><span style=\"color: red;\">,</span><span style=\"color: green;\">-</span><span class=\"hs-num\">0.5102027925579049</span><span style=\"color: red;\">]</span><span style=\"color: red;\">,</span>
>        <span style=\"color: red;\">[</span><span style=\"color: green;\">-</span><span class=\"hs-num\">0.7545728756863981</span><span style=\"color: red;\">,</span><span style=\"color: green;\">-</span><span class=\"hs-num\">0.4830112128458844</span><span style=\"color: red;\">,</span><span style=\"color: green;\">-</span><span class=\"hs-num\">1.2901624541811962</span><span style=\"color: red;\">,</span>
>         <span class=\"hs-num\">1.0487049495446408</span><span style=\"color: red;\">,</span><span class=\"hs-num\">9.746209726152217e-3</span><span style=\"color: red;\">]</span><span style=\"color: red;\">,</span>
>        <span style=\"color: red;\">[</span><span style=\"color: green;\">-</span><span class=\"hs-num\">0.8576212271328413</span><span style=\"color: red;\">,</span><span style=\"color: green;\">-</span><span class=\"hs-num\">0.9035219951783956</span><span style=\"color: red;\">,</span><span style=\"color: green;\">-</span><span class=\"hs-num\">0.4034500456652809</span><span style=\"color: red;\">,</span>
>         <span class=\"hs-num\">0.10091187689838758</span><span style=\"color: red;\">,</span><span class=\"hs-num\">0.781835908789879</span><span style=\"color: red;\">]</span><span style=\"color: red;\">]</span>
>
> testNet3 <span style=\"color: red;\">::</span> BackpropNet Double
> testNet3 <span style=\"color: red;\">=</span> buildBackpropNet lRate <span style=\"color: red;\">[</span>w31<span style=\"color: red;\">,</span> w32<span style=\"color: red;\">]</span> logitAF
</code>
<code>> labels3 <span style=\"color: red;\">::</span> V.Vector Int
> labels3 <span style=\"color: red;\">=</span> V.map <span style=\"color: red;\">(</span>round . fst<span style=\"color: red;\">)</span> createSample3
> inputs3 <span style=\"color: red;\">::</span> V.Vector <span style=\"color: red;\">[</span>Double<span style=\"color: red;\">]</span>
> inputs3 <span style=\"color: red;\">=</span> V.map <span style=\"color: red;\">(</span><span style=\"color: red;\">(</span><span style=\"color: red;\">\\</span><span style=\"color: red;\">(</span>x<span style=\"color: red;\">,</span> y<span style=\"color: red;\">)</span> <span style=\"color: red;\">-></span> <span style=\"color: red;\">[</span>x<span style=\"color: red;\">,</span> y<span style=\"color: red;\">]</span><span style=\"color: red;\">)</span> . snd<span style=\"color: red;\">)</span> createSample3
</code></pre>
<p>Now we use the library <em>gradientDescent</em> function to generate neural nets which ever better fit the data.</p>
<pre><code>> estimates3 <span style=\"color: red;\">::</span> <span style=\"color: red;\">(</span>Floating a<span style=\"color: red;\">,</span> Ord a<span style=\"color: red;\">,</span> Show a<span style=\"color: red;\">)</span> <span style=\"color: red;\">=></span>
>               V.Vector Int <span style=\"color: red;\">-></span>
>               V.Vector <span style=\"color: red;\">[</span>a<span style=\"color: red;\">]</span> <span style=\"color: red;\">-></span>
>               BackpropNet a <span style=\"color: red;\">-></span>
>               <span style=\"color: red;\">[</span>BackpropNet a<span style=\"color: red;\">]</span>
> estimates3 y x <span style=\"color: red;\">=</span> gradientDescent $
>                  <span style=\"color: red;\">\\</span>theta <span style=\"color: red;\">-></span> totalCostNN <span class=\"hs-num\">4</span> y <span style=\"color: red;\">(</span>V.map <span style=\"color: red;\">(</span>map auto<span style=\"color: red;\">)</span> x<span style=\"color: red;\">)</span> theta
</code></pre>
<p>Finally we can fit a neural net and check that it correctly classifies some data.</p>
<pre><code>> test3 <span style=\"color: red;\">::</span> IO ()
> test3 <span style=\"color: red;\">=</span> <span style=\"color: blue; font-weight: bold;\">do</span>
>   <span style=\"color: blue; font-weight: bold;\">let</span> fs <span style=\"color: red;\">=</span> drop <span class=\"hs-num\">100</span> $ estimates3 labels3 inputs3 testNet3
>   mapM_ putStrLn $ map <span style=\"color: red;\">(</span>take <span class=\"hs-num\">60</span><span style=\"color: red;\">)</span> $ map show $ extractWeights $ head fs
>   putStrLn $ take <span class=\"hs-num\">60</span> $ show $ evalNeuralNet <span style=\"color: red;\">(</span>head fs<span style=\"color: red;\">)</span> <span style=\"color: red;\">[</span><span class=\"hs-num\">0.1</span><span style=\"color: red;\">,</span> <span class=\"hs-num\">0.1</span><span style=\"color: red;\">]</span>
>   putStrLn $ take <span class=\"hs-num\">60</span> $ show $ evalNeuralNet <span style=\"color: red;\">(</span>head fs<span style=\"color: red;\">)</span> <span style=\"color: red;\">[</span><span class=\"hs-num\">0.1</span><span style=\"color: red;\">,</span> <span class=\"hs-num\">0.9</span><span style=\"color: red;\">]</span>
>   putStrLn $ take <span class=\"hs-num\">60</span> $ show $ evalNeuralNet <span style=\"color: red;\">(</span>head fs<span style=\"color: red;\">)</span> <span style=\"color: red;\">[</span><span class=\"hs-num\">0.9</span><span style=\"color: red;\">,</span> <span class=\"hs-num\">0.1</span><span style=\"color: red;\">]</span>
>   putStrLn $ take <span class=\"hs-num\">60</span> $ show $ evalNeuralNet <span style=\"color: red;\">(</span>head fs<span style=\"color: red;\">)</span> <span style=\"color: red;\">[</span><span class=\"hs-num\">0.9</span><span style=\"color: red;\">,</span> <span class=\"hs-num\">0.9</span><span style=\"color: red;\">]</span>
</code>
<code><span style=\"color: gray;\">ghci> </span>test3
[[-2.295896239599931,2.705409060274802,2.1377566388724047],[
[[-0.6169787627963551,2.5369568963968256,-0.3515306366626614
[2.638026636449198e-2,9.091308688841797e-2,0.373349222824566
[0.13674565454319784,1.128123133092104e-2,0.8525700090804755
[0.30731134024095474,0.8197492648500939,1.3704140162804749e-
[0.6773814649389487,0.22533958204471505,0.1957913744022863,4
</code></pre>
<h2 id=\"references\">References</h2>
<p>Bishop, Christopher M. 2006. <em>Pattern Recognition and Machine Learning (Information Science and Statistics)</em>. Secaucus, NJ, USA: Springer-Verlag New York, Inc.</p>
<p>Rojas, R. 1996. <em>Neural networks: a systematic introduction</em>. Springer-Verlag New York Incorporated. <a href=\"http://books.google.co.uk/books?id=txsjjYzFJS4C\" title=\"http://books.google.co.uk/books?id=txsjjYzFJS4C\">http://books.google.co.uk/books?id=txsjjYzFJS4C</a>.</p>
<br />  <a href=\"http://feeds.wordpress.com/1.0/gocomments/idontgetoutmuch.wordpress.com/460/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/idontgetoutmuch.wordpress.com/460/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=idontgetoutmuch.wordpress.com&blog=2944309&post=460&subd=idontgetoutmuch&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "299b5540ab5ae0c68c14d54b47869d69") (22 (20928 8813 635460) "http://tomschrijvers.blogspot.com/2013/05/ghent-fp-meeting-on-june-26.html" "Tom Schrijvers: Ghent FP meeting on June 26" "noreply@blogger.com (Tom Schrijvers)" "Fri, 31 May 2013 09:36:41 +0000" "<div style=\"text-align: left;\" dir=\"ltr\"><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">The \"Functional Programming Group Ghent\" (GhentFPG) [1] is a friendly group for</span><br /><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">all people interested in functional programming, with a tendency towards Haskell.</span><br /><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">It is organised as part of Zeus WPI [2].</span><br /><br style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\" /><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">We are pleased to announce that we will hold a next meeting on Wednesday, 26th</span><br /><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">of June, starting at 19h00! There will be three talks.</span><br /><br /><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">The main presentation, by Adam Bergmark from Silk [3] is about <b>Fay</b> [4]:</span><br /><blockquote class=\"tr_bq\"><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">Fay is a proper subset of Haskell that compiles to JavaScript. There is a</span><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">  compiler with the same name written in Haskell. Web browsers only speak</span><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">  JavaScript but more and more people find that they want to compile to</span><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">  JavaScript instead.</span><br /><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">Why do we want to compile Haskell to JavaScript, and what advantages does</span><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">  Fay have compared to other compilers?</span><br /><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">What are the challenges in compiling Haskell and supporting a language</span><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">  ecosystem, and how do we do it?</span><br /><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">What can Fay currently do, and what is planned for the future?</span><br /><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">This will be a broad overview about Fay for prospective users, followed by</span><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">  an in-depth look at interesting parts of the compiler internals.</span></blockquote><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">Additionally, there will be two short talks by two students who did an Msc. Thesis</span><br /><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">about functional programming languages:</span><br /><br style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\" /><ul style=\"text-align: left;\"><li><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\"><b>Genetic Algorithms in Haskell</b><br />Matthias Delbar</span></li><li><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\"><b>Automatic Detection of Recursion Patterns</b>Jasper Van der Jeugt</span></li></ul><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">The meeting will take place in the Jozef Plateauzaal at the following address,</span><br /><blockquote class=\"tr_bq\"><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">Faculteit Ingenieurswetenschappen</span><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">Universiteit Gent</span><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">Plateaustraat 22</span><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">9000 Gent</span></blockquote><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">As mentioned above, we aim to start at </span><span style=\"\" class=\"aBn\" tabindex=\"0\"><span style=\"\" class=\"aQJ\">19:00</span></span><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">. After the meeting we can go</span><br /><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">for drinks in a nearby pub (this latter part is, of course, completely optional)</span><br /><br style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\" /><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">We hope to see you all there!</span><br /><br style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\" /><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">Regards,</span><br /><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">On behalf of the GhentFPG organising committee.</span><br /><br style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\" /><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">[1]: </span><a style=\"background-color: white; color: #1155cc; font-family: arial, sans-serif; font-size: 12.800000190734863px;\" href=\"http://groups.google.com/group/ghent-fpg\" target=\"_blank\">http://groups.google.com/<wbr></wbr>group/ghent-fpg</a><br /><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">[2]: </span><a style=\"background-color: white; color: #1155cc; font-family: arial, sans-serif; font-size: 12.800000190734863px;\" href=\"http://zeus.ugent.be/\" target=\"_blank\">http://zeus.ugent.be/</a><br /><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">[3]: </span><a style=\"background-color: white; color: #1155cc; font-family: arial, sans-serif; font-size: 12.800000190734863px;\" href=\"http://www.silkapp.com/\" target=\"_blank\">http://www.silkapp.com/</a><br /><span style=\"background-color: white; color: #222222; font-family: arial, sans-serif; font-size: 12.800000190734863px;\">[4]: </span><a style=\"background-color: white; color: #1155cc; font-family: arial, sans-serif; font-size: 12.800000190734863px;\" href=\"http://www.fay-lang.org/\" target=\"_blank\">http://www.fay-lang.org/</a></div>" nil nil "fd5501fce6735d3f6ea39392b3d804a8") (21 (20928 8813 634206) "http://winterkoninkje.dreamwidth.org/83994.html" "wren ng thornton: ANN: prelude-safeenum" nil "Thu, 30 May 2013 00:05:57 +0000" "<h3>prelude-safeenum 0.1.0</h3>
<p>The prelude-safeenum package offers a safe alternative to the Prelude's <code>Enum</code> class in order to render it safe. While we're at it, we also generalize the notion of enumeration to support types which can only be enumerated in one direction.</p>
<h3>Description</h3>
<p>The prelude-safeenum package offers an alternative to the notion of enumeration provided by the Prelude. For now it is just a package, but the eventual goal is to be incorporated into haskell prime. Some salient characteristics of the new type-class hierarchy are:</p>
<dl>
<dt>Removes partial functions</dt>
<dd>The Haskell Language Report <a href=\"http://www.haskell.org/onlinereport/haskell2010/haskellch6.html#x13-1310006.3.4\">section 6.3.4</a> defines <code>pred</code>, <code>succ</code>, <code>fromEnum</code>, and <code>toEnum</code> to be partial functions when the type is <code>Bounded</code>, but this is unacceptable. The new classes remove this problem by correcting the type signatures for these functions.</dd>
<dt>Generalizes the notion of enumeration</dt>
<dd>Rather than requiring that the type is linearly enumerable, we distinguish between forward enumeration (which allows for multiple predecessors) and backward enumeration (which allows for multiple successors).</dd>
<dt>Adds new functions: <code>enumDownFrom</code>, <code>enumDownFromTo</code></dt>
<dd>One of the big problems with the partiality of <code>pred</code> is that there is no safe way to enumerate downwards since in the border case <code>enumFromThen x (pred x)</code> will throw an error rather than evaluating to <code>[x]</code> as desired. These new functions remove this problem.</dd>
<dt>Removes the requirement...</dt>
<dd>...that the enumeration order coincides with the
<code>Ord</code> ordering (if one exists). Though, of course, it's advisable to keep
them in sync if possible, for your sanity.</dd>
<dt>Ensures that the notion of enumeration is well-defined</dt>
<dd>This much-needed rigor clarifies the meaning of enumeration. In addition, it rules out instances for <code>Float</code> and <code>Double</code> which are highly problematic and often confuse newcomers to Haskell. Unfortunately, this rigor does render the instance for <code>Ratio</code> problematic. However, <code>Ratio</code> instances <i>can</i> be provided so long as the base type is enumerable (and <code>Integral</code>, naturally); but they must be done in an obscure order that does not coincide with <code>Ord</code>.
</dd><dt>The obscure order required for well-defined enumeration of <code>Ratio</code> is provided.</dt>
</dl>
<h3>Links</h3>
<ul>
<li>Homepage: <a href=\"http://code.haskell.org/~wren/\">http://code.haskell.org/~wren/</a></li>
<li>Hackage: <a href=\"http://hackage.haskell.org/package/prelude-safeenum\">http://hackage.haskell.org/package/prelude-safeenum</a></li>
<li>Darcs: <a href=\"http://community.haskell.org/~wren/prelude-safeenum\">http://community.haskell.org/~wren/prelude-safeenum</a></li>
<li>Haddock: <a href=\"http://community.haskell.org/~wren/prelude-safeenum/dist/doc/html/prelude-safeenum/\">Darcs version</a></li>
</ul><br /><br /><img src=\"http://www.dreamwidth.org/tools/commentcount?user=winterkoninkje&ditemid=83994\" alt=\"comment count unavailable\" height=\"12\" style=\"vertical-align: middle;\" width=\"30\" /> comments" nil nil "95d4292f1e33df4aaf2acb718e9ae441") (20 (20928 8813 633558) "http://feedproxy.google.com/~r/ezyang/~3/EpcxawDNuhI/" "Edward Z. Yang: The AST Typing Problem" nil "Tue, 28 May 2013 11:25:03 +0000" "<div class=\"document\">
<p>This <a href=\"http://lambda-the-ultimate.org/node/4170\" class=\"reference external\">Lambda the Ultimate post (dated 2010)</a> describes a rather universal problem faced by compiler writers: how does one go about adding “extra information” (e.g. types) to an AST? (The post itself divides the problem into three components: adding the information to the data types, using the information to inform the construction of the node, and using the information to inform the destruction of a node—but I’m really only interested in the question of how you define your data type, not do things to it.) In this post, I want to sum up ways of solving the problem which were described in this post, and also take a look at what some real world compilers do.  The running example lambda calculus looks like the following:</p>
<pre class=\"literal-block\">data Exp = Num Int
| Bool Bool
| Var Var
| If Exp Exp Exp
| Lambda Var Exp
| App Exp Exp
data Type = TyInt | TyBool | TyArrow Type Type
</pre>
<div id=\"separate-ir-where-nodes-are-decorated-with-types\" class=\"section\">
<h3>Separate IR where nodes are decorated with types</h3>
<p>The low-tech solution: if you need a new version of the IR with more information, just define a new IR type where each node can also carry the information. A trick to make these definitions more concise is to make a mutually recursive data structure. <a href=\"http://lambda-the-ultimate.org/node/4170#comment-63834\" class=\"reference external\">[1]</a></p>
<pre class=\"literal-block\">type TExp = (TExp', Type)
data TExp' = TNum Int
| TBool Bool
| TVar Var
| TIf TExp TExp TExp
| TLambda Var TExp
| TApp TExp TExp
</pre>
<p>Despite (or perhaps because of) it’s simplicity, this approach is extremely popular among many compilers, especially in the ML community.  A few examples include OCaml (parsetree/typedtree), MLton (AST/CoreML) and Ikarus Scheme. Part of the reason for this is that the transition from frontend language to typed language also comes with some other changes, and when a new AST is defined those changes can be combined in too.</p>
</div>
<div id=\"nullable-field\" class=\"section\">
<h3>Nullable field</h3>
<p>The unprincipled solution: use one AST, but have an optional field in which you can slot in the information. <a href=\"http://lambda-the-ultimate.org/node/4170#comment-63832\" class=\"reference external\">[2]</a></p>
<pre class=\"literal-block\">type TExp = (TExp', Maybe Type)
data TExp' = TNum Int
| TBool Bool
| TVar Var
| TIf TExp TExp TExp
| TLambda Var TExp
| TApp TExp TExp
</pre>
<p>Presented without further comment.</p>
</div>
<div id=\"explicit-typing\" class=\"section\">
<h3>Explicit typing</h3>
<p>While closely related to the separate IR solution, an explicitly typed IR takes the approach of not decorating each node with a type, but arranging that the type of any given node can be quickly computed using only local information. <a href=\"http://lambda-the-ultimate.org/node/4170#comment-63884\" class=\"reference external\">[3]</a></p>
<pre class=\"literal-block\">data TExp = TNum Int
| TBool Bool
| TVar Var
| TIf TExp TExp TExp
| TLambda Var Type TExp
| TApp TExp TExp
</pre>
<p>Here, the difference between <tt class=\"docutils literal\">TExp</tt> and <tt class=\"docutils literal\">Exp</tt> is very slight; the <tt class=\"docutils literal\">TLambda</tt> is annotated with an explicit type for the binder. As far as type-checking is concerned, this makes a world of difference: we no longer need to look outside a lambda to figure out what the binder could be.</p>
<p>Forcing your IR to be explicitly typed is often a good idea for metatheoretic reasons, as complicated type systems often don’t have decidable inference algorithms.  Both GHC’s core IR, Ur/Web's core and Coq are explicitly typed in this way.</p>
</div>
<div id=\"two-level-types\" class=\"section\">
<h3>Two-level types</h3>
<p>By deferring when you tie the knot of a recursive data-structure, you can arrange for the base functor to do double-duty for the untyped and typed representations. <a href=\"http://lambda-the-ultimate.org/node/4170#comment-63836\" class=\"reference external\">[4]</a></p>
<pre class=\"literal-block\">data ExpF a = Num Int
| Bool Bool
| Var Var
| If a a a
| Lambda Var a
| App a a
newtype Exp = Exp (ExpF Exp)
newtype TExp = TExp (ExpF TExp, Type)
</pre>
<p>The Coq kernel uses this to define its expression type, although it doesn’t use it to define an untyped variant.</p>
</div>
<div id=\"lazy-attribute-grammars\" class=\"section\">
<h3>(Lazy) Attribute grammars</h3>
<p>I don’t claim to understand this approach too well, but essentially it is a programming model distinct from usual algebraic data types which associates attributes over nodes of a tree. In some sense, it can be thought as a memoized function from AST nodes to the attributes. Many compilers do utlize maps, but only for top-level declarations. <a href=\"http://lambda-the-ultimate.org/node/4170#comment-63903\" class=\"reference external\">[5]</a></p>
</div>
<div id=\"closing-remarks\" class=\"section\">
<h3>Closing remarks</h3>
<p>There were a few things that I did not mention here which came up in the discussion. One participant suggested using <a href=\"http://lambda-the-ultimate.org/node/4170#comment-63842(polymorphicvariants)\" class=\"reference external\">polymorphic variants</a> to define the data type; this doesn’t help much with adding extra information but allows for different ways of writing traversal functions. Indeed, traversal is one of the big concerns, and the mention of <a href=\"http://lambda-the-ultimate.org/node/4170#comment-63846\" class=\"reference external\">generic programming</a> also is targeted at this problem.</p>
<p>As for my preference? It’s hard to say. I’ve worked with compilers mostly written in the “define a new IR style”, and while the initial outlay of defining two data structures is quite annoying, it is mostly a fixed cost. What’s yours?</p>
<p><strong>Also, a question.</strong> Is there a presentation of the conventional set of annotations needed to get explicitly typed System F?</p>
</div>
</div>
<img src=\"http://feeds.feedburner.com/~r/ezyang/~4/EpcxawDNuhI\" height=\"1\" width=\"1\" />" nil nil "6899593e23b9bf5068cbeed2a5d4e558") (19 (20928 8813 632364) "http://leepike.wordpress.com/2013/05/27/book-review-automate-this/" "Lee Pike: Book Review: Automate This" nil "Tue, 28 May 2013 01:00:03 +0000" "<p>A family member gave me a copy of <em><a href=\"http://www.amazon.com/dp/1591844924\">Automate This</a></em> by Christopher Steiner as a gift a few months ago.  The subtitle of the book is “How algorithms came to rule our world.”  The book is a non-technical, fast, and easy read.  I did read a few interesting stories, such as NASA’s use of personality categorization algorithms in the 70s to predict which potential astronauts would work well together, or a math professor’s algorithmic dissection of Beatles songs.  The book particularly emphasizes algorithmic trading on Wall Street.  The somewhat non sequitur conclusion is that we need more science, engineering, and math graduates.</p>
<p>The main point of the book is that algorithms are pervasive and will become more so.  Toward this point, I think the author could have cast an even wider net, mentioning that algorithms are implemented in everything from elevator controllers to autopilots.  There is a cursory pre-computing history of algorithms at the beginning of the book that is (tenuously) tied to a Wall Street trading.</p>
<p>Rather than focus on algorithms broadly, the focus is patchy, hitting on machine learning, high-speed trading, and game theory.  Some mention of algorithms as might be taught in a “Analysis of Algorithms” course, covering basic topics like time-space complexity and decidability, would help prevent the general public from having a narrow-minded interpretation of algorithms.  Computer scientists invent, analyze, and implement algorithms every day, but much of that work is perhaps not sexy enough for a popular science book.</p>
<p>Incidentally, for the topics Steiner does cover, an excellent companion treating similar topics, but with a different focus, is Nate Silver’s (of <a href=\"http://fivethirtyeight.blogs.nytimes.com/\">538</a> fame) book, <em><a href=\"http://www.amazon.com/dp/159420411X\">The Signal and the Noise</a></em>.</p>
<br />  <a href=\"http://feeds.wordpress.com/1.0/gocomments/leepike.wordpress.com/556/\" rel=\"nofollow\"><img src=\"http://feeds.wordpress.com/1.0/comments/leepike.wordpress.com/556/\" alt=\"\" border=\"0\" /></a> <img src=\"http://stats.wordpress.com/b.gif?host=leepike.wordpress.com&blog=7358124&post=556&subd=leepike&ref=&feed=1\" alt=\"\" height=\"1\" border=\"0\" width=\"1\" />" nil nil "7ce92d0f54a14242729cf14cadaa0492") (18 (20928 8813 631804) "http://wadler.blogspot.com/2013/05/how-to-reject-paper.html" "Philip Wadler: How to reject a paper" "noreply@blogger.com (Philip Wadler)" "Mon, 27 May 2013 09:24:19 +0000" "<div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://4.bp.blogspot.com/-Nr_jG4UMaAA/UaMkctFqUcI/AAAAAAAACCQ/wYhoeiOP6T0/s1600/reject.jpg\"><img src=\"http://4.bp.blogspot.com/-Nr_jG4UMaAA/UaMkctFqUcI/AAAAAAAACCQ/wYhoeiOP6T0/s320/reject.jpg\" height=\"240\" border=\"0\" width=\"320\" /></a></div><br /><div style=\"font-family: inherit; margin-bottom: 0px; margin-top: 0px;\" class=\"mediumb-text\"><span style=\"font-size: small;\"><a href=\"http://dl.acm.org/citation.cfm?doid=1519103.1519122\">How NOT to review a paper: the tools and techniques of the adversarial reviewer</a> and </span><a href=\"http://vixra.org/pdf/0907.0020v1.pdf\">How to reject any scientific manuscript</a>.  Photo from <a href=\"http://academicnegativity.tumblr.com/\">Academic Negativity</a>.</div>" nil nil "1bbef13d038198b9229509e60e3ae0e7") (17 (20928 8813 631380) "http://kenta.blogspot.com/2013/05/ryvpijhs-code-reflection-at-compile-time.html" "Ken T Takusagawa: [ryvpijhs] Code reflection at compile time" "noreply@blogger.com (Ken)" "Mon, 27 May 2013 08:29:01 +0000" "<p dir=\"ltr\">Consider a Haskell extension providing this function:</p><p dir=\"ltr\">compileTimeAnalyze :: (Code -> IO ()) -> a -> a</p><p dir=\"ltr\">\"compileTypeAnalyze f e\" passes to user-defined function \"f\" the parse tree (and any other useful information such as types and symbol table) of the expression \"e\" and evaluates \"f\" at compile time.  At run time, it simply evaluates \"e\".</p><p dir=\"ltr\">The likely use is to emit warnings or errors if there is something domain-specifically wrong with the code that the compiler might not detect.</p><p dir=\"ltr\">Inspired by debugging 2D graphics code.  We often want the number of references to some X coordinate be the same as the number to the corresponding Y coordinate, or else there is likely a typo where we typed X instead of Y or vice versa.</p><p dir=\"ltr\">We probably also want the user to be able to define</p><p dir=\"ltr\">compileTimeAnalyzeModule :: Code -> IO()</p><p dir=\"ltr\">which gets the entire contents of the module for static analysis.  What about static analysis across many modules?</p><p dir=\"ltr\">Template Haskell can probably do most of this.</p>" nil nil "3784fe424e47c9aea22145e5bc66107c") (16 (20928 8813 630832) "http://neilmitchell.blogspot.com/2013/05/three-types-of-build-system-dependency.html" "Neil Mitchell: Three types of build-system dependency" "noreply@blogger.com (Neil Mitchell)" "Sun, 26 May 2013 19:58:13 +0000" "<i>Summary: There are three types of dependencies you might want to express in a build system, all of which are supported by Shake.</i><br /><br />A build system, at its heart, is a system which runs commands in an order satisfying user-specified dependencies. But what kind of dependencies can be expressed? This post describes three different types of dependency, only one of which is available in Make, but all of which are available in both <a href=\"https://github.com/ndmitchell/shake#readme\">Shake</a> and <a href=\"http://martine.github.io/ninja/\">Ninja</a>.<br /><br /><b>Feature 1: Static dependencies (available in every build system)</b><br /><br />The most basic form of dependency is a static dependency, where a rule produces an output from some inputs:<br /><br /><pre>-- In Make --<br />result.tar : file1 file2<br />    tar -cf result.tar file1 file2<br /><br />-- In Shake --<br />\"result.tar\" *> \\out -> do<br />    let deps = [\"file1\",\"file2\"]<br />    need deps<br />    cmd \"tar -cf\" [out] deps<br /></pre><br />This rule says that the file <tt>result.tar</tt> depends on the inputs <tt>file1</tt> and <tt>file2</tt>, and provides a command to build <tt>result.tar</tt>. Whenever <tt>file1</tt> or <tt>file2</tt> change, the command will be run, and <tt>result.tar</tt> will be built.<br /><br />Static dependencies occur in almost every build rule, and are supported by all build tools, including Make and Shake.<br /><br /><b>Feature 2: Dynamic dependencies (available in Shake, Ninja and Redo)</b><br /><br />A more advanced dependency is where the list of dependencies itself depends on the results of previous dependencies. Imagine we want to build <tt>result.tar</tt> from the list of files stored in <tt>list.txt</tt>. The dependencies of <tt>result.tar</tt> cannot be specified statically, but depend on <i>the contents</i> of <tt>list.txt</tt>. In Shake we can write:<br /><br /><pre>\"result.tar\" *> \\out -> do<br />    need [\"list.txt\"]<br />    contents <- readFileLines \"list.txt\"<br />    need contents<br />    cmd \"tar -cf\" [out] contents<br /></pre><br />This rule describes how to build <tt>result.tar</tt>. We depend on (<tt>need</tt>) the file <tt>list.txt</tt>. We read each line from <tt>list.txt</tt> into the variable <tt>contents</tt> - being a list of the files that should go into <tt>result.tar</tt>. Next, we depend on all the files in <tt>contents</tt>, and finally call the <tt>tar</tt> program. If either <tt>list.txt</tt> changes, or any of the files listed by <tt>list.txt</tt> change, then <tt>result.tar</tt> will be rebuilt.<br /><br />This feature is necessary in almost every build system, yet is shockingly lacking from most build tools - I am only aware of it being available in <a href=\"https://github.com/ndmitchell/shake#readme\">Shake</a>, <a href=\"http://martine.github.io/ninja/\">Ninja</a> and <a href=\"https://github.com/apenwarr/redo#readme\">Redo</a>. As a common example, in Make you might write:<br /><br /><pre>result.o : result.c result_header1.h result_header2.h<br />    gcc ...<br /></pre><br />The file <tt>result.o</tt> depends on both the C source file <tt>result.c</tt> and all headers that file includes. But listing the headers both in <tt>result.c</tt> with <tt>#include</tt> directives, and in the Makefile, is a brittle form of duplication. A better approach is for the build system to run <tt>gcc -M result.c</tt> and extract the includes from there. In Shake we can write:<br /><br /><pre>\"result.o\" *> \\out -> do<br />    let src = \"result.c\"<br />    Stdout stdout <- cmd \"gcc -MM\" [src]<br />    need $ src : drop 2 (words stdout)<br />    cmd \"gcc -o\" [out] \"-c\" [src]<br /></pre><br />My experience is that about a quarter of rules require some kind of additional dependency based on previous dependencies. While you can hack round some of the issues in Make, and people have become disturbingly adept at doing so, the result often only approximates the dependencies - building either too much or too little.<br /><br /><b>Feature 3: Multiple outputs from one rule (available in Shake and Ninja)</b><br /><br />The final feature is producing multiple outputs from one command, and is used far more rarely (perhaps one or two rules in a complex build system) - but when needed, is essential. Some programs, such as GHC, can produce two outputs with one command - compiling <tt>Foo.hs</tt> produces both <tt>Foo.o</tt> and <tt>Foo.hi</tt>. As a first approximation, the <tt>.o</tt> file depends on the entire contents of the source file, while the <tt>.hi</tt> file depends only on the type signatures. A single <tt>ghc</tt> invocation needs to do all the work to produce both, but often the <tt>.hi</tt> file will be left unchanged. In Shake we can write:<br /><br /><pre>[\"Foo.hi\",\"Foo.o\"] *>> \\_ -> do<br />    need [\"Foo.hs\"]<br />    cmd \"gcc -c Foo.hs\"<br /></pre><br />While it is often possible to construct a series of dependencies to approximate a single rule producing multiple outputs, it only works in some cases, and is brittle. The only build systems I am aware of which support multiple outputs are <a href=\"https://github.com/ndmitchell/shake#readme\">Shake</a> and <a href=\"http://martine.github.io/ninja/\">Ninja</a>.<br /><br /><b>Essential features</b><br /><br />My standard advice when people ask about writing a build system is \"don't\". If some existing build system (e.g. ghc --make or Cabal) is capable of building your project, use that instead. Custom build systems are necessary for many complex projects, but many projects are not complex. If you have decided your project is complex, you should use a build tool that can express complex dependencies, both for writing the initial system and to provide the flexibility to make the inevitable changes required.<br /><br />Looking only at dependency features, I would consider it unwise to start a complex build system using a tool other than Shake or Ninja, or perhaps Redo (if you accept the absence of multiple outputs from one rule).<br /><br />Weak dependency specification in build tools, particularly Make, has left its mark on many programs. I recently talked to some OCaml hackers complaining that their tools were not \"Make friendly\" because they produced multiple output files. I wonder what lengths other tools have gone to in order to cope with weak dependency specification...<br />" nil nil "855d421047eff4dbeed42248f8e2307f") (15 (20928 8813 629674) "http://blog.moertel.com/posts/2013-05-26-python-lazy-merge.html" "Tom Moertel: Lazy merging in Python using streams" nil "Sun, 26 May 2013 00:00:00 +0000" "<div class=\"info\">Posted on May 26, 2013</div>
<div class=\"tags\">Tags: <a href=\"http://blog.moertel.com/tags/programming.html\">programming</a>, <a href=\"http://blog.moertel.com/tags/python.html\">python</a>, <a href=\"http://blog.moertel.com/tags/iterators.html\">iterators</a>, <a href=\"http://blog.moertel.com/tags/streams.html\">streams</a>, <a href=\"http://blog.moertel.com/tags/SICP.html\">SICP</a>, <a href=\"http://blog.moertel.com/tags/functional programming.html\">functional programming</a></div>
<p>Recently while solving a programming puzzle in Python, I needed to merge a series of <em>N</em> iterators, each yielding values in sorted order, into a single iterator over the sorted values. The trick is that, when asked for a value from the merged series, to determine which iterator should contribute that value, you must extract all <em>N</em> iterators’ next values. And then, of course, you can emit only one. So what do you do with the remaining <em>N</em> – 1 values you’ve extracted?</p>
<p>Rather than think about that question too hard, I just converted the iterators into an equivalent form in which the next value was always exposed and hence available for making decisions <em>before</em> extraction. This form is basically the <a href=\"http://mitpress.mit.edu/sicp/full-text/sicp/book/node69.html\"><em>stream</em> of SICP fame</a>.</p>
<p>The idea is to convert each <a href=\"http://www.python.org/dev/peps/pep-0234/\">Python iterator</a> into either <code>None</code> (representing an empty stream) or a pair containing the iterator’s next value and the iterator itself:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> iterator_to_stream(iterator):
<span class=\"co\">\"\"\"Convert an iterator into a stream (None if the iterator is empty).\"\"\"</span>
<span class=\"kw\">try</span>:
<span class=\"kw\">return</span> iterator.<span class=\"dt\">next</span>(), iterator
<span class=\"kw\">except</span> <span class=\"ot\">StopIteration</span>:
<span class=\"kw\">return</span> <span class=\"ot\">None</span></code></pre>
<p>Then to extract values from the stream, you just apply <code>stream_next</code> to it, and it will hand you back the next value and the updated state of the stream:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"kw\">def</span> stream_next(stream):
<span class=\"co\">\"\"\"Get (next_value, next_stream) from a stream.\"\"\"</span>
val, iterator = stream
<span class=\"kw\">return</span> val, iterator_to_stream(iterator)</code></pre>
<p>Since streams expose their next value, they can be ordered by that value. And for my task that was the property that made all the difference:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\"><span class=\"ch\">import</span> heapq
<span class=\"kw\">def</span> merge(iterators):
<span class=\"co\">\"\"\"Make a lazy sorted iterator that merges lazy sorted iterators.\"\"\"</span>
streams = <span class=\"dt\">map</span>(iterator_to_stream, <span class=\"dt\">map</span>(<span class=\"dt\">iter</span>, iterators))
heapq.heapify(streams)
<span class=\"kw\">while</span> streams:
stream = heapq.heappop(streams)
<span class=\"kw\">if</span> stream is not <span class=\"ot\">None</span>:
val, stream = stream_next(stream)
heapq.heappush(streams, stream)
<span class=\"kw\">yield</span> val</code></pre>
<p>An example use:</p>
<pre class=\"sourceCode python\"><code class=\"sourceCode python\">>>> xs = merge([<span class=\"dt\">xrange</span>(<span class=\"dv\">3</span>), <span class=\"dt\">xrange</span>(<span class=\"dv\">2</span>, <span class=\"dv\">9</span>), <span class=\"dt\">xrange</span>(<span class=\"dv\">5</span>)])
>>> xs
<generator <span class=\"dt\">object</span> merge at <span class=\"bn\">0x7fea07c9d320</span>>
>>> <span class=\"dt\">list</span>(xs)
[<span class=\"dv\">0</span>, <span class=\"dv\">0</span>, <span class=\"dv\">1</span>, <span class=\"dv\">1</span>, <span class=\"dv\">2</span>, <span class=\"dv\">2</span>, <span class=\"dv\">2</span>, <span class=\"dv\">3</span>, <span class=\"dv\">3</span>, <span class=\"dv\">4</span>, <span class=\"dv\">4</span>, <span class=\"dv\">5</span>, <span class=\"dv\">6</span>, <span class=\"dv\">7</span>, <span class=\"dv\">8</span>]</code></pre>" nil nil "1f5b5eb91038585a9cadcdb08e8b6918") (14 (20928 8813 628681) "http://www.joachim-breitner.de/blog/archives/597-My-first-CTAN-package-Typesetting-Continued-Equalities.html" "Joachim Breitner: My first CTAN package: Typesetting Continued Equalities" "mail@joachim-breitner.de (nomeata)" "Sat, 25 May 2013 14:05:10 +0000" "<p>I recently had a <a href=\"http://tex.stackexchange.com/questions/108277/automatic-arrangement-of-equations-with-comments\">TeX itch to scratch</a>: I am working on a paper that has several multi-line continued equalities¹ where, depending on the size of the expressions and the explanations of each step, I chose among a few layouts. But implementing the layout together with the actual code was inefficient, as switching the layout involved changing every line.</p>
<p>So I came up with the package <tt>conteq</tt> which allows you to typeset continued equations in a simple declarative manner, e.g.</p>
<pre>\\begin{conteq}
e^{\\pi\\cdot i} \\\\
= -1               & Euler's formula \\\\
< 0                & this is an inequality \\\\
< \\sqrt 3 \\\\
= \\int e^{-x^2} dx & this is due to Gauss.
\\end{conteq}</pre>
<p>and allows you to select the layout via an parameter to the environment, or globally, or either. Also, the styling of the explanations (italics? wrapped in <tt>{</tt>...<tt>}</tt>?) can be configured simply by redefining a macro. For more details and an overview of the various styles, check out the <a href=\"http://mirrors.ctan.org/macros/latex/contrib/conteq/conteq.pdf\">package documentation</a>.<br /></p>
<p>If this sounds useful to you, fetch the <a href=\"http://ctan.org/pkg/conteq\"><tt>conteq</tt> package from CTAN</a>. But beware: It uses quite current features of the <a href=\"http://ctan.org/pkg/expl3\"><tt>expl3</tt></a> package, so you need at least the version from 2012/07/02 (TeXLive 2013 is good). You can file bug reports at the <a href=\"https://github.com/nomeata/conteq\">GitHub mirror</a> of <a href=\"http://git.nomeata.de/?p=conteq.git\">my git repository</a>.<br /></p>
<p>I’d like to thank <a href=\"http://tex.stackexchange.com/users/2707/bruno-le-floch\">Bruno Le Floch</a> and <a href=\"http://tex.stackexchange.com/users/73/joseph-wright\">Joseph Wright</a>, who made me aware of expl3 on <a href=\"http://tex.stackexchange.com/q/115700/15107\">various</a> <a href=\"http://tex.stackexchange.com/a/115816/15107\">TeX</a> <a href=\"http://tex.stackexchange.com/a/115909/15107\">Exchange</a> <a href=\"http://tex.stackexchange.com/a/115575/15107\">questions</a>.</p>
<p>¹ I haven’t heard of this term before, but <a href=\"http://english.stackexchange.com/questions/114746/correct-phrase-for-chain-of-equations\">supposedly it is the right translation</a> for the German word „Gleichungskette“.<br /></p>" nil nil "803a7c9ed9bf7ec6306752051e7b1bef") (13 (20928 8813 628054) "http://lpuppet.banquise.net/blog/2013/05/24/embedded-ruby-interpreter-and-performance-increase/" "language-puppet: Embedded ruby interpreter and performance increase" nil "Fri, 24 May 2013 17:38:00 +0000" "<p>Despite hitting a nasty (but obvious) bug involving Ruby’s GC, it seems that the feature is now stable.</p>
<p>I have been using a script for a while that computes catalogs for 30 nodes, taking into account exported resources, and runs some tests on the results. This script used to run in around 50 seconds. On my puppet master, the combined catalog generation time for those hosts is around 10 minutes¹.</p>
<p>Language-puppet was about ten times faster than the original implementation, but was wasting a significant amount of time spawning Ruby processes, rendering gobs of data (the list of all known variables and their values), and feeding them to said process, for each template evaluation. On the Ruby side, the data was interpreted (with eval), the templates were loaded and interpolated, and the response spit back to the Haskell executable. For this reason I wrote a minimalist template parser that is capable of interpolating the simplest ones while staring in Haskell land.</p>
<p>Now the Ruby process is embedded, and variable resolution happens only when needed, by providing a callback Haskell function to the Ruby runtime.</p>
<p>The whole script now runs in less than 10 seconds (six if you omit the tunnelled accesses to PuppetDB). This is now acceptable to run it before almost all commits, which was the goal. It will help making sure nothing got (too) broken, especially with regards to exported resources.</p>
<p>The software is now stable enough, and I will probably prepare a new binary release soon, along with a Debian-style repository.</p>
<hr />
<p>¹ This is not a fair comparison however. My script queries the PuppetDB for facts using a SSH tunnel, whereas the puppet master is local. On the other hand the puppet master does stuff my script doesn’t, such as updating facts and reporting data into PuppetDB (in all fairness my script updates a local PuppetDB-like database). I do not believe this accounts for an important fraction of those ten minutes, but might be wrong. Also, the puppet master has a faster CPU, and does not run unit tests on the catalogs.</p>" nil nil "dfe829c647f58f3e27bcbedce5bba38c") (12 (20928 8813 627382) "http://paulspontifications.blogspot.com/2013/05/elevator-pitch-for-haskell-short-enough.html" "Paul Johnson: Elevator pitch for Haskell short enough for an elevator ride" "noreply@blogger.com (Paul Johnson)" "Fri, 24 May 2013 15:08:27 +0000" "Greg Hale has written an \"<a href=\"https://www.fpcomplete.com/user/imalsogreg/functional-programming-elevator-pitch\">elevator pitch</a>\" for Haskell. While it is certainly a good piece of advocacy, it is quite long, and therefore not an elevator pitch. The idea of an elevator pitch is something you can deliver in the 30 seconds or so that you find yourself sharing an elevator with a potential investor.<br /><br />I've been looking for an effective Haskell elevator pitch for some years now, but the only thing I was able to come up with was just that you can deliver software better, faster and cheaper because you need fewer lines of code. This just sounds like hype.<br /><br />However I think I've now got something better. Here it is:<br /><br /><blockquote class=\"tr_bq\">Conventional languages make the programmer construct both a control flow and a data flow for the program. There is no way to check they are consistent, and anytime they are inconsistent you get a bug. In Haskell the programmer just specifies the data flow: the control flow is up to the compiler. That simplifies the program, cutting down the work and completely preventing a big class of errors.</blockquote>" nil nil "7f8ff4c0f6371238c73423543a61a113") (11 (20928 8813 506007) "http://twanvl.nl/blog/agda/sorting" "Twan van Laarhoven: The complete correctness of sorting" nil "Thu, 23 May 2013 12:43:33 +0000" "<p>A while ago I set out to prove the correctness of <a href=\"http://en.wikipedia.org/wiki/Merge_sort\">merge sort</a> in Agda.
Of course this has been done before.
But <a href=\"http://mazzo.li/posts/AgdaSort.html\">most</a> <a href=\"http://www.iis.sinica.edu.tw/~scm/2007/agda-exercise-proving-that-mergesort-returns-ordered-list/\">proofs</a> you find are far from complete.
All they prove is a lemma such as
</p><pre class=\"agda\"><span class=\"varid\">is-sorted</span> <span class=\"listcon\">:</span> <span class=\"keyglyph\">∀</span> (<span class=\"varid\">xs</span> <span class=\"listcon\">:</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">IsSortedList</span> (<span class=\"varid\">sort</span> <span class=\"varid\">xs</span>)
</pre><p>Maybe even restricted to lists of natural numbers.
While it is nice that a sort function indeed produces a sorted output, that is only half of the story.
Consider this function:
</p><pre class=\"agda\"><span class=\"varid\">cheat-sort</span> <span class=\"listcon\">:</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span>
<span class=\"varid\">cheat-sort</span> <span class=\"keyglyph\">_</span> <span class=\"keyglyph\">=</span> <span class=\"listcon\">[</span><span class=\"listcon\">]</span>
</pre><p>Clearly the empty list is sorted. So we are done.
What is missing is the second half of correctness of sorting: that the output is a permutation of the input.
You want something like:
</p><pre class=\"agda\"><span class=\"varid\">sort</span> <span class=\"listcon\">:</span> (<span class=\"varid\">xs</span> <span class=\"listcon\">:</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">Sorted'</span> <span class=\"conid\">A</span>
<span class=\"keyword\">record</span> <span class=\"conid\">Sorted'</span> (<span class=\"varid\">xs</span> <span class=\"listcon\">:</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span>) <span class=\"listcon\">:</span> <span class=\"conid\">Set</span> <span class=\"keyword\">where</span>
<span class=\"keyword\">field</span>
<span class=\"varid\">ys</span>       <span class=\"listcon\">:</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span>
<span class=\"varid\">isSorted</span> <span class=\"listcon\">:</span> <span class=\"conid\">IsSorted</span> <span class=\"varid\">ys</span>
<span class=\"varid\">isPerm</span>   <span class=\"listcon\">:</span> <span class=\"conid\">IsPermutation</span> <span class=\"varid\">ys</span> <span class=\"varid\">xs</span>
</pre><p>While I was at it, I decided to add the third half of correctness: a bound on the runtime or computational complexity.
In the end I was able to define:
</p><pre class=\"agda\"><span class=\"varid\">insertion-sort</span> <span class=\"listcon\">:</span> <span class=\"keyglyph\">∀</span> <span class=\"varid\">xs</span> <span class=\"keyglyph\">→</span> (<span class=\"conid\">Sorted</span> <span class=\"varid\">xs</span>) <span class=\"varop\">in-time</span> (<span class=\"varid\">length</span> <span class=\"varid\">xs</span> <span class=\"varop\">*</span> <span class=\"varid\">length</span> <span class=\"varid\">xs</span>)
<span class=\"varid\">selection-sort</span> <span class=\"listcon\">:</span> <span class=\"keyglyph\">∀</span> <span class=\"varid\">xs</span> <span class=\"keyglyph\">→</span> (<span class=\"conid\">Sorted</span> <span class=\"varid\">xs</span>) <span class=\"varop\">in-time</span> (<span class=\"varid\">length</span> <span class=\"varid\">xs</span> <span class=\"varop\">*</span> <span class=\"varid\">length</span> <span class=\"varid\">xs</span>)
<span class=\"varid\">merge-sort</span> <span class=\"listcon\">:</span> <span class=\"keyglyph\">∀</span> <span class=\"varid\">xs</span> <span class=\"keyglyph\">→</span> (<span class=\"conid\">Sorted</span> <span class=\"varid\">xs</span>) <span class=\"varop\">in-time</span> (<span class=\"varid\">length</span> <span class=\"varid\">xs</span> <span class=\"varop\">*</span> <span class=\"varop\">⌈log₂</span> <span class=\"varid\">length</span> <span class=\"varid\">xs</span> <span class=\"varop\">⌉</span>)
</pre><p>This was not as easy as I would have hoped.
In this post I will not bore you with all the details, I'll just go over some of the highlights. The <a href=\"https://gist.github.com/twanvl/5635740\">full code is on github</a>.
</p><h2><a name=\"what-it-means-to-be-sorted\"></a>What it means to be sorted </h2>
<p>There are roughly two ways to define sorted lists that I know of:
</p><ol><li> Parametrize the sorted list by a lower bound on the values it contains. For a cons cell the head should be smaller than the lower bound, and the tail should be larger than the head. This requires the type to have a smallest element, but you can adjoin -∞ with a new datatype.</li>
<li> Parametrize the sorted list by a list of all values in it. For a cons cell require that the head is smaller than all the values in the tail.</li>
</ol><p>Since I already need to parametrize by all values in the list to show that the sorted list contains a permutation of them, I went with the second approach:
</p><pre class=\"agda\"><span class=\"comment\">-- A proof that x is less than all values in xs</span>
<span class=\"keyword\">data</span> <span class=\"keyglyph\">_</span><span class=\"varop\">≤*</span><span class=\"keyglyph\">_</span> (<span class=\"varid\">x</span> <span class=\"listcon\">:</span> <span class=\"conid\">A</span>) <span class=\"listcon\">:</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"keyword\">where</span>
<span class=\"listcon\">[</span><span class=\"listcon\">]</span>  <span class=\"listcon\">:</span> <span class=\"varid\">x</span> <span class=\"varop\">≤*</span> <span class=\"listcon\">[</span><span class=\"listcon\">]</span>
<span class=\"keyglyph\">_</span>∷<span class=\"keyglyph\">_</span> <span class=\"listcon\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">y</span> <span class=\"varid\">ys</span>} <span class=\"keyglyph\">→</span> (<span class=\"varid\">x</span> <span class=\"varop\">≤</span> <span class=\"varid\">y</span>) <span class=\"keyglyph\">→</span> <span class=\"varid\">x</span> <span class=\"varop\">≤*</span> <span class=\"varid\">ys</span> <span class=\"keyglyph\">→</span> <span class=\"varid\">x</span> <span class=\"varop\">≤*</span> (<span class=\"varid\">y</span> ∷ <span class=\"varid\">ys</span>)
<div class=\"empty-line\"></div>
<span class=\"comment\">-- Proof that a list is sorted</span>
<span class=\"keyword\">data</span> <span class=\"conid\">IsSorted</span> <span class=\"listcon\">:</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"keyword\">where</span>
<span class=\"listcon\">[</span><span class=\"listcon\">]</span>  <span class=\"listcon\">:</span> <span class=\"conid\">IsSorted</span> <span class=\"listcon\">[</span><span class=\"listcon\">]</span>
<span class=\"keyglyph\">_</span>∷<span class=\"keyglyph\">_</span> <span class=\"listcon\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">x</span> <span class=\"varid\">xs</span>} <span class=\"keyglyph\">→</span> <span class=\"varid\">x</span> <span class=\"varop\">≤*</span> <span class=\"varid\">xs</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">IsSorted</span> <span class=\"varid\">xs</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">IsSorted</span> (<span class=\"varid\">x</span> ∷ <span class=\"varid\">xs</span>)
</pre><h2><a name=\"what-it-means-to-be-a-permutation\"></a>What it means to be a permutation </h2>
<p>To show that one list is a permutation of another I again used two data types.
Suppose that we know that <tt><span class=\"varid\">xs</span></tt> is a permutation of <tt><span class=\"varid\">ys</span></tt>. Then when is <tt class=\"complex\"><span class=\"varid\">x</span> ∷ <span class=\"varid\">xs</span></tt> a permutation of some list <tt><span class=\"varid\">xys</span></tt>? Well, we can permute <tt><span class=\"varid\">xs</span></tt> to <tt><span class=\"varid\">ys</span></tt>, and insert <tt><span class=\"varid\">x</span></tt> anywhere. I used <tt class=\"complex\"><span class=\"varop\">◂</span></tt> to denote this insertion,
</p><pre class=\"agda\"><span class=\"comment\">-- x ◂ xs ≡ xys means that xys is equal to xs with x inserted somewhere</span>
<span class=\"keyword\">data</span> <span class=\"keyglyph\">_</span><span class=\"varop\">◂</span><span class=\"keyglyph\">_</span><span class=\"varop\">≡</span><span class=\"keyglyph\">_</span> (<span class=\"varid\">x</span> <span class=\"listcon\">:</span> <span class=\"conid\">A</span>) <span class=\"listcon\">:</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span> <span class=\"keyword\">where</span>
<span class=\"varid\">here</span>  <span class=\"listcon\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">xs</span>}           <span class=\"keyglyph\">→</span> <span class=\"varid\">x</span> <span class=\"varop\">◂</span> <span class=\"varid\">xs</span> <span class=\"varop\">≡</span> (<span class=\"varid\">x</span> ∷ <span class=\"varid\">xs</span>)
<span class=\"varid\">there</span> <span class=\"listcon\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">y</span>} {<span class=\"varid\">xs</span>} {<span class=\"varid\">xys</span>} <span class=\"keyglyph\">→</span> (<span class=\"varid\">p</span> <span class=\"listcon\">:</span> <span class=\"varid\">x</span> <span class=\"varop\">◂</span> <span class=\"varid\">xs</span> <span class=\"varop\">≡</span> <span class=\"varid\">xys</span>) <span class=\"keyglyph\">→</span> <span class=\"varid\">x</span> <span class=\"varop\">◂</span> (<span class=\"varid\">y</span> ∷ <span class=\"varid\">xs</span>) <span class=\"varop\">≡</span> (<span class=\"varid\">y</span> ∷ <span class=\"varid\">xys</span>)
</pre><pre class=\"agda\"><span class=\"comment\">-- Proof that a list is a permutation of another one</span>
<span class=\"keyword\">data</span> <span class=\"conid\">IsPermutation</span> <span class=\"listcon\">:</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span> <span class=\"keyword\">where</span>
<span class=\"listcon\">[</span><span class=\"listcon\">]</span>  <span class=\"listcon\">:</span> <span class=\"conid\">IsPermutation</span> <span class=\"listcon\">[</span><span class=\"listcon\">]</span> <span class=\"listcon\">[</span><span class=\"listcon\">]</span>
<span class=\"keyglyph\">_</span>∷<span class=\"keyglyph\">_</span> <span class=\"listcon\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">x</span> <span class=\"varid\">xs</span> <span class=\"varid\">ys</span> <span class=\"varid\">xys</span>}
<span class=\"keyglyph\">→</span> (<span class=\"varid\">p</span> <span class=\"listcon\">:</span> <span class=\"varid\">x</span> <span class=\"varop\">◂</span> <span class=\"varid\">ys</span> <span class=\"varop\">≡</span> <span class=\"varid\">xys</span>)
<span class=\"keyglyph\">→</span> (<span class=\"varid\">ps</span> <span class=\"listcon\">:</span> <span class=\"conid\">IsPermutation</span> <span class=\"varid\">xs</span> <span class=\"varid\">ys</span>)
<span class=\"keyglyph\">→</span> <span class=\"conid\">IsPermutation</span> (<span class=\"varid\">x</span> ∷ <span class=\"varid\">xs</span>) <span class=\"varid\">xys</span>
</pre><p>Now the <tt><span class=\"conid\">Sorted</span></tt> data type has three components: the sorted list, a proof that it is sorted, and a proof that it is a permutation of the input. These parts are either all <tt class=\"complex\"><span class=\"listcon\">[</span><span class=\"listcon\">]</span></tt>, or they are all <tt class=\"complex\"><span class=\"keyglyph\">_</span>∷<span class=\"keyglyph\">_</span></tt>.
It turns out to be much nicer to combine the parts together,
</p><pre class=\"agda\"><span class=\"comment\">-- Sorted permutations of a list</span>
<span class=\"keyword\">data</span> <span class=\"conid\">Sorted</span> <span class=\"listcon\">:</span> <span class=\"conid\">List</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Set</span>  <span class=\"keyword\">where</span>
<span class=\"listcon\">[</span><span class=\"listcon\">]</span>   <span class=\"listcon\">:</span> <span class=\"conid\">Sorted</span> <span class=\"listcon\">[</span><span class=\"listcon\">]</span>
<span class=\"varid\">cons</span> <span class=\"listcon\">:</span> <span class=\"keyglyph\">∀</span> <span class=\"varid\">x</span> {<span class=\"varid\">xs</span> <span class=\"varid\">xxs</span>}
<span class=\"keyglyph\">→</span> (<span class=\"varid\">p</span> <span class=\"listcon\">:</span> <span class=\"varid\">x</span> <span class=\"varop\">◂</span> <span class=\"varid\">xs</span> <span class=\"varop\">≡</span> <span class=\"varid\">xxs</span>) <span class=\"comment\">-- inserting x somewhere into xs gives xxs</span>
<span class=\"keyglyph\">→</span> (<span class=\"varid\">least</span> <span class=\"listcon\">:</span> <span class=\"varid\">x</span> <span class=\"varop\">≤*</span> <span class=\"varid\">xs</span>)  <span class=\"comment\">-- x is the smallest element of the list</span>
<span class=\"keyglyph\">→</span> (<span class=\"varid\">rest</span> <span class=\"listcon\">:</span> <span class=\"conid\">Sorted</span> <span class=\"varid\">xs</span>) <span class=\"comment\">-- and we have also sorted xs</span>
<span class=\"keyglyph\">→</span> <span class=\"conid\">Sorted</span> <span class=\"varid\">xxs</span>
</pre><p>Of course <tt><span class=\"conid\">Sorted</span></tt> and <tt class=\"complex\"><span class=\"conid\">Sorted'</span></tt> are equivalent.
</p><p>As an aside, these are all the ingredients necessary for proving
</p><pre class=\"agda\"><span class=\"varid\">sorted-unique</span> <span class=\"listcon\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">xs</span>} <span class=\"keyglyph\">→</span> (<span class=\"varid\">ys</span> <span class=\"varid\">zs</span> <span class=\"listcon\">:</span> <span class=\"conid\">Sorted</span> <span class=\"varid\">xs</span>)
<span class=\"keyglyph\">→</span> <span class=\"varid\">sorted-to-List</span> <span class=\"varid\">ys</span> <span class=\"varop\">≡</span> <span class=\"varid\">sorted-to-List</span> <span class=\"varid\">zs</span>
</pre><h2><a name=\"a-monad-for-keeping-track-of-the-runtime\"></a>A monad for keeping track of the runtime </h2>
<p>To be able to reason about the runtime, as measured in the number of comparisons performed, I decided to use a monad. The type is simply
</p><pre class=\"agda\"><span class=\"keyword\">data</span> <span class=\"keyglyph\">_</span><span class=\"varop\">in-time</span><span class=\"keyglyph\">_</span> (<span class=\"conid\">A</span> <span class=\"listcon\">:</span> <span class=\"conid\">Set</span>) (<span class=\"varid\">n</span> <span class=\"listcon\">:</span> <span class=\"conop\">ℕ</span>) <span class=\"listcon\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span> <span class=\"keyword\">where</span>
<span class=\"varid\">box</span> <span class=\"listcon\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">C</span> <span class=\"conid\">A</span> <span class=\"varid\">n</span>
</pre><p>the constructor <tt><span class=\"varid\">box</span></tt> is private, and it can only be accessed through the standard monad operations,
</p><pre class=\"agda\"><span class=\"varid\">return</span> <span class=\"listcon\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"conid\">A</span> <span class=\"varid\">n</span>} <span class=\"keyglyph\">→</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">A</span> <span class=\"varop\">in-time</span> <span class=\"varid\">n</span>
<div class=\"empty-line\"></div>
<span class=\"keyglyph\">_</span><span class=\"varop\">>>=</span><span class=\"keyglyph\">_</span> <span class=\"listcon\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"conid\">A</span> <span class=\"conid\">B</span>} {<span class=\"varid\">m</span> <span class=\"varid\">n</span>} <span class=\"keyglyph\">→</span> <span class=\"conid\">A</span> <span class=\"varop\">in-time</span> <span class=\"varid\">n</span> <span class=\"keyglyph\">→</span> (<span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span> <span class=\"varop\">in-time</span> <span class=\"varid\">m</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">B</span> <span class=\"varop\">in-time</span> (<span class=\"varid\">n</span> <span class=\"varop\">+</span> <span class=\"varid\">m</span>)
</pre><p>Then the sorting functions will be parametrized by a function that for some partial order decides between <tt class=\"complex\"><span class=\"varid\">x</span> <span class=\"varop\">≤</span> <span class=\"varid\">y</span></tt> and <tt class=\"complex\"><span class=\"varid\">y</span> <span class=\"varop\">≤</span> <span class=\"varid\">x</span></tt> in one step, using the monad we defined above:
</p><pre class=\"agda\"><span class=\"keyword\">module</span> <span class=\"conid\">Sorting</span>
{<span class=\"conid\">A</span> <span class=\"listcon\">:</span> <span class=\"conid\">Set</span>} {<span class=\"varid\">l</span>} {<span class=\"keyglyph\">_</span><span class=\"varop\">≤</span><span class=\"keyglyph\">_</span> <span class=\"listcon\">:</span> <span class=\"conid\">Rel</span> <span class=\"conid\">A</span> <span class=\"varid\">l</span>}
(<span class=\"varid\">isPartialOrder</span> <span class=\"listcon\">:</span> <span class=\"conid\">IsPartialOrder</span> <span class=\"keyglyph\">_</span><span class=\"varop\">≡</span><span class=\"keyglyph\">_</span> <span class=\"keyglyph\">_</span><span class=\"varop\">≤</span><span class=\"keyglyph\">_</span>)
(<span class=\"keyglyph\">_</span><span class=\"varop\">≤?</span><span class=\"keyglyph\">_</span> <span class=\"listcon\">:</span> (<span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"listcon\">:</span> <span class=\"conid\">A</span>) <span class=\"keyglyph\">→</span> (<span class=\"varid\">x</span> <span class=\"varop\">≤</span> <span class=\"varid\">y</span> <span class=\"conop\">⊎</span> <span class=\"varid\">y</span> <span class=\"varop\">≤</span> <span class=\"varid\">x</span>) <span class=\"varop\">in-time</span> <span class=\"num\">1</span>)
<span class=\"keyword\">where</span> <span class=\"varop\">...</span>
</pre><p>Note that I specify that <tt class=\"complex\"><span class=\"keyglyph\">_</span><span class=\"varop\">≤</span><span class=\"keyglyph\">_</span></tt> is a <em>partial</em> order,
because the Agda standard library definition of a total order actually comes with a function
</p><pre class=\"agda\"><span class=\"varid\">total</span> <span class=\"listcon\">:</span> <span class=\"keyglyph\">∀</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"keyglyph\">→</span> (<span class=\"varid\">x</span> <span class=\"varop\">≤</span> <span class=\"varid\">y</span>) <span class=\"conop\">⊎</span> (<span class=\"varid\">y</span> <span class=\"varop\">≤</span> <span class=\"varid\">x</span>)
</pre><p>which would defeat the whole prupose of <tt class=\"complex\"><span class=\"keyglyph\">_</span><span class=\"varop\">≤?</span><span class=\"keyglyph\">_</span></tt>.
In fact, the standard <tt><span class=\"conid\">TotalOrder</span></tt>s are decidable up to base equality, and if the base equality is propositional equality, then they are decidable. I.e.
</p><pre class=\"agda\"><span class=\"varid\">total-decidable</span> <span class=\"listcon\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">a</span> <span class=\"varid\">r</span>} {<span class=\"conid\">A</span> <span class=\"listcon\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span>} <span class=\"keyglyph\">→</span> (<span class=\"keyglyph\">_</span><span class=\"varop\">≤</span><span class=\"keyglyph\">_</span> <span class=\"listcon\">:</span> <span class=\"conid\">Rel</span> <span class=\"conid\">A</span> <span class=\"varid\">r</span>)
<span class=\"keyglyph\">→</span> <span class=\"conid\">IsTotalOrder</span> <span class=\"keyglyph\">_</span><span class=\"varop\">≡</span><span class=\"keyglyph\">_</span> <span class=\"keyglyph\">_</span><span class=\"varop\">≤</span><span class=\"keyglyph\">_</span>
<span class=\"keyglyph\">→</span> <span class=\"conid\">IsDecTotalOrder</span> <span class=\"keyglyph\">_</span><span class=\"varop\">≡</span><span class=\"keyglyph\">_</span> <span class=\"keyglyph\">_</span><span class=\"varop\">≤</span><span class=\"keyglyph\">_</span>
</pre><p>See the source for the proof of this side theorem. It relies on a trick to show that <tt class=\"complex\"><span class=\"varid\">total</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span></tt> can only be different from <tt class=\"complex\"><span class=\"varid\">total</span> <span class=\"varid\">y</span> <span class=\"varid\">x</span></tt> if <tt class=\"complex\"><span class=\"varid\">x</span> <span class=\"varop\">≢</span> <span class=\"varid\">y</span></tt>. Which holds for propositional equality, but not in general.
</p><h2><a name=\"logarithms\"></a>Logarithms </h2>
<p>To be able to complete the specification of merge sort, we still need to add some missing functions on natural numbers. In particular, we need a logarithm.
This logarithm turns out to be surprisingly tricky to define in Agda.
Why? Because the usual definition uses non-structural recursion. In haskell you would write
</p><pre class=\"haskell\"><span class=\"comment\">-- @log n@ calculates ⌊log₂ (n+1)⌋</span>
<span class=\"varid\">log</span> <span class=\"num\">0</span> <span class=\"keyglyph\">=</span> <span class=\"num\">0</span>
<span class=\"varid\">log</span> <span class=\"varid\">n</span> <span class=\"keyglyph\">=</span> <span class=\"num\">1</span> <span class=\"varop\">+</span> <span class=\"varid\">log</span> (<span class=\"varid\">n</span> `<span class=\"varid\">div`</span> <span class=\"num\">2</span>)
</pre><p>But Agda is not able to see that <tt class=\"complex\"><span class=\"varid\">n</span> `<span class=\"varid\">div`</span> <span class=\"num\">2</span></tt> (or in agda notation, <tt class=\"complex\"><span class=\"varop\">⌊</span> <span class=\"varid\">n</span> <span class=\"varop\">/2⌋</span></tt>) is smaller than <tt><span class=\"varid\">n</span></tt>.
There are two approaches to circumvent this problem:
</p><ol><li> Use a different algorithm: Convert <tt><span class=\"varid\">n</span></tt> to a binary representation, and count the number of digits.</li>
<li> Use well-founded recursion, manually supplying a proof that <tt class=\"complex\"><span class=\"varop\">⌊</span> <span class=\"varid\">n</span> <span class=\"varop\">/2⌋</span> <span class=\"varop\"><</span> <span class=\"varid\">n</span></tt>.</li>
</ol><p>I went with the second option, because I will also be using the same shape of recursion inside merge sort itself.
The standard way to use well-founded recursion is through the function <tt class=\"complex\"><span class=\"keyglyph\"><-</span><span class=\"varid\">rec</span></tt>, which works a bit like <tt><span class=\"varid\">fix</span></tt> in haskell, except that you need to pass in a proof that the argument is smaller. The code would look like this:
</p><pre class=\"agda\"><span class=\"varid\">log</span> <span class=\"keyglyph\">=</span> <span class=\"keyglyph\"><-</span><span class=\"varid\">rec</span> <span class=\"varid\">log'</span>
<span class=\"keyword\">where</span>
<span class=\"varid\">log′</span> <span class=\"varid\">self</span> <span class=\"num\">0</span> <span class=\"keyglyph\">=</span> <span class=\"num\">0</span>
<span class=\"varid\">log′</span> <span class=\"varid\">self</span> (<span class=\"varid\">suc</span> <span class=\"varid\">n</span>) <span class=\"keyglyph\">=</span> <span class=\"num\">1</span> <span class=\"varop\">+</span> <span class=\"varid\">self</span> <span class=\"varop\">⌊</span> <span class=\"varid\">suc</span> <span class=\"varid\">n</span> <span class=\"varop\">/2⌋</span> (<span class=\"comment\">{-proof ommitted-}</span>)
</pre><p>But this leads to a problem as soon as you want to prove a property of logarithms. For example, you would think that <tt class=\"complex\"><span class=\"varid\">log</span> (<span class=\"varid\">suc</span> <span class=\"varid\">n</span>) <span class=\"varop\">≡</span> <span class=\"num\">1</span> <span class=\"varop\">+</span> (<span class=\"varid\">log</span> <span class=\"varop\">⌊</span> <span class=\"varid\">suc</span> <span class=\"varid\">n</span> <span class=\"varop\">/2⌋</span>)</tt>. But that is not definitionally true, since one <tt class=\"complex\"><span class=\"keyglyph\"><-</span><span class=\"varid\">rec</span></tt> is not like another. I found that the well-founded recursion library was in general a pain to work with, especially because it uses so many type synonyms. My solution was to use the slightly lower level accessibility relation. A value of type <tt class=\"complex\"><span class=\"conid\">Acc</span> <span class=\"keyglyph\">_</span><span class=\"varop\"><′</span><span class=\"keyglyph\">_</span> <span class=\"varid\">n</span></tt> allows you to do recursion with any <tt class=\"complex\"><span class=\"varid\">m</span> <span class=\"varop\"><′</span> <span class=\"varid\">n</span></tt>. Now I can use actual recursion:
</p><pre class=\"agda\"><span class=\"varid\">log-acc</span> <span class=\"listcon\">:</span> <span class=\"keyglyph\">∀</span> <span class=\"varid\">n</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Acc</span> <span class=\"keyglyph\">_</span><span class=\"varop\"><′</span><span class=\"keyglyph\">_</span> <span class=\"varid\">n</span> <span class=\"keyglyph\">→</span> <span class=\"conop\">ℕ</span>
<span class=\"varid\">log-acc</span> <span class=\"num\">0</span> <span class=\"keyglyph\">_</span> <span class=\"keyglyph\">=</span> <span class=\"num\">0</span>
<span class=\"varid\">log-acc</span> (<span class=\"varid\">suc</span> <span class=\"varid\">n</span>) (<span class=\"varid\">acc</span> <span class=\"varid\">more</span>) <span class=\"keyglyph\">=</span> <span class=\"num\">1</span> <span class=\"varop\">+</span> <span class=\"varid\">log-acc</span> <span class=\"varop\">⌊</span> <span class=\"varid\">suc</span> <span class=\"varid\">n</span> <span class=\"varop\">/2⌋</span> (<span class=\"varid\">more</span> <span class=\"keyglyph\">_</span> <span class=\"comment\">{-proof ommitted-}</span>)
</pre><p>And use the well-foundedness of ℕ to get an <tt><span class=\"conid\">Acc</span></tt> for any number:
</p><pre class=\"agda\"><span class=\"varid\">log</span> <span class=\"listcon\">:</span> <span class=\"conop\">ℕ</span> <span class=\"keyglyph\">→</span> <span class=\"conop\">ℕ</span>
<span class=\"varid\">log</span> <span class=\"varid\">n</span> <span class=\"keyglyph\">=</span> <span class=\"varid\">log-acc</span> <span class=\"varid\">n</span> (<span class=\"keyglyph\"><-</span><span class=\"varid\">well-founded</span> <span class=\"varid\">n</span>)
<div class=\"empty-line\"></div>
<span class=\"varop\">⌈log₂</span><span class=\"keyglyph\">_</span><span class=\"varop\">⌉</span> <span class=\"listcon\">:</span> <span class=\"conop\">ℕ</span> <span class=\"keyglyph\">→</span> <span class=\"conop\">ℕ</span>
<span class=\"varop\">⌈log₂</span> <span class=\"varid\">n</span> <span class=\"varop\">⌉</span> <span class=\"keyglyph\">=</span> <span class=\"varid\">log</span> (<span class=\"varid\">pred</span> <span class=\"varid\">n</span>)
</pre><p>There is still a snag when proving properties of <tt><span class=\"varid\">log</span></tt> or <tt class=\"complex\"><span class=\"varid\">log-acc</span></tt>, namely that you need to prove that <tt class=\"complex\">(<span class=\"varid\">more</span> <span class=\"varid\">n</span> <span class=\"varop\">...</span>) <span class=\"varop\">≡</span> <span class=\"keyglyph\"><-</span><span class=\"varid\">well-founded</span> <span class=\"varid\">n</span></tt>. But the accessibility relation doesn't actually matter for the computation, so I decided to just postulate
</p><pre class=\"agda\"><span class=\"varid\">postulate</span> <span class=\"varid\">acc-irrelevance</span> <span class=\"listcon\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">n</span> <span class=\"listcon\">:</span> <span class=\"conop\">ℕ</span>} <span class=\"keyglyph\">→</span> {<span class=\"varid\">a</span> <span class=\"varid\">b</span> <span class=\"listcon\">:</span> <span class=\"conid\">Acc</span> <span class=\"keyglyph\">_</span><span class=\"varop\"><′</span><span class=\"keyglyph\">_</span> <span class=\"varid\">n</span>} <span class=\"keyglyph\">→</span> <span class=\"varid\">a</span> <span class=\"varop\">≡</span> <span class=\"varid\">b</span>
<span class=\"comment\">-- this also follows from function extensionality</span>
</pre><p>If anyone knows a better way to prove properties of functions defined with well-founded recursion, I am open to suggestions.
</p><h2><a name=\"vectors-versus-lists\"></a>Vectors versus lists </h2>
<p>While working on the proofs I had to choose: Do I use fixed length <tt><span class=\"conid\">Vec</span></tt>s or variable length <tt><span class=\"conid\">List</span></tt>s? Both have their pros and cons.
</p><p>On the one hand, the sorting functions with vectors look a bit nicer, because we can use <tt><span class=\"varid\">n</span></tt> instead of <tt class=\"complex\"><span class=\"varid\">length</span> <span class=\"varid\">xs</span></tt>:
</p><pre class=\"agda\"><span class=\"varid\">merge-sort</span> <span class=\"listcon\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">n</span>} (<span class=\"varid\">xs</span> <span class=\"listcon\">:</span> <span class=\"conid\">Vec</span> <span class=\"conid\">A</span> <span class=\"varid\">n</span>) <span class=\"keyglyph\">→</span> <span class=\"conid\">Sorted</span> <span class=\"varid\">xs</span> <span class=\"varop\">in-time</span> (<span class=\"varid\">n</span> <span class=\"varop\">*</span> <span class=\"varop\">⌈log₂</span> <span class=\"varid\">n</span> <span class=\"varop\">⌉</span>)
</pre><p>Additionally, with lists we can only do recursion on the input list, with vectors we can do recursion on the length of the list. The former works fine for insertion sort, where in each step you do something with the head element of the list; but it fails for selection and merge sort.
</p><p>On the other hand, with vectors you sometimes can't even <em>state</em> the property that one vector is equal to another.
For the term <tt class=\"complex\"><span class=\"varid\">xs</span> <span class=\"varop\">≡</span> <span class=\"varid\">ys</span> <span class=\"varop\">++</span> <span class=\"varid\">zs</span></tt> to be well-typed, <tt><span class=\"varid\">xs</span></tt> must have the type <tt class=\"complex\"><span class=\"conid\">Vec</span> <span class=\"conid\">A</span> (<span class=\"varid\">m</span> <span class=\"varop\">+</span> <span class=\"varid\">n</span>)</tt>.
</p><p>I went back and forth a couple of times between vectors and lists.
In the end I settled for using vectors only when needed, and specifying properties in terms of lists.
For example the split function for merge sort has the type
</p><pre class=\"agda\"><span class=\"varid\">splitHalf</span> <span class=\"listcon\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">n</span>} <span class=\"keyglyph\">→</span> (<span class=\"varid\">xs</span> <span class=\"listcon\">:</span> <span class=\"conid\">Vec</span> <span class=\"conid\">A</span> <span class=\"varid\">n</span>)
<span class=\"keyglyph\">→</span> ∃₂ <span class=\"keyglyph\">\\</span>(<span class=\"varid\">ys</span> <span class=\"listcon\">:</span> <span class=\"conid\">Vec</span> <span class=\"conid\">A</span> <span class=\"varop\">⌈</span> <span class=\"varid\">n</span> <span class=\"varop\">/2⌉</span>) (<span class=\"varid\">zs</span> <span class=\"listcon\">:</span> <span class=\"conid\">Vec</span> <span class=\"conid\">A</span> <span class=\"varop\">⌊</span> <span class=\"varid\">n</span> <span class=\"varop\">/2⌋</span>)
<span class=\"keyglyph\">→</span> <span class=\"varid\">toList</span> <span class=\"varid\">ys</span> <span class=\"varop\">++</span> <span class=\"varid\">toList</span> <span class=\"varid\">zs</span> <span class=\"varop\">≡</span> <span class=\"varid\">toList</span> <span class=\"varid\">xs</span>
</pre><p>So instead of using <tt class=\"complex\">Vec<span class=\"varop\">.</span><span class=\"keyglyph\">_</span><span class=\"varop\">++</span><span class=\"keyglyph\">_</span></tt>, I use <tt class=\"complex\">List<span class=\"varop\">.</span><span class=\"keyglyph\">_</span><span class=\"varop\">++</span><span class=\"keyglyph\">_</span></tt>.
In this style 'select' from selection sort looks like
</p><pre class=\"agda\"><span class=\"varid\">select</span> <span class=\"listcon\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"varid\">n</span>} (<span class=\"varid\">xs</span> <span class=\"listcon\">:</span> <span class=\"conid\">Vec</span> <span class=\"conid\">A</span> (<span class=\"varid\">suc</span> <span class=\"varid\">n</span>))
<span class=\"keyglyph\">→</span> (∃₂ <span class=\"keyglyph\">\\</span><span class=\"varid\">y</span> <span class=\"varid\">ys</span> <span class=\"keyglyph\">→</span> (<span class=\"varid\">y</span> <span class=\"varop\">◂</span> <span class=\"varid\">toList</span> <span class=\"varid\">ys</span> <span class=\"varop\">≡</span> <span class=\"varid\">toList</span> <span class=\"varid\">xs</span>) × (<span class=\"varid\">y</span> <span class=\"varop\">≤*</span> <span class=\"varid\">toList</span> <span class=\"varid\">ys</span>)) <span class=\"varop\">in-time</span> <span class=\"varid\">n</span>
</pre><p>I.e. given a <em>vector</em> <tt><span class=\"varid\">xs</span></tt> with <tt class=\"complex\"><span class=\"varid\">n+1</span></tt> elements, return a vector <tt><span class=\"varid\">ys</span></tt> with <tt><span class=\"varid\">n</span></tt> elements, such that inserting <tt><span class=\"varid\">y</span></tt> into it gives us back <tt><span class=\"varid\">xs</span></tt>. And this item <tt><span class=\"varid\">y</span></tt> should be the smallest one.
</p><h2><a name=\"extension-expected-runtime\"></a>Extension: expected runtime </h2>
<p>An extension of this post would be to look at randomized sorting algorithms. In particular, quick sort with a randomly chosen pivot has expected runtime <tt class=\"complex\"><span class=\"conid\">O</span>(<span class=\"varid\">n</span> <span class=\"varop\">*</span> <span class=\"varid\">log</span> <span class=\"varid\">n</span>)</tt>. At first I thought that all that would be needed is a function
</p><pre class=\"agda\"><span class=\"varid\">expected</span> <span class=\"listcon\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"conid\">P</span>}
<span class=\"keyglyph\">→</span> (<span class=\"varid\">ns</span> <span class=\"listcon\">:</span> <span class=\"conid\">List</span> <span class=\"conop\">ℕ</span>)             <span class=\"comment\">-- A list of numbers</span>
<span class=\"keyglyph\">→</span> <span class=\"conid\">All</span> (<span class=\"keyglyph\">\\</span><span class=\"varid\">n</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">P</span> <span class=\"varop\">in-time</span> <span class=\"varid\">n</span>) <span class=\"varid\">ns</span> <span class=\"comment\">-- for each n we have P in-time n</span>
<span class=\"keyglyph\">→</span> <span class=\"conid\">P</span> <span class=\"varop\">in-time</span> <span class=\"varop\">⌈mean</span> <span class=\"varid\">ns</span> <span class=\"varop\">⌉</span>      <span class=\"comment\">-- then expect time is mean of ns</span>
</pre><p>But that is not quite right, since if we actually knew the runtimes <tt><span class=\"varid\">ns</span></tt> we could just pick the fastest one.
With the randomized quicksort you will end up in a situation where you have two or more computations to choose from, and you know that some are faster than the others, but you don't yet know which one. That sounds a bit classical. A second idea is to return the runtimes at a later time, something like
</p><pre class=\"agda\"><span class=\"varid\">expected</span> <span class=\"listcon\">:</span> <span class=\"keyglyph\">∀</span> {<span class=\"conid\">P</span>} {<span class=\"varid\">long-time</span>}
<span class=\"keyglyph\">→</span> (<span class=\"varid\">xs</span> <span class=\"listcon\">:</span> <span class=\"conid\">List</span> (<span class=\"keyglyph\">\\</span><span class=\"varid\">ex</span> <span class=\"varid\">n</span> <span class=\"conid\">P</span> <span class=\"varop\">in-time</span> <span class=\"varid\">n</span>) <span class=\"varop\">in-time</span> <span class=\"varid\">long-time</span>)
<span class=\"keyglyph\">→</span> <span class=\"conid\">P</span> <span class=\"varop\">in-time</span> <span class=\"varop\">⌈mean</span> <span class=\"varid\">map</span> <span class=\"varid\">proj1</span> <span class=\"varid\">xs</span> <span class=\"varop\">⌉</span>
</pre><p>But this is not quite right either, since after <tt class=\"complex\"><span class=\"varid\">long-time</span></tt> computing <tt><span class=\"conid\">P</span></tt> (i.e. a sorting) can be done in 0 time.
Rather, we need to decouple the proof about the runtime from the computation.
This is not possible with the <tt class=\"complex\"><span class=\"keyglyph\">_</span><span class=\"varop\">in-time</span><span class=\"keyglyph\">_</span></tt> monad. We would need to get rid of the runtime from the type, and store it as a value instead.
</p><p>I have tried redoing the proofs in this post with the monad
</p><pre class=\"agda\"><span class=\"keyword\">data</span> <span class=\"conid\">Timed</span> (<span class=\"conid\">A</span> <span class=\"listcon\">:</span> <span class=\"conid\">Set</span>) <span class=\"listcon\">:</span> <span class=\"conid\">Set</span> <span class=\"varid\">a</span> <span class=\"keyword\">where</span>
<span class=\"keyglyph\">_</span><span class=\"varop\">in-time</span><span class=\"keyglyph\">_</span> <span class=\"listcon\">:</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conop\">ℕ</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Timed</span> <span class=\"conid\">A</span>
<span class=\"varid\">runtime</span> <span class=\"listcon\">:</span> <span class=\"conid\">Timed</span> <span class=\"conid\">A</span> <span class=\"keyglyph\">→</span> <span class=\"conop\">ℕ</span>
</pre><p>But I didn't succeed; I ended up with the baffling error message
</p><pre class=\"agda\"><span class=\"varid\">runtime</span> (<span class=\"varid\">big-lambda-term</span> (<span class=\"varid\">unbox</span> (<span class=\"varid\">x</span> <span class=\"varop\">≤?</span> <span class=\"varid\">u</span>)))
<span class=\"varop\">!=</span>
<span class=\"varid\">runtime</span> (<span class=\"varid\">big-lambda-term</span> (<span class=\"varid\">unbox</span> (<span class=\"varid\">x</span> <span class=\"varop\">≤?</span> <span class=\"varid\">u</span>)))
</pre><h2><a name=\"another-extension-lower-bound-on-runtime\"></a>Another extension: lower bound on runtime </h2>
<p>So far I have proved that you can sort a list in time <tt class=\"complex\"><span class=\"varid\">n</span> <span class=\"varop\">*</span> <span class=\"varid\">log</span> <span class=\"varid\">n</span></tt>.
It would also be interesting to look at the well known <a href=\"http://planetmath.org/LowerBoundForSorting\">lower bound on the runtime of sorting</a>, and prove a theorem such as
</p><pre class=\"agda\"><span class=\"varid\">can't-sort-in-linear-time</span> <span class=\"listcon\">:</span> ¬ ∃ <span class=\"keyglyph\">\\</span><span class=\"varid\">k</span> <span class=\"keyglyph\">→</span> <span class=\"keyglyph\">∀</span> <span class=\"varid\">xs</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Sorted</span> <span class=\"varid\">xs</span> <span class=\"varop\">in-time</span> <span class=\"varid\">k</span> <span class=\"varop\">*</span> <span class=\"varid\">length</span> <span class=\"varid\">xs</span>
</pre><p>unfortunately this statement is not actually true for all types. For finite sets you actually <em>can</em> sort in linear time with counting sort.
It also fails if we happen to have some decidable total order for that type lying around. But it might be possible to prove
</p><pre class=\"agda\"><span class=\"varid\">can't-sort-in-linear-time</span>
<span class=\"listcon\">:</span> (<span class=\"varid\">no-fast-compare</span> <span class=\"listcon\">:</span> <span class=\"keyglyph\">∀</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"keyglyph\">→</span> (<span class=\"varid\">x</span> <span class=\"varop\">≤</span> <span class=\"varid\">y</span> <span class=\"conop\">⊎</span> <span class=\"varid\">y</span> <span class=\"varop\">≤</span> <span class=\"varid\">x</span>) <span class=\"varop\">in-time</span> <span class=\"num\">0</span> <span class=\"keyglyph\">→</span> <span class=\"varid\">x</span> <span class=\"varop\">≡</span> <span class=\"varid\">y</span>)
<span class=\"keyglyph\">→</span> ¬ ∃ <span class=\"keyglyph\">\\</span><span class=\"varid\">k</span> <span class=\"keyglyph\">→</span> <span class=\"keyglyph\">∀</span> <span class=\"varid\">xs</span> <span class=\"keyglyph\">→</span> <span class=\"conid\">Sorted</span> <span class=\"varid\">xs</span> <span class=\"varop\">in-time</span> <span class=\"varid\">k</span> <span class=\"varop\">*</span> <span class=\"varid\">length</span> <span class=\"varid\">xs</span>
</pre><p>But you have to be really careful with a term like <tt class=\"complex\"><span class=\"varid\">no-fast-compare</span></tt>, because inside the runtime monad we do have values of type <tt class=\"complex\">(<span class=\"varid\">x</span> <span class=\"varop\">≤</span> <span class=\"varid\">y</span> <span class=\"conop\">⊎</span> <span class=\"varid\">y</span> <span class=\"varop\">≤</span> <span class=\"varid\">x</span>)</tt>. And so you can derive <tt class=\"complex\"><span class=\"keyglyph\">∀</span> <span class=\"varid\">x</span> <span class=\"varid\">y</span> <span class=\"keyglyph\">→</span> <span class=\"varid\">x</span> <span class=\"varop\">≡</span> <span class=\"varid\">y</span> <span class=\"varop\">in-time</span> <span class=\"num\">1</span></tt>, and therefore also <tt class=\"complex\">⊥ <span class=\"varop\">in-time</span> <span class=\"num\">1</span></tt> for non trivial types. Which certainly looks wrong to me.
</p><p>I don't know a way around this problem, but it might be related to the same issue as expected runtime.
I.e. the problem is that all information about the runtime is bundled together with the return value.
The lower bound proof essentially asks to sort a 'random' list, and by a counting argument shows that at least a certain number of comparisons are needed to be able to produce all outputs.
</p>" nil nil "0a51b69552d8b27e054de1f8ef275edc") (10 (20928 8813 500485) "http://winterkoninkje.dreamwidth.org/83774.html" "wren ng thornton: Upcoming talk" nil "Mon, 20 May 2013 22:11:45 +0000" "<p>Next month I'll be giving a talk at the <a href=\"http://www.indiana.edu/~iulg/nlcs.html\">NLCS</a> workshop, on the chiastic lambda-calculi I first presented at NASSLLI 2010 (<a href=\"http://llama.freegeek.org/~wren/pubs/ccgjp_nasslli2010.pdf\">slides</a>[1]). After working out some of the metatheory for one of my quals, I gave more recent talks at our local PL Wonks and CLingDing seminars (<a href=\"http://llama.freegeek.org/~wren/pubs/chiastic_plwonks2013.pdf\">slides</a>). The NASSLLI talk was more about the linguistic motivations and the general idea, whereas the PLWonks/CLingDing talks were more about the formal properties of the calculus itself. For NLCS I hope to combine these threads a bit better— which has always been the challenge with this work.</p>
<p>NLCS is collocated with this year's <a href=\"http://lii.rwth-aachen.de/lics/lics13/\">LICS</a> (and MFPS and CSF). I'll also be around for LICS itself, and in town for MFPS though probably not attending. So if you're around, feel free to stop by and chat.</p>
<p>[1] N.B., the NASSLLI syntax is a bit different than the newer version: square brackets were used instead of angle brackets (the latter were chosen because they typeset better in general); juxtaposition was just juxtaposition rather than being made explicit; and the left- vs right-chiastic distinction was called chi vs ksi (however, it turns out that ksi already has an important meaning in type theory).</p><br /><br /><img src=\"http://www.dreamwidth.org/tools/commentcount?user=winterkoninkje&ditemid=83774\" alt=\"comment count unavailable\" height=\"12\" style=\"vertical-align: middle;\" width=\"30\" /> comments" nil nil "a6aa493dcbfb0220560a86db3a660d38") (9 (20928 8813 499712) "http://lpuppet.banquise.net/blog/2013/05/20/incoming-ruby-bridge/" "language-puppet: Incoming: Ruby bridge" nil "Mon, 20 May 2013 09:35:00 +0000" "<p>I am working on a quick and dirty Ruby bridge <a href=\"https://github.com/bartavelle/hruby\">library</a>, that I hope will yield a huge performance gain with template interpolation in the language-puppet library. Right now, it is capable of:</p>
<ul>
<li>Initializing a Ruby interpreter from libruby</li>
<li>Calling Ruby methods and functions</li>
<li>Registering methods or functions that will be called from Ruby code</li>
<li>Converting data between the two Worlds (right now the most complex instance is the JSON one, which means that many complex Ruby types can’t be converted, but it is more than enough for passing data)</li>
<li>Embedding native Haskell values that can be passed around in Ruby to the Haskell-provided external functions (I will use this for passing the Puppet catalog state around)</li>
</ul>
<p>There are still a few things to do before releasing it :</p>
<ul>
<li>Making compilation a bit less dependant on the system. This will probably require quite a few flags in the cabal definition …</li>
<li>Hunting for memory leaks. I am not sure how to do this with the GHC Runtime in the middle, and I do hope that <em>ruby_finalize</em> frees everything that is managed by the Ruby runtime. After all, restarting processes seems to be the only working garbage collection method for Ruby daemons …</li>
<li>Writing stubs for the Puppet library methods that might be needed by templates. I would like to be able to support custom types and functions directly written in Ruby instead of Lua, but this will probably turn into a nightmare …</li>
<li>Cleaning things up !</li>
</ul>
<p>Here is a quick code preview :</p>
<figure class=\"code\"><figcaption><span>test.hs </span></figcaption>
<div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
<span class=\"line-number\">2</span>
<span class=\"line-number\">3</span>
<span class=\"line-number\">4</span>
<span class=\"line-number\">5</span>
<span class=\"line-number\">6</span>
<span class=\"line-number\">7</span>
<span class=\"line-number\">8</span>
<span class=\"line-number\">9</span>
<span class=\"line-number\">10</span>
<span class=\"line-number\">11</span>
<span class=\"line-number\">12</span>
<span class=\"line-number\">13</span>
<span class=\"line-number\">14</span>
<span class=\"line-number\">15</span>
<span class=\"line-number\">16</span>
<span class=\"line-number\">17</span>
<span class=\"line-number\">18</span>
<span class=\"line-number\">19</span>
<span class=\"line-number\">20</span>
<span class=\"line-number\">21</span>
<span class=\"line-number\">22</span>
<span class=\"line-number\">23</span>
<span class=\"line-number\">24</span>
<span class=\"line-number\">25</span>
<span class=\"line-number\">26</span>
<span class=\"line-number\">27</span>
<span class=\"line-number\">28</span>
<span class=\"line-number\">29</span>
<span class=\"line-number\">30</span>
<span class=\"line-number\">31</span>
<span class=\"line-number\">32</span>
<span class=\"line-number\">33</span>
<span class=\"line-number\">34</span>
<span class=\"line-number\">35</span>
<span class=\"line-number\">36</span>
<span class=\"line-number\">37</span>
<span class=\"line-number\">38</span>
<span class=\"line-number\">39</span>
<span class=\"line-number\">40</span>
<span class=\"line-number\">41</span>
<span class=\"line-number\">42</span>
<span class=\"line-number\">43</span>
<span class=\"line-number\">44</span>
<span class=\"line-number\">45</span>
<span class=\"line-number\">46</span>
<span class=\"line-number\">47</span>
<span class=\"line-number\">48</span>
<span class=\"line-number\">49</span>
<span class=\"line-number\">50</span>
<span class=\"line-number\">51</span>
<span class=\"line-number\">52</span>
<span class=\"line-number\">53</span>
</pre></td><td class=\"code\"><pre><code class=\"hs\"><span class=\"line\"><span class=\"cm\">{-# LANGUAGE OverloadedStrings, OverloadedStrings #-}</span>
</span><span class=\"line\"><span class=\"kr\">module</span> <span class=\"nn\">Main</span> <span class=\"kr\">where</span>
</span><span class=\"line\">
</span><span class=\"line\"><span class=\"kr\">import</span> <span class=\"nn\">Foreign.Ruby.Bindings</span>
</span><span class=\"line\"><span class=\"kr\">import</span> <span class=\"nn\">Data.Aeson</span>
</span><span class=\"line\"><span class=\"kr\">import</span> <span class=\"nn\">Data.Attoparsec.Number</span>
</span><span class=\"line\">
</span><span class=\"line\"><span class=\"c1\">-- this is an external function that will be executed from the Ruby interpreter</span>
</span><span class=\"line\"><span class=\"c1\">-- the first parameter to the function is probably some reference to some top object</span>
</span><span class=\"line\"><span class=\"c1\">-- my knowledge of ruby is close to nonexistent, so I can't say for sure ...</span>
</span><span class=\"line\"><span class=\"nf\">extfunc</span> <span class=\"ow\">::</span> <span class=\"kt\">RValue</span> <span class=\"ow\">-></span> <span class=\"kt\">RValue</span> <span class=\"ow\">-></span> <span class=\"kt\">IO</span> <span class=\"kt\">RValue</span>
</span><span class=\"line\"><span class=\"nf\">extfunc</span> <span class=\"kr\">_</span> <span class=\"n\">v</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>
</span><span class=\"line\">    <span class=\"c1\">-- deserialize the Ruby value into some JSON Value</span>
</span><span class=\"line\">    <span class=\"n\">onv</span> <span class=\"ow\"><-</span> <span class=\"n\">fromRuby</span> <span class=\"n\">v</span> <span class=\"ow\">::</span> <span class=\"kt\">IO</span> <span class=\"p\">(</span><span class=\"kt\">Maybe</span> <span class=\"kt\">Value</span><span class=\"p\">)</span>
</span><span class=\"line\">    <span class=\"c1\">-- and display it</span>
</span><span class=\"line\">    <span class=\"n\">print</span> <span class=\"n\">onv</span>
</span><span class=\"line\">    <span class=\"c1\">-- now let's create a JSON object containing all kind of data types</span>
</span><span class=\"line\">    <span class=\"kr\">let</span> <span class=\"n\">nv</span> <span class=\"ow\">=</span> <span class=\"n\">object</span> <span class=\"p\">[</span> <span class=\"p\">(</span><span class=\"s\">\"bigint\"</span> <span class=\"p\">,</span> <span class=\"kt\">Number</span> <span class=\"p\">(</span><span class=\"kt\">I</span> <span class=\"mi\">16518656116889898998656112323135664684684</span><span class=\"p\">))</span>
</span><span class=\"line\">                    <span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"s\">\"int\"</span><span class=\"p\">,</span> <span class=\"kt\">Number</span> <span class=\"p\">(</span><span class=\"kt\">I</span> <span class=\"mi\">12</span><span class=\"p\">))</span>
</span><span class=\"line\">                    <span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"s\">\"double\"</span><span class=\"p\">,</span> <span class=\"kt\">Number</span> <span class=\"p\">(</span><span class=\"kt\">D</span> <span class=\"mf\">0.123</span><span class=\"p\">))</span>
</span><span class=\"line\">                    <span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"s\">\"null\"</span><span class=\"p\">,</span> <span class=\"s\">\"Null\"</span><span class=\"p\">)</span>
</span><span class=\"line\">                    <span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"s\">\"string\"</span><span class=\"p\">,</span> <span class=\"kt\">String</span> <span class=\"s\">\"string\"</span><span class=\"p\">)</span>
</span><span class=\"line\">                    <span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"s\">\"true\"</span><span class=\"p\">,</span> <span class=\"kt\">Bool</span> <span class=\"kt\">True</span><span class=\"p\">)</span>
</span><span class=\"line\">                    <span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"s\">\"false\"</span><span class=\"p\">,</span> <span class=\"kt\">Bool</span> <span class=\"kt\">False</span><span class=\"p\">)</span>
</span><span class=\"line\">                    <span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"s\">\"array\"</span><span class=\"p\">,</span> <span class=\"n\">toJSON</span> <span class=\"p\">([</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">3</span><span class=\"p\">,</span><span class=\"mi\">4</span><span class=\"p\">,</span><span class=\"mi\">5</span><span class=\"p\">]</span> <span class=\"ow\">::</span> <span class=\"p\">[</span><span class=\"kt\">Int</span><span class=\"p\">]))</span>
</span><span class=\"line\">                    <span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"s\">\"object\"</span><span class=\"p\">,</span> <span class=\"n\">object</span> <span class=\"p\">[</span> <span class=\"p\">(</span><span class=\"s\">\"k\"</span><span class=\"p\">,</span> <span class=\"kt\">String</span> <span class=\"s\">\"v\"</span><span class=\"p\">)</span> <span class=\"p\">]</span> <span class=\"p\">)</span>
</span><span class=\"line\">                    <span class=\"p\">]</span>
</span><span class=\"line\">    <span class=\"c1\">-- turn it into Ruby values, and return this</span>
</span><span class=\"line\">    <span class=\"n\">toRuby</span> <span class=\"n\">nv</span>
</span><span class=\"line\">
</span><span class=\"line\"><span class=\"c1\">-- this is the function that is called if everything was loaded properly</span>
</span><span class=\"line\"><span class=\"nf\">nextThings</span> <span class=\"ow\">::</span> <span class=\"kt\">IO</span> <span class=\"nb\">()</span>
</span><span class=\"line\"><span class=\"nf\">nextThings</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>
</span><span class=\"line\">    <span class=\"c1\">-- turn the extfunc function into something that can be called by the Ruby interpreter</span>
</span><span class=\"line\">    <span class=\"n\">myfunc</span> <span class=\"ow\"><-</span> <span class=\"n\">mkRegistered2</span> <span class=\"n\">extfunc</span>
</span><span class=\"line\">    <span class=\"c1\">-- and bind it to the global 'hsfunction' function</span>
</span><span class=\"line\">    <span class=\"n\">rb_define_global_function</span> <span class=\"s\">\"hsfunction\"</span> <span class=\"n\">myfunc</span> <span class=\"mi\">1</span>
</span><span class=\"line\">    <span class=\"c1\">-- now call a method in the Ruby interpreter</span>
</span><span class=\"line\">    <span class=\"n\">o</span> <span class=\"ow\"><-</span> <span class=\"n\">safeMethodCall</span> <span class=\"s\">\"MyClass\"</span> <span class=\"s\">\"testfunc\"</span> <span class=\"kt\">[]</span>
</span><span class=\"line\">    <span class=\"kr\">case</span> <span class=\"n\">o</span> <span class=\"kr\">of</span>
</span><span class=\"line\">        <span class=\"kt\">Right</span> <span class=\"n\">v</span> <span class=\"ow\">-></span> <span class=\"p\">(</span><span class=\"n\">fromRuby</span> <span class=\"n\">v</span> <span class=\"ow\">::</span> <span class=\"kt\">IO</span> <span class=\"p\">(</span><span class=\"kt\">Maybe</span> <span class=\"kt\">Value</span><span class=\"p\">))</span> <span class=\"o\">>>=</span> <span class=\"n\">print</span>
</span><span class=\"line\">        <span class=\"kt\">Left</span> <span class=\"n\">r</span> <span class=\"ow\">-></span> <span class=\"n\">putStrLn</span> <span class=\"n\">r</span>
</span><span class=\"line\">
</span><span class=\"line\"><span class=\"nf\">main</span> <span class=\"ow\">::</span> <span class=\"kt\">IO</span> <span class=\"nb\">()</span>
</span><span class=\"line\"><span class=\"nf\">main</span> <span class=\"ow\">=</span> <span class=\"kr\">do</span>
</span><span class=\"line\">    <span class=\"c1\">-- initialize stuff</span>
</span><span class=\"line\">    <span class=\"n\">ruby_init</span>
</span><span class=\"line\">    <span class=\"n\">ruby_init_loadpath</span>
</span><span class=\"line\">    <span class=\"c1\">-- and load \"test.rb\"</span>
</span><span class=\"line\">    <span class=\"n\">s</span> <span class=\"ow\"><-</span> <span class=\"n\">rb_load_protect</span> <span class=\"s\">\"test.rb\"</span> <span class=\"mi\">0</span>
</span><span class=\"line\">    <span class=\"kr\">if</span> <span class=\"n\">s</span> <span class=\"o\">==</span> <span class=\"mi\">0</span>
</span><span class=\"line\">        <span class=\"kr\">then</span> <span class=\"n\">nextThings</span>
</span><span class=\"line\">        <span class=\"kr\">else</span> <span class=\"n\">showError</span> <span class=\"o\">>>=</span> <span class=\"n\">putStrLn</span>
</span></code></pre></td></tr></tbody></table></div></figure>
<p>And here is the ruby program, that calls our external function :</p>
<figure class=\"code\"><figcaption><span>test.rb </span></figcaption>
<div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
<span class=\"line-number\">2</span>
<span class=\"line-number\">3</span>
<span class=\"line-number\">4</span>
<span class=\"line-number\">5</span>
<span class=\"line-number\">6</span>
<span class=\"line-number\">7</span>
<span class=\"line-number\">8</span>
<span class=\"line-number\">9</span>
<span class=\"line-number\">10</span>
<span class=\"line-number\">11</span>
<span class=\"line-number\">12</span>
<span class=\"line-number\">13</span>
<span class=\"line-number\">14</span>
<span class=\"line-number\">15</span>
</pre></td><td class=\"code\"><pre><code class=\"rb\"><span class=\"line\"><span class=\"k\">class</span> <span class=\"nc\">MyClass</span>
</span><span class=\"line\">    <span class=\"k\">def</span> <span class=\"nc\">self</span><span class=\"o\">.</span><span class=\"nf\">testfunc</span>
</span><span class=\"line\">        <span class=\"n\">hsfunction</span><span class=\"p\">(</span> <span class=\"o\">[</span><span class=\"mi\">16588</span><span class=\"p\">,</span>
</span><span class=\"line\">                    <span class=\"s2\">\"qsqsd\"</span><span class=\"p\">,</span>
</span><span class=\"line\">                    <span class=\"kp\">true</span><span class=\"p\">,</span>
</span><span class=\"line\">                    <span class=\"p\">{</span> <span class=\"s1\">'a'</span> <span class=\"o\">=></span> <span class=\"s1\">'b'</span> <span class=\"p\">},</span>
</span><span class=\"line\">                    <span class=\"ss\">:symbol</span><span class=\"p\">,</span>
</span><span class=\"line\">                    <span class=\"mi\">0</span><span class=\"o\">.</span><span class=\"mi\">432</span><span class=\"p\">,</span>
</span><span class=\"line\">                    <span class=\"mi\">5611561561186918918918618789115616591891198189123165165889</span> <span class=\"o\">]</span>
</span><span class=\"line\">                <span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">each</span> <span class=\"k\">do</span> <span class=\"o\">|</span><span class=\"n\">k</span><span class=\"p\">,</span><span class=\"n\">v</span><span class=\"o\">|</span>
</span><span class=\"line\">            <span class=\"nb\">puts</span> <span class=\"s2\">\"</span><span class=\"si\">#{</span><span class=\"n\">k</span><span class=\"si\">}</span><span class=\"s2\"> => </span><span class=\"si\">#{</span><span class=\"n\">v</span><span class=\"si\">}</span><span class=\"s2\"> [</span><span class=\"si\">#{</span><span class=\"n\">v</span><span class=\"o\">.</span><span class=\"n\">class</span><span class=\"si\">}</span><span class=\"s2\">]\"</span>
</span><span class=\"line\">        <span class=\"k\">end</span>
</span><span class=\"line\">        <span class=\"mi\">12</span>
</span><span class=\"line\">    <span class=\"k\">end</span>
</span><span class=\"line\"><span class=\"k\">end</span>
</span></code></pre></td></tr></tbody></table></div></figure>
<p>And the output, showing that data is properly converted from either sides :</p>
<figure class=\"code\"><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
<span class=\"line-number\">2</span>
<span class=\"line-number\">3</span>
<span class=\"line-number\">4</span>
<span class=\"line-number\">5</span>
<span class=\"line-number\">6</span>
<span class=\"line-number\">7</span>
<span class=\"line-number\">8</span>
<span class=\"line-number\">9</span>
<span class=\"line-number\">10</span>
<span class=\"line-number\">11</span>
</pre></td><td class=\"code\"><pre><code class=\"\"><span class=\"line\">Just (Array (fromList [Number 16588,String \"qsqsd\",Bool True,Object fromList [(\"a\",String \"b\")],String \"symbol\",Number 0.432,Number 5611561561186918918918618789115616591891198189123165165889]))
</span><span class=\"line\">bigint => 16518656116889898998656112323135664684684 [Bignum]
</span><span class=\"line\">int => 12 [Fixnum]
</span><span class=\"line\">double => 0.123 [Float]
</span><span class=\"line\">array => 12345 [Array]
</span><span class=\"line\">true => true [TrueClass]
</span><span class=\"line\">null => Null [String]
</span><span class=\"line\">string => string [String]
</span><span class=\"line\">object => kv [Hash]
</span><span class=\"line\">false => false [FalseClass]
</span><span class=\"line\">Just (Number 12)</span></code></pre></td></tr></tbody></table></div></figure>
<p>EDIT: added link to the code.</p>" nil nil "7130ea6f5da7abbbc77587284be6f1b7") (8 (20928 8813 497288) "http://kpreid.livejournal.com/50670.html" "Kevin Reid (kpreid): Game idea: reverse bullet hell" "kpreid@switchb.org (Kevin Reid (kpreid))" "Mon, 20 May 2013 04:56:02 +0000" "<p>I have come to realize that I have more ideas for programs than I'll ever have time to write. (This means they're not actually all that significant, on average — see all that's been said on ‘ideas vs. execution’.) But maybe I have the time to scribble a blog post about them, and that's stuff to blog about, if nothing else.
</p><p>So, a video game idea I had today: reverse bullet-hell shooter.
</p><p>A regular bullet-hell shooter is a game where you move in a 2D space dodging an immense number of mostly dumb instant-death projectiles launched in mostly predefined patterns, and trying to shoot back with dinkier, but better aimed, weapons. Instead, here you design the bullet pattern so as to trap and kill AI enemies doing the dodging.
</p><p>The roles seem a bit similar to tower defense, but the space of strategies would be considerably more, ah, bumpy, since you're not doing a little bit of damage at a time and how it plays out depends strongly on the AI's choices.
</p><p>That's probably the downfall of this idea: either the outcome is basically <a href=\"http://en.wikipedia.org/wiki/Butterfly_effect\" rel=\"nofollow\">butterfly effect</a> random due to enemy AI decisions and you mostly lose, or there are trivial ways to design undodgeable bullet patterns and you mostly win. I don't immediately see how to make the space of inputs and outcomes “smooth” enough.</p>" nil nil "11701305a123b249a6fc8546bb29841b") (7 (20928 8813 496668) "http://feedproxy.google.com/~r/ezyang/~3/nmmQFXNcDMg/" "Edward Z. Yang: Anatomy of an MVar operation" nil "Mon, 20 May 2013 00:00:37 +0000" "<div class=\"document\">
<p>Adam Belay (of <a href=\"http://dune.scs.stanford.edu/\" class=\"reference external\">Dune</a> fame) was recently wondering why Haskell’s MVars are so slow. “Slow?” I thought, “aren’t Haskell’s MVars supposed to be really fast?” So I did some digging around how MVars worked, to see if I could explain.</p>
<p>Let’s consider the operation of the function <tt class=\"docutils literal\">takeMVar</tt> in <a href=\"http://hackage.haskell.org/packages/archive/base/latest/doc/html/Control-Concurrent-MVar.html#v:takeMVar\" class=\"reference external\">Control.Concurrent.MVar</a>.  This function is very simple, it unpacks <tt class=\"docutils literal\">MVar</tt> to get the underlying <tt class=\"docutils literal\">MVar#</tt> primitive value, and then calls the primop <tt class=\"docutils literal\">takeMVar#</tt>:</p>
<pre class=\"literal-block\">takeMVar :: MVar a -> IO a
takeMVar (MVar mvar#) = IO $ \\ s# -> takeMVar# mvar# s#
</pre>
<p><a href=\"http://hackage.haskell.org/trac/ghc/wiki/Commentary/PrimOps\" class=\"reference external\">Primops</a> result in the invocation of <tt class=\"docutils literal\">stg_takeMVarzh</tt> in <tt class=\"docutils literal\">PrimOps.cmm</tt>, which is where the magic happens. For simplicity, we consider only the <em>multithreaded</em> case.</p>
<p>The first step is to <strong>lock the closure</strong>:</p>
<pre class=\"literal-block\">(\"ptr\" info) = ccall lockClosure(mvar \"ptr\");
</pre>
<p>Objects on the GHC heap have an <em>info table header</em> which indicates what kind of object they are, by pointing to the relevant info table for the object.  These headers are <em>also</em> used for synchronization: since they are word-sized, they can be atomically swapped for other values. <tt class=\"docutils literal\">lockClosure</tt> is in fact a spin-lock on the info table header:</p>
<pre class=\"literal-block\">EXTERN_INLINE StgInfoTable *lockClosure(StgClosure *p)
{
StgWord info;
do {
nat i = 0;
do {
info = xchg((P_)(void *)&p->header.info, (W_)&stg_WHITEHOLE_info);
if (info != (W_)&stg_WHITEHOLE_info) return (StgInfoTable *)info;
} while (++i < SPIN_COUNT);
yieldThread();
} while (1);
}
</pre>
<p><tt class=\"docutils literal\">lockClosure</tt> is used for some other objects, namely thread state objects (<tt class=\"docutils literal\">stg_TSO_info</tt>, via <tt class=\"docutils literal\">lockTSO</tt>) and thread messages i.e. exceptions (<tt class=\"docutils literal\">stg_MSG_THROWTO_info</tt>, <tt class=\"docutils literal\">stg_MSG_NULL_info</tt>).</p>
<p>The next step is to <strong>apply a GC write barrier on the MVar</strong>:</p>
<pre class=\"literal-block\">if (info == stg_MVAR_CLEAN_info) {
ccall dirty_MVAR(BaseReg \"ptr\", mvar \"ptr\");
}
</pre>
<p>As I’ve <a href=\"http://blog.ezyang.com/2013/01/the-ghc-scheduler/\" class=\"reference external\">written before</a>, as the MVar is a mutable object, it can be mutated to point to objects in generation 0; thus, when a mutation happens, it has to be added to the root set via the mutable list. Since mutable is per capability, this boils down into a bunch of pointer modifications, and does not require any synchronizations. Note that we will need to add the MVar to the mutable list, <em>even</em> if we end up blocking on it, because the MVar is a retainer of the <em>thread</em> (TSO) which is blocked on it! (However, I suspect in some cases we can get away with not doing this.)</p>
<p>Next, we case split depending on whether or not the MVar is full or empty.  If the MVar is empty, we need to <strong>block the thread until the MVar is full</strong>:</p>
<pre class=\"literal-block\">/* If the MVar is empty, put ourselves on its blocking queue,
* and wait until we're woken up.
*/
if (StgMVar_value(mvar) == stg_END_TSO_QUEUE_closure) {
// We want to put the heap check down here in the slow path,
// but be careful to unlock the closure before returning to
// the RTS if the check fails.
ALLOC_PRIM_WITH_CUSTOM_FAILURE
(SIZEOF_StgMVarTSOQueue,
unlockClosure(mvar, stg_MVAR_DIRTY_info);
GC_PRIM_P(stg_takeMVarzh, mvar));
q = Hp - SIZEOF_StgMVarTSOQueue + WDS(1);
SET_HDR(q, stg_MVAR_TSO_QUEUE_info, CCS_SYSTEM);
StgMVarTSOQueue_link(q) = END_TSO_QUEUE;
StgMVarTSOQueue_tso(q)  = CurrentTSO;
if (StgMVar_head(mvar) == stg_END_TSO_QUEUE_closure) {
StgMVar_head(mvar) = q;
} else {
StgMVarTSOQueue_link(StgMVar_tail(mvar)) = q;
ccall recordClosureMutated(MyCapability() \"ptr\",
StgMVar_tail(mvar));
}
StgTSO__link(CurrentTSO)       = q;
StgTSO_block_info(CurrentTSO)  = mvar;
StgTSO_why_blocked(CurrentTSO) = BlockedOnMVar::I16;
StgMVar_tail(mvar)             = q;
jump stg_block_takemvar(mvar);
}
</pre>
<p>A useful thing to know when decoding C-- primop code is that <tt class=\"docutils literal\"><span class=\"pre\">StgTSO_block_info(...)</span></tt> and its kin are how we spell field access on objects. C-- doesn’t know anything about C struct layout, and so these “functions” are actually macros generated by <tt class=\"docutils literal\">utils/deriveConstants</tt>. Blocking a thread consists of three steps:</p>
<ol class=\"arabic simple\">
<li>We have to add the thread to the blocked queue attached to the MVar (that’s why blocking on an MVar mutates the MVar!) This involves performing a heap allocation for the linked list node as well as mutating the tail of the old linked list.</li>
<li>We have to mark the thread as blocked (the <tt class=\"docutils literal\">StgTSO</tt> modifications).</li>
<li>We need to setup a stack frame for the thread so that when the thread wakes up, it performs the correct action (the invocation to <tt class=\"docutils literal\">stg_block_takemvar</tt>). This invocation is also responsible for unlocking the closure. While the machinery here is pretty intricate, it’s not really in scope for this blog post.</li>
</ol>
<p>If the MVar is full, then we can go ahead and <strong>take the value from the MVar.</strong></p>
<pre class=\"literal-block\">/* we got the value... */
val = StgMVar_value(mvar);
</pre>
<p>But that’s not all. If there are other blocked <tt class=\"docutils literal\">putMVars</tt> on the MVar (remember, when a thread attempts to put an MVar that is already full, it blocks until the MVar empties out), then we should immediately unblock one of these threads so that the MVar can always be left in a full state:</p>
<pre class=\"literal-block\">    q = StgMVar_head(mvar);
loop:
if (q == stg_END_TSO_QUEUE_closure) {
/* No further putMVars, MVar is now empty */
StgMVar_value(mvar) = stg_END_TSO_QUEUE_closure;
unlockClosure(mvar, stg_MVAR_DIRTY_info);
return (val);
}
if (StgHeader_info(q) == stg_IND_info ||
StgHeader_info(q) == stg_MSG_NULL_info) {
q = StgInd_indirectee(q);
goto loop;
}
</pre>
<p>There is one interesting thing about the code that checks for blocked threads, and that is the check for <em>indirectees</em> (<tt class=\"docutils literal\">stg_IND_info</tt>). Under what circumstances would a queue object be stubbed out with an indirection? As it turns out, this occurs when we <em>delete</em> an item from the linked list. This is quite nice, because on a singly-linked list, we don't have an easy way to delete items unless we also have a pointer to the previous item. With this scheme, we just overwrite out the current item with an indirection, to be cleaned up next GC. (This, by the way, is why we can't just chain up the TSOs directly, without the extra linked list nodes. [1])</p>
<p>When we find some other threads, we immediately run them, so that the MVar never becomes empty:</p>
<pre class=\"literal-block\">// There are putMVar(s) waiting... wake up the first thread on the queue
tso = StgMVarTSOQueue_tso(q);
StgMVar_head(mvar) = StgMVarTSOQueue_link(q);
if (StgMVar_head(mvar) == stg_END_TSO_QUEUE_closure) {
StgMVar_tail(mvar) = stg_END_TSO_QUEUE_closure;
}
ASSERT(StgTSO_why_blocked(tso) == BlockedOnMVar::I16); // note: I16 means this is a 16-bit integer
ASSERT(StgTSO_block_info(tso) == mvar);
// actually perform the putMVar for the thread that we just woke up
W_ stack;
stack = StgTSO_stackobj(tso);
PerformPut(stack, StgMVar_value(mvar));
</pre>
<p>There is one detail here: <tt class=\"docutils literal\">PerformPut</tt> doesn’t actually run the thread, it just looks at the thread’s stack to figure out what it was <em>going</em> to put. Once the MVar is put, we then wake up the thread, so it can go on its merry way:</p>
<pre class=\"literal-block\">// indicate that the MVar operation has now completed.
StgTSO__link(tso) = stg_END_TSO_QUEUE_closure;
// no need to mark the TSO dirty, we have only written END_TSO_QUEUE.
ccall tryWakeupThread(MyCapability() \"ptr\", tso);
unlockClosure(mvar, stg_MVAR_DIRTY_info);
return (val);
</pre>
<p>To sum up, when you <tt class=\"docutils literal\">takeMVar</tt>, you pay the costs of:</p>
<ul class=\"simple\">
<li>one spinlock,</li>
<li>on order of several dozen memory operations (write barriers, queue twiddling), and</li>
<li>when the MVar is empty, a (small) heap allocation and stack write.</li>
</ul>
<p>Adam and I puzzled about this a bit, and then realized the reason why the number of cycles was so large: our numbers are for <em>roundtrips</em>, and even with such lightweight synchronization (and lack of syscalls), you still have to go through the scheduler when all is said and done, and that blows up the number of cycles.</p>
<hr class=\"docutils\" />
<p>[1] It wasn’t always this way, see:</p>
<pre class=\"literal-block\">commit f4692220c7cbdadaa633f50eb2b30b59edb30183
Author: Simon Marlow <marlowsd@gmail.com>
Date:   Thu Apr 1 09:16:05 2010 +0000
Change the representation of the MVar blocked queue
The list of threads blocked on an MVar is now represented as a list of
separately allocated objects rather than being linked through the TSOs
themselves.  This lets us remove a TSO from the list in O(1) time
rather than O(n) time, by marking the list object.  Removing this
linear component fixes some pathalogical performance cases where many
threads were blocked on an MVar and became unreachable simultaneously
(nofib/smp/threads007), or when sending an asynchronous exception to a
TSO in a long list of thread blocked on an MVar.
MVar performance has actually improved by a few percent as a result of
this change, slightly to my surprise.
This is the final cleanup in the sequence, which let me remove the old
way of waking up threads (unblockOne(), MSG_WAKEUP) in favour of the
new way (tryWakeupThread and MSG_TRY_WAKEUP, which is idempotent).  It
is now the case that only the Capability that owns a TSO may modify
its state (well, almost), and this simplifies various things.  More of
the RTS is based on message-passing between Capabilities now.
</pre>
</div>
<img src=\"http://feeds.feedburner.com/~r/ezyang/~4/nmmQFXNcDMg\" height=\"1\" width=\"1\" />" nil nil "8f0b4d503e1a9c605ef081b47152f27e") (6 (20928 8813 494510) "http://alessandrovermeulen.me/2013/05/19/why-you-should-switch-to-declarative-programming/" "Alessandro Vermeulen: Why you should switch to declarative programming" nil "Sun, 19 May 2013 10:52:00 +0000" "<p>We are reaching limits of what is feasible with imperative languages and we should move to declarative languages. </p>
<p>When applications written in imperative languages grow, the code becomes convoluted. Why? Imperatively programmed applications contain statements such as <code>if X do Y else do Z</code>. As <code>Y</code> and <code>Z</code> contain <em>invisible</em> side-effects the correctness of the program relies on some implicit invariant. This invariant has to be maintained by the programmer or else the code will break. Thus each time a new feature is added to an application or a bug is fixed the code for the application gets more complex as keeping the invariant intact becomes harder. After a while the code becomes spaghetti-code and bugs are introduced as the programmer fails to maintain the invariant. This is going to happen despite the best intentions of the programmer to keep things clean. Why is this? </p>
<p>An imperative language is a type of language that tells the computer what to do and in which order. However, most, if not all, applications are nothing but a translation of some business domain into a computer program. In order to get the imperative code the programmer has to translate the business model to a set of imperative instructions, the business logic. The imperative instructions bear little resemblance to the original description of the business model. When the business model changes the imperative counterpart could change entirely but what happens is that programmers make incremental updates to the code. This is done because either they do not see that a more drastic change is necessary or because they are under pressure to deliver results. Over time this leads to bugs and unmaintainable code. Summarized, bugs are introduced because there is a manual translation step between the business model and the program code.</p>
<p>Imagine a system for calculating whether a person should receive a certain allowance. To receive the allowance a person has to meet several criteria such as <code>age > 18 and income < 2400</code>. We can denote this in the following way:</p>
<div class=\"bogus-wrapper\"><notextile><figure class=\"code\"><figcaption><span></span></figcaption><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
<span class=\"line-number\">2</span>
<span class=\"line-number\">3</span>
</pre></td><td class=\"code\"><pre><code class=\"ruby\"><span class=\"line\"><span class=\"k\">def</span> <span class=\"nf\">receives_allowance?</span><span class=\"p\">(</span><span class=\"n\">age</span><span class=\"p\">,</span> <span class=\"n\">income</span><span class=\"p\">)</span>
</span><span class=\"line\">  <span class=\"n\">age</span> <span class=\"o\">></span> <span class=\"mi\">18</span> <span class=\"o\">&&</span> <span class=\"n\">income</span> <span class=\"o\"><</span> <span class=\"mi\">2400</span>
</span><span class=\"line\"><span class=\"k\">end</span>
</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>There are several remarks to be made for this code. Adding a criteria such as marital status would involve adding a parameter to the function and changing the boolean expression. We could already avoid having to change parameters when we had chosen a parameter of type Person that contains the information about a person. But what if we would introduce time as an aspect in our criteria? We need to change the function again. And what if the age criteria changed? If the programmer erroneously codes something like <code>age > 18 && age < 18</code> into the condition we would only find the bug during testing, if we are lucky. Additionally when our criteria become more complex we would like to extract criteria to their own functions. In short, it is easy to make mistakes this way.</p>
<p>A solution to this is to avoid the translation process by using a declarative language. A declarative language is a language that describes <em>what</em> is to be computed but not <em>how</em> it should be computed.<sup id=\"fnref:declarativereference\"><a href=\"http://alessandrovermeulen.me/atom.xml#fn:declarativereference\" rel=\"footnote\">1</a></sup> In essence: it omits control-flow. By encoding and thereby recording the business model into a set of declarative statements it becomes easier to spot irregularities in the business logic as the business logic reads more like the description of the business model and all invariants are <em>visible</em>. In this manner the programmer no longer tells the computer how to perform a computation but rather what the computation should be. This makes it easier to maintain </p>
<p>However, we take it even to an higher level entirely. By just using the declarative language, such as Haskell or Prolog, you are still using a general-purpose language and are thus lacking domain specific checks. It would be advantageous to devise a Domain Specific Language (DSL) instead. This would be a language specifically geared towards your business domain and can be done easily in a language such as Haskell. Creating a DSL has a great benefit: Because the business domain is written down in code the responsibility of translating the business domain into a program shifts from the programmer to the interpreter of the DSL. This has two benefits: the translation is consolidated in one single point (the interpreter) and can be verified or even proven to be correct. It could be checked that no contradicting statements are present. In this sense we can compare the validation to a spell-checker or JSLint but for our specific domain. Secondly the programmer cannot make mistakes in the translation of the business logic to imperative code.</p>
<p>A simple DSL embedding the idea of the allowance could look like the text in the examples below. The interpreter / compiler is able to inspect the separate rules and check whether they would cause a tautology or contradiction.</p>
<p>We will illustrate this with some examples. Consider the following text below, it is easy to read and it is clear what it means. Each line is a condition that has to hold, so we could read an “AND” at eacht line end. <small>(Whether Income is monthly or annually or weekly is not taken into account here but you get the picture.)</small></p>
<div class=\"bogus-wrapper\"><notextile><figure class=\"code\"><figcaption><span></span></figcaption><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
<span class=\"line-number\">2</span>
<span class=\"line-number\">3</span>
<span class=\"line-number\">4</span>
<span class=\"line-number\">5</span>
</pre></td><td class=\"code\"><pre><code class=\"ruby\"><span class=\"line\"><span class=\"n\">A</span> <span class=\"n\">person</span> <span class=\"n\">is</span> <span class=\"n\">an</span> <span class=\"n\">adult</span> <span class=\"k\">when</span> <span class=\"n\">his</span> <span class=\"no\">Age</span> <span class=\"n\">is</span> <span class=\"no\">GREATER</span> <span class=\"no\">THAN</span> <span class=\"no\">OR</span> <span class=\"no\">EQUAL</span> <span class=\"no\">TO</span> <span class=\"mi\">18</span>
</span><span class=\"line\"><span class=\"n\">A</span> <span class=\"n\">person</span> <span class=\"n\">is</span> <span class=\"n\">allegeable</span> <span class=\"k\">for</span> <span class=\"n\">an</span> <span class=\"n\">allowance</span> <span class=\"no\">IF</span>
</span><span class=\"line\">  <span class=\"n\">he</span> <span class=\"n\">is</span> <span class=\"n\">an</span> <span class=\"n\">adult</span>
</span><span class=\"line\"><span class=\"n\">A</span> <span class=\"n\">person</span> <span class=\"n\">is</span> <span class=\"n\">allegeable</span> <span class=\"k\">for</span> <span class=\"n\">an</span> <span class=\"n\">allowance</span> <span class=\"no\">IF</span>
</span><span class=\"line\">  <span class=\"n\">his</span> <span class=\"no\">Income</span> <span class=\"n\">is</span> <span class=\"no\">NOT</span> <span class=\"no\">GREATER</span> <span class=\"no\">THAN</span> <span class=\"err\">€</span><span class=\"mi\">2400</span>
</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>When we would add a rule as shown below, we could get a warning or error from the interpreter telling us that we have two different conditions on a person’s age.</p>
<div class=\"bogus-wrapper\"><notextile><figure class=\"code\"><figcaption><span></span></figcaption><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
<span class=\"line-number\">2</span>
<span class=\"line-number\">3</span>
<span class=\"line-number\">4</span>
<span class=\"line-number\">5</span>
<span class=\"line-number\">6</span>
<span class=\"line-number\">7</span>
</pre></td><td class=\"code\"><pre><code class=\"ruby\"><span class=\"line\"><span class=\"n\">A</span> <span class=\"n\">person</span> <span class=\"n\">is</span> <span class=\"n\">an</span> <span class=\"n\">adult</span> <span class=\"k\">when</span> <span class=\"n\">his</span> <span class=\"no\">Age</span> <span class=\"n\">is</span> <span class=\"no\">GREATER</span> <span class=\"no\">THAN</span> <span class=\"no\">OR</span> <span class=\"no\">EQUAL</span> <span class=\"no\">TO</span> <span class=\"mi\">18</span>
</span><span class=\"line\"><span class=\"n\">A</span> <span class=\"n\">person</span> <span class=\"n\">is</span> <span class=\"n\">allegeable</span> <span class=\"k\">for</span> <span class=\"n\">an</span> <span class=\"n\">allowance</span> <span class=\"no\">IF</span>
</span><span class=\"line\">  <span class=\"n\">he</span> <span class=\"n\">is</span> <span class=\"n\">an</span> <span class=\"n\">adult</span>
</span><span class=\"line\"><span class=\"n\">A</span> <span class=\"n\">person</span> <span class=\"n\">is</span> <span class=\"n\">allegeable</span> <span class=\"k\">for</span> <span class=\"n\">an</span> <span class=\"n\">allowance</span> <span class=\"no\">IF</span>
</span><span class=\"line\">  <span class=\"n\">his</span> <span class=\"no\">Income</span> <span class=\"n\">is</span> <span class=\"no\">NOT</span> <span class=\"no\">GREATER</span> <span class=\"no\">THAN</span> <span class=\"err\">€</span><span class=\"mi\">2400</span>
</span><span class=\"line\"><span class=\"n\">A</span> <span class=\"n\">person</span> <span class=\"n\">is</span> <span class=\"n\">allegeable</span> <span class=\"k\">for</span> <span class=\"n\">an</span> <span class=\"n\">allowance</span> <span class=\"no\">IF</span>
</span><span class=\"line\">  <span class=\"n\">his</span> <span class=\"no\">Age</span> <span class=\"n\">is</span> <span class=\"no\">GREATER</span> <span class=\"no\">THAN</span> <span class=\"mi\">21</span>
</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>And when we would add a rule as this it could warn us that no-one will ever get an allowance.</p>
<div class=\"bogus-wrapper\"><notextile><figure class=\"code\"><figcaption><span></span></figcaption><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
<span class=\"line-number\">2</span>
<span class=\"line-number\">3</span>
<span class=\"line-number\">4</span>
<span class=\"line-number\">5</span>
<span class=\"line-number\">6</span>
<span class=\"line-number\">7</span>
</pre></td><td class=\"code\"><pre><code class=\"ruby\"><span class=\"line\"><span class=\"n\">A</span> <span class=\"n\">person</span> <span class=\"n\">is</span> <span class=\"n\">an</span> <span class=\"n\">adult</span> <span class=\"k\">when</span> <span class=\"n\">his</span> <span class=\"no\">Age</span> <span class=\"n\">is</span> <span class=\"no\">GREATER</span> <span class=\"no\">THAN</span> <span class=\"no\">OR</span> <span class=\"no\">EQUAL</span> <span class=\"no\">TO</span> <span class=\"mi\">18</span>
</span><span class=\"line\"><span class=\"n\">A</span> <span class=\"n\">person</span> <span class=\"n\">is</span> <span class=\"n\">allegeable</span> <span class=\"k\">for</span> <span class=\"n\">an</span> <span class=\"n\">allowance</span> <span class=\"no\">IF</span>
</span><span class=\"line\">  <span class=\"n\">he</span> <span class=\"n\">is</span> <span class=\"n\">an</span> <span class=\"n\">adult</span>
</span><span class=\"line\"><span class=\"n\">A</span> <span class=\"n\">person</span> <span class=\"n\">is</span> <span class=\"n\">allegeable</span> <span class=\"k\">for</span> <span class=\"n\">an</span> <span class=\"n\">allowance</span> <span class=\"no\">IF</span>
</span><span class=\"line\">  <span class=\"n\">his</span> <span class=\"no\">Income</span> <span class=\"n\">is</span> <span class=\"no\">NOT</span> <span class=\"no\">GREATER</span> <span class=\"no\">THAN</span> <span class=\"err\">€</span><span class=\"mi\">2400</span>
</span><span class=\"line\"><span class=\"n\">A</span> <span class=\"n\">person</span> <span class=\"n\">is</span> <span class=\"n\">allegeable</span> <span class=\"k\">for</span> <span class=\"n\">an</span> <span class=\"n\">allowance</span> <span class=\"no\">IF</span>
</span><span class=\"line\">  <span class=\"n\">his</span> <span class=\"no\">Age</span> <span class=\"n\">is</span> <span class=\"no\">LESS</span> <span class=\"no\">THAN</span> <span class=\"mi\">12</span>
</span></code></pre></td></tr></tbody></table></div></figure></notextile></div>
<p>Not only would the interpreter be able to spot these kinds of errors but it would also be easier for the writer of these rules to spot whether there is a mistake.
The astute reader will have noticed than we have not included any control flow into our language making it a declarative language.</p>
<p>Because the business-logic is now represented by the DSL it can be written by domain experts instead of the programmers of the application itself. The compiler can provide feedback when something is wrong in the DSL and there is less chance for errors in the implementation of the business logic. Additionally this frees the programmes for implementing better translations of the DSL or other projects saving time and other resources. </p>
<p>To summarise 4 reasons why you should switch to declarative languages:</p>
<ol>
<li>Direct translation of the business model into business logic </li>
<li>Better readability of the business logic</li>
<li>Better scalability for the program in terms of functionality</li>
<li>Less bugs</li>
</ol>
<p>And 3 reasons why you should use DSLs to boot:</p>
<ol>
<li>Free up programmers to do important stuff</li>
<li>Let the domain-experts handle the business logic and have it machine-checked!</li>
<li>It is just awesome</li>
</ol>
<div class=\"footnotes\">
<ol>
<li id=\"fn:declarativereference\">
<p><a href=\"ftp://clip.dia.fi.upm.es/pub/papers/PARFORCE/second_review/D.WP3.1.M2.3.ps.Z\">Lloyd, J.W., Practical Advantages of Declarative Programming</a><a href=\"http://alessandrovermeulen.me/atom.xml#fnref:declarativereference\" rev=\"footnote\">↩</a></p>
</li>
</ol>
</div>" nil nil "5d7cdbe4cd6717e1f50bf1e84f98bf9f") (5 (20928 8813 492238) "http://lpuppet.banquise.net/blog/2013/05/16/language-puppet-v0-dot-4-0/" "language-puppet: language-puppet v0.4.0" nil "Thu, 16 May 2013 18:32:00 +0000" "<p>I just released the latest language-puppet version. For the full list of changes, please take a look at the
<a href=\"https://github.com/bartavelle/language-puppet/blob/master/Changelog\">changelog</a>. Here are the highlights.</p>
<h3>PuppetDB code reworked</h3>
<p>The PuppetDB code and API has been completely overhauled. It is now more generic : the resource collection and puppet
query functions now work the same. Additionally, a PuppetDB stub has been created for testing use.</p>
<h3>Better diagnostic facilities</h3>
<p>As the main use of this library is to test stuff, the following features were added:</p>
<ul>
<li>Several error messages have been reworked so that they are more informative.</li>
<li>A <code>dumpvariables</code> built-in function has been added. It just prints all known variables (and facts) to stdout, and can
be quite handy.</li>
<li>The “scope stack” description is stored with the resources. This turned out to be extremely useful when debugging
resource names colisions or to find out where some resource is defined.</li>
</ul>
<p>Here is an example, let’s say you do not remember which package installs the <code>collectd</code> package. Just run this :</p>
<figure class=\"code\"><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
<span class=\"line-number\">2</span>
<span class=\"line-number\">3</span>
<span class=\"line-number\">4</span>
<span class=\"line-number\">5</span>
<span class=\"line-number\">6</span>
<span class=\"line-number\">7</span>
</pre></td><td class=\"code\"><pre><code class=\"\"><span class=\"line\">» puppetresources . default.domain 'Package[collectd]'
</span><span class=\"line\">
</span><span class=\"line\">package {
</span><span class=\"line\">    \"collectd\": #\"./modules/collectd/manifests/base.pp\" (line 4, column 9) [\"::\",\"site::baseconfig\",\"collectd\",\"collectd::client\",\"collectd::base\"]
</span><span class=\"line\">        ensure          => \"installed\",
</span><span class=\"line\">        require         => [Class[\"collectd\"], Class[\"collectd::base\"], Class[\"collectd::client\"], Class[\"site::baseconfig\"]];
</span><span class=\"line\">}</span></code></pre></td></tr></tbody></table></div></figure>
<p>You now know exactly where the <code>package</code> resource is declared, and the list of “scopes” that have been traversed in
order to do so. Note that this information is displayed when resources names collide.</p>
<h3>Easier to setup</h3>
<p>This library doesn’t depend from a newish <code>bytestring</code> anymore, and should build with the package provided with a GHC
compiler of the 7.6.x serie.</p>
<p>This is not yet done, but I will certainly soon publish a debian-style repository of the compiled <code>puppetresources</code> binary. I am interested in suggestions for an automated building system.</p>
<h3>Better testing</h3>
<p>The testing API seems sufficient to write pretty strong tests, but would still benefit from a few more helper functions.
The testing “daemon” has been reworked to use the new PuppetDB stub. It makes it possible to test complex interactions
between hosts using the exported resource or PuppetDB query features.</p>
<h3>Work in progress</h3>
<p>I will probably <a href=\"http://hackage.haskell.org/package/lens\">lensify</a> the code until I get a descent understanding of it.</p>
<p>I do not intend to work on Hiera emulation just yet, as I am probably the only user of this library for now and I do not
use this feature.</p>
<p>One area of improvement would be to embed the ruby interpreter in the library. I am not sure how to do this, but as
there are quite a few projects of lightweight interpreters sprouting from the earth, it might be possible in the near
future. The only problem would be figuring out how to build a large C project with cabal.</p>
<h3>Some other considerations</h3>
<p>I recently ported the code from <code>random.c</code> to Haskell
(<a href=\"https://github.com/bartavelle/language-puppet/blob/master/Puppet/Interpreter/RubyRandom.hs\">here</a>). This has been
quite tedious, and is quite hard to read. This is an almost naive port of the code found in the Ruby interpreter,
without the useless loop variables. For some reason, there are many loops like this :</p>
<figure class=\"code\"><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
<span class=\"line-number\">2</span>
<span class=\"line-number\">3</span>
<span class=\"line-number\">4</span>
<span class=\"line-number\">5</span>
<span class=\"line-number\">6</span>
<span class=\"line-number\">7</span>
<span class=\"line-number\">8</span>
<span class=\"line-number\">9</span>
<span class=\"line-number\">10</span>
</pre></td><td class=\"code\"><pre><code class=\"\"><span class=\"line\">i=1; j=0;
</span><span class=\"line\">k = (N>key_length ? N : key_length);
</span><span class=\"line\">for (; k; k--) {
</span><span class=\"line\">    mt->state[i] = (mt->state[i] ^ ((mt->state[i-1] ^ (mt->state[i-1] >> 30)) * 1664525U))
</span><span class=\"line\">        + init_key[j] + j; /* non linear */
</span><span class=\"line\">    mt->state[i] &= 0xffffffffU; /* for WORDSIZE > 32 machines */
</span><span class=\"line\">    i++; j++;
</span><span class=\"line\">    if (i>=N) { mt->state[0] = mt->state[N-1]; i=1; }
</span><span class=\"line\">    if (j>=key_length) j=0;
</span><span class=\"line\">}</span></code></pre></td></tr></tbody></table></div></figure>
<p>As you can see, the value of k is never used in the loop. I am not sure why the author didn’t go for something like :</p>
<figure class=\"code\"><div class=\"highlight\"><table><tbody><tr><td class=\"gutter\"><pre class=\"line-numbers\"><span class=\"line-number\">1</span>
</pre></td><td class=\"code\"><pre><code class=\"\"><span class=\"line\">for(i=1;i<k;i++) {</span></code></pre></td></tr></tbody></table></div></figure>
<p>Anyway, the Haskell code is pretty bad, and will certainly only work for 64-bit builds. I am not sure how I should have
written it. I suppose staying in the ST monad would have lead to nicer code, and I am open to suggestions.</p>" nil nil "bab8597b76f29cf825ac29a0b13a9614") (4 (20928 8813 491049) "http://wadler.blogspot.com/2013/05/from-session-types-to-data-types-ra.html" "Philip Wadler: From Session Types to Data Types: RA posts and PhD studentships" "noreply@blogger.com (Philip Wadler)" "Thu, 16 May 2013 13:39:54 +0000" "<div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://2.bp.blogspot.com/-nZkF32umhTc/UZTeDERPduI/AAAAAAAABi4/Ybi1BefzLhw/s1600/Screenshot-1.png\"><img src=\"http://2.bp.blogspot.com/-nZkF32umhTc/UZTeDERPduI/AAAAAAAABi4/Ybi1BefzLhw/s320/Screenshot-1.png\" height=\"160\" border=\"0\" width=\"320\" /></a></div>I've posted this elsewhere, but neglected to blog before now. <br /><br />We are recruiting for research associate positions in design and implementation of  programming languages, and also may have PhD studentships available this year and next.  The posts are on the project \"From <span class=\"il\">Data</span> <span class=\"il\">Types</span> to  <span class=\"il\">Session</span> <span class=\"il\">Types</span>: A Basis for Concurrency and Distribution\" which is a  programme grant funded by EPSRC for five years from 20 May 2013, joint with Simon Gay at the University of Glasgow and Nobuko Yoshida at Imperial College London.<br /><br />The RA post at Edinburgh for an initial period of 24 months, with  possibility of extension, and is on the UE07 scale (£30,424 - £36,298). Deadline for applications for the RA post is Monday 20 May 2013, anyone interested in a PhD studentship should apply as soon as possible.  Glasgow and Imperial are also recruiting.<br /><br />Please contact me if you are interested in either the RA post or a PhD studentship.  Further description of the Edinburgh RA post is below. <br /><div class=\"yj6qo ajU\"><div tabindex=\"0\" id=\":4y\" class=\"ajR\"><img src=\"https://mail.google.com/mail/u/0/images/cleardot.gif\" class=\"ajT\" /></div></div><br /><br /><br />   <b>Project Description</b><br /><br />Just as <span class=\"il\">data</span> <span class=\"il\">types</span> describe the structure of <span class=\"il\">data</span>, <span class=\"il\">session</span> <span class=\"il\">types</span> describe the structure of communication between concurrent and  distributed processes. Our project has particular emphasis on putting  theory into practice, by embedding <span class=\"il\">session</span> <span class=\"il\">types</span> in a range of programming languages and applying them to realistic case  studies. The research programme is joint between the University of  Edinburgh, University of Glasgow, and Imperial College London, and  includes collaboration with Amazon, Cognizant, Red Hat, VMware, and the  Ocean Observatories Initiative.<br /><br /><b>Principal Duties</b><br /><br />The successful candidate will join a team responsible for extending  the functional web programming language Links with <span class=\"il\">session</span> <span class=\"il\">types</span> to  support concurrency and distribution.  We will test our techniques by  providing a library to access Amazon Web Services (AWS) cloud computing  infrastructure, and perform empirical experiments to assess how our  language design impacts the performance of programmers. <br /><br />You should possess a PhD in a relevant area, or be nearing  completion of same, or have comparable experience.  You should have a  track-record of publication, or other evidence of ability to undertake  research and communicate well.  You should have a strong background in  programming languages, including <span class=\"il\">type</span> systems, and strong programming  and software engineering skills. <br /><br />It is desirable for candidates to also have one or more of the  following: a combination of theoretical and practical skills; experience  of web programming or cloud programming; knowledge of the theory or  practice of concurrent and distributed systems; knowledge of linear  logic; or training in empirical measurement of programming tasks. <br /><br />We seek applicants at an international level of excellence.  The  Laboratory for Foundations of Computer Science is internationally  renowned, the School of Informatics at Edinburgh is among the strongest  in the world, and Edinburgh is known as a cultural centre providing a  high quality of life. <br /><br />Further details of the RA post, including how to apply, are <a href=\"https://www.vacancies.ed.ac.uk/pls/corehrrecruit/erq_jobspec_version_4.jobspec?p_id=013243\">here</a>." nil nil "8ffc40155bb811aa4741bb9a609cdd66") (3 (20928 8813 490200) "http://www.xoltar.org/?p=127" "Bryn Keller: Hot Towel SPA Is a Great Starter" nil "Thu, 16 May 2013 10:30:00 +0000" "<p>A few months ago, <a href=\"http://www.johnpapa.net/\">John Papa</a> released a Visual Studio template called <a href=\"http://www.johnpapa.net/hottowel/\">Hot Towel SPA</a>, which <a href=\"http://www.hanselman.com/\">Scott Hanselman</a> kindly pointed out to me. SPA, as all the hip kids will tell you, stands for Single Page Application. That is, the kind of application that you start by visiting a web page, and you stay on that same page for as long as you use the application. As opposed to most web applications, where you skip from page to page as you interact with the site.</p>
<p>People have been doing this for a long time, of course,  but the Hot Towel SPA starter really is a nice introduction to the style. In a SPA, you really  need to think of the browser as “the client,” a standalone entity that communicates with your server via (web) API calls. Once you get used to it, it’s really rather refreshing, and it allows you to take advantage of all the computing power on the client machine in a way that can be quite liberating.</p>
<p>Hot Towel uses a JavaScript application framework called <a href=\"http://durandaljs.com/\">Durandal</a> to structure the client side code. It divides the world up into services (JavaScript modules, basically), views, and view models. All of this is just for the JavaScript side of things, remember – you may also have views and view models and so on on the server side, but that’s a different thing – you’ll interact with those via AJAX calls, usually using JSON to encode the data.</p>
<p>Hot Towel uses HTML for the views and lets <a href=\"http://knockoutjs.com/\">Knockout</a> do the view composition and data binding, which makes it a good source of examples for learning Knockout as well.</p>
<p>The JavaScript code is nicely modular, in the style of <a href=\"http://requirejs.org/\">require.js</a>. If you’ve not seen this style, it’s worth checking out. Basically, you declare all your dependencies for your JavaScript module, and the framework asynchronously loads them as necessary, as passes them to your module. It’s great documentation, great for structuring the code so you don’t get circular dependencies, and makes for easier unit testing too, since can easily supply alternative (mock) implementations of your module’s dependencies.</p>
<p>On the server, the MVC code is well organized as well, and it’s straightforward to plug in your new Web API controllers and start coding.</p>
<p>I’ve been playing with this starter for a while, working on a proof of concept for a new series of articles on my blog. I found Hot Towel to be a great starting point, and it opened my eyes to some interesting new techniques on the client side. Give Hot Towel a try for your next project, it’ll be fun.</p>" nil nil "f3d151c9ffc9063e843c6f9345fbd382") (2 (20928 8813 489626) "http://wadler.blogspot.com/2013/05/aleph-cloud.html" "Philip Wadler: Aleph Cloud" "noreply@blogger.com (Philip Wadler)" "Thu, 16 May 2013 09:36:14 +0000" "<div style=\"clear: both; text-align: center;\" class=\"separator\"><a style=\"margin-left: 1em; margin-right: 1em;\" href=\"http://1.bp.blogspot.com/-5PEq8CrNw1I/UZSm9ZuKzXI/AAAAAAAABhw/F82qIaaKv0g/s1600/aleph-cloud-logo.png\"><img src=\"http://1.bp.blogspot.com/-5PEq8CrNw1I/UZSm9ZuKzXI/AAAAAAAABhw/F82qIaaKv0g/s320/aleph-cloud-logo.png\" height=\"78\" border=\"0\" width=\"320\" /></a></div><br /><div style=\"clear: both; text-align: center;\" class=\"separator\"></div><a href=\"http://www.alephcloud.com/\">Aleph Cloud</a> is looking to <a href=\"http://homepages.inf.ed.ac.uk/wadler/documents/AlephCloud_Haskell_Engineer_JD_final.pdf\">hire Haskell programmers</a>." nil nil "979c9618d41475805da13a76334fa959") (1 (20928 8813 489184) "http://snapframework.com/blog/2013/05/15/snap-0.12-released" "Snap Framework: Announcing: Snap Framework v0.12" "mightybyte@gmail.com (Doug Beardsley)" "Thu, 16 May 2013 00:15:00 +0000" "<div class=\"markdown\">
<p>The Snap team is happy to announce the release of version 0.12 of the Snap Framework.</p><h2 id=\"new-features\">New features</h2><ul><li><p>Heist now has the ability to reload templates. Along with this, <code>HeistConfig</code> now stores template locations instead of templates. A template location is essentially an IO action returning templates. This allows you to have Heist get its templates from a database, over the network, etc–anything that can be done from IO.</p></li><li><p>The Heist snaplet now has generic functions that can work with either interpreted or compiled templates. Most applications will choose one of either interpreted or compiled templates and not need this new functionality. However, if you are writing a generic snaplet, then you probably want it to work no matter which mode the end application uses. All you need to do is import the <code>Snap.Snaplet.Heist.Generic</code> module. The Heist snaplet defaults to compiled mode. If you want to use interpreted mode, call the <code>setInterpreted</code> function in your application initializer.</p></li><li><p>It is now possible to reload individual snaplets without reloading the whole site. The snaplet API now includes a function <code>modifyMaster</code> that you can use to write reload functions for individual snaplets. The Heist snaplet now provides a reloader leveraging this functionality. We found this very useful in allowing us to rapidly iterate when making changes to markup in large applications that take a long time to initialize.</p></li></ul><h2 id=\"bugfixes-minor-improvements\">Bugfixes / minor improvements</h2><ul><li><p>Generalized parts of the compiled splice API to use <code>RuntimeSplice n a</code> instead of the less general <code>n a</code>. Since RuntimeSplice is a monad transformer, this change only requires you to add a call to <code>lift</code> in places where you have an <code>n a</code>.</p></li><li><p>Fixed Heist’s <code>runAttributesRaw</code> function to do both types of attribute parsing.</p></li><li><p>Fixed Heist bug that caused XML templates to be rendered as HTML5.</p></li><li><p>Improve the consistency of the auth snaplet API.</p></li><li><p>Eliminated the inappropriate export of orphan instances.</p></li></ul>
</div>" nil nil "3ff86b164d5fb245760f98f326724895")))